
@article{garivier20non,
  author = {Garivier, Aur{\'{e}}lien and Kaufmann, Emilie},
  journal = {Submitted to the Annals of Statistics},
  mendeley-groups = {simpleregret},
  title = {{Non-Asymptotic Sequential Tests for Overlapping Hypotheses and application to near optimal arm identification in bandit models}},
  url = {https://lilloa.univ-lille.fr/bitstream/handle/20.500.12210/22482/https:/hal.archives-ouvertes.fr/hal-02123833/document?sequence=1},
  year = {2020}
}

@inproceedings{katzsamuels20true,
  author = {Katz-Samuels, Julian and Jamieson, Kevin},
  booktitle = {Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)},
  mendeley-groups = {prps-20career},
  pages = {1781--1791},
  title = {{The true sample complexity of identifying good arms}},
  year = {2020}
}


@article{bartlett05local,
  abstract = {We propose new bounds on the error of learning algorithms in terms of a data-dependent notion of complexity. The estimates we establish give optimal rates and are based on a local and empirical version of Rademacher averages, in the sense that the Rademacher averages are computed from the data, on a subset of functions with small empirical error. We present some applications to classification and prediction with convex function classes, and with kernel classes in particular.},
  author = {Bartlett, Peter L. and Bousquet, Olivier and Mendelson, Shahar},
  journal = {Annals of Statistics},
  mendeley-groups = {radeemacher},
  title = {{Local rademacher complexities}},
  year = {2005}
}


@article{agarwal12information,
  author = {Agarwal, Alekh and Bartlett, Peter L and Ravikumar, Pradeep and Wainwright, Martin J},
  journal = {IEEE Transactions on Information Theory},
  mendeley-groups = {advmab},
  number = {5},
  pages = {3235},
  title = {{Information-Theoretic Lower Bounds on the Oracle Complexity of Stochastic Convex Optimization}},
  volume = {58},
  year = {2012}
}

@inproceedings{mcmahan14unconstrained,
author = {McMahan, HB and Orabona, F},
booktitle = {Proceedings of The Conference on Learning Theory (COLT)},
pages = {1020--1039},
title = {{Unconstrained Online Linear Learning in Hilbert Spaces: Minimax Algorithms and Normal Approximations}},
volume = {35},
year = {2014}
}
@inproceedings{wang13active,
author = {Wang, Xuezhi and Garnett, Roman and Schneider, Jeff},
booktitle = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)},
pages = {731--738},
title = {{Active Search on Graphs}},
year = {2013}
}
@article{freund97using,
author = {Freund, Yoav and Schapire, Robert E and Singer, Yoram and Warmuth, Manfred K},
doi = {10.1145/258533.258616},
isbn = {0897918886},
issn = {07349025},
journal = {Proceedings of the ACM symposium on Theory of computing (STOC)},
number = {3},
pages = {334--343},
title = {{Using and combining predictors that specialize}},
volume = {37},
year = {1997}
}
@incollection{jamieson15next,
author = {Jamieson, Kevin G and Jain, Lalit and Fernandez, Chris and Glattard, Nicholas J and Nowak, Rob},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
pages = {2638--2646},
title = {{NEXT: A System for Real-World Development, Evaluation, and Application of Active Learning}},
year = {2015}
}
@article{li10acontextual,
author = {Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E.},
journal = {Proceedings of the International Conference on World Wide Web (WWW)},
pages = {661--670},
title = {{A Contextual-Bandit Approach to Personalized News Article Recommendation}},
year = {2010}
}
@book{stewart90matrix,
author = {Stewart, G. W. and guang Sun, Ji},
publisher = {Academic Press},
title = {{Matrix Perturbation Theory}},
year = {1990}
}
@article{russo14learning,
author = {Russo, Daniel and Roy, Benjamin Van},
journal = {Mathematics of Operations Research},
number = {4},
pages = {1221--1243},
title = {{Learning to Optimize via Posterior Sampling}},
volume = {39},
year = {2014}
}
@inproceedings{walsh09exploring,
author = {Walsh, Thomas J and Szita, Istv{\'{a}}n and Diuk, Carlos and Littman, Michael L},
booktitle = {Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI)},
pages = {591--598},
title = {{Exploring compact reinforcement-learning representations with linear regression}},
year = {2009}
}
@book{mccullagh89generalized,
address = {London},
author = {McCullagh, P and Nelder, J A},
keywords = {generalized glm linear models statistics},
title = {{Generalized Linear Models}},
year = {1989}
}
@inproceedings{gabillon12aunified,
author = {Gabillon, Victor and Ghavamzadeh, Mohammad and Lazaric, Alessandro},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
pages = {3221--3229},
title = {{Best Arm Identification: A Unified Approach to Fixed Budget and Fixed Confidence}},
year = {2012}
}
@article{jegou10improving,
author = {J{\'{e}}gou, Herv{\'{e}} and Douze, Matthijs and Schmid, Cordelia},
journal = {International Journal of Computer Vision},
keywords = {Image retrieval,Image search,Nearest neighbor search,Object recognition},
number = {3},
pages = {316--336},
title = {{Improving Bag-of-Features for Large Scale Image Search}},
volume = {87},
year = {2010}
}
@article{gentile14onmultilabel,
author = {Gentile, Claudio and Orabona, Francesco},
journal = {Journal of Machine Learning Research},
pages = {2451--2487},
title = {{On Multilabel Classification and Ranking with Bandit Feedback}},
volume = {15},
year = {2014}
}
@phdthesis{kaly11thesis,
author = {Kalyanakrishnan, Shivaram},
school = {Department of Computer Science, The University of Texas at Austin},
title = {{Learning Methods for Sequential Decision Makingwith Imperfect Representations}},
year = {2011}
}
@inproceedings{karnin13almost,
author = {Karnin, Zohar and Koren, Tomer and Somekh, Oren},
booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
pages = {1238--1246},
title = {{Almost Optimal Exploration in Multi-Armed Bandits}},
year = {2013}
}
@article{hazan07logarithmic,
author = {Hazan, Elad and Agarwal, Amit and Kale, Satyen},
journal = {Mach. Learn.},
number = {2-3},
pages = {169--192},
title = {{Logarithmic Regret Algorithms for Online Convex Optimization}},
volume = {69},
year = {2007}
}
@article{Vovk1999,
author = {Vovk, V.},
doi = {10.1023/A:1007595032382},
isbn = {0897918916},
issn = {08856125},
journal = {Machine Learning},
keywords = {on-line learning,prediction with expert advice,regression,tracking the best expert},
number = {3},
pages = {247--282},
title = {{Derandomizing stochastic prediction strategies}},
volume = {35},
year = {1999}
}
@article{indyk12approximate,
author = {Har-Peled, Sariel and Indyk, Piotr and Motwani, Rajeev},
journal = {Theory of Computing},
pages = {321--350},
title = {{Approximate nearest neighbor: towards removing the curse of dimensionality}},
volume = {8},
year = {2012}
}
@incollection{jun17scalable,
author = {Jun, Kwang-Sung and Bhargava, Aniruddha and Nowak, Robert and Willett, Rebecca},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
pages = {99--109},
title = {{Scalable Generalized Linear Bandits: Online Computation and Hashing}},
year = {2017}
}
@inproceedings{gentile17oncontext,
author = {Gentile, Claudio and Li, Shuai and Kar, Purushottam and Karatzoglou, Alexandros and Zappella, Giovanni and Etrue, Evans},
booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
pages = {1253--1262},
title = {{On Context-Dependent Clustering of Bandits}},
volume = {70},
year = {2017}
}
@inproceedings{agarwal17corralling,
author = {Agarwal, Alekh and Luo, Haipeng and Neyshabur, Behnam and Schapire, Robert E},
booktitle = {Proceedings of the Conference on Learning Theory (COLT)},
pages = {12--38},
title = {{Corralling a Band of Bandit Algorithms}},
volume = {65},
year = {2017}
}
@inproceedings{gadde15aprobabilistic,
abstract = {We give a probabilistic interpretation of sampling theory of graph signals. To do this, we first define a generative model for the data using a pairwise Gaussian random field (GRF) which depends on the graph. We show that, under certain conditions, reconstructing a graph signal from a subset of its samples by least squares is equivalent to performing MAP inference on an approximation of this GRF which has a low rank covariance matrix. We then show that a sampling set of given size with the largest associated cut-off frequency, which is optimal from a sampling theoretic point of view, minimizes the worst case predictive covariance of the MAP estimate on the GRF. This interpretation also gives an intuitive explanation for the superior performance of the sampling theoretic approach to active semi-supervised classification.},
archivePrefix = {arXiv},
arxivId = {1503.06629},
author = {Gadde, Akshay and Ortega, Antonio},
booktitle = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
doi = {10.1109/ICASSP.2015.7178573},
eprint = {1503.06629},
isbn = {9781467369978},
issn = {15206149},
keywords = {Active learning,Gaussian Markov random field,Graph Signal Processing,Sampling theorem,Semi-supervised learning},
pages = {3257--3261},
title = {{A probabilistic interpretation of sampling theory of graph signals}},
volume = {2015-Augus},
year = {2015}
}
@incollection{gong12angular,
author = {Gong, Yunchao and Kumar, Sanjiv and Verma, Vishal and Lazebnik, Svetlana},
booktitle = {Advances in Neural Information Processing Systems 25},
editor = {Pereira, F and Burges, C J C and Bottou, L and Weinberger, K Q},
pages = {1196--1204},
publisher = {Curran Associates, Inc.},
title = {{Angular Quantization-based Binary Codes for Fast Similarity Search}},
year = {2012}
}
@inproceedings{ji12avariance,
author = {Ji, Ming and Han, Jiawei},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)},
pages = {556--564},
title = {{A Variance Minimization Criterion to Active Learning on Graphs}},
url = {http://jmlr.csail.mit.edu/proceedings/papers/v22/ji12.html},
year = {2012}
}
@inproceedings{chu11contextual,
author = {Chu, Wei and Li, Lihong and Reyzin, Lev and Schapire, Robert E},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)},
pages = {208--214},
title = {{Contextual Bandits with Linear Payoff Functions.}},
volume = {15},
year = {2011}
}
@article{Engineering2012,
author = {Engineering, Electronic and Szepesv, U K Csaba and Science, Computing},
number = {2001},
title = {{Shifting Regret , Mirror Descent , and Matrices}},
year = {2012}
}
@article{gyorgy07theonline,
author = {Gy{\"{o}}rgy, Andr{\'{a}}s and Linder, Tam{\'{a}}s and Lugosi, G{\'{a}}bor and Ottucs{\'{a}}k, Gy{\"{o}}rgy},
journal = {Journal of Machine Learning Research},
pages = {2369--2403},
title = {{The On-Line Shortest Path Problem Under Partial Monitoring.}},
volume = {8},
year = {2007}
}
@article{audibert14regret,
author = {Audibert, Jean-Yves and Bubeck, S{\'{e}}bastien and Lugosi, G{\'{a}}bor},
journal = {Mathematics of Operations Research},
number = {1},
pages = {31--45},
title = {{Regret in Online Combinatorial Optimization}},
volume = {39},
year = {2014}
}
@inproceedings{ay12online,
author = {Abbasi-Yadkori, Yasin and Pal, David and Szepesvari, Csaba},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)},
title = {{Online-to-Confidence-Set Conversions and Application to Sparse Stochastic Bandits}},
year = {2012}
}
@inproceedings{yang07bayesian,
author = {Yang, Liu and Jin, Rong and Sukthankar, Rahul},
booktitle = {Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI)},
editor = {Parr, Ronald and van der Gaag, Linda C},
isbn = {0-9749039-3-0},
keywords = {dblp},
pages = {442--449},
publisher = {AUAI Press},
title = {{Bayesian Active Distance Metric Learning.}},
url = {http://dblp.uni-trier.de/db/conf/uai/uai2007.html{\#}YangJS07},
year = {2007}
}
@incollection{kawale15efficient,
author = {Kawale, Jaya and Bui, Hung H and Kveton, Branislav and Tran-Thanh, Long and Chawla, Sanjay},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
pages = {1297--1305},
title = {{Efficient Thompson Sampling for Online Matrix-Factorization Recommendation}},
year = {2015}
}
@article{he11avariance,
abstract = {In many information processing tasks, one is often confronted with very high dimensional data. Feature selection techniques are designed to find the meaningful feature subset of the original features which can facilitate clustering, classification and retrieval. In this paper, we consider the feature selection problem in unsupervised learning scenarios, which is particularly difficult due to the absence of class labels that would guide the search for relevant information. Based on Laplacian regularized least squares which finds a smooth function on the data manifold and minimizes the empirical loss, we propose two novel feature selection algorithms which aim to minimize the expected prediction error of the regularized regression model. Specifically, we select those features such that the size of the parameter covariance matrix of the regularized regression model is minimized. Motivated from experimental design, we use trace and determinant operators to measure the size of the covariance matrix. Efficient computational schemes are also introduced to solve the corresponding optimization problems. Extensive experimental results over various real-life data sets have demonstrated the superiority of the proposed algorithms.},
author = {He, Xiaofei and Ji, Ming and Zhang, Chiyuan and Bao, Hujun},
doi = {10.1109/TPAMI.2011.44},
isbn = {1939-3539 (Electronic)$\backslash$r0098-5589 (Linking)},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Feature selection,clustering.,dimensionality reduction,manifold,regression,regularization},
number = {10},
pages = {2013--2025},
pmid = {21383399},
title = {{A variance minimization criterion to feature selection using laplacian regularization}},
volume = {33},
year = {2011}
}
@article{kveton17stochastic_arxiv,
author = {Kveton, Branislav and Szepesv{\'{a}}ri, Csaba and Rao, Anup and Wen, Zheng and Abbasi-Yadkori, Yasin and Muthukrishnan, S},
journal = {CoRR},
title = {{Stochastic Low-Rank Bandits}},
volume = {abs/1712.0},
year = {2017}
}
@inproceedings{walsh09exploring,
archivePrefix = {arXiv},
arxivId = {1205.2606},
author = {Thomas, Walsh J and IstWalsh, Thomas J and Diuk, Carlos and Littman, Michael L},
booktitle = {Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI)},
eprint = {1205.2606},
isbn = {978-0-9749039-5-8},
pages = {591--598},
title = {{Exploring compact reinforcement-learning representations with linear regression}},
year = {2009}
}
@article{yue12hierarchical,
author = {Yue, Yisong and Hong, Sue Ann Sa and Guestrin, Carlos},
journal = {Proceedings of the International Conference on Machine Learning (ICML)},
pages = {1895--1902},
title = {{Hierarchical exploration for accelerating contextual bandits}},
year = {2012}
}
@incollection{allenberg06hannan,
author = {Allenberg, Chamy and Auer, Peter and Gy{\"{o}}rfi, L{\'{a}}szl{\'{o}} and Ottucs{\'{a}}k, Gy{\"{o}}rgy},
booktitle = {Algorithmic Learning Theory (ALT)},
pages = {229--243},
title = {{Hannan Consistency in On-Line Learning in Case of Unbounded Losses Under Partial Monitoring}},
year = {2006}
}
@unpublished{lattimore18bandit,
author = {Lattimore, Tor and Szepesv$\backslash$'ari, Csaba},
title = {{Bandit Algorithms}},
url = {http://downloads.tor-lattimore.com/book.pdf},
year = {2018}
}
@article{adamskiy16acloser,
author = {Adamskiy, Dmitry and Koolen, Wouter M. and Chernov, Alexey and Vovk, Vladimir},
isbn = {9781921915697},
issn = {15414302},
journal = {Journal of Machine Learning Research},
keywords = {adaptive regret,fixed share,online learning,specialist experts},
number = {1},
pages = {1--21},
title = {{A Closer Look at Adaptive Regret}},
volume = {17},
year = {2016}
}
@article{blum97empirical,
author = {Blum, Avrim},
journal = {Machine Learning},
number = {1},
pages = {5--23},
title = {{Empirical Support for Winnow and Weighted-Majority Algorithms: Results on a Calendar Scheduling Domain}},
volume = {26},
year = {1997}
}
@inproceedings{konyushkova13content,
author = {Konyushkova, Ksenia and Glowacka, Dorota},
booktitle = {21st European Symposium on Artificial Neural Networks},
title = {{Content-based image retrieval with hierarchical Gaussian Process bandits with self-organizing maps}},
year = {2013}
}
@article{weinberger02ondelayed,
author = {Weinberger, Marcelo J and Ordentlich, Erik},
journal = {IEEE Transactions on Information Theory},
number = {7},
pages = {1959--1976},
title = {{On delayed prediction of individual sequences.}},
volume = {48},
year = {2002}
}
@inproceedings{ma15active,
author = {Ma, Yifei and Huang, Tzu-Kuo and Schneider, Jeff G},
booktitle = {Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI)},
editor = {Meila, Marina and Heskes, Tom},
isbn = {978-0-9966431-0-8},
pages = {542--551},
publisher = {AUAI Press},
title = {{Active Search and Bandits on Graphs using Sigma-Optimality.}},
url = {http://dblp.uni-trier.de/db/conf/uai/uai2015.html{\#}MaHS15},
year = {2015}
}
@article{anantharam87asymptotically,
author = {Anantharam, V and Varaiya, P and Walrand, J},
journal = {Automatic Control, IEEE Transactions on},
number = {11},
pages = {968--976},
title = {{Asymptotically efficient allocation rules for the multiarmed bandit problem with multiple plays-Part I: I.I.D. rewards}},
volume = {32},
year = {1987}
}
@article{daniely15strongly,
author = {Daniely, Amit and Gonen, Alon and Shalev-Shwartz, Shai},
journal = {Proceedings of the International Conference on Machine Learning (ICML)},
pages = {1--18},
title = {{Strongly Adaptive Online Learning}},
year = {2015}
}
@inproceedings{jain10hashing,
author = {Jain, Prateek and Vijayanarasimhan, Sudheendra and Grauman, Kristen},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
pages = {928--936},
title = {{Hashing Hyperplane Queries to Near Points with Applications to Large-Scale Active Learning}},
year = {2010}
}
@inproceedings{kulis09fast,
abstract = {We introduce a method that enables scalable similarity search for learned metrics. Given pairwise similarity and dissimilarity constraints between some examples, we learn a Mahalanobis distance function that captures the examples' underlying relationships well. To allow sublinear time similarity search under the learned metric, we show how to encode the learned metric parameterization into randomized locality-sensitive hash functions. We further formulate an indirect solution that enables metric learning and hashing for vector spaces whose high dimensionality makes it infeasible to learn an explicit transformation over the feature dimensions. We demonstrate the approach applied to a variety of image data sets, as well as a systems data set. The learned metrics improve accuracy relative to commonly used metric baselines, while our hashing construction enables efficient indexing with learned distances and very large databases.},
author = {Kulis, Brian and Jain, Prateek and Grauman, Kristen},
booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
doi = {10.1109/TPAMI.2009.151},
isbn = {9781424422432},
issn = {01628828},
keywords = {Image search,Kernel learning,Locality-sensitive hashing,LogDet divergence,Metric learning,Similarity search},
number = {12},
pages = {2143--2157},
pmid = {19834137},
title = {{Fast similarity search for learned metrics}},
volume = {31},
year = {2009}
}
@article{hao13limited,
author = {Hao, Linhui and He, Quiling and Wang, Zhishi and Craven, Mark and Newton, Michael A and Ahlquist, Paul},
editor = {Rao, Christopher V},
journal = {PLoS Computational Biology},
number = {9},
pages = {e1003235},
publisher = {Public Library of Science},
title = {{Limited Agreement of Independent RNAi Screens for Virus-Required Host Genes Owes More to False-Negative than False-Positive Factors}},
volume = {9},
year = {2013}
}
@article{burtini2015asurvey,
archivePrefix = {arXiv},
arxivId = {1510.00757},
author = {Burtini, Giuseppe and Loeppky, Jason and Lawrence, Ramon},
eprint = {1510.00757},
journal = {arXiv:1609.00845},
title = {{A Survey of Online Experiment Design with the Stochastic Multi-Armed Bandit}},
year = {2015}
}
@inproceedings{bresler16collaborative,
author = {Bresler, Guy and Shah, Devavrat and Voloch, Luis Filipe},
booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Science},
pages = {207--220},
title = {{Collaborative Filtering with Low Regret}},
year = {2016}
}
@inproceedings{orabona16coin,
author = {Orabona, Francesco and Pal, David},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
pages = {577--585},
title = {{Coin Betting and Parameter-Free Online Learning}},
year = {2016}
}
@inproceedings{zhu03combining,
abstract = {Active and semi-supervised learning are important techniques when labeled data are scarce. We combine the two under a Gaussian random field model. Labeled and unlabeled data are represented as vertices in a weighted graph, with edge weights encoding the similarity between instances. The semi-supervised learning problem is then formulated in terms of a Gaussian random field on this graph, the mean of which is characterized in terms of harmonic functions. Active learning is performed on top of the semisupervised learning scheme by greedily selecting queries from the unlabeled data to minimize the estimated expected classification error (risk); in the case of Gaussian fields the risk is efficiently computed using matrix methods. We present experimental results on synthetic data, handwritten digit recognition, and text classification tasks. The active learning scheme requires a much smaller number of queries to achieve high accuracy compared with random query selection. 1.},
author = {Zhu, Xiaojin and Lafferty, John and Ghahramani, Zoubin},
booktitle = {ICML workshop on The Continuum from Labeled to Unlabeled Data in Machine Learning and Data Mining},
isbn = {1-57735-189-4},
pages = {58--65},
title = {{Combining Active Learning and Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions}},
year = {2003}
}
@article{even-dar06action,
author = {Even-Dar, Eyal and Mannor, Shie and Mansour, Yishay},
journal = {Journal of Machine Learning Research},
pages = {1079--1105},
title = {{Action Elimination and Stopping Conditions for the Multi-Armed Bandit and Reinforcement Learning Problems}},
volume = {7},
year = {2006}
}
@inproceedings{jamieson14lil,
author = {Jamieson, Kevin and Malloy, Matthew and Nowak, Robert and Bubeck, S{\'{e}}bastien},
booktitle = {Proceedings of the Conference on Learning Theory (COLT)},
pages = {423--439},
title = {{lil' UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits}},
year = {2014}
}
@article{hazan09efficient,
abstract = {We study online learning in an oblivious changing environment. The standard measure of regret bounds the difference between the cost of the online learner and the best decision in hindsight. Hence, regret minimizing algorithms tend to converge to the static best optimum, clearly a suboptimal behavior in changing environments. On the other hand, various metrics proposed to strengthen regret and allow for more dynamic algorithms produce inefficient algorithms. We propose a different performance met- ric which strengthens the standard met- ric of regret and measures performance with respect to a changing compara- tor. We then describe a series of data- streaming-based reductions which trans- form algorithms for minimizing (standard) regret into adaptive algorithms albeit incurring only poly-logarithmic computational overhead. Using this reduction, we obtain efficient low adaptive-regret algorithms for the problem of online convex optimization. This can be applied to various learning scenarios, i.e. online portfolio selection, for which we describe experimental results showing the advantage of adaptivity.},
author = {Hazan, Elad and Seshadri, C.},
doi = {10.1145/1553374.1553425},
isbn = {9781605585161},
journal = {Proceedings of the International Conference on Machine Learning (ICML)},
title = {{Efficient learning algorithms for changing environments}},
year = {2009}
}
@inproceedings{hofmann11contextual,
author = {Hofmann, Katja and Whiteson, Shimon and de Rijke, Maarten},
booktitle = {NIPS 2011: Proceedings of the Conference on Neural Information Processing Systems, Workshop on Bayesian Optimization, Experimental Design and Bandits: Theory and Applications},
month = {dec},
title = {{Contextual Bandits for Information Retrieval}},
year = {2011}
}
@inproceedings{maron94hoeffding,
address = {340 Pine Street, 6th Fl., San Francisco, CA 94104},
author = {{Oded Maron}, Andrew Moore},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
editor = {{Jack D. Cowan}, G Tesauro {\&} J Alspector},
month = {apr},
pages = {59--66},
publisher = {Morgan Kaufmann},
title = {{Hoeffding Races: Accelerating Model Selection Search for Classification and Function Approximation}},
year = {1994}
}
@article{hazan16oco,
author = {Hazan, Elad},
journal = {Foundations and Trends{\textregistered} in Optimization},
number = {3-4},
pages = {157--325},
publisher = {Now Publishers, Inc.},
title = {{Introduction to online convex optimization}},
volume = {2},
year = {2016}
}
@article{maron97theracing,
author = {Maron, Oded and Moore, Andrew W},
journal = {Artificial Intelligence Review},
pages = {193--225},
title = {{The Racing Algorithm: Model Selection for Lazy Learners}},
volume = {11},
year = {1997}
}
@inproceedings{cover65behaviour,
author = {Cover, Thomas M},
booktitle = {Transactions of the 4th Prague Conf. Inform. Thoery, Statistical Decision Functions, Random Processes},
title = {{Behaviour of sequential predictors of binary sequences}},
year = {1965}
}
@inproceedings{karnin13almost,
author = {Karnin, Zohar Shay and Koren, Tomer and Somekh, Oren},
booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
pages = {1238--1246},
title = {{Almost Optimal Exploration in Multi-Armed Bandits.}},
year = {2013}
}
@inproceedings{datar04locality,
author = {Datar, Mayur and Immorlica, Nicole and Indyk, Piotr and Mirrokni, Vahab S},
booktitle = {Proceedings of the Twentieth Annual Symposium on Computational Geometry},
pages = {253--262},
title = {{Locality-sensitive Hashing Scheme Based on P-stable Distributions}},
year = {2004}
}
@article{recht10guaranteed,
author = {Recht, Benjamin and Fazel, Maryam and Parrilo, Pablo A},
journal = {SIAM Rev.},
keywords = {compressed sensing,convex optimization,matrix norms,random matrices,rank,semidefinite programming},
number = {3},
pages = {471--501},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Guaranteed Minimum-Rank Solutions of Linear Matrix Equations via Nuclear Norm Minimization}},
volume = {52},
year = {2010}
}
@article{hao08drosophila,
author = {Hao, Linhui and Sakurai, Akira and Watanabe, Tokiko and Sorensen, Ericka and Nidom, Chairul A and Newton, Michael A and Ahlquist, Paul and Kawaoka, Yoshihiro},
journal = {Nature},
number = {7206},
pages = {890--893},
publisher = {Nature Publishing Group},
title = {{Drosophila RNAi screen identifies host genes important for influenza virus replication}},
volume = {454},
year = {2008}
}
@article{herbster98tracking,
author = {Herbster, Mark and Warmuth, Manfred K},
journal = {Mach. Learn.},
number = {2},
pages = {151--178},
title = {{Tracking the Best Expert}},
volume = {32},
year = {1998}
}
@article{hoeffding63probability,
author = {Hoeffding, Wassily},
journal = {Journal of the American Statistical Association},
month = {mar},
number = {301},
pages = {13--30},
title = {{Probability Inequalities for Sums of Bounded Random Variables}},
volume = {58},
year = {1963}
}
@article{johnson16structured,
archivePrefix = {arXiv},
arxivId = {stat.ML/1606.05693},
author = {Johnson, N and Sivakumar, V and Banerjee, A},
eprint = {1606.05693},
journal = {ArXiv e-prints},
primaryClass = {stat.ML},
title = {{Structured Stochastic Linear Bandits}},
year = {2016}
}
@inproceedings{chapelle12open,
author = {Chapelle, Olivier and Li, Lihong},
booktitle = {Proceedings of the Conference on Learning Theory (COLT)},
title = {{Open Problem: Regret Bounds for Thompson Sampling}},
year = {2012}
}
@inproceedings{bresler16collaborative,
author = {Bresler, Guy and Shah, Devavrat and Voloch, Luis Filipe},
booktitle = {Proceedings of the ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Science},
pages = {207--220},
title = {{Collaborative Filtering with Low Regret}},
year = {2016}
}
@article{yang06distance,
author = {Yang, Liu and Jin, Rong},
journal = {Michigan State Universiy},
keywords = {distance final learning metric survey thema:Distan},
title = {{Distance metric learning: A comprehensive survey}},
volume = {2},
year = {2006}
}
@inproceedings{kaly10efficient,
author = {Kalyanakrishnan, Shivaram and Stone, Peter},
booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
pages = {511--518},
title = {{Efficient Selection of Multiple Bandit Arms: Theory and Practice}},
year = {2010}
}
@inproceedings{jiang17contextual,
author = {Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John and Schapire, Robert E},
booktitle = {ICML},
pages = {1704--1713},
title = {{Contextual Decision Processes with low Bellman rank are PAC-Learnable}},
volume = {70},
year = {2017}
}
@article{crammer13multiclass,
author = {Crammer, Koby and Gentile, Claudio},
journal = {Mach. Learn.},
number = {3},
pages = {347--383},
title = {{Multiclass Classification with Bandit Feedback Using Adaptive Regularization}},
volume = {90},
year = {2013}
}
@article{wang14hashing,
author = {Wang, Jingdong and Shen, Heng Tao and Song, Jingkuan and Ji, Jianqiu},
journal = {CoRR},
title = {{Hashing for Similarity Search: A Survey}},
volume = {abs/1408.2},
year = {2014}
}
@inproceedings{even-dar02pac,
author = {Even-dar, Eyal and Mannor, Shie and Mansour, Yishay},
booktitle = {Proceedings of the Conference on Learning Theory (COLT)},
pages = {255--270},
title = {{PAC bounds for multi-armed bandit and Markov decision processes}},
year = {2002}
}
@inproceedings{yue12thekarmed,
author = {Yue, Yisong and Broder, Josef and Kleinberg, Robert and Joachims, Thorsten},
booktitle = {Journal of Computer and System Sciences},
title = {{The K-armed dueling bandits problem}},
year = {2012}
}
@techreport{zhu05semi,
author = {Zhu, Xiaojin},
institution = {Computer Sciences, University of Wisconsin-Madison},
keywords = {SemiSupervised classification learning survey},
number = {1530},
title = {{Semi-Supervised Learning Literature Survey}},
year = {2005}
}
@article{orabona16from,
author = {Orabona, Francesco and P{\'{a}}l, D{\'{a}}vid},
journal = {CoRR},
title = {{From Coin Betting to Parameter-Free Online Learning}},
volume = {abs/1602.0},
year = {2016}
}
@inproceedings{niculescu-mizil09multi,
author = {Niculescu-Mizil, Alexandru},
booktitle = {COLT'09 Workshop on On-line Learning with Limited Feedback},
title = {{Multi-Armed Bandits with Betting}},
year = {2009}
}
@inproceedings{khanna17scalable,
author = {Khanna, Rajiv and Elenberg, Ethan and Dimakis, Alex and Negahban, Sahand and Ghosh, Joydeep},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)},
pages = {1560--1568},
title = {{Scalable Greedy Feature Selection via Weak Submodularity}},
volume = {54},
year = {2017}
}
@article{neyshabur15on,
abstract = {We consider the problem of designing locality sensitive hashes (LSH) for inner product similarity, and of the power of asymmetric hashes in this context. Shrivastava and Li argue that there is no symmetric LSH for the problem and propose an asymmetric LSH based on different mappings for query and database points. However, we show there does exist a simple symmetric LSH that enjoys stronger guarantees and better empirical performance than the asymmetric LSH they suggest. We also show a variant of the settings where asymmetry is in-fact needed, but there a different asymmetric LSH is required.},
archivePrefix = {arXiv},
arxivId = {1410.5518},
author = {Neyshabur, Behnam and Srebro, Nathan},
eprint = {1410.5518},
isbn = {9781510810587},
journal = {Proceedings of the International Conference on Machine Learning (ICML)},
pages = {1926--1934},
title = {{On Symmetric and Asymmetric LSHs for Inner Product Search}},
url = {http://jmlr.org/proceedings/papers/v37/neyshabur15.html},
volume = {37},
year = {2015}
}
@inproceedings{li12anunbiased,
author = {Li, Lihong and Chu, Wei and Langford, John and Moon, Taesup and Wang, Xuanhui},
booktitle = {Proceedings of the Workshop on On-line Trading of Exploration and Exploitation 2},
pages = {19--36},
title = {{An Unbiased Offline Evaluation of Contextual Bandit Algorithms with Generalized Linear Models}},
volume = {26},
year = {2012}
}
@inproceedings{wei18more,
archivePrefix = {arXiv},
arxivId = {1801.03265},
author = {Wei, Chen-Yu and Luo, Haipeng},
booktitle = {Proceedings of the Conference on Learning Theory (COLT)},
eprint = {1801.03265},
pages = {1263--1291},
title = {{More Adaptive Algorithms for Adversarial Bandits}},
url = {http://arxiv.org/abs/1801.03265},
year = {2018}
}
@inproceedings{agrawal13thompson,
author = {Agrawal, Shipra and Goyal, Navin},
booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
pages = {127--135},
title = {{Thompson Sampling for Contextual Bandits with Linear Payoffs}},
year = {2013}
}
@article{patel15visual,
author = {Patel, Vishal M and Gopalan, Raghuraman and Li, Ruonan and Chellappa, Rama},
journal = {IEEE Signal Process. Mag.},
number = {3},
pages = {53--69},
title = {{Visual Domain Adaptation: A survey of recent advances}},
volume = {32},
year = {2015}
}
@incollection{hillel13distributed,
author = {Hillel, Eshcar and Karnin, Zohar S and Koren, Tomer and Lempel, Ronny and Somekh, Oren},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
editor = {Burges, C J C and Bottou, L and Welling, M and Ghahramani, Z and Weinberger, K Q},
pages = {854--862},
publisher = {Curran Associates, Inc.},
title = {{Distributed Exploration in Multi-Armed Bandits}},
year = {2013}
}
@article{Deshpande2012,
archivePrefix = {arXiv},
arxivId = {1301.1722},
author = {Deshpande, Yash and Montanari, Andrea},
doi = {10.1109/Allerton.2012.6483433},
eprint = {1301.1722},
isbn = {9781467345385},
journal = {2012 50th Annual Allerton Conference on Communication, Control, and Computing, Allerton 2012},
pages = {1750--1754},
title = {{Linear bandits in high dimension and recommendation systems}},
year = {2012}
}
@article{jain08fast,
abstract = {We introduce a method that enables scalable image$\backslash$n$\backslash$nsearch for learned metrics. Given pairwise similarity and$\backslash$n$\backslash$ndissimilarity constraints between some images, we learn a$\backslash$n$\backslash$nMahalanobis distance function that captures the images'$\backslash$n$\backslash$nunderlying relationships well. To allow sub-linear time sim-$\backslash$n$\backslash$nilarity search under the learned metric, we show how to en-$\backslash$n$\backslash$ncode the learned metric parameterization into randomized$\backslash$n$\backslash$nlocality-sensitive hash functions. We further formulate an$\backslash$n$\backslash$nindirect solution that enables metric learning and hashing$\backslash$n$\backslash$nfor vector spaces whose high dimensionality make it infea-$\backslash$n$\backslash$nsible to learn an explicit weighting over the feature dimen-$\backslash$n$\backslash$nsions. We demonstrate the approach applied to a variety of$\backslash$n$\backslash$nimage datasets. Our learned metrics improve accuracy rel-$\backslash$n$\backslash$native to commonly-used metric baselines, while our hash-$\backslash$n$\backslash$ning construction enables efficient indexing with learned dis-$\backslash$n$\backslash$ntances and very large databases.},
author = {Jain, P and Kulis, B and Grauman, K},
journal = {Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)},
keywords = {kernels,learned metrics,locality-sensitive hash,scalable image search,similarity},
pages = {1--8},
title = {{Fast Image Search for Learned Metrics}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4587841},
year = {2008}
}
@article{pellegrini02longitudinal,
author = {Pellegrini, A D and Long, Jeffrey D},
issn = {0261-510X},
journal = {British Journal of Developmental Psychology},
number = {2},
pages = {259--280},
title = {{A longitudinal study of bullying, dominance, and victimization during the transition from primary school through secondary school}},
volume = {20},
year = {2002}
}
@article{hazan07adaptive,
author = {Hazan, Elad and Seshadhri, Comandur},
journal = {IBM Research Report},
pages = {1--19},
title = {{Adaptive Algorithms for Online Decision Problems}},
volume = {10418},
year = {2007}
}
@inproceedings{abe99associative,
author = {Abe, Naoki and Long, Philip M.},
booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
pages = {3--11},
title = {{Associative reinforcement learning using linear probabilistic concepts}},
year = {1999}
}
@inproceedings{gu12towards,
abstract = {—Active learning on graphs has received increas-ing interest in the past years. In this paper, we propose a nonadaptive active learning approach on graphs, based on generalization error bound minimization. In particular, we present a data-dependent error bound for a graph-based learn-ing method, namely learning with local and global consistency (LLGC). We show that the empirical transductive Rademacher complexity of the function class for LLGC provides a natural criterion for active learning. The resulting active learning approach is to select a subset of nodes on a graph such that the empirical transductive Rademacher complexity of LLGC is minimized. We propose a simple yet effective sequential optimization algorithm to solve it. Experiments on benchmark datasets show that the proposed method outperforms the state-of-the-art active learning methods on graphs.},
author = {Gu, Quanquan and Han, Jiawei},
booktitle = {Proceedings - IEEE International Conference on Data Mining (ICDM)},
doi = {10.1109/ICDM.2012.72},
isbn = {9780769549057},
issn = {15504786},
keywords = {Active learning,Generalization error bound,Graph,Sequential optimization},
pages = {882--887},
title = {{Towards active learning on graphs: An error bound minimization approach}},
year = {2012}
}
@article{kelly56anew,
author = {Kelly, J L},
journal = {The Bell System Technical Journal},
month = {jul},
number = {4},
pages = {917--926},
title = {{A new interpretation of information rate}},
volume = {35},
year = {1956}
}
@inproceedings{hadi2015buy,
author = {{Hadi Kiapour}, M and Han, Xufeng and Lazebnik, Svetlana and Berg, Alexander C and Berg, Tamara L},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {3343--3351},
title = {{Where to buy it: Matching street clothing photos in online shops}},
year = {2015}
}
@article{krichevsky81theperformance,
author = {Krichevsky, Raphail E and Trofimov, Victor K},
journal = {IEEE Trans. Information Theory},
number = {2},
pages = {199--206},
title = {{The performance of universal encoding.}},
volume = {27},
year = {1981}
}
@inproceedings{mohan10new,
author = {Mohan, Karthik and Fazel, Maryam},
booktitle = {IEEE International Symposium on Information Theory - Proceedings},
title = {{New restricted isometry results for noisy low-rank recovery}},
year = {2010}
}
@inproceedings{jun16graph,
archivePrefix = {arXiv},
arxivId = {1609.00845},
author = {Jun, Kwang Sung and Nowak, Robert},
booktitle = {IEEE Global Conference on Signal and Information Processing (GlobalSIP) Symposium on Non-Commutative Theory and Applications},
doi = {10.1109/GlobalSIP.2016.7906056},
eprint = {1609.00845},
isbn = {9781509045457},
pages = {1325--1329},
title = {{Graph-based active learning: A new look at expected error minimization}},
year = {2016}
}
@incollection{filippi10parametric,
author = {Filippi, Sarah and Cappe, Olivier and Garivier, Aur{\'{e}}lien and Szepesv{\'{a}}ri, Csaba},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
pages = {586--594},
title = {{Parametric Bandits: The Generalized Linear Case}},
year = {2010}
}
@inproceedings{audibert10best,
author = {Audibert, Jean-Yves and Bubeck, S{\'{e}}bastien and Munos, R{\'{e}}mi},
booktitle = {Proceedings of the Conference on Learning Theory (COLT)},
title = {{Best Arm Identification in Multi-Armed Bandits}},
year = {2010}
}
@article{srinivas10gaussian,
author = {Srinivas, Niranjan and Krause, Andreas and Kakade, Sham M. and Seeger, Matthias},
journal = {Proceedings of the 27th International Conference on Machine Learning (ICML 2010)},
pages = {1015--1022},
title = {{Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design}},
year = {2010}
}
@inproceedings{shrivastava15improved,
abstract = {Recently it was shown that the problem of Maximum Inner Product Search (MIPS) is efficient and it admits provably sub-linear hashing algorithms. Asymmetric transformations before hashing were the key in solving MIPS which was otherwise hard. In the prior work, the authors use asymmetric transformations which convert the problem of approximate MIPS into the problem of approximate near neighbor search which can be efficiently solved using hashing. In this work, we provide a different transformation which converts the problem of approximate MIPS into the problem of approximate cosine similarity search which can be efficiently solved using signed random projections. Theoretical analysis show that the new scheme is significantly better than the original scheme for MIPS. Experimental evaluations strongly support the theoretical findings.},
archivePrefix = {arXiv},
arxivId = {1410.5410},
author = {Shrivastava, Anshumali and Li, Ping},
booktitle = {Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI)},
eprint = {1410.5410},
isbn = {9780000000002},
pages = {812--821},
title = {{Improved Asymmetric Locality Sensitive Hashing (ALSH) for Maximum Inner Product Search (MIPS)}},
url = {http://arxiv.org/abs/1410.5410},
year = {2015}
}
@inproceedings{adamskiy12acloser,
author = {Adamskiy, Dmitry and Koolen, Wouter M and Chernov, Alexey and Vovk, Vladimir},
booktitle = {Proceedings of the International Conference on Algorithmic Learning Theory (ALT)},
keywords = {adaptive regret,fixed share,online learning,specialist experts},
pages = {290--304},
title = {{A Closer Look at Adaptive Regret}},
url = {http://dx.doi.org/10.1007/978-3-642-34106-9{\_}24},
year = {2012}
}
@inproceedings{katariya16dcm,
author = {Katariya, Sumeet and Kveton, Branislav and Szepesv{\'{a}}ri, Csaba and Wen, Zheng},
booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
pages = {1215--1224},
title = {{DCM Bandits: Learning to Rank with Multiple Clicks}},
year = {2016}
}
@article{koolen13universal,
abstract = {We discuss algorithms for combining sequential prediction strategies, a task which can be viewed as a natural generalization of the concept of universal coding. We describe a graphical language based on hidden Markov models for defining prediction strategies, and we provide both existing and new models as examples. The models include efficient, parameterless models for switching between the input strategies over time, including a model for the case where switches tend to occur in clusters, and finally a new model for the scenario where the prediction strategies have a known relationship, and where jumps are typically between strongly related ones. This last model is relevant for coding time series data where parameter drift is expected. As theoretical contributions, we introduce an interpolation construction that is useful in the development and analysis of new algorithms, and we establish a new sophisticated lemma for analyzing the individual sequence regret of parameterized models.},
archivePrefix = {arXiv},
arxivId = {1311.6536},
author = {Koolen, Wouter M. and {De Rooij}, Steven},
doi = {10.1109/TIT.2013.2273353},
eprint = {1311.6536},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
keywords = {Expert tracking,hidden Markov models (HMMs),individual sequence,prediction with expert advice,regret,universal coding},
number = {11},
pages = {7168--7185},
title = {{Universal codes from switching strategies}},
volume = {59},
year = {2013}
}
@inproceedings{abeille17linear,
author = {Abeille, Marc and Lazaric, Alessandro},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)},
pages = {176--184},
title = {{Linear Thompson Sampling Revisited}},
volume = {54},
year = {2017}
}
@inproceedings{kaly12pac,
author = {Kalyanakrishnan, Shivaram and Tewari, Ambuj and Auer, Peter and Stone, Peter},
booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
pages = {655--662},
title = {{PAC Subset Selection in Stochastic Multi-armed Bandits}},
year = {2012}
}
@inproceedings{li16collaborative,
author = {Li, Shuai and Karatzoglou, Alexandros and Gentile, Claudio},
booktitle = {Proceedings of the International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)},
pages = {539--548},
title = {{Collaborative Filtering Bandits}},
year = {2016}
}
@phdthesis{konyushkova13imse,
author = {Konyushkova, Ksenia},
pages = {307--319},
school = {University of Helsinki},
title = {{Imse: Instant interactive image retrieval system with exploration/exploitation trade-off}},
year = {2014}
}
@article{bechhofer58sequential,
author = {Bechhofer, Robert E},
journal = {Biometrics},
number = {3},
pages = {408--429},
title = {{A Sequential Multiple-Decision Procedure for Selecting the Best One of Several Normal Populations with a Common Unknown Variance, and Its Use with Various Experimental Designs}},
volume = {14},
year = {1958}
}
@article{jun17online,
author = {Jun, Kwang-Sung and Orabona, Francesco and Wright, Stephen and Willett, Rebecca},
doi = {10.1214/17-EJS1379SI},
issn = {1935-7524},
journal = {Electron. J. Statist.},
number = {2},
pages = {5282--5310},
title = {{Online learning for changing environments using coin betting}},
volume = {11},
year = {2017}
}
@inproceedings{jamieson15next,
author = {Jamieson, Kevin and Jain, Lalit and Fernandez, Chris and Glattard, Nicholas and Nowak, Robert},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
title = {{NEXT: A System for Real-World Development, Evaluation, and Application of Active Learning.}},
year = {2015}
}
@inproceedings{glowacka15balancing,
author = {Ahukorala, Kumaripaba and Medlar, Alan and Ilves, Kalle and Glowacka, Dorota},
booktitle = {Proceedings of the ACM International Conference on Information and Knowledge Management (CIKM)},
pages = {1703--1706},
title = {{Balancing Exploration and Exploitation: Empirical Parameterization of Exploratory Search Systems}},
year = {2015}
}
@inproceedings{valko14spectral,
author = {Valko, Michal and Munos, Remi and Kveton, Branislav and Kocak, Tomas},
booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
pages = {46----54},
title = {{Spectral Bandits for Smooth Graph Functions}},
year = {2014}
}
@inproceedings{ma18data,
author = {Ma, Yuzhe and Jun, Kwang-Sung and Li, Lihong and Zhu, Xiaojin},
booktitle = {Conference on Decision and Game Theory for Security (GameSec)},
title = {{Data Poisoning Attacks in Contextual Bandits}},
year = {2018}
}
@inproceedings{zhu03semi,
author = {Zhu, Xiaojin and Ghahramani, Zoubin and Lafferty, John},
booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
pages = {912--919},
title = {{Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions}},
year = {2003}
}
@inproceedings{jegou08hamming,
author = {J{\'{e}}gou, Herv{\'{e}} and Douze, Matthijs and Schmid, Cordelia},
booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
pages = {304--317},
title = {{Hamming Embedding and Weak Geometric Consistency for Large Scale Image Search}},
year = {2008}
}
@inproceedings{Jain:2013:LMC:2488608.2488693,
address = {New York, NY, USA},
author = {Jain, Prateek and Netrapalli, Praneeth and Sanghavi, Sujay},
booktitle = {Proceedings of the Annual ACM Symposium on Theory of Computing},
doi = {10.1145/2488608.2488693},
isbn = {978-1-4503-2029-0},
keywords = {alternating minimization,matrix completion,matrix sensing},
pages = {665--674},
publisher = {ACM},
series = {STOC '13},
title = {{Low-rank Matrix Completion Using Alternating Minimization}},
url = {http://doi.acm.org/10.1145/2488608.2488693},
year = {2013}
}
@incollection{gunasekar13noisy,
author = {Gunasekar, Suriya and Acharya, Ayan and Gaur, Neeraj and Ghosh, Joydeep},
booktitle = {Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD},
pages = {194--209},
publisher = {Springer Berlin Heidelberg},
title = {{Noisy Matrix Completion Using Alternating Minimization}},
year = {2013}
}
@inproceedings{joulani13online,
author = {Joulani, Pooria and Gy{\"{o}}rgy, Andr{\'{a}}s and Szepesv{\'{a}}ri, Csaba},
booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
pages = {1453--1461},
title = {{Online Learning under Delayed Feedback.}},
year = {2013}
}
@article{ma08sorec,
author = {Ma, Hao and Yang, Haixuan and Lyu, Michael R. and King, Irwin},
journal = {Proceeding of the ACM Conference on Information and Knowledge Mining (CIKM)},
title = {{SoRec: Social Recommendation Using Probabilistic Matrix Factorization}},
year = {2008}
}
@article{guo16quantization,
abstract = {We propose a quantization based approach for fast approximate Maximum Inner Product Search (MIPS). Each database vector is quantized in multiple subspaces via a set of codebooks, learned directly by minimizing the inner product quantization error. Then, the inner product of a query to a database vector is approximated as the sum of inner products with the subspace quantizers. Different from recently proposed LSH approaches to MIPS, the database vectors and queries do not need to be augmented in a higher dimensional feature space. We also provide a theoretical analysis of the proposed approach, consisting of the concentration results under mild assumptions. Furthermore, if a small sample of example queries is given at the training time, we propose a modified codebook learning procedure which further improves the accuracy. Experimental results on a variety of datasets including those arising from deep neural networks show that the proposed approach significantly outperforms the existing state-of-the-art.},
archivePrefix = {arXiv},
arxivId = {1509.01469},
author = {Guo, Ruiqi and Kumar, Sanjiv and Choromanski, Krzysztof and Simcha, David},
eprint = {1509.01469},
journal = {Journal of Machine Learning Research},
pages = {482--490},
title = {{Quantization based Fast Inner Product Search}},
url = {http://arxiv.org/abs/1509.01469},
volume = {41},
year = {2016}
}
@article{kovashka2015whittlesearch,
author = {Kovashka, Adriana and Parikh, Devi and Grauman, Kristen},
journal = {International Journal of Computer Vision},
number = {2},
pages = {185--210},
publisher = {Springer},
title = {{Whittlesearch: Interactive image search with relative attribute feedback}},
volume = {115},
year = {2015}
}
@techreport{rakhlin16atutorial,
archivePrefix = {arXiv},
arxivId = {1608.09014},
author = {Rakhlin, Alexander and Sridharan, Karthik},
booktitle = {CoRR},
eprint = {1608.09014},
title = {{A Tutorial on Online Supervised Learning with Applications to Node Classification in Social Networks}},
volume = {1608.09014},
year = {2016}
}
@article{hazan16volumetric,
author = {Hazan, Elad and Karnin, Zohar},
journal = {Journal of Machine Learning Research},
number = {119},
pages = {1--34},
title = {{Volumetric Spanners: An Efficient Exploration Basis for Learning}},
volume = {17},
year = {2016}
}
@inproceedings{jun17improved,
author = {Jun, Kwang-Sung and Orabona, Francesco and Wright, Stephen and Willett, Rebecca},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)},
pages = {943--951},
title = {{Improved Strongly Adaptive Online Learning using Coin Betting}},
volume = {54},
year = {2017}
}
@article{Nickl2013,
archivePrefix = {arXiv},
arxivId = {arXiv:1209.1508v4},
author = {Nickl, Richard and {Van De Geer}, Sara},
doi = {10.1214/13-AOS1170},
eprint = {arXiv:1209.1508v4},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Composite testing problem,Detection boundary,High-dimensional inference,Quadratic risk estimation},
number = {6},
pages = {2852--2876},
title = {{Confidence sets in sparse regression}},
volume = {41},
year = {2013}
}
@article{keshavan10matrix,
author = {Keshavan, Raghunandan H and Montanari, Andrea and Oh, Sewoong},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
pages = {2057--2078},
title = {{Matrix Completion from Noisy Entries}},
volume = {11},
year = {2010}
}
@inproceedings{DudaHart2nd,
author = {Duda, R O and Hart, P E and Stork, D G},
edition = {2nd},
publisher = {John Wiley and Sons},
title = {{Pattern Classification}},
year = {2000}
}
@article{Cesa-Bianchi2012a,
archivePrefix = {arXiv},
arxivId = {arXiv:1202.3323v1},
author = {Cesa-Bianchi, N and Gaillard, Pierre and Lugosi, G and Stoltz, Gilles},
eprint = {arXiv:1202.3323v1},
journal = {Jmlr},
keywords = {online convex optimization,prediction with expert advice,tracking the best expert},
pages = {1--18},
title = {{A new look at shifting regret}},
url = {http://hal.inria.fr/hal-00670514/},
year = {2012}
}
@article{burer03anonlinear,
author = {Burer, Samuel and Monteiro, Renato D C},
doi = {10.1007/s10107-002-0352-8},
isbn = {00255610},
issn = {00255610},
journal = {Mathematical Programming, Series B},
title = {{A nonlinear programming algorithm for solving semidefinite programs via low-rank factorization}},
year = {2003}
}
@article{robbins85asymptotically,
author = {Lai, T L and Robbins, Herbert},
journal = {Advances in Applied Mathematics},
number = {1},
pages = {4--22},
title = {{Asymptotically Efficient Adaptive Allocation Rules}},
volume = {6},
year = {1985}
}
@misc{JPLBigData,
annote = {$\backslash$url{\{}http://www.jpl.nasa.gov/news/news.php?release=2013-299{\}}},
author = {Clavin, W},
title = {{Managing the Deluge of `Big Data' From Space}},
year = {2013}
}
@inproceedings{kunapuli12mirror,
abstract = {Most metric learning methods are characterized by diverse loss functions and projection methods, which naturally begs the question: is there a wider framework that can generalize many of these methods? In addition, ever persistent issues are those of scalability to large data sets and the question of kernelizability. We propose a unified approach to Mahalanobis metric learning: an online regularized metric learning algorithm based on the ideas of composite objective mirror descent (comid). The metric learning problem is formulated as a regularized positive semi-definite matrix learning problem, whose update rules can be derived using the comid framework. This approach aims to be scalable, kernelizable, and admissible to many different types of Bregman and loss functions, which allows for the tailoring of several different classes of algorithms. The most novel contribution is the use of the trace norm, which yields a sparse metric in its eigenspectrum, thus simultaneously performing feature selection along with metric learning.},
author = {Kunapuli, Gautam and Shavlik, Jude},
booktitle = {Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Database (ECML/PKDD)},
doi = {10.1007/978-3-642-33460-3_60},
isbn = {9783642334597},
issn = {03029743},
pages = {859--874},
title = {{Mirror descent for metric learning: A unified approach}},
year = {2012}
}
@inproceedings{orabona12beyond,
author = {Orabona, Francesco and Cesa-Bianchi, Nicolo and Gentile, Claudio},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)},
pages = {823--831},
title = {{Beyond Logarithmic Bounds in Online Learning}},
volume = {22},
year = {2012}
}
@article{dekel12selective,
author = {Dekel, Ofer and Gentile, Claudio and Sridharan, Karthik},
journal = {Journal of Machine Learning Research},
pages = {2655--2697},
title = {{Selective sampling and active learning from single and multiple teachers}},
volume = {13},
year = {2012}
}
@article{paulson64sequential,
author = {Paulson, Edward},
journal = {Annals of Mathematical Statistics},
number = {1},
pages = {174--180},
title = {{A Sequential Procedure for Selecting the Population with the Largest Mean from k Normal Populations}},
volume = {35},
year = {1964}
}
@article{zinkevich03online,
abstract = {Convex programming involves a convex set F R and a convex function c : F R. The goal of convex programming is to nd a point in F which minimizes c. In this paper, we introduce online convex programming. In online convex programming, the convex set is known in advance, but in each step of some repeated optimization problem, one must select a point in F before seeing the cost function for that step. This can be used to model factory production, farm production, and many other industrial optimization problems where one is unaware of the value of the items produced until they have already been constructed. We introduce an algorithm for this domain, apply it to repeated games, and show that it is really a generalization of in nitesimal gradient ascent, and the results here imply that generalized in nitesimal gradient ascent (GIGA) is universally consistent.},
author = {Zinkevich, Martin},
doi = {10.1.1.10.9960},
isbn = {1-57735-189-4},
journal = {Machine Learning},
number = {February},
pages = {421--422},
title = {{Online Convex Programming and Generalized Infinitesimal Gradient Ascent}},
url = {http://www.aaai.org/Papers/ICML/2003/ICML03-120.pdf},
volume = {20},
year = {2003}
}
@inproceedings{sen17contextual,
author = {Sen, Rajat and Shanmugam, Karthikeyan and Kocaoglu, Murat and Dimakis, Alex and Shakkottai, Sanjay},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)},
pages = {518--527},
title = {{Contextual Bandits with Latent Confounders: An NMF Approach}},
volume = {54},
year = {2017}
}
@inproceedings{jamieson14bestarm,
author = {Jamieson, Kevin G and Nowak, Robert},
booktitle = {48th Annual Conference on Information Sciences and Systems, (CISS) 2014, Princeton, NJ, USA, March 19-21, 2014},
pages = {1--6},
title = {{Best-arm identification algorithms for multi-armed bandits in the fixed confidence setting}},
year = {2014}
}
@article{auer02finite,
address = {Amsterdam, The Netherlands},
author = {Auer, Peter and Cesa-Bianchi, Nicol{\`{o}} and Fischer, Paul},
journal = {Machine Learning},
number = {2--3},
pages = {235--256},
publisher = {Kluwer Academic},
title = {{Finite-time Analysis of the Multiarmed Bandit Problem}},
volume = {47},
year = {2002}
}
@article{kannan09spectral,
author = {Kannan, Ravindran and Vempala, Santosh and Others},
journal = {Foundations and Trends{\{}{\textregistered}{\}} in Theoretical Computer Science},
number = {3--4},
pages = {157--288},
publisher = {Now Publishers, Inc.},
title = {{Spectral algorithms}},
volume = {4},
year = {2009}
}
@inproceedings{kalai09theisotron,
author = {Kalai, Adam Tauman and Sastry, Ravi},
booktitle = {Proceedings of the Conference on Learning Theory (COLT)},
title = {{The Isotron Algorithm: High-Dimensional Isotonic Regression.}},
year = {2009}
}
@inproceedings{chapelle11anempirical,
author = {Chapelle, Olivier and Li, Lihong},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
pages = {2249--2257},
title = {{An Empirical Evaluation of Thompson Sampling}},
year = {2011}
}
@article{slaney12optimal,
abstract = {Locality-sensitive hashing (LSH) is the basis of many algorithms that use a probabilistic approach to find nearest neighbors.We describe an algorithmfor optimizing the parameters and use of LSH. Prior work ignores these issues or suggests a search for the best parameters. We start with two histograms: one that characterizes the distributions of dis- tances to a point's nearest neighbors and the second that characterizes the distance between a query and any point in the data set. Given a desired performance level (the chance of finding the true nearest neighbor) and a simple computational cost model, we return the LSH parameters that allow an LSH index to meet the performance goal and have the minimum computational cost. We can also use this analysis to connect LSH to deterministic nearest-neighbor algorithms such as k-d trees and thus start to unify the two approaches. KEYWORDS},
author = {Slaney, Malcolm and Lifshits, Yury and He, Junfeng},
doi = {10.1109/JPROC.2012.2193849},
issn = {00189219},
journal = {Proceedings of the IEEE},
keywords = {Database index,information retrieval,locality-sensitive hashing,multimedia databases,nearest-neighbor search},
number = {9},
pages = {2604--2623},
title = {{Optimal parameters for locality-sensitive hashing}},
volume = {100},
year = {2012}
}
@inproceedings{vaswani17horde,
author = {Vaswani, Sharan and Schmidt, Mark and Lakshmanan, Laks V S},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)},
pages = {690--699},
title = {{Horde of Bandits using Gaussian Markov Random Fields}},
year = {2017}
}
@article{bubeck11pure-tcs,
author = {Stoltz, Gilles and Bubeck, S{\'{e}}bastien and Munos, R{\'{e}}mi},
journal = {Theoretical Computer Science},
month = {apr},
number = {19},
pages = {1832--1852},
publisher = {Elsevier},
title = {{Pure exploration in finitely-armed and continuous-armed bandits}},
url = {https://hal-hec.archives-ouvertes.fr/hal-00609550},
volume = {412},
year = {2011}
}
@article{ay11improved,
author = {Abbasi-Yadkori, Yasin and Pal, David and Szepesvari, Csaba},
journal = {Advances in Neural Information Processing Systems (NIPS)},
pages = {1--19},
title = {{Improved Algorithms for Linear Stochastic Bandits}},
year = {2011}
}
@article{greenewald16nonstationary,
author = {Greenewald, Kristjan and Kelley, Stephen and Hero, Alfred O},
journal = {54th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
title = {{Dynamic metric learning from pairwise comparisons}},
url = {https://arxiv.org/abs/1603.03678},
year = {2016}
}
@inproceedings{Dekel10robust,
author = {Dekel, Ofer and Gentile, Claudio and Sridharan, Karthik},
booktitle = {In Proceedings of the Conference on Learning Theory (COLT)},
title = {{Robust selective sampling from single and multiple teachers}},
year = {2010}
}
@inproceedings{qin14contextual,
author = {Qin, Lijing and Chen, Shouyuan and Zhu, Xiaoyan},
booktitle = {SDM},
keywords = {dblp},
pages = {461--469},
title = {{Contextual Combinatorial Bandit and its Application on Diversified Online Recommendation.}},
year = {2014}
}
@inproceedings{bubeck13multiple,
author = {Bubeck, S{\'{e}}bastien and Wang, Tengyao and Viswanathan, Nitin},
booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
pages = {258--265},
title = {{Multiple Identifications in Multi-Armed Bandits}},
year = {2013}
}
@article{bubeck12regret,
author = {Bubeck, S{\'{e}}bastien and Cesa-Bianchi, Nicol{\`{o}}},
journal = {Foundations and Trends in Machine Learning},
keywords = {dblp},
pages = {1--122},
title = {{Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems}},
volume = {5},
year = {2012}
}
@article{nelder65simplex,
author = {Nelder, J A and Mead, R},
doi = {10.1093/comjnl/7.4.308},
issn = {1460-2067},
journal = {The Computer Journal},
month = {jan},
number = {4},
pages = {308--313},
publisher = {Oxford University Press},
title = {{A Simplex Method for Function Minimization}},
volume = {7},
year = {1965}
}
@inproceedings{katariya17bernoulli,
author = {Katariya, Sumeet and Kveton, Branislav and Szepesv{\'{a}}ri, Csaba and Vernade, Claire and Wen, Zheng},
booktitle = {Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI)},
pages = {2001--2007},
title = {{Bernoulli Rank-1 Bandits for Click Feedback}},
year = {2017}
}
@inproceedings{kaufmann13information,
author = {Kaufmann, Emilie and Kalyanakrishnan, Shivaram},
booktitle = {Proceedings of the Conference on Learning Theory (COLT)},
pages = {228--251},
title = {{Information Complexity in Bandit Subset Selection.}},
year = {2013}
}
@inproceedings{cesa-bianchi12mirror,
author = {Cesa-Bianchi, Nicolo and Gaillard, Pierre and Lugosi, G{\'{a}}bor and Stoltz, Gilles},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
pages = {980--988},
title = {{Mirror descent meets fixed share (and feels no regret)}},
year = {2012}
}
@inproceedings{bhargava17active,
author = {Bhargava, Aniruddha and Ganti, Ravi and Nowak, Rob},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)},
pages = {1349--1357},
title = {{Active Positive Semidefinite Matrix Completion: Algorithms, Theory and Applications}},
volume = {54},
year = {2017}
}
@inproceedings{luo15achieving,
author = {Luo, Haipeng and Schapire, Robert E},
booktitle = {Proceedings of the Conference on Learning Theory (COLT)},
pages = {1286--1304},
title = {{Achieving All with No Parameters: AdaNormalHedge}},
year = {2015}
}
@article{wainwright08graphical,
author = {Wainwright, Martin J and Jordan, Michael I},
journal = {Found. Trends Mach. Learn.},
number = {1-2},
pages = {1--305},
title = {{Graphical Models, Exponential Families, and Variational Inference}},
volume = {1},
year = {2008}
}
@inproceedings{dani08stochastic,
author = {Dani, Varsha and Hayes, Thomas P and Kakade, Sham M},
booktitle = {Proceedings of the Conference on Learning Theory (COLT)},
keywords = {dblp},
pages = {355--366},
title = {{Stochastic Linear Optimization under Bandit Feedback.}},
year = {2008}
}
@inproceedings{agrawal12analysis,
author = {Agrawal, Shipra and Goyal, Navin},
booktitle = {In Proceedings of the Conference on Learning Theory (COLT)},
pages = {39.1--39.26},
title = {{Analysis of Thompson Sampling for the Multi-armed Bandit Problem.}},
volume = {23},
year = {2012}
}
@incollection{guillory09label,
author = {Guillory, Andrew and Bilmes, Jeff A},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
pages = {691--699},
title = {{Label Selection on Graphs}},
url = {http://papers.nips.cc/paper/3752-label-selection-on-graphs.pdf},
year = {2009}
}
@article{rusmevichientong10linearly,
author = {Rusmevichientong, Paat and Tsitsiklis, John N},
journal = {Math. Oper. Res.},
number = {2},
pages = {395--411},
title = {{Linearly Parameterized Bandits}},
volume = {35},
year = {2010}
}
@article{kulis09kernelized,
abstract = {Fast retrieval methods are critical for large-scale and data-driven vision applications. Recent work has explored ways to embed high-dimensional features or complex distance functions into a low-dimensional Hamming space where items can be efficiently searched. However, existing methods do not apply for high-dimensional kernelized data when the underlying feature embedding for the kernel is unknown. We show how to generalize locality-sensitive hashing to accommodate arbitrary kernel functions, making it possible to preserve the algorithm's sub-linear time similarity search guarantees for a wide class of useful similarity functions. Since a number of successful image-based kernels have unknown or incomputable embeddings, this is especially valuable for image retrieval tasks. We validate our technique on several large-scale datasets, and show that it enables accurate and fast performance for example-based object classification, feature matching, and content-based retrieval. {\textcopyright}2009 IEEE.},
author = {Kulis, Brian and Grauman, Kristen},
journal = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
keywords = {Classification (of information),Computer vision,Content based retrieval,Data-driven,Distance functions,Embeddings,Existing method,Feature embedding,Feature matching,Hamming distance,Hamming space,High-dimensional,Image-based,Information retrieval,Kernel function,Large-scale datasets,Linear time,Locality sensitive hashing,Object classification,Retrieval methods,Scalable image,Similarity functions,Similarity search,Vision applications},
pages = {2130--2137},
title = {{Kernelized locality-sensitive hashing for scalable image search}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77953184849{\&}partnerID=40{\&}md5=215f75697066ee3b2e5628faf3db131b},
year = {2009}
}
@article{gyorgy12efficient,
author = {Gy{\"{o}}rgy, Andr{\'{a}}s and Linder, Tam{\'{a}}s and Lugosi, G{\'{a}}bor},
journal = {IEEE Transactions on Information Theory},
keywords = {Algorithmic efficiency,changing environments,compound experts,data compression,individual sequences,nonstationary sources,sequential coding,sequential decision making,sequential prediction},
number = {11},
pages = {6709--6725},
title = {{Efficient tracking of large classes of experts}},
volume = {58},
year = {2012}
}
@article{li17provable,
author = {Li, Lihong and Lu, Yu and Zhou, Dengyong},
journal = {CoRR},
title = {{Provable Optimal Algorithms for Generalized Linear Contextual Bandits}},
volume = {abs/1703.0},
year = {2017}
}
@article{bengio13representation,
author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
number = {8},
pages = {1798--1828},
title = {{Representation Learning: A Review and New Perspectives}},
url = {http://dx.doi.org/10.1109/TPAMI.2013.50},
volume = {35},
year = {2013}
}
@incollection{NIPS1989_261,
author = {Atlas, Les E and Cohn, David A and Ladner, Richard E},
booktitle = {Advances in Neural Information Processing Systems 2},
editor = {Touretzky, D S},
pages = {566--573},
publisher = {Morgan-Kaufmann},
title = {{Training Connectionist Networks with Queries and Selective Sampling}},
url = {http://papers.nips.cc/paper/261-training-connectionist-networks-with-queries-and-selective-sampling.pdf},
year = {1990}
}
@inproceedings{perchet15batched,
author = {Perchet, Vianney and Rigollet, Philippe and Chassang, Sylvain and Snowberg, Erik},
booktitle = {Proceedings of the Conference on Learning Theory (COLT)},
pages = {1456},
title = {{Batched Bandit Problems}},
year = {2015}
}
@inproceedings{sen17contextual,
author = {Sen, Rajat and Shanmugam, Karthikeyan and Kocaoglu, Murat and Dimakis, Alex and Shakkottai, Sanjay},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)},
pages = {518--527},
title = {{Contextual Bandits with Latent Confounders: An NMF Approach}},
volume = {54},
year = {2017}
}
@book{cesa-bianchi06prediction,
author = {Cesa-Bianchi, Nicolo and Lugosi, Gabor},
isbn = {0521841089},
publisher = {Cambridge University Press},
title = {{Prediction, Learning, and Games}},
year = {2006}
}
@inproceedings{bubeck09pure,
author = {Bubeck, S{\'{e}}bastien and Munos, R{\'{e}}mi and Stoltz, Gilles},
booktitle = {Proceedings of the International Conference on Algorithmic Learning Theory (ALT)},
pages = {23--37},
title = {{Pure Exploration in Multi-armed Bandits Problems}},
year = {2009}
}
@article{thompson33onthelikelihood,
author = {Thompson, William R.},
journal = {Biometrika},
number = {3/4},
pages = {285},
title = {{On the Likelihood that One Unknown Probability Exceeds Another in View of the Evidence of Two Samples}},
volume = {25},
year = {1933}
}
@article{auer02using,
author = {Auer, Peter and Long, M},
journal = {Journal of Machine Learning Research},
pages = {2002},
title = {{Using Confidence Bounds for Exploitation-Exploration Trade-offs}},
volume = {3},
year = {2002}
}
@article{agrawal14thompson,
author = {Agrawal, Shipra and Goyal, Navin},
journal = {CoRR},
title = {{Thompson Sampling for Contextual Bandits with Linear Payoffs}},
volume = {abs/1209.3},
year = {2012}
}
@incollection{combes17minimal,
author = {Combes, Richard and Magureanu, Stefan and Proutiere, Alexandre},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
pages = {1763--1771},
title = {{Minimal Exploration in Structured Stochastic Bandits}},
year = {2017}
}
@article{kaufmann14onthecomplexity,
author = {Kaufmann, Emilie and Capp{\'{e}}, Olivier and Garivier, Aur{\'{e}}lien},
title = {{On the Complexity of Best Arm Identiﬁcation in Multi-Armed Bandit Models}}
}
@article{Slaney2012a,
abstract = {Locality-sensitive hashing (LSH) is the basis of many algorithms that use a probabilistic approach to find nearest neighbors.We describe an algorithmfor optimizing the parameters and use of LSH. Prior work ignores these issues or suggests a search for the best parameters. We start with two histograms: one that characterizes the distributions of dis- tances to a point's nearest neighbors and the second that characterizes the distance between a query and any point in the data set. Given a desired performance level (the chance of finding the true nearest neighbor) and a simple computational cost model, we return the LSH parameters that allow an LSH index to meet the performance goal and have the minimum computational cost. We can also use this analysis to connect LSH to deterministic nearest-neighbor algorithms such as k-d trees and thus start to unify the two approaches. KEYWORDS},
author = {Slaney, Malcolm and Lifshits, Yury and He, Junfeng},
doi = {10.1109/JPROC.2012.2193849},
issn = {00189219},
journal = {Proceedings of the IEEE},
keywords = {Database index,information retrieval,locality-sensitive hashing,multimedia databases,nearest-neighbor search},
number = {9},
pages = {2604--2623},
title = {{Optimal parameters for locality-sensitive hashing}},
volume = {100},
year = {2012}
}
@article{rui98relevance,
author = {Rui, Yong and Huang, T S and Ortega, M and Mehrotra, S},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
keywords = {Computer graphics,Content based retrieval,Digital images,Explosions,Feedback,Humans,IEC standards,ISO standards,Image retrieval,Information retrieval,dynamically updated weights,experimental results,feature extraction,feedback,high-level query,human visual perception,image representation,interactive content-based image retrieval,interactive video,low-level features,multimedia communication,multimedia computing,multimedia object model,perception subjectivity,query processing,relevance feedback,user feedback,user information,video signal processing,visual databases,visual feature representations,visual perception},
number = {5},
pages = {644--655},
title = {{Relevance feedback: a power tool for interactive content-based image retrieval}},
volume = {8},
year = {1998}
}
@article{kveton17stochastic_arxiv,
author = {Kveton, Branislav and Szepesv{\'{a}}ri, Csaba and Rao, Anup and Wen, Zheng and Abbasi-Yadkori, Yasin and Muthukrishnan, S},
journal = {CoRR},
title = {{Stochastic Low-Rank Bandits}},
volume = {abs/1712.0},
year = {2017}
}
@article{angluin88queries,
author = {Angluin, Dana},
journal = {Mach. Learn.},
number = {4},
pages = {319--342},
title = {{Queries and Concept Learning}},
volume = {2},
year = {1988}
}
@inproceedings{gentile14online,
author = {Gentile, Claudio and Li, Shuai and Zappella, Giovanni},
booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
number = {2},
pages = {757--765},
title = {{Online Clustering of Bandits}},
volume = {32},
year = {2014}
}
@article{shrivastava14asymmetric,
abstract = {We present the first provably sublinear time algorithm for approximate $\backslash$emph{\{}Maximum Inner Product Search{\}} (MIPS). Our proposal is also the first hashing algorithm for searching with (un-normalized) inner product as the underlying similarity measure. Finding hashing schemes for MIPS was considered hard. We formally show that the existing Locality Sensitive Hashing (LSH) framework is insufficient for solving MIPS, and then we extend the existing LSH framework to allow asymmetric hashing schemes. Our proposal is based on an interesting mathematical phenomenon in which inner products, after independent asymmetric transformations, can be converted into the problem of approximate near neighbor search. This key observation makes efficient sublinear hashing scheme for MIPS possible. In the extended asymmetric LSH (ALSH) framework, we provide an explicit construction of provably fast hashing scheme for MIPS. The proposed construction and the extended LSH framework could be of independent theoretical interest. Our proposed algorithm is simple and easy to implement. We evaluate the method, for retrieving inner products, in the collaborative filtering task of item recommendations on Netflix and Movielens datasets.},
author = {Shrivastava, Anshumali and Li, Ping},
journal = {Advances in Neural Information Processing Systems 27},
pages = {2321--2329},
title = {{Asymmetric LSH ( ALSH ) for Sublinear Time Maximum Inner Product Search ( MIPS )}},
year = {2014}
}
@article{ss12online,
author = {Shalev-Shwartz, Shai},
journal = {Found. Trends Mach. Learn.},
number = {2},
pages = {107--194},
title = {{Online Learning and Online Convex Optimization}},
volume = {4},
year = {2012}
}
@article{auer03nonstochastic,
address = {Philadelphia, PA, USA},
author = {Auer, Peter and Cesa-Bianchi, Nicol{\`{o}} and Freund, Yoav and Schapire, Robert E},
doi = {10.1137/S0097539701398375},
issn = {0097-5397},
journal = {SIAM J. Comput.},
month = {jan},
number = {1},
pages = {48--77},
publisher = {Society for Industrial and Applied Mathematics},
title = {{The Nonstochastic Multiarmed Bandit Problem}},
volume = {32},
year = {2003}
}
@inproceedings{gadde14active,
author = {Gadde, Akshay and Anis, Aamir and Ortega, Antonio},
booktitle = {Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/2623330.2623760},
isbn = {978-1-4503-2956-9},
keywords = {active semi-supervised learning,graph signal filtering,graph signal processing,sampling theory},
pages = {492--501},
title = {{Active Semi-supervised Learning Using Sampling Theory for Graph Signals}},
url = {http://doi.acm.org/10.1145/2623330.2623760},
year = {2014}
}
@inproceedings{heidrich-meisner09hoeffding,
author = {Heidrich-Meisner, V and Igel, Christian},
booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
pages = {401--408},
title = {{Hoeffding and Bernstein Races for Selecting Policies in Evolutionary Direct Policy Search}},
year = {2009}
}
@inproceedings{zhang16online,
author = {Zhang, Lijun and Yang, Tianbao and Jin, Rong and Xiao, Yichi and Zhou, Zhi-hua},
booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
pages = {392--401},
title = {{Online Stochastic Linear Optimization under One-bit Feedback}},
volume = {48},
year = {2016}
}
@inproceedings{xu12learning,
author = {Xu, Jun-Ming and Jun, Kwang-Sung and Zhu, Xiaojin and Bellmore, Amy},
booktitle = {Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL HLT)},
pages = {656--666},
publisher = {The Association for Computational Linguistics},
title = {{Learning from Bullying Traces in Social Media}},
year = {2012}
}
@inproceedings{ma13sigma,
author = {Ma, Yifei and Garnett, Roman and Schneider, Jeff},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
title = {{Sigma-Optimality in Active Learning on Gaussian Random Fields}},
year = {2013}
}
@article{mcmahan09tighter,
author = {McMahan, HB and Streeter, MJ},
journal = {In Proceedings of the Conference on Learning Theory (COLT)},
title = {{Tighter Bounds for Multi-Armed Bandits with Expert Advice.}},
year = {2009}
}
@inproceedings{rakhlin17efficient,
author = {Rakhlin, Alexander and Sridharan, Karthik},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)},
pages = {1403--1411},
title = {{Efficient Online Multiclass Prediction on Graphs via Surrogate Losses}},
volume = {54},
year = {2017}
}
@inproceedings{katariya17stochastic,
author = {Katariya, Sumeet and Kveton, Branislav and Szepesv{\'{a}}ri, Csaba and Vernade, Claire and Wen, Zheng},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)},
pages = {392--401},
title = {{Stochastic Rank-1 Bandits}},
year = {2017}
}
@incollection{kawale15efficient,
author = {Kawale, Jaya and Bui, Hung H and Kveton, Branislav and Tran-Thanh, Long and Chawla, Sanjay},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
pages = {1297--1305},
title = {{Efficient Thompson Sampling for Online Matrix-Factorization Recommendation}},
year = {2015}
}
@incollection{abernethy15fighting,
author = {Abernethy, Jacob D and Lee, Chansoo and Tewari, Ambuj},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
pages = {2197--2205},
title = {{Fighting Bandits with a New Kind of Smoothness}},
year = {2015}
}
@article{koren09,
author = {Koren, Yehuda and Bell, Robert and Volinsky, Chris},
journal = {Computer},
number = {8},
pages = {30--37},
publisher = {IEEE Computer Society Press},
title = {{Matrix Factorization Techniques for Recommender Systems}},
volume = {42},
year = {2009}
}
@incollection{cb13agang,
author = {Cesa-Bianchi, Nicol{\`{o}} and Gentile, Claudio and Zappella, Giovanni},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
editor = {Burges, C J C and Bottou, L and Welling, M and Ghahramani, Z and Weinberger, K Q},
pages = {737--745},
title = {{A Gang of Bandits}},
year = {2013}
}
@article{jia14caffe,
author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
journal = {arXiv preprint arXiv:1408.5093},
title = {{Caffe: Convolutional Architecture for Fast Feature Embedding}},
year = {2014}
}
