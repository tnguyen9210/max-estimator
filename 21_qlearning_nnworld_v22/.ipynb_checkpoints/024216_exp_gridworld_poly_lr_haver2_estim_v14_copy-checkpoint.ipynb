{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "383e247e-5b67-4df9-a315-54c8a84b0d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configs:\n",
    "    # Env\n",
    "    env_id=\"NNWorld01-v01\", \n",
    "     - once in the goal state, each action ends the episode and returns a reward of 5\n",
    "     - no clear episodes, continuously train the agent with num_train_steps, \n",
    "       if the agent reaches terminal, just reset environment and keep training \n",
    "     - try to immitate the bandit experiments\n",
    "    # Params\n",
    "    eps_sched_fn=poly(0.5), lr_sched_fn=poly(0.8)\n",
    "    # Algos\n",
    "    haver2, action_sigma=adaptive(1), haver_delta=0.01, haver_const=varied\n",
    "Status:\n",
    "\"\"\"\n",
    "\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=5, suppress=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_palette(\"tab20\")\n",
    "colors = sns.color_palette(\"bright\")\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm \n",
    "import multiprocessing\n",
    "\n",
    "# import gymnasium as gym\n",
    "import gym\n",
    "import gym_examples\n",
    "from gym.wrappers import FlattenObservation\n",
    "\n",
    "from algos import *\n",
    "from bandit_problem import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "470972cc-8018-41a5-a4f2-dd2b76cec119",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_mus = [ 0.  0.  0.  0.  0.  0.  0.  0. -5. -5. -5. -5. -5. -5. -5. -5.]\n",
      "action_sigmas = [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "optimal_num_steps = 4\n",
      "optimal_reward_per_step = -2.5\n",
      "optimal_vstar = -8.573749999999999\n",
      "\n",
      "-> est_name = haver3_1.0\n",
      "haver_const = 1.0\n",
      "\n",
      "-> i_step = 4000\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 1.31\n",
      "new_state = [1 3]\n",
      "[ 56. 102. 111. 257.  35.  40.  79. 283.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 102. 111. 257.  35.  40.  79. 283.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.95977  -5.95903  -5.95915  -5.96109  -5.96452  -5.98338\n",
      "  -5.9588   -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24074 2.46316 2.57212 3.18384 2.72436 3.43189 2.40352 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.96\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05726 0.10429 0.1135  0.26278 0.03579 0.0409  0.08078 0.28937 0.\n",
      " 0.00204 0.00409 0.00511 0.00409 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 102. 111. 257.  35.  40.  79. 283.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.01\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14 15]\n",
      "probs = [0.148 0.138 0.097 0.074 0.128 0.107 0.146 0.087 0.    0.019 0.009 0.014\n",
      " 0.008 0.    0.02  0.005]\n",
      "Q_est = -6.26\n",
      "\n",
      "-> i_step = 4001\n",
      "cur_state = [1 3]\n",
      "action = 5\n",
      "reward = -0.31\n",
      "new_state = [2 5]\n",
      "[ 56. 102. 111. 257.  35.  40.  79. 283.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 102. 111. 257.  35.  40.  79. 283.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.95977  -5.95903  -5.95915  -5.96109  -5.96452  -5.98338\n",
      "  -5.9588   -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24074 2.46316 2.57212 3.18384 2.72436 3.43189 2.40352 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.96\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05726 0.10429 0.1135  0.26278 0.03579 0.0409  0.08078 0.28937 0.\n",
      " 0.00204 0.00409 0.00511 0.00409 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 102. 111. 257.  35.  40.  79. 283.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.01\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14 15]\n",
      "probs = [0.144 0.149 0.091 0.083 0.143 0.111 0.163 0.071 0.    0.007 0.005 0.011\n",
      " 0.004 0.    0.015 0.003]\n",
      "Q_est = -6.16\n",
      "\n",
      "-> i_step = 4002\n",
      "cur_state = [2 5]\n",
      "action = 6\n",
      "reward = 2.34\n",
      "new_state = [3 6]\n",
      "[ 56. 102. 111. 257.  35.  40.  79. 283.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 102. 111. 257.  35.  40.  79. 283.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.95977  -5.95903  -5.95915  -5.96109  -5.96452  -5.98338\n",
      "  -5.9588   -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24074 2.46316 2.57212 3.18384 2.72436 3.43189 2.40352 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.96\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05726 0.10429 0.1135  0.26278 0.03579 0.0409  0.08078 0.28937 0.\n",
      " 0.00204 0.00409 0.00511 0.00409 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 102. 111. 257.  35.  40.  79. 283.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.01\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.151 0.121 0.079 0.1   0.138 0.108 0.162 0.087 0.    0.013 0.009 0.009\n",
      " 0.004 0.003 0.015 0.001]\n",
      "Q_est = -6.17\n",
      "\n",
      "-> i_step = 4003\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 56. 102. 111. 257.  35.  40.  79. 283.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 102. 111. 257.  35.  40.  79. 283.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.95977  -5.95903  -5.95915  -5.96109  -5.96452  -5.98338\n",
      "  -5.9588   -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24074 2.46316 2.57212 3.18384 2.72436 3.43189 2.40352 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.96\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05726 0.10429 0.1135  0.26278 0.03579 0.0409  0.08078 0.28937 0.\n",
      " 0.00204 0.00409 0.00511 0.00409 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 102. 111. 257.  35.  40.  79. 283.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.01\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.134 0.12  0.089 0.102 0.156 0.109 0.148 0.085 0.    0.014 0.007 0.013\n",
      " 0.009 0.003 0.011 0.   ]\n",
      "Q_est = -6.16\n",
      "\n",
      "-> i_step = 4004\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 1.44\n",
      "new_state = [1 7]\n",
      "[ 56. 102. 111. 257.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 102. 111. 257.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.95977  -5.95903  -5.95915  -5.96109  -5.96452  -5.98338\n",
      "  -5.95965  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24074 2.46316 2.57212 3.18384 2.72436 3.43189 2.39933 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.96\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0572  0.10419 0.11338 0.26251 0.03575 0.04086 0.08069 0.29009 0.\n",
      " 0.00204 0.00409 0.00511 0.00409 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 102. 111. 257.  35.  40.  79. 284.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.01\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.125 0.138 0.082 0.102 0.134 0.09  0.17  0.092 0.    0.014 0.005 0.013\n",
      " 0.005 0.002 0.025 0.003]\n",
      "Q_est = -6.25\n",
      "\n",
      "-> i_step = 4005\n",
      "cur_state = [1 7]\n",
      "action = 2\n",
      "reward = -0.30\n",
      "new_state = [2 2]\n",
      "[ 56. 102. 111. 257.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 102. 111. 257.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.95977  -5.95903  -5.95915  -5.96109  -5.96452  -5.98338\n",
      "  -5.95965  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24074 2.46316 2.57212 3.18384 2.72436 3.43189 2.39933 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.96\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0572  0.10419 0.11338 0.26251 0.03575 0.04086 0.08069 0.29009 0.\n",
      " 0.00204 0.00409 0.00511 0.00409 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 102. 111. 257.  35.  40.  79. 284.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.01\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.139 0.147 0.072 0.091 0.151 0.113 0.15  0.083 0.    0.012 0.009 0.014\n",
      " 0.003 0.001 0.014 0.001]\n",
      "Q_est = -6.17\n",
      "\n",
      "-> i_step = 4006\n",
      "cur_state = [2 2]\n",
      "action = 2\n",
      "reward = 1.17\n",
      "new_state = [3 2]\n",
      "[ 56. 102. 111. 257.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 102. 111. 257.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.95977  -5.95903  -5.95915  -5.96109  -5.96452  -5.98338\n",
      "  -5.95965  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24074 2.46316 2.57212 3.18384 2.72436 3.43189 2.39933 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.96\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0572  0.10419 0.11338 0.26251 0.03575 0.04086 0.08069 0.29009 0.\n",
      " 0.00204 0.00409 0.00511 0.00409 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 102. 111. 257.  35.  40.  79. 284.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.01\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.156 0.137 0.092 0.092 0.109 0.103 0.162 0.093 0.001 0.017 0.003 0.013\n",
      " 0.004 0.001 0.014 0.003]\n",
      "Q_est = -6.18\n",
      "\n",
      "-> i_step = 4007\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 56. 102. 111. 257.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 102. 111. 257.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.95977  -5.95903  -5.95915  -5.96109  -5.96452  -5.98338\n",
      "  -5.95965  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24074 2.46316 2.57212 3.18384 2.72436 3.43189 2.39933 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.96\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0572  0.10419 0.11338 0.26251 0.03575 0.04086 0.08069 0.29009 0.\n",
      " 0.00204 0.00409 0.00511 0.00409 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 102. 111. 257.  35.  40.  79. 284.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.01\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14 15]\n",
      "probs = [0.15  0.142 0.093 0.102 0.144 0.086 0.137 0.087 0.    0.011 0.01  0.013\n",
      " 0.005 0.    0.019 0.001]\n",
      "Q_est = -6.20\n",
      "\n",
      "-> i_step = 4008\n",
      "cur_state = [0 0]\n",
      "action = 2\n",
      "reward = -0.07\n",
      "new_state = [1 2]\n",
      "[ 56. 102. 112. 257.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 102. 112. 257.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.95977  -5.97517  -5.95915  -5.96109  -5.96452  -5.98338\n",
      "  -5.95965  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24074 2.45803 2.57212 3.18384 2.72436 3.43189 2.39933 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.96\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05714 0.10408 0.11429 0.26224 0.03571 0.04082 0.08061 0.2898  0.\n",
      " 0.00204 0.00408 0.0051  0.00408 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 102. 112. 257.  35.  40.  79. 284.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.01\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.131 0.128 0.098 0.088 0.119 0.103 0.153 0.102 0.001 0.021 0.012 0.012\n",
      " 0.007 0.003 0.018 0.004]\n",
      "Q_est = -6.25\n",
      "\n",
      "-> i_step = 4009\n",
      "cur_state = [1 2]\n",
      "action = 5\n",
      "reward = 2.25\n",
      "new_state = [2 5]\n",
      "[ 56. 102. 112. 257.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 102. 112. 257.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.95977  -5.97517  -5.95915  -5.96109  -5.96452  -5.98338\n",
      "  -5.95965  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24074 2.45803 2.57212 3.18384 2.72436 3.43189 2.39933 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.96\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05714 0.10408 0.11429 0.26224 0.03571 0.04082 0.08061 0.2898  0.\n",
      " 0.00204 0.00408 0.0051  0.00408 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 102. 112. 257.  35.  40.  79. 284.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.01\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.132 0.153 0.084 0.096 0.141 0.117 0.138 0.082 0.    0.015 0.009 0.008\n",
      " 0.008 0.003 0.012 0.002]\n",
      "Q_est = -6.17\n",
      "\n",
      "-> i_step = 4010\n",
      "cur_state = [2 5]\n",
      "action = 6\n",
      "reward = 0.23\n",
      "new_state = [3 6]\n",
      "[ 56. 102. 112. 257.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 102. 112. 257.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.95977  -5.97517  -5.95915  -5.96109  -5.96452  -5.98338\n",
      "  -5.95965  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24074 2.45803 2.57212 3.18384 2.72436 3.43189 2.39933 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.96\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05714 0.10408 0.11429 0.26224 0.03571 0.04082 0.08061 0.2898  0.\n",
      " 0.00204 0.00408 0.0051  0.00408 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 102. 112. 257.  35.  40.  79. 284.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.01\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15]\n",
      "probs = [0.128 0.137 0.084 0.108 0.153 0.122 0.153 0.077 0.001 0.006 0.005 0.012\n",
      " 0.005 0.    0.006 0.003]\n",
      "Q_est = -6.12\n",
      "\n",
      "-> i_step = 4011\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 56. 102. 112. 257.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 102. 112. 257.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.95977  -5.97517  -5.95915  -5.96109  -5.96452  -5.98338\n",
      "  -5.95965  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24074 2.45803 2.57212 3.18384 2.72436 3.43189 2.39933 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.96\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05714 0.10408 0.11429 0.26224 0.03571 0.04082 0.08061 0.2898  0.\n",
      " 0.00204 0.00408 0.0051  0.00408 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 102. 112. 257.  35.  40.  79. 284.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.01\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.144 0.139 0.084 0.09  0.139 0.103 0.156 0.083 0.    0.011 0.012 0.011\n",
      " 0.006 0.002 0.018 0.002]\n",
      "Q_est = -6.21\n",
      "\n",
      "-> i_step = 4012\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 0.24\n",
      "new_state = [1 3]\n",
      "[ 56. 102. 112. 258.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 102. 112. 258.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.95977  -5.97517  -5.9652   -5.96109  -5.96452  -5.98338\n",
      "  -5.95965  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24074 2.45803 2.56896 3.18384 2.72436 3.43189 2.39933 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.96\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05708 0.10398 0.11417 0.263   0.03568 0.04077 0.08053 0.2895  0.\n",
      " 0.00204 0.00408 0.0051  0.00408 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 102. 112. 258.  35.  40.  79. 284.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.01\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.146 0.132 0.094 0.081 0.15  0.123 0.15  0.074 0.    0.01  0.008 0.011\n",
      " 0.005 0.002 0.013 0.001]\n",
      "Q_est = -6.16\n",
      "\n",
      "-> i_step = 4013\n",
      "cur_state = [1 3]\n",
      "action = 5\n",
      "reward = 0.77\n",
      "new_state = [2 5]\n",
      "[ 56. 102. 112. 258.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 102. 112. 258.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.95977  -5.97517  -5.9652   -5.96109  -5.96452  -5.98338\n",
      "  -5.95965  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24074 2.45803 2.56896 3.18384 2.72436 3.43189 2.39933 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.96\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05708 0.10398 0.11417 0.263   0.03568 0.04077 0.08053 0.2895  0.\n",
      " 0.00204 0.00408 0.0051  0.00408 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 102. 112. 258.  35.  40.  79. 284.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.01\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.142 0.151 0.069 0.098 0.125 0.097 0.152 0.091 0.    0.019 0.011 0.015\n",
      " 0.008 0.001 0.021 0.   ]\n",
      "Q_est = -6.24\n",
      "\n",
      "-> i_step = 4014\n",
      "cur_state = [2 5]\n",
      "action = 6\n",
      "reward = -1.57\n",
      "new_state = [3 6]\n",
      "[ 56. 102. 112. 258.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 102. 112. 258.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.95977  -5.97517  -5.9652   -5.96109  -5.96452  -5.98338\n",
      "  -5.95965  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24074 2.45803 2.56896 3.18384 2.72436 3.43189 2.39933 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.96\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05708 0.10398 0.11417 0.263   0.03568 0.04077 0.08053 0.2895  0.\n",
      " 0.00204 0.00408 0.0051  0.00408 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 102. 112. 258.  35.  40.  79. 284.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.01\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14 15]\n",
      "probs = [0.139 0.14  0.08  0.103 0.136 0.112 0.15  0.077 0.    0.011 0.009 0.008\n",
      " 0.01  0.    0.023 0.002]\n",
      "Q_est = -6.23\n",
      "\n",
      "-> i_step = 4015\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 56. 102. 112. 258.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 102. 112. 258.  35.  40.  79. 284.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.95977  -5.97517  -5.9652   -5.96109  -5.96452  -5.98338\n",
      "  -5.95965  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24074 2.45803 2.56896 3.18384 2.72436 3.43189 2.39933 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.96\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05708 0.10398 0.11417 0.263   0.03568 0.04077 0.08053 0.2895  0.\n",
      " 0.00204 0.00408 0.0051  0.00408 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 102. 112. 258.  35.  40.  79. 284.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.01\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.142 0.155 0.086 0.092 0.14  0.112 0.153 0.065 0.    0.013 0.008 0.015\n",
      " 0.002 0.003 0.009 0.005]\n",
      "Q_est = -6.17\n",
      "\n",
      "-> i_step = 4016\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = -0.91\n",
      "new_state = [1 7]\n",
      "[ 56. 102. 112. 258.  35.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 102. 112. 258.  35.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.95977  -5.97517  -5.9652   -5.96109  -5.96452  -5.98338\n",
      "  -5.96877  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24074 2.45803 2.56896 3.18384 2.72436 3.43189 2.40003 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05703 0.10387 0.11405 0.26273 0.03564 0.04073 0.08045 0.29022 0.\n",
      " 0.00204 0.00407 0.00509 0.00407 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 102. 112. 258.  35.  40.  79. 285.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.01\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.134 0.117 0.088 0.101 0.145 0.1   0.172 0.082 0.    0.009 0.007 0.02\n",
      " 0.005 0.003 0.014 0.003]\n",
      "Q_est = -6.21\n",
      "\n",
      "-> i_step = 4017\n",
      "cur_state = [1 7]\n",
      "action = 0\n",
      "reward = -1.55\n",
      "new_state = [2 0]\n",
      "[ 56. 102. 112. 258.  35.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 102. 112. 258.  35.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.95977  -5.97517  -5.9652   -5.96109  -5.96452  -5.98338\n",
      "  -5.96877  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24074 2.45803 2.56896 3.18384 2.72436 3.43189 2.40003 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05703 0.10387 0.11405 0.26273 0.03564 0.04073 0.08045 0.29022 0.\n",
      " 0.00204 0.00407 0.00509 0.00407 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 102. 112. 258.  35.  40.  79. 285.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.01\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.117 0.171 0.099 0.074 0.144 0.103 0.148 0.075 0.    0.017 0.004 0.014\n",
      " 0.006 0.004 0.017 0.007]\n",
      "Q_est = -6.25\n",
      "\n",
      "-> i_step = 4018\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = 1.47\n",
      "new_state = [3 7]\n",
      "[ 56. 102. 112. 258.  35.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 102. 112. 258.  35.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.95977  -5.97517  -5.9652   -5.96109  -5.96452  -5.98338\n",
      "  -5.96877  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24074 2.45803 2.56896 3.18384 2.72436 3.43189 2.40003 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05703 0.10387 0.11405 0.26273 0.03564 0.04073 0.08045 0.29022 0.\n",
      " 0.00204 0.00407 0.00509 0.00407 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 102. 112. 258.  35.  40.  79. 285.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.01\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.143 0.146 0.082 0.087 0.125 0.113 0.162 0.079 0.    0.009 0.007 0.019\n",
      " 0.006 0.004 0.014 0.004]\n",
      "Q_est = -6.22\n",
      "\n",
      "-> i_step = 4019\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 56. 102. 112. 258.  35.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 102. 112. 258.  35.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.95977  -5.97517  -5.9652   -5.96109  -5.96452  -5.98338\n",
      "  -5.96877  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24074 2.45803 2.56896 3.18384 2.72436 3.43189 2.40003 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05703 0.10387 0.11405 0.26273 0.03564 0.04073 0.08045 0.29022 0.\n",
      " 0.00204 0.00407 0.00509 0.00407 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 102. 112. 258.  35.  40.  79. 285.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.01\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.128 0.135 0.095 0.088 0.15  0.098 0.151 0.092 0.    0.015 0.009 0.01\n",
      " 0.003 0.002 0.019 0.005]\n",
      "Q_est = -6.22\n",
      "\n",
      "-> i_step = 4020\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -1.47\n",
      "new_state = [1 1]\n",
      "[ 56. 103. 112. 258.  35.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 258.  35.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9652   -5.96109  -5.96452  -5.98338\n",
      "  -5.96877  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56896 3.18384 2.72436 3.43189 2.40003 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05697 0.10478 0.11394 0.26246 0.03561 0.04069 0.08037 0.28993 0.\n",
      " 0.00203 0.00407 0.00509 0.00407 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 258.  35.  40.  79. 285.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.02\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.142 0.158 0.081 0.076 0.141 0.103 0.144 0.092 0.    0.012 0.009 0.019\n",
      " 0.003 0.004 0.013 0.003]\n",
      "Q_est = -6.21\n",
      "\n",
      "-> i_step = 4021\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -0.55\n",
      "new_state = [2 5]\n",
      "[ 56. 103. 112. 258.  35.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 258.  35.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9652   -5.96109  -5.96452  -5.98338\n",
      "  -5.96877  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56896 3.18384 2.72436 3.43189 2.40003 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05697 0.10478 0.11394 0.26246 0.03561 0.04069 0.08037 0.28993 0.\n",
      " 0.00203 0.00407 0.00509 0.00407 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 258.  35.  40.  79. 285.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.02\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.151 0.149 0.093 0.079 0.144 0.137 0.131 0.078 0.    0.012 0.002 0.009\n",
      " 0.002 0.001 0.012 0.   ]\n",
      "Q_est = -6.12\n",
      "\n",
      "-> i_step = 4022\n",
      "cur_state = [2 5]\n",
      "action = 6\n",
      "reward = -0.56\n",
      "new_state = [3 6]\n",
      "[ 56. 103. 112. 258.  35.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 258.  35.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9652   -5.96109  -5.96452  -5.98338\n",
      "  -5.96877  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56896 3.18384 2.72436 3.43189 2.40003 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05697 0.10478 0.11394 0.26246 0.03561 0.04069 0.08037 0.28993 0.\n",
      " 0.00203 0.00407 0.00509 0.00407 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 258.  35.  40.  79. 285.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.02\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.141 0.155 0.083 0.088 0.134 0.09  0.156 0.086 0.001 0.013 0.009 0.011\n",
      " 0.006 0.003 0.021 0.003]\n",
      "Q_est = -6.24\n",
      "\n",
      "-> i_step = 4023\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 56. 103. 112. 258.  35.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 258.  35.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9652   -5.96109  -5.96452  -5.98338\n",
      "  -5.96877  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56896 3.18384 2.72436 3.43189 2.40003 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05697 0.10478 0.11394 0.26246 0.03561 0.04069 0.08037 0.28993 0.\n",
      " 0.00203 0.00407 0.00509 0.00407 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 258.  35.  40.  79. 285.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.02\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.147 0.126 0.091 0.118 0.146 0.09  0.166 0.075 0.    0.008 0.006 0.011\n",
      " 0.005 0.001 0.008 0.002]\n",
      "Q_est = -6.13\n",
      "\n",
      "-> i_step = 4024\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = -0.91\n",
      "new_state = [1 4]\n",
      "[ 56. 103. 112. 258.  36.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 258.  36.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9652   -6.0476   -5.96452  -5.98338\n",
      "  -5.96877  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56896 3.18076 2.72436 3.43189 2.40003 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05691 0.10467 0.11382 0.2622  0.03659 0.04065 0.08028 0.28963 0.\n",
      " 0.00203 0.00407 0.00508 0.00407 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 258.  36.  40.  79. 285.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.02\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.144 0.139 0.061 0.096 0.125 0.101 0.174 0.092 0.    0.013 0.014 0.012\n",
      " 0.004 0.002 0.022 0.001]\n",
      "Q_est = -6.25\n",
      "\n",
      "-> i_step = 4025\n",
      "cur_state = [1 4]\n",
      "action = 4\n",
      "reward = -1.00\n",
      "new_state = [2 4]\n",
      "[ 56. 103. 112. 258.  36.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 258.  36.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9652   -6.0476   -5.96452  -5.98338\n",
      "  -5.96877  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56896 3.18076 2.72436 3.43189 2.40003 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05691 0.10467 0.11382 0.2622  0.03659 0.04065 0.08028 0.28963 0.\n",
      " 0.00203 0.00407 0.00508 0.00407 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 258.  36.  40.  79. 285.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.02\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.133 0.115 0.081 0.104 0.147 0.107 0.157 0.083 0.002 0.022 0.007 0.014\n",
      " 0.003 0.003 0.019 0.003]\n",
      "Q_est = -6.26\n",
      "\n",
      "-> i_step = 4026\n",
      "cur_state = [2 4]\n",
      "action = 1\n",
      "reward = 0.12\n",
      "new_state = [3 1]\n",
      "[ 56. 103. 112. 258.  36.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 258.  36.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9652   -6.0476   -5.96452  -5.98338\n",
      "  -5.96877  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56896 3.18076 2.72436 3.43189 2.40003 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05691 0.10467 0.11382 0.2622  0.03659 0.04065 0.08028 0.28963 0.\n",
      " 0.00203 0.00407 0.00508 0.00407 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 258.  36.  40.  79. 285.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.02\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.165 0.134 0.083 0.087 0.124 0.104 0.148 0.099 0.    0.019 0.008 0.008\n",
      " 0.004 0.003 0.01  0.004]\n",
      "Q_est = -6.18\n",
      "\n",
      "-> i_step = 4027\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 56. 103. 112. 258.  36.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 258.  36.  40.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9652   -6.0476   -5.96452  -5.98338\n",
      "  -5.96877  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56896 3.18076 2.72436 3.43189 2.40003 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05691 0.10467 0.11382 0.2622  0.03659 0.04065 0.08028 0.28963 0.\n",
      " 0.00203 0.00407 0.00508 0.00407 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 258.  36.  40.  79. 285.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.02\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.151 0.145 0.099 0.082 0.137 0.102 0.156 0.081 0.001 0.011 0.004 0.009\n",
      " 0.002 0.003 0.016 0.001]\n",
      "Q_est = -6.18\n",
      "\n",
      "-> i_step = 4028\n",
      "cur_state = [0 0]\n",
      "action = 5\n",
      "reward = 0.42\n",
      "new_state = [1 5]\n",
      "[ 56. 103. 112. 258.  36.  41.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 258.  36.  41.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9652   -6.0476   -6.00519  -5.98338\n",
      "  -5.96877  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56896 3.18076 2.7032  3.43189 2.40003 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05685 0.10457 0.11371 0.26193 0.03655 0.04162 0.0802  0.28934 0.\n",
      " 0.00203 0.00406 0.00508 0.00406 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 258.  36.  41.  79. 285.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.02\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.14  0.129 0.097 0.099 0.131 0.1   0.165 0.086 0.    0.009 0.006 0.014\n",
      " 0.006 0.001 0.016 0.001]\n",
      "Q_est = -6.20\n",
      "\n",
      "-> i_step = 4029\n",
      "cur_state = [1 5]\n",
      "action = 5\n",
      "reward = 1.10\n",
      "new_state = [2 5]\n",
      "[ 56. 103. 112. 258.  36.  41.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 258.  36.  41.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9652   -6.0476   -6.00519  -5.98338\n",
      "  -5.96877  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56896 3.18076 2.7032  3.43189 2.40003 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05685 0.10457 0.11371 0.26193 0.03655 0.04162 0.0802  0.28934 0.\n",
      " 0.00203 0.00406 0.00508 0.00406 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 258.  36.  41.  79. 285.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.02\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.142 0.134 0.081 0.108 0.133 0.103 0.143 0.09  0.    0.013 0.011 0.015\n",
      " 0.001 0.004 0.019 0.003]\n",
      "Q_est = -6.25\n",
      "\n",
      "-> i_step = 4030\n",
      "cur_state = [2 5]\n",
      "action = 6\n",
      "reward = 0.16\n",
      "new_state = [3 6]\n",
      "[ 56. 103. 112. 258.  36.  41.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 258.  36.  41.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9652   -6.0476   -6.00519  -5.98338\n",
      "  -5.96877  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56896 3.18076 2.7032  3.43189 2.40003 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05685 0.10457 0.11371 0.26193 0.03655 0.04162 0.0802  0.28934 0.\n",
      " 0.00203 0.00406 0.00508 0.00406 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 258.  36.  41.  79. 285.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.02\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14]\n",
      "probs = [0.138 0.125 0.1   0.09  0.139 0.104 0.148 0.094 0.    0.013 0.008 0.019\n",
      " 0.008 0.    0.014 0.   ]\n",
      "Q_est = -6.22\n",
      "\n",
      "-> i_step = 4031\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 56. 103. 112. 258.  36.  41.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 258.  36.  41.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9652   -6.0476   -6.00519  -5.98338\n",
      "  -5.96877  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56896 3.18076 2.7032  3.43189 2.40003 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05685 0.10457 0.11371 0.26193 0.03655 0.04162 0.0802  0.28934 0.\n",
      " 0.00203 0.00406 0.00508 0.00406 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 258.  36.  41.  79. 285.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.02\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15]\n",
      "probs = [0.157 0.139 0.109 0.082 0.133 0.092 0.145 0.082 0.002 0.011 0.009 0.012\n",
      " 0.008 0.    0.015 0.004]\n",
      "Q_est = -6.23\n",
      "\n",
      "-> i_step = 4032\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 0.82\n",
      "new_state = [1 3]\n",
      "[ 56. 103. 112. 259.  36.  41.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 259.  36.  41.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.96895  -6.0476   -6.00519  -5.98338\n",
      "  -5.96877  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56471 3.18076 2.7032  3.43189 2.40003 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0568  0.10446 0.11359 0.26268 0.03651 0.04158 0.08012 0.28905 0.\n",
      " 0.00203 0.00406 0.00507 0.00406 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 259.  36.  41.  79. 285.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.02\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.165 0.125 0.087 0.111 0.136 0.094 0.143 0.082 0.    0.008 0.013 0.007\n",
      " 0.005 0.002 0.019 0.003]\n",
      "Q_est = -6.22\n",
      "\n",
      "-> i_step = 4033\n",
      "cur_state = [1 3]\n",
      "action = 5\n",
      "reward = 0.80\n",
      "new_state = [2 5]\n",
      "[ 56. 103. 112. 259.  36.  41.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 259.  36.  41.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.96895  -6.0476   -6.00519  -5.98338\n",
      "  -5.96877  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56471 3.18076 2.7032  3.43189 2.40003 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0568  0.10446 0.11359 0.26268 0.03651 0.04158 0.08012 0.28905 0.\n",
      " 0.00203 0.00406 0.00507 0.00406 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 259.  36.  41.  79. 285.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.02\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.149 0.139 0.071 0.088 0.151 0.093 0.164 0.084 0.    0.016 0.004 0.011\n",
      " 0.002 0.005 0.017 0.006]\n",
      "Q_est = -6.24\n",
      "\n",
      "-> i_step = 4034\n",
      "cur_state = [2 5]\n",
      "action = 6\n",
      "reward = 1.43\n",
      "new_state = [3 6]\n",
      "[ 56. 103. 112. 259.  36.  41.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 259.  36.  41.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.96895  -6.0476   -6.00519  -5.98338\n",
      "  -5.96877  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56471 3.18076 2.7032  3.43189 2.40003 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0568  0.10446 0.11359 0.26268 0.03651 0.04158 0.08012 0.28905 0.\n",
      " 0.00203 0.00406 0.00507 0.00406 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 259.  36.  41.  79. 285.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.02\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.144 0.123 0.09  0.093 0.135 0.098 0.161 0.097 0.    0.018 0.006 0.012\n",
      " 0.005 0.003 0.014 0.001]\n",
      "Q_est = -6.20\n",
      "\n",
      "-> i_step = 4035\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 56. 103. 112. 259.  36.  41.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 259.  36.  41.  79. 285.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.96895  -6.0476   -6.00519  -5.98338\n",
      "  -5.96877  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56471 3.18076 2.7032  3.43189 2.40003 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0568  0.10446 0.11359 0.26268 0.03651 0.04158 0.08012 0.28905 0.\n",
      " 0.00203 0.00406 0.00507 0.00406 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 259.  36.  41.  79. 285.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.02\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.167 0.112 0.09  0.099 0.132 0.095 0.151 0.097 0.    0.006 0.002 0.013\n",
      " 0.009 0.005 0.018 0.004]\n",
      "Q_est = -6.24\n",
      "\n",
      "-> i_step = 4036\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 0.31\n",
      "new_state = [1 7]\n",
      "[ 56. 103. 112. 259.  36.  41.  79. 286.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 259.  36.  41.  79. 286.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.96895  -6.0476   -6.00519  -5.98338\n",
      "  -5.97357  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56471 3.18076 2.7032  3.43189 2.3972  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05674 0.10436 0.11348 0.26241 0.03647 0.04154 0.08004 0.28977 0.\n",
      " 0.00203 0.00405 0.00507 0.00405 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 259.  36.  41.  79. 286.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.148 0.129 0.103 0.088 0.14  0.096 0.164 0.083 0.    0.009 0.005 0.007\n",
      " 0.003 0.003 0.021 0.001]\n",
      "Q_est = -6.20\n",
      "\n",
      "-> i_step = 4037\n",
      "cur_state = [1 7]\n",
      "action = 5\n",
      "reward = 0.25\n",
      "new_state = [2 5]\n",
      "[ 56. 103. 112. 259.  36.  41.  79. 286.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 259.  36.  41.  79. 286.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.96895  -6.0476   -6.00519  -5.98338\n",
      "  -5.97357  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56471 3.18076 2.7032  3.43189 2.3972  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05674 0.10436 0.11348 0.26241 0.03647 0.04154 0.08004 0.28977 0.\n",
      " 0.00203 0.00405 0.00507 0.00405 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 259.  36.  41.  79. 286.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.152 0.142 0.082 0.095 0.122 0.107 0.147 0.086 0.    0.019 0.009 0.014\n",
      " 0.006 0.001 0.015 0.003]\n",
      "Q_est = -6.23\n",
      "\n",
      "-> i_step = 4038\n",
      "cur_state = [2 5]\n",
      "action = 6\n",
      "reward = -0.66\n",
      "new_state = [3 6]\n",
      "[ 56. 103. 112. 259.  36.  41.  79. 286.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 259.  36.  41.  79. 286.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.96895  -6.0476   -6.00519  -5.98338\n",
      "  -5.97357  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56471 3.18076 2.7032  3.43189 2.3972  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05674 0.10436 0.11348 0.26241 0.03647 0.04154 0.08004 0.28977 0.\n",
      " 0.00203 0.00405 0.00507 0.00405 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 259.  36.  41.  79. 286.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14 15]\n",
      "probs = [0.147 0.146 0.075 0.098 0.147 0.105 0.155 0.082 0.    0.01  0.005 0.009\n",
      " 0.003 0.    0.016 0.002]\n",
      "Q_est = -6.18\n",
      "\n",
      "-> i_step = 4039\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 56. 103. 112. 259.  36.  41.  79. 286.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 259.  36.  41.  79. 286.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.96895  -6.0476   -6.00519  -5.98338\n",
      "  -5.97357  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56471 3.18076 2.7032  3.43189 2.3972  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05674 0.10436 0.11348 0.26241 0.03647 0.04154 0.08004 0.28977 0.\n",
      " 0.00203 0.00405 0.00507 0.00405 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 259.  36.  41.  79. 286.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.151 0.139 0.1   0.076 0.125 0.101 0.168 0.083 0.    0.015 0.004 0.014\n",
      " 0.006 0.003 0.014 0.001]\n",
      "Q_est = -6.20\n",
      "\n",
      "-> i_step = 4040\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -0.41\n",
      "new_state = [1 3]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 286.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 286.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97357  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56338 3.18076 2.7032  3.43189 2.3972  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05668 0.10425 0.11336 0.26316 0.03644 0.0415  0.07996 0.28947 0.\n",
      " 0.00202 0.00405 0.00506 0.00405 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 260.  36.  41.  79. 286.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.137 0.145 0.095 0.094 0.117 0.114 0.161 0.087 0.    0.009 0.006 0.018\n",
      " 0.007 0.001 0.007 0.002]\n",
      "Q_est = -6.17\n",
      "\n",
      "-> i_step = 4041\n",
      "cur_state = [1 3]\n",
      "action = 5\n",
      "reward = -0.09\n",
      "new_state = [2 5]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 286.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 286.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97357  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56338 3.18076 2.7032  3.43189 2.3972  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05668 0.10425 0.11336 0.26316 0.03644 0.0415  0.07996 0.28947 0.\n",
      " 0.00202 0.00405 0.00506 0.00405 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 260.  36.  41.  79. 286.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.135 0.142 0.086 0.105 0.118 0.101 0.138 0.098 0.001 0.012 0.014 0.01\n",
      " 0.003 0.006 0.027 0.004]\n",
      "Q_est = -6.31\n",
      "\n",
      "-> i_step = 4042\n",
      "cur_state = [2 5]\n",
      "action = 6\n",
      "reward = -1.41\n",
      "new_state = [3 6]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 286.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 286.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97357  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56338 3.18076 2.7032  3.43189 2.3972  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05668 0.10425 0.11336 0.26316 0.03644 0.0415  0.07996 0.28947 0.\n",
      " 0.00202 0.00405 0.00506 0.00405 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 260.  36.  41.  79. 286.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14 15]\n",
      "probs = [0.149 0.16  0.099 0.075 0.12  0.099 0.157 0.09  0.    0.008 0.01  0.014\n",
      " 0.003 0.    0.015 0.001]\n",
      "Q_est = -6.19\n",
      "\n",
      "-> i_step = 4043\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 286.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 286.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97357  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56338 3.18076 2.7032  3.43189 2.3972  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05668 0.10425 0.11336 0.26316 0.03644 0.0415  0.07996 0.28947 0.\n",
      " 0.00202 0.00405 0.00506 0.00405 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 260.  36.  41.  79. 286.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.143 0.124 0.082 0.096 0.13  0.122 0.164 0.078 0.    0.011 0.006 0.015\n",
      " 0.002 0.003 0.022 0.002]\n",
      "Q_est = -6.25\n",
      "\n",
      "-> i_step = 4044\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 1.98\n",
      "new_state = [1 7]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 287.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 287.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97254  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56338 3.18076 2.7032  3.43189 2.39309 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05662 0.10415 0.11325 0.26289 0.0364  0.04146 0.07988 0.29019 0.\n",
      " 0.00202 0.00404 0.00506 0.00404 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 260.  36.  41.  79. 287.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "probs = [0.162 0.136 0.099 0.085 0.132 0.101 0.129 0.103 0.001 0.012 0.006 0.009\n",
      " 0.006 0.003 0.016 0.   ]\n",
      "Q_est = -6.19\n",
      "\n",
      "-> i_step = 4045\n",
      "cur_state = [1 7]\n",
      "action = 6\n",
      "reward = 0.62\n",
      "new_state = [2 6]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 287.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 287.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97254  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56338 3.18076 2.7032  3.43189 2.39309 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05662 0.10415 0.11325 0.26289 0.0364  0.04146 0.07988 0.29019 0.\n",
      " 0.00202 0.00404 0.00506 0.00404 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 260.  36.  41.  79. 287.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.139 0.144 0.094 0.084 0.134 0.103 0.142 0.088 0.    0.019 0.006 0.018\n",
      " 0.007 0.003 0.016 0.003]\n",
      "Q_est = -6.26\n",
      "\n",
      "-> i_step = 4046\n",
      "cur_state = [2 6]\n",
      "action = 5\n",
      "reward = -1.08\n",
      "new_state = [3 5]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 287.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 287.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97254  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56338 3.18076 2.7032  3.43189 2.39309 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05662 0.10415 0.11325 0.26289 0.0364  0.04146 0.07988 0.29019 0.\n",
      " 0.00202 0.00404 0.00506 0.00404 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 260.  36.  41.  79. 287.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.156 0.179 0.086 0.067 0.13  0.106 0.158 0.059 0.001 0.012 0.009 0.011\n",
      " 0.004 0.003 0.015 0.004]\n",
      "Q_est = -6.22\n",
      "\n",
      "-> i_step = 4047\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 287.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 287.   7.   2.   4.   5.   4.   6.\n",
      "   6.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97254  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.22733 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56338 3.18076 2.7032  3.43189 2.39309 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.5719  3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05662 0.10415 0.11325 0.26289 0.0364  0.04146 0.07988 0.29019 0.\n",
      " 0.00202 0.00404 0.00506 0.00404 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 260.  36.  41.  79. 287.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.128 0.146 0.09  0.102 0.125 0.106 0.155 0.096 0.    0.008 0.007 0.008\n",
      " 0.001 0.003 0.02  0.005]\n",
      "Q_est = -6.22\n",
      "\n",
      "-> i_step = 4048\n",
      "cur_state = [0 0]\n",
      "action = 14\n",
      "reward = -6.68\n",
      "new_state = [ 1 14]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 287.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 287.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97254  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56338 3.18076 2.7032  3.43189 2.39309 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05662 0.10415 0.11325 0.26289 0.0364  0.04146 0.07988 0.29019 0.\n",
      " 0.00202 0.00404 0.00506 0.00404 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 260.  36.  41.  79. 287.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.159 0.153 0.091 0.092 0.14  0.086 0.14  0.084 0.001 0.015 0.003 0.012\n",
      " 0.003 0.001 0.017 0.003]\n",
      "Q_est = -6.22\n",
      "\n",
      "-> i_step = 4049\n",
      "cur_state = [ 1 14]\n",
      "action = 12\n",
      "reward = -6.38\n",
      "new_state = [ 2 12]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 287.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 287.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97254  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56338 3.18076 2.7032  3.43189 2.39309 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05662 0.10415 0.11325 0.26289 0.0364  0.04146 0.07988 0.29019 0.\n",
      " 0.00202 0.00404 0.00506 0.00404 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 260.  36.  41.  79. 287.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.14  0.148 0.079 0.076 0.12  0.137 0.15  0.095 0.002 0.017 0.009 0.011\n",
      " 0.004 0.001 0.01  0.001]\n",
      "Q_est = -6.18\n",
      "\n",
      "-> i_step = 4050\n",
      "cur_state = [ 2 12]\n",
      "action = 13\n",
      "reward = -4.92\n",
      "new_state = [ 3 13]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 287.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 287.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97254  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56338 3.18076 2.7032  3.43189 2.39309 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05662 0.10415 0.11325 0.26289 0.0364  0.04146 0.07988 0.29019 0.\n",
      " 0.00202 0.00404 0.00506 0.00404 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 260.  36.  41.  79. 287.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.139 0.147 0.069 0.092 0.146 0.108 0.152 0.081 0.    0.021 0.007 0.015\n",
      " 0.005 0.002 0.012 0.004]\n",
      "Q_est = -6.23\n",
      "\n",
      "-> i_step = 4051\n",
      "cur_state = [ 3 13]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 287.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 287.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97254  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56338 3.18076 2.7032  3.43189 2.39309 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.97\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05662 0.10415 0.11325 0.26289 0.0364  0.04146 0.07988 0.29019 0.\n",
      " 0.00202 0.00404 0.00506 0.00404 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 260.  36.  41.  79. 287.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.128 0.143 0.083 0.102 0.13  0.11  0.155 0.082 0.    0.016 0.011 0.019\n",
      " 0.004 0.003 0.011 0.003]\n",
      "Q_est = -6.23\n",
      "\n",
      "-> i_step = 4052\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 0.84\n",
      "new_state = [1 7]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 288.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 288.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97546  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56338 3.18076 2.7032  3.43189 2.38944 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.98\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05657 0.10404 0.11313 0.26263 0.03636 0.04141 0.0798  0.29091 0.\n",
      " 0.00202 0.00404 0.00505 0.00404 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 260.  36.  41.  79. 288.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.158 0.131 0.075 0.104 0.106 0.114 0.158 0.085 0.001 0.014 0.013 0.015\n",
      " 0.008 0.001 0.014 0.003]\n",
      "Q_est = -6.25\n",
      "\n",
      "-> i_step = 4053\n",
      "cur_state = [1 7]\n",
      "action = 6\n",
      "reward = -0.30\n",
      "new_state = [2 6]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 288.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 288.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97546  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56338 3.18076 2.7032  3.43189 2.38944 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.98\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05657 0.10404 0.11313 0.26263 0.03636 0.04141 0.0798  0.29091 0.\n",
      " 0.00202 0.00404 0.00505 0.00404 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 260.  36.  41.  79. 288.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.142 0.128 0.097 0.1   0.136 0.087 0.162 0.086 0.    0.016 0.013 0.015\n",
      " 0.005 0.001 0.009 0.003]\n",
      "Q_est = -6.21\n",
      "\n",
      "-> i_step = 4054\n",
      "cur_state = [2 6]\n",
      "action = 5\n",
      "reward = -0.55\n",
      "new_state = [3 5]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 288.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 288.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97546  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56338 3.18076 2.7032  3.43189 2.38944 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.98\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05657 0.10404 0.11313 0.26263 0.03636 0.04141 0.0798  0.29091 0.\n",
      " 0.00202 0.00404 0.00505 0.00404 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 260.  36.  41.  79. 288.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.165 0.131 0.099 0.089 0.122 0.09  0.174 0.078 0.    0.015 0.004 0.015\n",
      " 0.004 0.004 0.007 0.003]\n",
      "Q_est = -6.18\n",
      "\n",
      "-> i_step = 4055\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 288.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 112. 260.  36.  41.  79. 288.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.97517  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97546  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45803 2.56338 3.18076 2.7032  3.43189 2.38944 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.98\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05657 0.10404 0.11313 0.26263 0.03636 0.04141 0.0798  0.29091 0.\n",
      " 0.00202 0.00404 0.00505 0.00404 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 112. 260.  36.  41.  79. 288.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.128 0.159 0.1   0.076 0.138 0.123 0.153 0.083 0.    0.011 0.007 0.008\n",
      " 0.004 0.002 0.007 0.001]\n",
      "Q_est = -6.13\n",
      "\n",
      "-> i_step = 4056\n",
      "cur_state = [0 0]\n",
      "action = 2\n",
      "reward = -0.26\n",
      "new_state = [1 2]\n",
      "[ 56. 103. 113. 260.  36.  41.  79. 288.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 113. 260.  36.  41.  79. 288.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.99258  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97546  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45405 2.56338 3.18076 2.7032  3.43189 2.38944 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.98\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05651 0.10394 0.11403 0.26236 0.03633 0.04137 0.07972 0.29062 0.\n",
      " 0.00202 0.00404 0.00505 0.00404 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 113. 260.  36.  41.  79. 288.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.129 0.174 0.084 0.089 0.144 0.106 0.131 0.093 0.    0.017 0.009 0.009\n",
      " 0.005 0.003 0.006 0.001]\n",
      "Q_est = -6.15\n",
      "\n",
      "-> i_step = 4057\n",
      "cur_state = [1 2]\n",
      "action = 3\n",
      "reward = -1.50\n",
      "new_state = [2 3]\n",
      "[ 56. 103. 113. 260.  36.  41.  79. 288.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 113. 260.  36.  41.  79. 288.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.99258  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97546  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45405 2.56338 3.18076 2.7032  3.43189 2.38944 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.98\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05651 0.10394 0.11403 0.26236 0.03633 0.04137 0.07972 0.29062 0.\n",
      " 0.00202 0.00404 0.00505 0.00404 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 113. 260.  36.  41.  79. 288.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.124 0.148 0.097 0.085 0.147 0.1   0.154 0.096 0.    0.013 0.008 0.012\n",
      " 0.002 0.002 0.008 0.004]\n",
      "Q_est = -6.17\n",
      "\n",
      "-> i_step = 4058\n",
      "cur_state = [2 3]\n",
      "action = 5\n",
      "reward = -1.68\n",
      "new_state = [3 5]\n",
      "[ 56. 103. 113. 260.  36.  41.  79. 288.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 113. 260.  36.  41.  79. 288.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.99258  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97546  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45405 2.56338 3.18076 2.7032  3.43189 2.38944 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.98\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05651 0.10394 0.11403 0.26236 0.03633 0.04137 0.07972 0.29062 0.\n",
      " 0.00202 0.00404 0.00505 0.00404 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 113. 260.  36.  41.  79. 288.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.134 0.155 0.083 0.106 0.152 0.087 0.154 0.091 0.    0.007 0.006 0.012\n",
      " 0.003 0.001 0.009 0.   ]\n",
      "Q_est = -6.14\n",
      "\n",
      "-> i_step = 4059\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 56. 103. 113. 260.  36.  41.  79. 288.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 113. 260.  36.  41.  79. 288.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.99258  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97546  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45405 2.56338 3.18076 2.7032  3.43189 2.38944 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.98\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05651 0.10394 0.11403 0.26236 0.03633 0.04137 0.07972 0.29062 0.\n",
      " 0.00202 0.00404 0.00505 0.00404 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 113. 260.  36.  41.  79. 288.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.139 0.14  0.072 0.113 0.15  0.111 0.139 0.08  0.    0.011 0.009 0.011\n",
      " 0.005 0.003 0.012 0.005]\n",
      "Q_est = -6.22\n",
      "\n",
      "-> i_step = 4060\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 0.75\n",
      "new_state = [1 7]\n",
      "[ 56. 103. 113. 260.  36.  41.  79. 289.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 113. 260.  36.  41.  79. 289.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.99258  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97872  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45405 2.56338 3.18076 2.7032  3.43189 2.38594 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.98\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05645 0.10383 0.11391 0.2621  0.03629 0.04133 0.07964 0.29133 0.\n",
      " 0.00202 0.00403 0.00504 0.00403 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 113. 260.  36.  41.  79. 289.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.13  0.147 0.091 0.094 0.135 0.106 0.165 0.081 0.    0.011 0.009 0.011\n",
      " 0.008 0.001 0.006 0.005]\n",
      "Q_est = -6.18\n",
      "\n",
      "-> i_step = 4061\n",
      "cur_state = [1 7]\n",
      "action = 7\n",
      "reward = -1.49\n",
      "new_state = [2 7]\n",
      "[ 56. 103. 113. 260.  36.  41.  79. 289.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 113. 260.  36.  41.  79. 289.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.99258  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97872  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45405 2.56338 3.18076 2.7032  3.43189 2.38594 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.98\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05645 0.10383 0.11391 0.2621  0.03629 0.04133 0.07964 0.29133 0.\n",
      " 0.00202 0.00403 0.00504 0.00403 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 113. 260.  36.  41.  79. 289.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.137 0.118 0.095 0.094 0.144 0.127 0.139 0.083 0.    0.011 0.007 0.017\n",
      " 0.004 0.005 0.017 0.002]\n",
      "Q_est = -6.25\n",
      "\n",
      "-> i_step = 4062\n",
      "cur_state = [2 7]\n",
      "action = 7\n",
      "reward = 0.92\n",
      "new_state = [3 7]\n",
      "[ 56. 103. 113. 260.  36.  41.  79. 289.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 113. 260.  36.  41.  79. 289.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.99258  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97872  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45405 2.56338 3.18076 2.7032  3.43189 2.38594 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.98\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05645 0.10383 0.11391 0.2621  0.03629 0.04133 0.07964 0.29133 0.\n",
      " 0.00202 0.00403 0.00504 0.00403 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 113. 260.  36.  41.  79. 289.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.131 0.149 0.091 0.092 0.145 0.092 0.156 0.084 0.001 0.017 0.01  0.016\n",
      " 0.003 0.004 0.008 0.001]\n",
      "Q_est = -6.19\n",
      "\n",
      "-> i_step = 4063\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 56. 103. 113. 260.  36.  41.  79. 289.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 113. 260.  36.  41.  79. 289.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.99258  -5.9774   -6.0476   -6.00519  -5.98338\n",
      "  -5.97872  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45405 2.56338 3.18076 2.7032  3.43189 2.38594 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.98\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05645 0.10383 0.11391 0.2621  0.03629 0.04133 0.07964 0.29133 0.\n",
      " 0.00202 0.00403 0.00504 0.00403 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 113. 260.  36.  41.  79. 289.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.148 0.122 0.085 0.106 0.134 0.114 0.142 0.087 0.    0.015 0.007 0.015\n",
      " 0.004 0.003 0.015 0.003]\n",
      "Q_est = -6.23\n",
      "\n",
      "-> i_step = 4064\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 0.81\n",
      "new_state = [1 3]\n",
      "[ 56. 103. 113. 261.  36.  41.  79. 289.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 113. 261.  36.  41.  79. 289.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.99258  -5.98112  -6.0476   -6.00519  -5.98338\n",
      "  -5.97872  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45405 2.55917 3.18076 2.7032  3.43189 2.38594 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.98\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05639 0.10373 0.1138  0.26284 0.03625 0.04129 0.07956 0.29104 0.\n",
      " 0.00201 0.00403 0.00504 0.00403 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 113. 261.  36.  41.  79. 289.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.148 0.144 0.078 0.093 0.13  0.103 0.146 0.088 0.    0.016 0.009 0.018\n",
      " 0.006 0.003 0.014 0.004]\n",
      "Q_est = -6.26\n",
      "\n",
      "-> i_step = 4065\n",
      "cur_state = [1 3]\n",
      "action = 5\n",
      "reward = -0.09\n",
      "new_state = [2 5]\n",
      "[ 56. 103. 113. 261.  36.  41.  79. 289.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 113. 261.  36.  41.  79. 289.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.99258  -5.98112  -6.0476   -6.00519  -5.98338\n",
      "  -5.97872  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45405 2.55917 3.18076 2.7032  3.43189 2.38594 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.98\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05639 0.10373 0.1138  0.26284 0.03625 0.04129 0.07956 0.29104 0.\n",
      " 0.00201 0.00403 0.00504 0.00403 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 113. 261.  36.  41.  79. 289.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14 15]\n",
      "probs = [0.131 0.154 0.074 0.104 0.151 0.109 0.162 0.064 0.    0.011 0.009 0.012\n",
      " 0.007 0.    0.01  0.002]\n",
      "Q_est = -6.18\n",
      "\n",
      "-> i_step = 4066\n",
      "cur_state = [2 5]\n",
      "action = 6\n",
      "reward = -1.53\n",
      "new_state = [3 6]\n",
      "[ 56. 103. 113. 261.  36.  41.  79. 289.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 113. 261.  36.  41.  79. 289.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.99258  -5.98112  -6.0476   -6.00519  -5.98338\n",
      "  -5.97872  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45405 2.55917 3.18076 2.7032  3.43189 2.38594 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.98\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05639 0.10373 0.1138  0.26284 0.03625 0.04129 0.07956 0.29104 0.\n",
      " 0.00201 0.00403 0.00504 0.00403 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 113. 261.  36.  41.  79. 289.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.163 0.135 0.081 0.09  0.145 0.088 0.158 0.085 0.    0.013 0.01  0.009\n",
      " 0.005 0.002 0.01  0.006]\n",
      "Q_est = -6.20\n",
      "\n",
      "-> i_step = 4067\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 56. 103. 113. 261.  36.  41.  79. 289.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 113. 261.  36.  41.  79. 289.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.99258  -5.98112  -6.0476   -6.00519  -5.98338\n",
      "  -5.97872  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45405 2.55917 3.18076 2.7032  3.43189 2.38594 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.98\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05639 0.10373 0.1138  0.26284 0.03625 0.04129 0.07956 0.29104 0.\n",
      " 0.00201 0.00403 0.00504 0.00403 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 113. 261.  36.  41.  79. 289.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.141 0.137 0.086 0.082 0.126 0.112 0.159 0.102 0.001 0.021 0.008 0.013\n",
      " 0.003 0.001 0.006 0.002]\n",
      "Q_est = -6.17\n",
      "\n",
      "-> i_step = 4068\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = -2.19\n",
      "new_state = [1 7]\n",
      "[ 56. 103. 113. 261.  36.  41.  79. 290.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 113. 261.  36.  41.  79. 290.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.99258  -5.98112  -6.0476   -6.00519  -5.98338\n",
      "  -5.99211  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45405 2.55917 3.18076 2.7032  3.43189 2.39267 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.99\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05634 0.10362 0.11368 0.26258 0.03622 0.04125 0.07948 0.29175 0.\n",
      " 0.00201 0.00402 0.00503 0.00402 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 113. 261.  36.  41.  79. 290.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.04\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.145 0.164 0.08  0.103 0.113 0.092 0.167 0.09  0.    0.011 0.008 0.015\n",
      " 0.002 0.003 0.004 0.003]\n",
      "Q_est = -6.15\n",
      "\n",
      "-> i_step = 4069\n",
      "cur_state = [1 7]\n",
      "action = 6\n",
      "reward = -0.75\n",
      "new_state = [2 6]\n",
      "[ 56. 103. 113. 261.  36.  41.  79. 290.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 113. 261.  36.  41.  79. 290.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.99258  -5.98112  -6.0476   -6.00519  -5.98338\n",
      "  -5.99211  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45405 2.55917 3.18076 2.7032  3.43189 2.39267 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.99\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05634 0.10362 0.11368 0.26258 0.03622 0.04125 0.07948 0.29175 0.\n",
      " 0.00201 0.00402 0.00503 0.00402 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 113. 261.  36.  41.  79. 290.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.04\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.16  0.121 0.088 0.092 0.129 0.103 0.165 0.087 0.    0.022 0.009 0.005\n",
      " 0.003 0.001 0.013 0.002]\n",
      "Q_est = -6.18\n",
      "\n",
      "-> i_step = 4070\n",
      "cur_state = [2 6]\n",
      "action = 5\n",
      "reward = -1.10\n",
      "new_state = [3 5]\n",
      "[ 56. 103. 113. 261.  36.  41.  79. 290.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 113. 261.  36.  41.  79. 290.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.99258  -5.98112  -6.0476   -6.00519  -5.98338\n",
      "  -5.99211  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45405 2.55917 3.18076 2.7032  3.43189 2.39267 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.99\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05634 0.10362 0.11368 0.26258 0.03622 0.04125 0.07948 0.29175 0.\n",
      " 0.00201 0.00402 0.00503 0.00402 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 113. 261.  36.  41.  79. 290.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.04\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.134 0.154 0.099 0.073 0.126 0.104 0.169 0.085 0.    0.013 0.008 0.013\n",
      " 0.004 0.003 0.012 0.003]\n",
      "Q_est = -6.21\n",
      "\n",
      "-> i_step = 4071\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 56. 103. 113. 261.  36.  41.  79. 290.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 56. 103. 113. 261.  36.  41.  79. 290.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -5.979    -5.99221  -5.99258  -5.98112  -6.0476   -6.00519  -5.98338\n",
      "  -5.99211  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31355 3.24156 2.45405 2.55917 3.18076 2.7032  3.43189 2.39267 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.99\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05634 0.10362 0.11368 0.26258 0.03622 0.04125 0.07948 0.29175 0.\n",
      " 0.00201 0.00402 0.00503 0.00402 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 56. 103. 113. 261.  36.  41.  79. 290.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.04\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.131 0.142 0.09  0.093 0.135 0.087 0.166 0.085 0.    0.02  0.008 0.02\n",
      " 0.005 0.004 0.012 0.002]\n",
      "Q_est = -6.24\n",
      "\n",
      "-> i_step = 4072\n",
      "cur_state = [0 0]\n",
      "action = 0\n",
      "reward = -2.79\n",
      "new_state = [1 0]\n",
      "[ 57. 103. 113. 261.  36.  41.  79. 290.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 103. 113. 261.  36.  41.  79. 290.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -5.99221  -5.99258  -5.98112  -6.0476   -6.00519  -5.98338\n",
      "  -5.99211  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24156 2.45405 2.55917 3.18076 2.7032  3.43189 2.39267 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.99\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05729 0.10352 0.11357 0.26231 0.03618 0.04121 0.0794  0.29146 0.\n",
      " 0.00201 0.00402 0.00503 0.00402 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 103. 113. 261.  36.  41.  79. 290.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.04\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.141 0.149 0.099 0.09  0.13  0.103 0.146 0.075 0.    0.019 0.007 0.017\n",
      " 0.003 0.003 0.016 0.002]\n",
      "Q_est = -6.26\n",
      "\n",
      "-> i_step = 4073\n",
      "cur_state = [1 0]\n",
      "action = 7\n",
      "reward = 1.29\n",
      "new_state = [2 7]\n",
      "[ 57. 103. 113. 261.  36.  41.  79. 290.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 103. 113. 261.  36.  41.  79. 290.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -5.99221  -5.99258  -5.98112  -6.0476   -6.00519  -5.98338\n",
      "  -5.99211  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24156 2.45405 2.55917 3.18076 2.7032  3.43189 2.39267 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -5.99\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05729 0.10352 0.11357 0.26231 0.03618 0.04121 0.0794  0.29146 0.\n",
      " 0.00201 0.00402 0.00503 0.00402 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 103. 113. 261.  36.  41.  79. 290.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.04\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.152 0.135 0.082 0.087 0.132 0.086 0.162 0.093 0.001 0.013 0.005 0.017\n",
      " 0.013 0.006 0.011 0.005]\n",
      "Q_est = -6.28\n",
      "\n",
      "-> i_step = 4074\n",
      "cur_state = [2 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q_est = -6.21\n",
      "\n",
      "-> i_step = 4171\n",
      "cur_state = [3 3]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 57. 105. 116. 268.  36.  42.  82. 298.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 116. 268.  36.  42.  82. 298.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.03847  -6.03462  -6.0476   -6.06227  -6.05098\n",
      "  -6.03812  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.4407  2.54973 3.18076 2.69571 3.40406 2.37936 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.04\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05594 0.10304 0.11384 0.263   0.03533 0.04122 0.08047 0.29244 0.\n",
      " 0.00196 0.00393 0.00491 0.00393 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 116. 268.  36.  42.  82. 298.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.09\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.146 0.141 0.097 0.078 0.142 0.098 0.142 0.087 0.    0.015 0.007 0.019\n",
      " 0.006 0.003 0.014 0.005]\n",
      "Q_est = -6.32\n",
      "\n",
      "-> i_step = 4172\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -2.42\n",
      "new_state = [1 3]\n",
      "[ 57. 105. 116. 269.  36.  42.  82. 298.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 116. 269.  36.  42.  82. 298.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.03847  -6.05011  -6.0476   -6.06227  -6.05098\n",
      "  -6.03812  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.4407  2.55759 3.18076 2.69571 3.40406 2.37936 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.04\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05588 0.10294 0.11373 0.26373 0.03529 0.04118 0.08039 0.29216 0.\n",
      " 0.00196 0.00392 0.0049  0.00392 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 116. 269.  36.  42.  82. 298.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.09\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.134 0.164 0.076 0.084 0.141 0.101 0.158 0.077 0.001 0.018 0.006 0.013\n",
      " 0.008 0.004 0.012 0.003]\n",
      "Q_est = -6.28\n",
      "\n",
      "-> i_step = 4173\n",
      "cur_state = [1 3]\n",
      "action = 1\n",
      "reward = -0.48\n",
      "new_state = [2 1]\n",
      "[ 57. 105. 116. 269.  36.  42.  82. 298.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 116. 269.  36.  42.  82. 298.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.03847  -6.05011  -6.0476   -6.06227  -6.05098\n",
      "  -6.03812  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.4407  2.55759 3.18076 2.69571 3.40406 2.37936 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.04\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05588 0.10294 0.11373 0.26373 0.03529 0.04118 0.08039 0.29216 0.\n",
      " 0.00196 0.00392 0.0049  0.00392 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 116. 269.  36.  42.  82. 298.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.09\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14 15]\n",
      "probs = [0.13  0.143 0.078 0.091 0.135 0.116 0.158 0.087 0.    0.016 0.01  0.016\n",
      " 0.005 0.    0.011 0.004]\n",
      "Q_est = -6.28\n",
      "\n",
      "-> i_step = 4174\n",
      "cur_state = [2 1]\n",
      "action = 1\n",
      "reward = 1.63\n",
      "new_state = [3 1]\n",
      "[ 57. 105. 116. 269.  36.  42.  82. 298.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 116. 269.  36.  42.  82. 298.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.03847  -6.05011  -6.0476   -6.06227  -6.05098\n",
      "  -6.03812  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.4407  2.55759 3.18076 2.69571 3.40406 2.37936 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.04\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05588 0.10294 0.11373 0.26373 0.03529 0.04118 0.08039 0.29216 0.\n",
      " 0.00196 0.00392 0.0049  0.00392 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 116. 269.  36.  42.  82. 298.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.09\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.137 0.149 0.082 0.096 0.144 0.103 0.151 0.08  0.    0.018 0.01  0.012\n",
      " 0.003 0.005 0.008 0.002]\n",
      "Q_est = -6.24\n",
      "\n",
      "-> i_step = 4175\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 57. 105. 116. 269.  36.  42.  82. 298.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 116. 269.  36.  42.  82. 298.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.03847  -6.05011  -6.0476   -6.06227  -6.05098\n",
      "  -6.03812  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.4407  2.55759 3.18076 2.69571 3.40406 2.37936 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.04\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05588 0.10294 0.11373 0.26373 0.03529 0.04118 0.08039 0.29216 0.\n",
      " 0.00196 0.00392 0.0049  0.00392 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 116. 269.  36.  42.  82. 298.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.09\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.167 0.135 0.087 0.093 0.133 0.112 0.144 0.067 0.    0.015 0.009 0.015\n",
      " 0.002 0.002 0.015 0.004]\n",
      "Q_est = -6.29\n",
      "\n",
      "-> i_step = 4176\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = -0.71\n",
      "new_state = [1 7]\n",
      "[ 57. 105. 116. 269.  36.  42.  82. 299.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 116. 269.  36.  42.  82. 299.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.03847  -6.05011  -6.0476   -6.06227  -6.05098\n",
      "  -6.04605  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.4407  2.55759 3.18076 2.69571 3.40406 2.37932 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05583 0.10284 0.11361 0.26347 0.03526 0.04114 0.08031 0.29285 0.\n",
      " 0.00196 0.00392 0.0049  0.00392 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 116. 269.  36.  42.  82. 299.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.09\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.142 0.126 0.094 0.087 0.136 0.11  0.157 0.084 0.    0.015 0.008 0.02\n",
      " 0.001 0.003 0.013 0.004]\n",
      "Q_est = -6.30\n",
      "\n",
      "-> i_step = 4177\n",
      "cur_state = [1 7]\n",
      "action = 1\n",
      "reward = 2.19\n",
      "new_state = [2 1]\n",
      "[ 57. 105. 116. 269.  36.  42.  82. 299.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 116. 269.  36.  42.  82. 299.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.03847  -6.05011  -6.0476   -6.06227  -6.05098\n",
      "  -6.04605  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.4407  2.55759 3.18076 2.69571 3.40406 2.37932 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05583 0.10284 0.11361 0.26347 0.03526 0.04114 0.08031 0.29285 0.\n",
      " 0.00196 0.00392 0.0049  0.00392 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 116. 269.  36.  42.  82. 299.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.09\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.148 0.119 0.087 0.088 0.136 0.106 0.176 0.085 0.    0.017 0.013 0.01\n",
      " 0.002 0.003 0.007 0.003]\n",
      "Q_est = -6.23\n",
      "\n",
      "-> i_step = 4178\n",
      "cur_state = [2 1]\n",
      "action = 1\n",
      "reward = 0.12\n",
      "new_state = [3 1]\n",
      "[ 57. 105. 116. 269.  36.  42.  82. 299.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 116. 269.  36.  42.  82. 299.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.03847  -6.05011  -6.0476   -6.06227  -6.05098\n",
      "  -6.04605  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.4407  2.55759 3.18076 2.69571 3.40406 2.37932 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05583 0.10284 0.11361 0.26347 0.03526 0.04114 0.08031 0.29285 0.\n",
      " 0.00196 0.00392 0.0049  0.00392 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 116. 269.  36.  42.  82. 299.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.09\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.155 0.16  0.079 0.085 0.121 0.095 0.159 0.09  0.    0.016 0.007 0.011\n",
      " 0.009 0.003 0.009 0.001]\n",
      "Q_est = -6.24\n",
      "\n",
      "-> i_step = 4179\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 57. 105. 116. 269.  36.  42.  82. 299.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 116. 269.  36.  42.  82. 299.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.03847  -6.05011  -6.0476   -6.06227  -6.05098\n",
      "  -6.04605  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.4407  2.55759 3.18076 2.69571 3.40406 2.37932 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05583 0.10284 0.11361 0.26347 0.03526 0.04114 0.08031 0.29285 0.\n",
      " 0.00196 0.00392 0.0049  0.00392 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 116. 269.  36.  42.  82. 299.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.09\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.146 0.133 0.078 0.084 0.142 0.112 0.167 0.074 0.    0.022 0.006 0.008\n",
      " 0.005 0.003 0.015 0.005]\n",
      "Q_est = -6.29\n",
      "\n",
      "-> i_step = 4180\n",
      "cur_state = [0 0]\n",
      "action = 2\n",
      "reward = -0.37\n",
      "new_state = [1 2]\n",
      "[ 57. 105. 117. 269.  36.  42.  82. 299.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 269.  36.  42.  82. 299.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.05011  -6.0476   -6.06227  -6.05098\n",
      "  -6.04605  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55759 3.18076 2.69571 3.40406 2.37932 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05577 0.10274 0.11448 0.26321 0.03523 0.0411  0.08023 0.29256 0.\n",
      " 0.00196 0.00391 0.00489 0.00391 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 269.  36.  42.  82. 299.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.09\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.151 0.137 0.085 0.079 0.141 0.089 0.165 0.09  0.    0.016 0.006 0.018\n",
      " 0.003 0.003 0.014 0.003]\n",
      "Q_est = -6.29\n",
      "\n",
      "-> i_step = 4181\n",
      "cur_state = [1 2]\n",
      "action = 7\n",
      "reward = -1.58\n",
      "new_state = [2 7]\n",
      "[ 57. 105. 117. 269.  36.  42.  82. 299.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 269.  36.  42.  82. 299.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.05011  -6.0476   -6.06227  -6.05098\n",
      "  -6.04605  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55759 3.18076 2.69571 3.40406 2.37932 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05577 0.10274 0.11448 0.26321 0.03523 0.0411  0.08023 0.29256 0.\n",
      " 0.00196 0.00391 0.00489 0.00391 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 269.  36.  42.  82. 299.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.09\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14 15]\n",
      "probs = [0.153 0.108 0.092 0.088 0.149 0.105 0.163 0.073 0.    0.018 0.012 0.017\n",
      " 0.003 0.    0.016 0.003]\n",
      "Q_est = -6.31\n",
      "\n",
      "-> i_step = 4182\n",
      "cur_state = [2 7]\n",
      "action = 7\n",
      "reward = 0.48\n",
      "new_state = [3 7]\n",
      "[ 57. 105. 117. 269.  36.  42.  82. 299.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 269.  36.  42.  82. 299.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.05011  -6.0476   -6.06227  -6.05098\n",
      "  -6.04605  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55759 3.18076 2.69571 3.40406 2.37932 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05577 0.10274 0.11448 0.26321 0.03523 0.0411  0.08023 0.29256 0.\n",
      " 0.00196 0.00391 0.00489 0.00391 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 269.  36.  42.  82. 299.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.09\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.152 0.141 0.085 0.093 0.133 0.102 0.151 0.086 0.    0.014 0.01  0.009\n",
      " 0.006 0.004 0.01  0.004]\n",
      "Q_est = -6.26\n",
      "\n",
      "-> i_step = 4183\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 57. 105. 117. 269.  36.  42.  82. 299.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 269.  36.  42.  82. 299.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.05011  -6.0476   -6.06227  -6.05098\n",
      "  -6.04605  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55759 3.18076 2.69571 3.40406 2.37932 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05577 0.10274 0.11448 0.26321 0.03523 0.0411  0.08023 0.29256 0.\n",
      " 0.00196 0.00391 0.00489 0.00391 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 269.  36.  42.  82. 299.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.09\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.157 0.145 0.107 0.096 0.111 0.123 0.145 0.064 0.002 0.016 0.001 0.007\n",
      " 0.006 0.004 0.012 0.004]\n",
      "Q_est = -6.25\n",
      "\n",
      "-> i_step = 4184\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 1.05\n",
      "new_state = [1 7]\n",
      "[ 57. 105. 117. 269.  36.  42.  82. 300.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 269.  36.  42.  82. 300.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.05011  -6.0476   -6.06227  -6.05098\n",
      "  -6.04805  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55759 3.18076 2.69571 3.40406 2.37561 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05572 0.10264 0.11437 0.26295 0.03519 0.04106 0.08016 0.29326 0.\n",
      " 0.00196 0.00391 0.00489 0.00391 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 269.  36.  42.  82. 300.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.10\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.159 0.139 0.072 0.102 0.146 0.104 0.139 0.088 0.    0.01  0.006 0.01\n",
      " 0.006 0.003 0.01  0.006]\n",
      "Q_est = -6.26\n",
      "\n",
      "-> i_step = 4185\n",
      "cur_state = [1 7]\n",
      "action = 1\n",
      "reward = 1.54\n",
      "new_state = [2 1]\n",
      "[ 57. 105. 117. 269.  36.  42.  82. 300.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 269.  36.  42.  82. 300.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.05011  -6.0476   -6.06227  -6.05098\n",
      "  -6.04805  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55759 3.18076 2.69571 3.40406 2.37561 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05572 0.10264 0.11437 0.26295 0.03519 0.04106 0.08016 0.29326 0.\n",
      " 0.00196 0.00391 0.00489 0.00391 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 269.  36.  42.  82. 300.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.10\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.142 0.14  0.086 0.082 0.14  0.098 0.167 0.076 0.001 0.017 0.011 0.011\n",
      " 0.009 0.004 0.015 0.001]\n",
      "Q_est = -6.30\n",
      "\n",
      "-> i_step = 4186\n",
      "cur_state = [2 1]\n",
      "action = 1\n",
      "reward = 1.34\n",
      "new_state = [3 1]\n",
      "[ 57. 105. 117. 269.  36.  42.  82. 300.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 269.  36.  42.  82. 300.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.05011  -6.0476   -6.06227  -6.05098\n",
      "  -6.04805  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55759 3.18076 2.69571 3.40406 2.37561 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05572 0.10264 0.11437 0.26295 0.03519 0.04106 0.08016 0.29326 0.\n",
      " 0.00196 0.00391 0.00489 0.00391 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 269.  36.  42.  82. 300.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.10\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.149 0.167 0.09  0.108 0.126 0.092 0.141 0.078 0.    0.008 0.01  0.018\n",
      " 0.003 0.002 0.008 0.   ]\n",
      "Q_est = -6.23\n",
      "\n",
      "-> i_step = 4187\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 57. 105. 117. 269.  36.  42.  82. 300.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 269.  36.  42.  82. 300.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.05011  -6.0476   -6.06227  -6.05098\n",
      "  -6.04805  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55759 3.18076 2.69571 3.40406 2.37561 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05572 0.10264 0.11437 0.26295 0.03519 0.04106 0.08016 0.29326 0.\n",
      " 0.00196 0.00391 0.00489 0.00391 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 269.  36.  42.  82. 300.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.10\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.158 0.119 0.101 0.102 0.132 0.093 0.167 0.076 0.001 0.014 0.007 0.01\n",
      " 0.004 0.002 0.009 0.005]\n",
      "Q_est = -6.25\n",
      "\n",
      "-> i_step = 4188\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = 0.22\n",
      "new_state = [1 4]\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 300.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 300.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.05011  -6.09997  -6.06227  -6.05098\n",
      "  -6.04805  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55759 3.15318 2.69571 3.40406 2.37561 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05566 0.10254 0.11426 0.2627  0.03613 0.04102 0.08008 0.29297 0.\n",
      " 0.00195 0.00391 0.00488 0.00391 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 269.  37.  42.  82. 300.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.10\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15]\n",
      "probs = [0.147 0.145 0.091 0.091 0.122 0.105 0.153 0.092 0.001 0.013 0.008 0.02\n",
      " 0.004 0.    0.007 0.001]\n",
      "Q_est = -6.24\n",
      "\n",
      "-> i_step = 4189\n",
      "cur_state = [1 4]\n",
      "action = 2\n",
      "reward = -2.02\n",
      "new_state = [2 2]\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 300.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 300.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.05011  -6.09997  -6.06227  -6.05098\n",
      "  -6.04805  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55759 3.15318 2.69571 3.40406 2.37561 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05566 0.10254 0.11426 0.2627  0.03613 0.04102 0.08008 0.29297 0.\n",
      " 0.00195 0.00391 0.00488 0.00391 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 269.  37.  42.  82. 300.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.10\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.145 0.14  0.08  0.097 0.129 0.108 0.145 0.093 0.    0.016 0.005 0.012\n",
      " 0.005 0.002 0.016 0.007]\n",
      "Q_est = -6.32\n",
      "\n",
      "-> i_step = 4190\n",
      "cur_state = [2 2]\n",
      "action = 2\n",
      "reward = -0.68\n",
      "new_state = [3 2]\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 300.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 300.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.05011  -6.09997  -6.06227  -6.05098\n",
      "  -6.04805  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55759 3.15318 2.69571 3.40406 2.37561 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05566 0.10254 0.11426 0.2627  0.03613 0.04102 0.08008 0.29297 0.\n",
      " 0.00195 0.00391 0.00488 0.00391 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 269.  37.  42.  82. 300.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.10\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.145 0.131 0.088 0.107 0.144 0.105 0.141 0.076 0.001 0.016 0.011 0.012\n",
      " 0.004 0.002 0.014 0.003]\n",
      "Q_est = -6.29\n",
      "\n",
      "-> i_step = 4191\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 300.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 300.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.05011  -6.09997  -6.06227  -6.05098\n",
      "  -6.04805  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55759 3.15318 2.69571 3.40406 2.37561 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05566 0.10254 0.11426 0.2627  0.03613 0.04102 0.08008 0.29297 0.\n",
      " 0.00195 0.00391 0.00488 0.00391 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 269.  37.  42.  82. 300.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.10\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.153 0.144 0.098 0.095 0.131 0.123 0.139 0.072 0.    0.012 0.006 0.012\n",
      " 0.001 0.007 0.005 0.002]\n",
      "Q_est = -6.21\n",
      "\n",
      "-> i_step = 4192\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 1.19\n",
      "new_state = [1 7]\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 301.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 301.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.05011  -6.09997  -6.06227  -6.05098\n",
      "  -6.04958  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55759 3.15318 2.69571 3.40406 2.3718  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05561 0.10244 0.11415 0.26244 0.0361  0.04098 0.08    0.29366 0.\n",
      " 0.00195 0.0039  0.00488 0.0039  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 269.  37.  42.  82. 301.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.10\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.156 0.148 0.088 0.1   0.125 0.1   0.143 0.085 0.    0.013 0.01  0.013\n",
      " 0.004 0.004 0.006 0.005]\n",
      "Q_est = -6.25\n",
      "\n",
      "-> i_step = 4193\n",
      "cur_state = [1 7]\n",
      "action = 1\n",
      "reward = 0.13\n",
      "new_state = [2 1]\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 301.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 301.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.05011  -6.09997  -6.06227  -6.05098\n",
      "  -6.04958  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55759 3.15318 2.69571 3.40406 2.3718  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05561 0.10244 0.11415 0.26244 0.0361  0.04098 0.08    0.29366 0.\n",
      " 0.00195 0.0039  0.00488 0.0039  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 269.  37.  42.  82. 301.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.10\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.151 0.14  0.091 0.088 0.136 0.108 0.143 0.07  0.    0.024 0.008 0.019\n",
      " 0.005 0.003 0.012 0.002]\n",
      "Q_est = -6.31\n",
      "\n",
      "-> i_step = 4194\n",
      "cur_state = [2 1]\n",
      "action = 1\n",
      "reward = 1.72\n",
      "new_state = [3 1]\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 301.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 301.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.05011  -6.09997  -6.06227  -6.05098\n",
      "  -6.04958  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55759 3.15318 2.69571 3.40406 2.3718  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05561 0.10244 0.11415 0.26244 0.0361  0.04098 0.08    0.29366 0.\n",
      " 0.00195 0.0039  0.00488 0.0039  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 269.  37.  42.  82. 301.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.10\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.159 0.13  0.082 0.088 0.13  0.123 0.157 0.077 0.    0.012 0.007 0.017\n",
      " 0.006 0.001 0.007 0.004]\n",
      "Q_est = -6.26\n",
      "\n",
      "-> i_step = 4195\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 301.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 301.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.05011  -6.09997  -6.06227  -6.05098\n",
      "  -6.04958  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55759 3.15318 2.69571 3.40406 2.3718  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05561 0.10244 0.11415 0.26244 0.0361  0.04098 0.08    0.29366 0.\n",
      " 0.00195 0.0039  0.00488 0.0039  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 269.  37.  42.  82. 301.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.10\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.138 0.144 0.093 0.114 0.132 0.096 0.146 0.085 0.    0.015 0.006 0.015\n",
      " 0.003 0.001 0.01  0.002]\n",
      "Q_est = -6.25\n",
      "\n",
      "-> i_step = 4196\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 0.06\n",
      "new_state = [1 7]\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.05011  -6.09997  -6.06227  -6.05098\n",
      "  -6.05483  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55759 3.15318 2.69571 3.40406 2.36963 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05556 0.10234 0.11404 0.26218 0.03606 0.04094 0.07992 0.29435 0.\n",
      " 0.00195 0.0039  0.00487 0.0039  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 269.  37.  42.  82. 302.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.10\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.142 0.136 0.096 0.103 0.134 0.106 0.131 0.082 0.    0.019 0.01  0.014\n",
      " 0.007 0.003 0.014 0.003]\n",
      "Q_est = -6.31\n",
      "\n",
      "-> i_step = 4197\n",
      "cur_state = [1 7]\n",
      "action = 1\n",
      "reward = 1.03\n",
      "new_state = [2 1]\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.05011  -6.09997  -6.06227  -6.05098\n",
      "  -6.05483  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55759 3.15318 2.69571 3.40406 2.36963 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05556 0.10234 0.11404 0.26218 0.03606 0.04094 0.07992 0.29435 0.\n",
      " 0.00195 0.0039  0.00487 0.0039  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 269.  37.  42.  82. 302.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.10\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.142 0.141 0.084 0.094 0.145 0.111 0.144 0.078 0.    0.012 0.014 0.012\n",
      " 0.007 0.003 0.01  0.003]\n",
      "Q_est = -6.28\n",
      "\n",
      "-> i_step = 4198\n",
      "cur_state = [2 1]\n",
      "action = 1\n",
      "reward = -1.21\n",
      "new_state = [3 1]\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.05011  -6.09997  -6.06227  -6.05098\n",
      "  -6.05483  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55759 3.15318 2.69571 3.40406 2.36963 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05556 0.10234 0.11404 0.26218 0.03606 0.04094 0.07992 0.29435 0.\n",
      " 0.00195 0.0039  0.00487 0.0039  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 269.  37.  42.  82. 302.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.10\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.158 0.169 0.08  0.083 0.115 0.094 0.142 0.093 0.    0.017 0.008 0.014\n",
      " 0.01  0.003 0.01  0.004]\n",
      "Q_est = -6.29\n",
      "\n",
      "-> i_step = 4199\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 269.  37.  42.  82. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.05011  -6.09997  -6.06227  -6.05098\n",
      "  -6.05483  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55759 3.15318 2.69571 3.40406 2.36963 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05556 0.10234 0.11404 0.26218 0.03606 0.04094 0.07992 0.29435 0.\n",
      " 0.00195 0.0039  0.00487 0.0039  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 269.  37.  42.  82. 302.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.10\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.139 0.15  0.082 0.085 0.117 0.104 0.159 0.092 0.    0.019 0.007 0.023\n",
      " 0.004 0.004 0.012 0.003]\n",
      "Q_est = -6.32\n",
      "\n",
      "-> i_step = 4200\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -1.28\n",
      "new_state = [1 3]\n",
      "[ 57. 105. 117. 270.  37.  42.  82. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 270.  37.  42.  82. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.06128  -6.09997  -6.06227  -6.05098\n",
      "  -6.05483  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55941 3.15318 2.69571 3.40406 2.36963 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0555  0.10224 0.11392 0.2629  0.03603 0.0409  0.07984 0.29406 0.\n",
      " 0.00195 0.00389 0.00487 0.00389 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 270.  37.  42.  82. 302.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.10\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14 15]\n",
      "probs = [0.165 0.139 0.092 0.09  0.132 0.097 0.138 0.093 0.    0.018 0.007 0.011\n",
      " 0.006 0.    0.009 0.003]\n",
      "Q_est = -6.25\n",
      "\n",
      "-> i_step = 4201\n",
      "cur_state = [1 3]\n",
      "action = 5\n",
      "reward = -1.62\n",
      "new_state = [2 5]\n",
      "[ 57. 105. 117. 270.  37.  42.  82. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 270.  37.  42.  82. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.06128  -6.09997  -6.06227  -6.05098\n",
      "  -6.05483  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55941 3.15318 2.69571 3.40406 2.36963 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0555  0.10224 0.11392 0.2629  0.03603 0.0409  0.07984 0.29406 0.\n",
      " 0.00195 0.00389 0.00487 0.00389 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 270.  37.  42.  82. 302.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.10\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.156 0.148 0.084 0.11  0.128 0.095 0.152 0.077 0.    0.01  0.012 0.014\n",
      " 0.005 0.002 0.005 0.002]\n",
      "Q_est = -6.23\n",
      "\n",
      "-> i_step = 4202\n",
      "cur_state = [2 5]\n",
      "action = 2\n",
      "reward = 0.65\n",
      "new_state = [3 2]\n",
      "[ 57. 105. 117. 270.  37.  42.  82. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 270.  37.  42.  82. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.06128  -6.09997  -6.06227  -6.05098\n",
      "  -6.05483  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55941 3.15318 2.69571 3.40406 2.36963 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0555  0.10224 0.11392 0.2629  0.03603 0.0409  0.07984 0.29406 0.\n",
      " 0.00195 0.00389 0.00487 0.00389 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 270.  37.  42.  82. 302.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.10\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.156 0.132 0.082 0.085 0.139 0.096 0.169 0.077 0.    0.013 0.007 0.015\n",
      " 0.006 0.002 0.018 0.003]\n",
      "Q_est = -6.32\n",
      "\n",
      "-> i_step = 4203\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 57. 105. 117. 270.  37.  42.  82. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 270.  37.  42.  82. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.06128  -6.09997  -6.06227  -6.05098\n",
      "  -6.05483  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55941 3.15318 2.69571 3.40406 2.36963 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0555  0.10224 0.11392 0.2629  0.03603 0.0409  0.07984 0.29406 0.\n",
      " 0.00195 0.00389 0.00487 0.00389 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 270.  37.  42.  82. 302.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.10\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.149 0.13  0.086 0.089 0.134 0.106 0.15  0.095 0.    0.02  0.009 0.014\n",
      " 0.004 0.002 0.01  0.002]\n",
      "Q_est = -6.27\n",
      "\n",
      "-> i_step = 4204\n",
      "cur_state = [0 0]\n",
      "action = 6\n",
      "reward = -1.63\n",
      "new_state = [1 6]\n",
      "[ 57. 105. 117. 270.  37.  42.  83. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 270.  37.  42.  83. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.06128  -6.09997  -6.06227  -6.09608\n",
      "  -6.05483  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55941 3.15318 2.69571 3.40805 2.36963 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05545 0.10214 0.11381 0.26265 0.03599 0.04086 0.08074 0.29377 0.\n",
      " 0.00195 0.00389 0.00486 0.00389 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 270.  37.  42.  83. 302.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.152 0.132 0.074 0.1   0.119 0.094 0.172 0.097 0.    0.017 0.006 0.011\n",
      " 0.008 0.003 0.013 0.002]\n",
      "Q_est = -6.28\n",
      "\n",
      "-> i_step = 4205\n",
      "cur_state = [1 6]\n",
      "action = 3\n",
      "reward = 1.08\n",
      "new_state = [2 3]\n",
      "[ 57. 105. 117. 270.  37.  42.  83. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 270.  37.  42.  83. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.06128  -6.09997  -6.06227  -6.09608\n",
      "  -6.05483  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55941 3.15318 2.69571 3.40805 2.36963 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05545 0.10214 0.11381 0.26265 0.03599 0.04086 0.08074 0.29377 0.\n",
      " 0.00195 0.00389 0.00486 0.00389 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 270.  37.  42.  83. 302.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.133 0.141 0.09  0.097 0.124 0.11  0.156 0.092 0.    0.015 0.011 0.011\n",
      " 0.004 0.005 0.008 0.003]\n",
      "Q_est = -6.26\n",
      "\n",
      "-> i_step = 4206\n",
      "cur_state = [2 3]\n",
      "action = 5\n",
      "reward = -1.52\n",
      "new_state = [3 5]\n",
      "[ 57. 105. 117. 270.  37.  42.  83. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 270.  37.  42.  83. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.06128  -6.09997  -6.06227  -6.09608\n",
      "  -6.05483  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55941 3.15318 2.69571 3.40805 2.36963 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05545 0.10214 0.11381 0.26265 0.03599 0.04086 0.08074 0.29377 0.\n",
      " 0.00195 0.00389 0.00486 0.00389 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 270.  37.  42.  83. 302.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.136 0.126 0.08  0.103 0.146 0.105 0.153 0.087 0.    0.017 0.007 0.02\n",
      " 0.008 0.001 0.01  0.001]\n",
      "Q_est = -6.29\n",
      "\n",
      "-> i_step = 4207\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 57. 105. 117. 270.  37.  42.  83. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 270.  37.  42.  83. 302.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.06128  -6.09997  -6.06227  -6.09608\n",
      "  -6.05483  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55941 3.15318 2.69571 3.40805 2.36963 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05545 0.10214 0.11381 0.26265 0.03599 0.04086 0.08074 0.29377 0.\n",
      " 0.00195 0.00389 0.00486 0.00389 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 270.  37.  42.  83. 302.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.149 0.14  0.074 0.113 0.134 0.113 0.114 0.095 0.    0.017 0.011 0.017\n",
      " 0.008 0.003 0.01  0.002]\n",
      "Q_est = -6.30\n",
      "\n",
      "-> i_step = 4208\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 0.55\n",
      "new_state = [1 7]\n",
      "[ 57. 105. 117. 270.  37.  42.  83. 303.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 270.  37.  42.  83. 303.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.06128  -6.09997  -6.06227  -6.09608\n",
      "  -6.05846  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55941 3.15318 2.69571 3.40805 2.36655 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05539 0.10204 0.1137  0.26239 0.03596 0.04082 0.08066 0.29446 0.\n",
      " 0.00194 0.00389 0.00486 0.00389 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 270.  37.  42.  83. 303.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.14  0.133 0.101 0.109 0.134 0.093 0.141 0.08  0.    0.019 0.008 0.012\n",
      " 0.01  0.007 0.01  0.003]\n",
      "Q_est = -6.30\n",
      "\n",
      "-> i_step = 4209\n",
      "cur_state = [1 7]\n",
      "action = 1\n",
      "reward = -0.11\n",
      "new_state = [2 1]\n",
      "[ 57. 105. 117. 270.  37.  42.  83. 303.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 270.  37.  42.  83. 303.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.06128  -6.09997  -6.06227  -6.09608\n",
      "  -6.05846  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55941 3.15318 2.69571 3.40805 2.36655 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05539 0.10204 0.1137  0.26239 0.03596 0.04082 0.08066 0.29446 0.\n",
      " 0.00194 0.00389 0.00486 0.00389 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 270.  37.  42.  83. 303.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.157 0.154 0.083 0.094 0.14  0.09  0.168 0.073 0.    0.01  0.002 0.017\n",
      " 0.003 0.002 0.004 0.003]\n",
      "Q_est = -6.22\n",
      "\n",
      "-> i_step = 4210\n",
      "cur_state = [2 1]\n",
      "action = 1\n",
      "reward = -0.61\n",
      "new_state = [3 1]\n",
      "[ 57. 105. 117. 270.  37.  42.  83. 303.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 270.  37.  42.  83. 303.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.06128  -6.09997  -6.06227  -6.09608\n",
      "  -6.05846  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55941 3.15318 2.69571 3.40805 2.36655 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05539 0.10204 0.1137  0.26239 0.03596 0.04082 0.08066 0.29446 0.\n",
      " 0.00194 0.00389 0.00486 0.00389 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 270.  37.  42.  83. 303.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.157 0.138 0.079 0.089 0.135 0.118 0.145 0.078 0.    0.018 0.005 0.016\n",
      " 0.004 0.002 0.015 0.001]\n",
      "Q_est = -6.29\n",
      "\n",
      "-> i_step = 4211\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 57. 105. 117. 270.  37.  42.  83. 303.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 117. 270.  37.  42.  83. 303.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.05608  -6.06128  -6.09997  -6.06227  -6.09608\n",
      "  -6.05846  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43763 2.55941 3.15318 2.69571 3.40805 2.36655 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05539 0.10204 0.1137  0.26239 0.03596 0.04082 0.08066 0.29446 0.\n",
      " 0.00194 0.00389 0.00486 0.00389 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 117. 270.  37.  42.  83. 303.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.153 0.136 0.087 0.134 0.138 0.095 0.133 0.067 0.    0.014 0.005 0.019\n",
      " 0.007 0.003 0.007 0.002]\n",
      "Q_est = -6.27\n",
      "\n",
      "-> i_step = 4212\n",
      "cur_state = [0 0]\n",
      "action = 2\n",
      "reward = 0.31\n",
      "new_state = [1 2]\n",
      "[ 57. 105. 118. 270.  37.  42.  83. 303.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 118. 270.  37.  42.  83. 303.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.06778  -6.06128  -6.09997  -6.06227  -6.09608\n",
      "  -6.05846  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43058 2.55941 3.15318 2.69571 3.40805 2.36655 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05534 0.10194 0.11456 0.26214 0.03592 0.04078 0.08058 0.29417 0.\n",
      " 0.00194 0.00388 0.00485 0.00388 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 118. 270.  37.  42.  83. 303.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.159 0.142 0.086 0.092 0.129 0.107 0.154 0.069 0.    0.016 0.009 0.016\n",
      " 0.005 0.003 0.013 0.   ]\n",
      "Q_est = -6.29\n",
      "\n",
      "-> i_step = 4213\n",
      "cur_state = [1 2]\n",
      "action = 5\n",
      "reward = -0.40\n",
      "new_state = [2 5]\n",
      "[ 57. 105. 118. 270.  37.  42.  83. 303.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 118. 270.  37.  42.  83. 303.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.06778  -6.06128  -6.09997  -6.06227  -6.09608\n",
      "  -6.05846  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43058 2.55941 3.15318 2.69571 3.40805 2.36655 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05534 0.10194 0.11456 0.26214 0.03592 0.04078 0.08058 0.29417 0.\n",
      " 0.00194 0.00388 0.00485 0.00388 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 118. 270.  37.  42.  83. 303.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.145 0.141 0.092 0.087 0.135 0.105 0.145 0.086 0.003 0.012 0.011 0.017\n",
      " 0.007 0.002 0.011 0.001]\n",
      "Q_est = -6.30\n",
      "\n",
      "-> i_step = 4214\n",
      "cur_state = [2 5]\n",
      "action = 2\n",
      "reward = 0.67\n",
      "new_state = [3 2]\n",
      "[ 57. 105. 118. 270.  37.  42.  83. 303.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 118. 270.  37.  42.  83. 303.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.06778  -6.06128  -6.09997  -6.06227  -6.09608\n",
      "  -6.05846  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43058 2.55941 3.15318 2.69571 3.40805 2.36655 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05534 0.10194 0.11456 0.26214 0.03592 0.04078 0.08058 0.29417 0.\n",
      " 0.00194 0.00388 0.00485 0.00388 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 118. 270.  37.  42.  83. 303.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.158 0.133 0.076 0.102 0.127 0.091 0.154 0.089 0.    0.018 0.016 0.018\n",
      " 0.007 0.001 0.01  0.   ]\n",
      "Q_est = -6.29\n",
      "\n",
      "-> i_step = 4215\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 57. 105. 118. 270.  37.  42.  83. 303.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 118. 270.  37.  42.  83. 303.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.06778  -6.06128  -6.09997  -6.06227  -6.09608\n",
      "  -6.05846  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43058 2.55941 3.15318 2.69571 3.40805 2.36655 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05534 0.10194 0.11456 0.26214 0.03592 0.04078 0.08058 0.29417 0.\n",
      " 0.00194 0.00388 0.00485 0.00388 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 118. 270.  37.  42.  83. 303.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.137 0.134 0.078 0.105 0.139 0.104 0.163 0.076 0.    0.02  0.006 0.019\n",
      " 0.009 0.001 0.007 0.002]\n",
      "Q_est = -6.28\n",
      "\n",
      "-> i_step = 4216\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = -0.08\n",
      "new_state = [1 7]\n",
      "[ 57. 105. 118. 270.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 118. 270.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.06778  -6.06128  -6.09997  -6.06227  -6.09608\n",
      "  -6.06413  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43058 2.55941 3.15318 2.69571 3.40805 2.36472 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05529 0.10184 0.11445 0.26188 0.03589 0.04074 0.0805  0.29486 0.\n",
      " 0.00194 0.00388 0.00485 0.00388 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 118. 270.  37.  42.  83. 304.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.15  0.148 0.086 0.091 0.146 0.1   0.146 0.08  0.    0.015 0.008 0.017\n",
      " 0.003 0.001 0.009 0.   ]\n",
      "Q_est = -6.25\n",
      "\n",
      "-> i_step = 4217\n",
      "cur_state = [1 7]\n",
      "action = 6\n",
      "reward = -0.27\n",
      "new_state = [2 6]\n",
      "[ 57. 105. 118. 270.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 118. 270.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.06778  -6.06128  -6.09997  -6.06227  -6.09608\n",
      "  -6.06413  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43058 2.55941 3.15318 2.69571 3.40805 2.36472 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05529 0.10184 0.11445 0.26188 0.03589 0.04074 0.0805  0.29486 0.\n",
      " 0.00194 0.00388 0.00485 0.00388 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 118. 270.  37.  42.  83. 304.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.139 0.143 0.095 0.113 0.13  0.095 0.151 0.081 0.    0.013 0.007 0.01\n",
      " 0.005 0.005 0.009 0.004]\n",
      "Q_est = -6.26\n",
      "\n",
      "-> i_step = 4218\n",
      "cur_state = [2 6]\n",
      "action = 5\n",
      "reward = -2.38\n",
      "new_state = [3 5]\n",
      "[ 57. 105. 118. 270.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 118. 270.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.06778  -6.06128  -6.09997  -6.06227  -6.09608\n",
      "  -6.06413  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43058 2.55941 3.15318 2.69571 3.40805 2.36472 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05529 0.10184 0.11445 0.26188 0.03589 0.04074 0.0805  0.29486 0.\n",
      " 0.00194 0.00388 0.00485 0.00388 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 118. 270.  37.  42.  83. 304.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.152 0.145 0.076 0.101 0.135 0.084 0.15  0.083 0.001 0.016 0.01  0.015\n",
      " 0.007 0.004 0.016 0.005]\n",
      "Q_est = -6.35\n",
      "\n",
      "-> i_step = 4219\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 57. 105. 118. 270.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 105. 118. 270.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.06024  -6.06778  -6.06128  -6.09997  -6.06227  -6.09608\n",
      "  -6.06413  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.24825 2.43058 2.55941 3.15318 2.69571 3.40805 2.36472 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05529 0.10184 0.11445 0.26188 0.03589 0.04074 0.0805  0.29486 0.\n",
      " 0.00194 0.00388 0.00485 0.00388 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 105. 118. 270.  37.  42.  83. 304.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14 15]\n",
      "probs = [0.155 0.14  0.095 0.096 0.127 0.106 0.152 0.08  0.    0.013 0.005 0.017\n",
      " 0.003 0.    0.01  0.001]\n",
      "Q_est = -6.25\n",
      "\n",
      "-> i_step = 4220\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 0.52\n",
      "new_state = [1 1]\n",
      "[ 57. 106. 118. 270.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 106. 118. 270.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.07211  -6.06778  -6.06128  -6.09997  -6.06227  -6.09608\n",
      "  -6.06413  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.23518 2.43058 2.55941 3.15318 2.69571 3.40805 2.36472 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05523 0.10271 0.11434 0.26163 0.03585 0.0407  0.08043 0.29457 0.\n",
      " 0.00194 0.00388 0.00484 0.00388 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 106. 118. 270.  37.  42.  83. 304.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.143 0.135 0.084 0.101 0.132 0.105 0.139 0.094 0.    0.02  0.008 0.015\n",
      " 0.002 0.004 0.013 0.005]\n",
      "Q_est = -6.32\n",
      "\n",
      "-> i_step = 4221\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 0.92\n",
      "new_state = [2 5]\n",
      "[ 57. 106. 118. 270.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 106. 118. 270.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.07211  -6.06778  -6.06128  -6.09997  -6.06227  -6.09608\n",
      "  -6.06413  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.23518 2.43058 2.55941 3.15318 2.69571 3.40805 2.36472 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05523 0.10271 0.11434 0.26163 0.03585 0.0407  0.08043 0.29457 0.\n",
      " 0.00194 0.00388 0.00484 0.00388 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 106. 118. 270.  37.  42.  83. 304.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.143 0.148 0.088 0.098 0.126 0.105 0.14  0.092 0.    0.01  0.011 0.014\n",
      " 0.007 0.004 0.013 0.001]\n",
      "Q_est = -6.29\n",
      "\n",
      "-> i_step = 4222\n",
      "cur_state = [2 5]\n",
      "action = 2\n",
      "reward = 1.06\n",
      "new_state = [3 2]\n",
      "[ 57. 106. 118. 270.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 106. 118. 270.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.07211  -6.06778  -6.06128  -6.09997  -6.06227  -6.09608\n",
      "  -6.06413  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.23518 2.43058 2.55941 3.15318 2.69571 3.40805 2.36472 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05523 0.10271 0.11434 0.26163 0.03585 0.0407  0.08043 0.29457 0.\n",
      " 0.00194 0.00388 0.00484 0.00388 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 106. 118. 270.  37.  42.  83. 304.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "probs = [0.152 0.153 0.077 0.087 0.133 0.116 0.134 0.08  0.001 0.017 0.007 0.015\n",
      " 0.007 0.007 0.014 0.   ]\n",
      "Q_est = -6.31\n",
      "\n",
      "-> i_step = 4223\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 57. 106. 118. 270.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 106. 118. 270.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.07211  -6.06778  -6.06128  -6.09997  -6.06227  -6.09608\n",
      "  -6.06413  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.23518 2.43058 2.55941 3.15318 2.69571 3.40805 2.36472 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05523 0.10271 0.11434 0.26163 0.03585 0.0407  0.08043 0.29457 0.\n",
      " 0.00194 0.00388 0.00484 0.00388 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 106. 118. 270.  37.  42.  83. 304.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.165 0.141 0.093 0.091 0.137 0.112 0.129 0.077 0.    0.012 0.009 0.016\n",
      " 0.002 0.004 0.009 0.003]\n",
      "Q_est = -6.27\n",
      "\n",
      "-> i_step = 4224\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -0.24\n",
      "new_state = [1 3]\n",
      "[ 57. 106. 118. 271.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 106. 118. 271.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.07211  -6.06778  -6.06854  -6.09997  -6.06227  -6.09608\n",
      "  -6.06413  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.23518 2.43058 2.55747 3.15318 2.69571 3.40805 2.36472 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05518 0.10261 0.11423 0.26234 0.03582 0.04066 0.08035 0.29429 0.\n",
      " 0.00194 0.00387 0.00484 0.00387 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 106. 118. 271.  37.  42.  83. 304.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.159 0.139 0.09  0.096 0.119 0.115 0.147 0.079 0.001 0.01  0.009 0.013\n",
      " 0.008 0.003 0.005 0.007]\n",
      "Q_est = -6.28\n",
      "\n",
      "-> i_step = 4225\n",
      "cur_state = [1 3]\n",
      "action = 1\n",
      "reward = 0.24\n",
      "new_state = [2 1]\n",
      "[ 57. 106. 118. 271.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 106. 118. 271.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.07211  -6.06778  -6.06854  -6.09997  -6.06227  -6.09608\n",
      "  -6.06413  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.23518 2.43058 2.55747 3.15318 2.69571 3.40805 2.36472 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05518 0.10261 0.11423 0.26234 0.03582 0.04066 0.08035 0.29429 0.\n",
      " 0.00194 0.00387 0.00484 0.00387 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 106. 118. 271.  37.  42.  83. 304.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.14  0.136 0.096 0.083 0.118 0.11  0.162 0.089 0.    0.015 0.012 0.017\n",
      " 0.006 0.003 0.008 0.005]\n",
      "Q_est = -6.30\n",
      "\n",
      "-> i_step = 4226\n",
      "cur_state = [2 1]\n",
      "action = 1\n",
      "reward = -0.72\n",
      "new_state = [3 1]\n",
      "[ 57. 106. 118. 271.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 106. 118. 271.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.07211  -6.06778  -6.06854  -6.09997  -6.06227  -6.09608\n",
      "  -6.06413  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.23518 2.43058 2.55747 3.15318 2.69571 3.40805 2.36472 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05518 0.10261 0.11423 0.26234 0.03582 0.04066 0.08035 0.29429 0.\n",
      " 0.00194 0.00387 0.00484 0.00387 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 106. 118. 271.  37.  42.  83. 304.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.161 0.136 0.102 0.1   0.14  0.091 0.153 0.066 0.    0.014 0.006 0.011\n",
      " 0.006 0.001 0.01  0.003]\n",
      "Q_est = -6.26\n",
      "\n",
      "-> i_step = 4227\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 57. 106. 118. 271.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 106. 118. 271.  37.  42.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.07211  -6.06778  -6.06854  -6.09997  -6.06227  -6.09608\n",
      "  -6.06413  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.23518 2.43058 2.55747 3.15318 2.69571 3.40805 2.36472 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05518 0.10261 0.11423 0.26234 0.03582 0.04066 0.08035 0.29429 0.\n",
      " 0.00194 0.00387 0.00484 0.00387 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 106. 118. 271.  37.  42.  83. 304.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.11\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.147 0.139 0.081 0.093 0.126 0.109 0.152 0.099 0.    0.015 0.011 0.011\n",
      " 0.003 0.001 0.011 0.002]\n",
      "Q_est = -6.26\n",
      "\n",
      "-> i_step = 4228\n",
      "cur_state = [0 0]\n",
      "action = 5\n",
      "reward = -1.11\n",
      "new_state = [1 5]\n",
      "[ 57. 106. 118. 271.  37.  43.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 106. 118. 271.  37.  43.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.07211  -6.06778  -6.06854  -6.09997  -6.13356  -6.09608\n",
      "  -6.06413  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.23518 2.43058 2.55747 3.15318 2.70395 3.40805 2.36472 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05513 0.10251 0.11412 0.26209 0.03578 0.04159 0.08027 0.294   0.\n",
      " 0.00193 0.00387 0.00484 0.00387 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 106. 118. 271.  37.  43.  83. 304.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.148 0.162 0.076 0.081 0.137 0.114 0.139 0.08  0.001 0.013 0.008 0.019\n",
      " 0.004 0.005 0.007 0.006]\n",
      "Q_est = -6.31\n",
      "\n",
      "-> i_step = 4229\n",
      "cur_state = [1 5]\n",
      "action = 5\n",
      "reward = 0.99\n",
      "new_state = [2 5]\n",
      "[ 57. 106. 118. 271.  37.  43.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 106. 118. 271.  37.  43.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.07211  -6.06778  -6.06854  -6.09997  -6.13356  -6.09608\n",
      "  -6.06413  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.23518 2.43058 2.55747 3.15318 2.70395 3.40805 2.36472 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05513 0.10251 0.11412 0.26209 0.03578 0.04159 0.08027 0.294   0.\n",
      " 0.00193 0.00387 0.00484 0.00387 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 106. 118. 271.  37.  43.  83. 304.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.161 0.157 0.09  0.094 0.124 0.091 0.129 0.09  0.001 0.019 0.009 0.014\n",
      " 0.005 0.004 0.008 0.004]\n",
      "Q_est = -6.29\n",
      "\n",
      "-> i_step = 4230\n",
      "cur_state = [2 5]\n",
      "action = 2\n",
      "reward = -0.83\n",
      "new_state = [3 2]\n",
      "[ 57. 106. 118. 271.  37.  43.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 106. 118. 271.  37.  43.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.07211  -6.06778  -6.06854  -6.09997  -6.13356  -6.09608\n",
      "  -6.06413  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.23518 2.43058 2.55747 3.15318 2.70395 3.40805 2.36472 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05513 0.10251 0.11412 0.26209 0.03578 0.04159 0.08027 0.294   0.\n",
      " 0.00193 0.00387 0.00484 0.00387 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 106. 118. 271.  37.  43.  83. 304.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14]\n",
      "probs = [0.149 0.138 0.092 0.094 0.136 0.111 0.15  0.088 0.    0.011 0.01  0.009\n",
      " 0.003 0.    0.009 0.   ]\n",
      "Q_est = -6.22\n",
      "\n",
      "-> i_step = 4231\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 57. 106. 118. 271.  37.  43.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 106. 118. 271.  37.  43.  83. 304.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.07211  -6.06778  -6.06854  -6.09997  -6.13356  -6.09608\n",
      "  -6.06413  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.23518 2.43058 2.55747 3.15318 2.70395 3.40805 2.36472 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.06\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05513 0.10251 0.11412 0.26209 0.03578 0.04159 0.08027 0.294   0.\n",
      " 0.00193 0.00387 0.00484 0.00387 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 106. 118. 271.  37.  43.  83. 304.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.145 0.132 0.082 0.1   0.14  0.109 0.148 0.084 0.    0.015 0.006 0.014\n",
      " 0.005 0.002 0.014 0.004]\n",
      "Q_est = -6.31\n",
      "\n",
      "-> i_step = 4232\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = -1.22\n",
      "new_state = [1 7]\n",
      "[ 57. 106. 118. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 106. 118. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.07211  -6.06778  -6.06854  -6.09997  -6.13356  -6.09608\n",
      "  -6.07352  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.23518 2.43058 2.55747 3.15318 2.70395 3.40805 2.36651 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.07\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05507 0.10242 0.11401 0.26184 0.03575 0.04155 0.08019 0.29469 0.\n",
      " 0.00193 0.00386 0.00483 0.00386 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 106. 118. 271.  37.  43.  83. 305.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.15  0.148 0.087 0.097 0.141 0.089 0.141 0.082 0.    0.024 0.004 0.016\n",
      " 0.004 0.001 0.01  0.006]\n",
      "Q_est = -6.31\n",
      "\n",
      "-> i_step = 4233\n",
      "cur_state = [1 7]\n",
      "action = 7\n",
      "reward = -0.28\n",
      "new_state = [2 7]\n",
      "[ 57. 106. 118. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 106. 118. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.07211  -6.06778  -6.06854  -6.09997  -6.13356  -6.09608\n",
      "  -6.07352  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.23518 2.43058 2.55747 3.15318 2.70395 3.40805 2.36651 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.07\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05507 0.10242 0.11401 0.26184 0.03575 0.04155 0.08019 0.29469 0.\n",
      " 0.00193 0.00386 0.00483 0.00386 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 106. 118. 271.  37.  43.  83. 305.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.119 0.131 0.093 0.087 0.139 0.109 0.174 0.099 0.    0.018 0.007 0.012\n",
      " 0.004 0.001 0.006 0.001]\n",
      "Q_est = -6.23\n",
      "\n",
      "-> i_step = 4234\n",
      "cur_state = [2 7]\n",
      "action = 7\n",
      "reward = 0.28\n",
      "new_state = [3 7]\n",
      "[ 57. 106. 118. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 106. 118. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.07211  -6.06778  -6.06854  -6.09997  -6.13356  -6.09608\n",
      "  -6.07352  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.23518 2.43058 2.55747 3.15318 2.70395 3.40805 2.36651 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.07\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05507 0.10242 0.11401 0.26184 0.03575 0.04155 0.08019 0.29469 0.\n",
      " 0.00193 0.00386 0.00483 0.00386 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 106. 118. 271.  37.  43.  83. 305.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.153 0.142 0.068 0.078 0.145 0.122 0.165 0.072 0.001 0.014 0.011 0.015\n",
      " 0.003 0.003 0.005 0.003]\n",
      "Q_est = -6.26\n",
      "\n",
      "-> i_step = 4235\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 57. 106. 118. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 106. 118. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.07211  -6.06778  -6.06854  -6.09997  -6.13356  -6.09608\n",
      "  -6.07352  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.23518 2.43058 2.55747 3.15318 2.70395 3.40805 2.36651 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.07\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05507 0.10242 0.11401 0.26184 0.03575 0.04155 0.08019 0.29469 0.\n",
      " 0.00193 0.00386 0.00483 0.00386 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 106. 118. 271.  37.  43.  83. 305.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.167 0.126 0.095 0.077 0.124 0.105 0.162 0.073 0.001 0.019 0.009 0.01\n",
      " 0.001 0.01  0.019 0.002]\n",
      "Q_est = -6.34\n",
      "\n",
      "-> i_step = 4236\n",
      "cur_state = [0 0]\n",
      "action = 2\n",
      "reward = -0.16\n",
      "new_state = [1 2]\n",
      "[ 57. 106. 119. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 106. 119. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.07211  -6.0833   -6.06854  -6.09997  -6.13356  -6.09608\n",
      "  -6.07352  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.23518 2.42621 2.55747 3.15318 2.70395 3.40805 2.36651 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.07\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05502 0.10232 0.11486 0.26158 0.03571 0.04151 0.08012 0.2944  0.\n",
      " 0.00193 0.00386 0.00483 0.00386 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 106. 119. 271.  37.  43.  83. 305.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14 15]\n",
      "probs = [0.15  0.134 0.076 0.106 0.139 0.103 0.152 0.082 0.    0.012 0.01  0.028\n",
      " 0.003 0.    0.004 0.001]\n",
      "Q_est = -6.28\n",
      "\n",
      "-> i_step = 4237\n",
      "cur_state = [1 2]\n",
      "action = 0\n",
      "reward = 1.08\n",
      "new_state = [2 0]\n",
      "[ 57. 106. 119. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 106. 119. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.07211  -6.0833   -6.06854  -6.09997  -6.13356  -6.09608\n",
      "  -6.07352  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.23518 2.42621 2.55747 3.15318 2.70395 3.40805 2.36651 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.07\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05502 0.10232 0.11486 0.26158 0.03571 0.04151 0.08012 0.2944  0.\n",
      " 0.00193 0.00386 0.00483 0.00386 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 106. 119. 271.  37.  43.  83. 305.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14 15]\n",
      "probs = [0.133 0.142 0.082 0.103 0.154 0.105 0.149 0.074 0.    0.023 0.007 0.009\n",
      " 0.011 0.    0.006 0.002]\n",
      "Q_est = -6.26\n",
      "\n",
      "-> i_step = 4238\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = -0.11\n",
      "new_state = [3 7]\n",
      "[ 57. 106. 119. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 106. 119. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.07211  -6.0833   -6.06854  -6.09997  -6.13356  -6.09608\n",
      "  -6.07352  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.23518 2.42621 2.55747 3.15318 2.70395 3.40805 2.36651 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.07\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05502 0.10232 0.11486 0.26158 0.03571 0.04151 0.08012 0.2944  0.\n",
      " 0.00193 0.00386 0.00483 0.00386 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 106. 119. 271.  37.  43.  83. 305.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.15  0.147 0.063 0.114 0.154 0.081 0.133 0.089 0.    0.016 0.01  0.018\n",
      " 0.005 0.004 0.012 0.004]\n",
      "Q_est = -6.33\n",
      "\n",
      "-> i_step = 4239\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 57. 106. 119. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 57. 106. 119. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.06789  -6.07211  -6.0833   -6.06854  -6.09997  -6.13356  -6.09608\n",
      "  -6.07352  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.35104 3.23518 2.42621 2.55747 3.15318 2.70395 3.40805 2.36651 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.07\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05502 0.10232 0.11486 0.26158 0.03571 0.04151 0.08012 0.2944  0.\n",
      " 0.00193 0.00386 0.00483 0.00386 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 57. 106. 119. 271.  37.  43.  83. 305.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.177 0.124 0.082 0.11  0.13  0.104 0.146 0.072 0.    0.012 0.007 0.013\n",
      " 0.005 0.004 0.011 0.003]\n",
      "Q_est = -6.29\n",
      "\n",
      "-> i_step = 4240\n",
      "cur_state = [0 0]\n",
      "action = 0\n",
      "reward = 0.42\n",
      "new_state = [1 0]\n",
      "[ 58. 106. 119. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 58. 106. 119. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.09813  -6.07211  -6.0833   -6.06854  -6.09997  -6.13356  -6.09608\n",
      "  -6.07352  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.32987 3.23518 2.42621 2.55747 3.15318 2.70395 3.40805 2.36651 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.07\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05593 0.10222 0.11475 0.26133 0.03568 0.04147 0.08004 0.29412 0.\n",
      " 0.00193 0.00386 0.00482 0.00386 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 58. 106. 119. 271.  37.  43.  83. 305.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.134 0.136 0.095 0.089 0.126 0.117 0.156 0.091 0.    0.019 0.005 0.014\n",
      " 0.004 0.002 0.012 0.   ]\n",
      "Q_est = -6.28\n",
      "\n",
      "-> i_step = 4241\n",
      "cur_state = [1 0]\n",
      "action = 7\n",
      "reward = -1.36\n",
      "new_state = [2 7]\n",
      "[ 58. 106. 119. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 58. 106. 119. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.09813  -6.07211  -6.0833   -6.06854  -6.09997  -6.13356  -6.09608\n",
      "  -6.07352  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.32987 3.23518 2.42621 2.55747 3.15318 2.70395 3.40805 2.36651 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.07\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05593 0.10222 0.11475 0.26133 0.03568 0.04147 0.08004 0.29412 0.\n",
      " 0.00193 0.00386 0.00482 0.00386 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 58. 106. 119. 271.  37.  43.  83. 305.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.141 0.147 0.097 0.097 0.115 0.093 0.146 0.095 0.001 0.015 0.009 0.021\n",
      " 0.008 0.005 0.009 0.001]\n",
      "Q_est = -6.32\n",
      "\n",
      "-> i_step = 4242\n",
      "cur_state = [2 7]\n",
      "action = 0\n",
      "reward = -1.76\n",
      "new_state = [3 0]\n",
      "[ 58. 106. 119. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 58. 106. 119. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.09813  -6.07211  -6.0833   -6.06854  -6.09997  -6.13356  -6.09608\n",
      "  -6.07352  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.32987 3.23518 2.42621 2.55747 3.15318 2.70395 3.40805 2.36651 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.07\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05593 0.10222 0.11475 0.26133 0.03568 0.04147 0.08004 0.29412 0.\n",
      " 0.00193 0.00386 0.00482 0.00386 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 58. 106. 119. 271.  37.  43.  83. 305.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.143 0.127 0.087 0.096 0.142 0.108 0.152 0.085 0.    0.013 0.014 0.014\n",
      " 0.006 0.002 0.008 0.003]\n",
      "Q_est = -6.29\n",
      "\n",
      "-> i_step = 4243\n",
      "cur_state = [3 0]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 58. 106. 119. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 58. 106. 119. 271.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.09813  -6.07211  -6.0833   -6.06854  -6.09997  -6.13356  -6.09608\n",
      "  -6.07352  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.32987 3.23518 2.42621 2.55747 3.15318 2.70395 3.40805 2.36651 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.07\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05593 0.10222 0.11475 0.26133 0.03568 0.04147 0.08004 0.29412 0.\n",
      " 0.00193 0.00386 0.00482 0.00386 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 58. 106. 119. 271.  37.  43.  83. 305.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 15]\n",
      "probs = [0.136 0.145 0.095 0.084 0.135 0.092 0.158 0.082 0.002 0.016 0.013 0.021\n",
      " 0.    0.004 0.016 0.001]\n",
      "Q_est = -6.35\n",
      "\n",
      "-> i_step = 4244\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -0.83\n",
      "new_state = [1 3]\n",
      "[ 58. 106. 119. 272.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 58. 106. 119. 272.  37.  43.  83. 305.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.09813  -6.07211  -6.0833   -6.07792  -6.09997  -6.13356  -6.09608\n",
      "  -6.07352  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.32987 3.23518 2.42621 2.55744 3.15318 2.70395 3.40805 2.36651 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.07\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05588 0.10212 0.11464 0.26204 0.03565 0.04143 0.07996 0.29383 0.\n",
      " 0.00193 0.00385 0.00482 0.00385 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 58. 106. 119. 272.  37.  43.  83. 305.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.154 0.143 0.083 0.092 0.139 0.108 0.146 0.087 0.001 0.017 0.005 0.01\n",
      " 0.002 0.001 0.007 0.005]\n",
      "Q_est = -6.26"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05556 0.10264 0.11299 0.26177 0.03578 0.04143 0.0791  0.29661 0.\n",
      " 0.00188 0.00377 0.00471 0.00377 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 120. 278.  38.  44.  84. 315.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.16\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.149 0.142 0.086 0.091 0.149 0.092 0.157 0.08  0.001 0.013 0.009 0.013\n",
      " 0.006 0.003 0.007 0.002]\n",
      "Q_est = -6.31\n",
      "\n",
      "-> i_step = 4342\n",
      "cur_state = [2 4]\n",
      "action = 6\n",
      "reward = -0.58\n",
      "new_state = [3 6]\n",
      "[ 59. 109. 120. 278.  38.  44.  84. 315.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 120. 278.  38.  44.  84. 315.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.11545  -6.11908  -6.16698  -6.17337  -6.12012\n",
      "  -6.11865  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.4414  2.54647 3.13799 2.68576 3.39478 2.34562 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05556 0.10264 0.11299 0.26177 0.03578 0.04143 0.0791  0.29661 0.\n",
      " 0.00188 0.00377 0.00471 0.00377 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 120. 278.  38.  44.  84. 315.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.16\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.136 0.125 0.095 0.082 0.157 0.094 0.163 0.085 0.    0.017 0.006 0.015\n",
      " 0.008 0.003 0.012 0.002]\n",
      "Q_est = -6.35\n",
      "\n",
      "-> i_step = 4343\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 59. 109. 120. 278.  38.  44.  84. 315.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 120. 278.  38.  44.  84. 315.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.11545  -6.11908  -6.16698  -6.17337  -6.12012\n",
      "  -6.11865  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.4414  2.54647 3.13799 2.68576 3.39478 2.34562 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05556 0.10264 0.11299 0.26177 0.03578 0.04143 0.0791  0.29661 0.\n",
      " 0.00188 0.00377 0.00471 0.00377 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 120. 278.  38.  44.  84. 315.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.16\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.129 0.139 0.118 0.087 0.153 0.086 0.155 0.061 0.    0.016 0.01  0.021\n",
      " 0.007 0.003 0.013 0.002]\n",
      "Q_est = -6.39\n",
      "\n",
      "-> i_step = 4344\n",
      "cur_state = [0 0]\n",
      "action = 2\n",
      "reward = 0.24\n",
      "new_state = [1 2]\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 315.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 315.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.11908  -6.16698  -6.17337  -6.12012\n",
      "  -6.11865  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.54647 3.13799 2.68576 3.39478 2.34562 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0555  0.10254 0.11383 0.26152 0.03575 0.04139 0.07902 0.29633 0.\n",
      " 0.00188 0.00376 0.0047  0.00376 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 278.  38.  44.  84. 315.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.142 0.135 0.084 0.111 0.119 0.09  0.175 0.086 0.002 0.013 0.01  0.014\n",
      " 0.004 0.001 0.011 0.003]\n",
      "Q_est = -6.34\n",
      "\n",
      "-> i_step = 4345\n",
      "cur_state = [1 2]\n",
      "action = 1\n",
      "reward = 0.71\n",
      "new_state = [2 1]\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 315.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 315.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.11908  -6.16698  -6.17337  -6.12012\n",
      "  -6.11865  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.54647 3.13799 2.68576 3.39478 2.34562 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0555  0.10254 0.11383 0.26152 0.03575 0.04139 0.07902 0.29633 0.\n",
      " 0.00188 0.00376 0.0047  0.00376 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 278.  38.  44.  84. 315.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.144 0.146 0.076 0.108 0.129 0.107 0.151 0.078 0.    0.016 0.012 0.011\n",
      " 0.002 0.003 0.015 0.002]\n",
      "Q_est = -6.35\n",
      "\n",
      "-> i_step = 4346\n",
      "cur_state = [2 1]\n",
      "action = 6\n",
      "reward = -0.37\n",
      "new_state = [3 6]\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 315.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 315.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.11908  -6.16698  -6.17337  -6.12012\n",
      "  -6.11865  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.54647 3.13799 2.68576 3.39478 2.34562 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0555  0.10254 0.11383 0.26152 0.03575 0.04139 0.07902 0.29633 0.\n",
      " 0.00188 0.00376 0.0047  0.00376 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 278.  38.  44.  84. 315.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.145 0.152 0.082 0.11  0.139 0.096 0.141 0.076 0.    0.016 0.005 0.015\n",
      " 0.001 0.006 0.015 0.001]\n",
      "Q_est = -6.35\n",
      "\n",
      "-> i_step = 4347\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 315.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 315.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.11908  -6.16698  -6.17337  -6.12012\n",
      "  -6.11865  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.54647 3.13799 2.68576 3.39478 2.34562 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0555  0.10254 0.11383 0.26152 0.03575 0.04139 0.07902 0.29633 0.\n",
      " 0.00188 0.00376 0.0047  0.00376 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 278.  38.  44.  84. 315.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.149 0.118 0.097 0.109 0.129 0.111 0.145 0.084 0.    0.012 0.014 0.008\n",
      " 0.008 0.005 0.009 0.002]\n",
      "Q_est = -6.32\n",
      "\n",
      "-> i_step = 4348\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 1.57\n",
      "new_state = [1 7]\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 316.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 316.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.11908  -6.16698  -6.17337  -6.12012\n",
      "  -6.1188   -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.54647 3.13799 2.68576 3.39478 2.34191 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05545 0.10244 0.11372 0.26128 0.03571 0.04135 0.07895 0.29699 0.\n",
      " 0.00188 0.00376 0.0047  0.00376 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 278.  38.  44.  84. 316.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.164 0.133 0.077 0.083 0.137 0.113 0.161 0.074 0.    0.013 0.011 0.016\n",
      " 0.003 0.003 0.01  0.002]\n",
      "Q_est = -6.34\n",
      "\n",
      "-> i_step = 4349\n",
      "cur_state = [1 7]\n",
      "action = 5\n",
      "reward = 1.39\n",
      "new_state = [2 5]\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 316.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 316.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.11908  -6.16698  -6.17337  -6.12012\n",
      "  -6.1188   -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.54647 3.13799 2.68576 3.39478 2.34191 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05545 0.10244 0.11372 0.26128 0.03571 0.04135 0.07895 0.29699 0.\n",
      " 0.00188 0.00376 0.0047  0.00376 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 278.  38.  44.  84. 316.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.154 0.145 0.08  0.092 0.124 0.099 0.149 0.097 0.    0.01  0.008 0.02\n",
      " 0.003 0.006 0.01  0.003]\n",
      "Q_est = -6.35\n",
      "\n",
      "-> i_step = 4350\n",
      "cur_state = [2 5]\n",
      "action = 2\n",
      "reward = -1.45\n",
      "new_state = [3 2]\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 316.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 316.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.11908  -6.16698  -6.17337  -6.12012\n",
      "  -6.1188   -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.54647 3.13799 2.68576 3.39478 2.34191 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05545 0.10244 0.11372 0.26128 0.03571 0.04135 0.07895 0.29699 0.\n",
      " 0.00188 0.00376 0.0047  0.00376 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 278.  38.  44.  84. 316.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.173 0.159 0.081 0.087 0.135 0.088 0.136 0.079 0.    0.023 0.008 0.011\n",
      " 0.006 0.004 0.008 0.002]\n",
      "Q_est = -6.32\n",
      "\n",
      "-> i_step = 4351\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 316.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 316.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.11908  -6.16698  -6.17337  -6.12012\n",
      "  -6.1188   -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.54647 3.13799 2.68576 3.39478 2.34191 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05545 0.10244 0.11372 0.26128 0.03571 0.04135 0.07895 0.29699 0.\n",
      " 0.00188 0.00376 0.0047  0.00376 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 278.  38.  44.  84. 316.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.136 0.148 0.076 0.09  0.15  0.102 0.143 0.093 0.001 0.014 0.004 0.016\n",
      " 0.006 0.004 0.013 0.004]\n",
      "Q_est = -6.37\n",
      "\n",
      "-> i_step = 4352\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 0.09\n",
      "new_state = [1 7]\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.11908  -6.16698  -6.17337  -6.12012\n",
      "  -6.12362  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.54647 3.13799 2.68576 3.39478 2.33978 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0554  0.10235 0.11362 0.26103 0.03568 0.04131 0.07887 0.29765 0.\n",
      " 0.00188 0.00376 0.00469 0.00376 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 278.  38.  44.  84. 317.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.153 0.132 0.083 0.1   0.131 0.105 0.142 0.09  0.    0.02  0.009 0.013\n",
      " 0.008 0.002 0.01  0.002]\n",
      "Q_est = -6.34\n",
      "\n",
      "-> i_step = 4353\n",
      "cur_state = [1 7]\n",
      "action = 5\n",
      "reward = -0.40\n",
      "new_state = [2 5]\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.11908  -6.16698  -6.17337  -6.12012\n",
      "  -6.12362  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.54647 3.13799 2.68576 3.39478 2.33978 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0554  0.10235 0.11362 0.26103 0.03568 0.04131 0.07887 0.29765 0.\n",
      " 0.00188 0.00376 0.00469 0.00376 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 278.  38.  44.  84. 317.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.153 0.139 0.09  0.095 0.144 0.093 0.145 0.087 0.    0.011 0.009 0.017\n",
      " 0.006 0.002 0.009 0.   ]\n",
      "Q_est = -6.32\n",
      "\n",
      "-> i_step = 4354\n",
      "cur_state = [2 5]\n",
      "action = 6\n",
      "reward = -1.51\n",
      "new_state = [3 6]\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.11908  -6.16698  -6.17337  -6.12012\n",
      "  -6.12362  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.54647 3.13799 2.68576 3.39478 2.33978 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0554  0.10235 0.11362 0.26103 0.03568 0.04131 0.07887 0.29765 0.\n",
      " 0.00188 0.00376 0.00469 0.00376 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 278.  38.  44.  84. 317.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15]\n",
      "probs = [0.147 0.14  0.076 0.105 0.147 0.109 0.126 0.085 0.002 0.012 0.008 0.018\n",
      " 0.006 0.    0.016 0.003]\n",
      "Q_est = -6.39\n",
      "\n",
      "-> i_step = 4355\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 278.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.11908  -6.16698  -6.17337  -6.12012\n",
      "  -6.12362  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.54647 3.13799 2.68576 3.39478 2.33978 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0554  0.10235 0.11362 0.26103 0.03568 0.04131 0.07887 0.29765 0.\n",
      " 0.00188 0.00376 0.00469 0.00376 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 278.  38.  44.  84. 317.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.144 0.135 0.094 0.082 0.122 0.103 0.169 0.094 0.    0.015 0.009 0.014\n",
      " 0.005 0.002 0.011 0.001]\n",
      "Q_est = -6.33\n",
      "\n",
      "-> i_step = 4356\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 1.62\n",
      "new_state = [1 3]\n",
      "[ 59. 109. 121. 279.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 279.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.11933  -6.16698  -6.17337  -6.12012\n",
      "  -6.12362  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.54191 3.13799 2.68576 3.39478 2.33978 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05535 0.10225 0.11351 0.26173 0.03565 0.04128 0.0788  0.29737 0.\n",
      " 0.00188 0.00375 0.00469 0.00375 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 279.  38.  44.  84. 317.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.154 0.119 0.083 0.089 0.134 0.112 0.159 0.088 0.001 0.014 0.009 0.016\n",
      " 0.006 0.003 0.011 0.002]\n",
      "Q_est = -6.35\n",
      "\n",
      "-> i_step = 4357\n",
      "cur_state = [1 3]\n",
      "action = 6\n",
      "reward = -0.52\n",
      "new_state = [2 6]\n",
      "[ 59. 109. 121. 279.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 279.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.11933  -6.16698  -6.17337  -6.12012\n",
      "  -6.12362  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.54191 3.13799 2.68576 3.39478 2.33978 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05535 0.10225 0.11351 0.26173 0.03565 0.04128 0.0788  0.29737 0.\n",
      " 0.00188 0.00375 0.00469 0.00375 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 279.  38.  44.  84. 317.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.138 0.118 0.089 0.099 0.143 0.107 0.15  0.092 0.001 0.016 0.006 0.011\n",
      " 0.007 0.004 0.018 0.001]\n",
      "Q_est = -6.37\n",
      "\n",
      "-> i_step = 4358\n",
      "cur_state = [2 6]\n",
      "action = 5\n",
      "reward = -0.20\n",
      "new_state = [3 5]\n",
      "[ 59. 109. 121. 279.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 279.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.11933  -6.16698  -6.17337  -6.12012\n",
      "  -6.12362  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.54191 3.13799 2.68576 3.39478 2.33978 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05535 0.10225 0.11351 0.26173 0.03565 0.04128 0.0788  0.29737 0.\n",
      " 0.00188 0.00375 0.00469 0.00375 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 279.  38.  44.  84. 317.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.152 0.142 0.095 0.093 0.135 0.091 0.145 0.069 0.    0.023 0.012 0.013\n",
      " 0.008 0.006 0.015 0.001]\n",
      "Q_est = -6.39\n",
      "\n",
      "-> i_step = 4359\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 59. 109. 121. 279.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 279.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.11933  -6.16698  -6.17337  -6.12012\n",
      "  -6.12362  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.54191 3.13799 2.68576 3.39478 2.33978 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05535 0.10225 0.11351 0.26173 0.03565 0.04128 0.0788  0.29737 0.\n",
      " 0.00188 0.00375 0.00469 0.00375 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 279.  38.  44.  84. 317.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.158 0.138 0.09  0.076 0.147 0.097 0.154 0.083 0.    0.014 0.009 0.015\n",
      " 0.007 0.002 0.007 0.003]\n",
      "Q_est = -6.33\n",
      "\n",
      "-> i_step = 4360\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 0.26\n",
      "new_state = [1 3]\n",
      "[ 59. 109. 121. 280.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 280.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.12445  -6.16698  -6.17337  -6.12012\n",
      "  -6.12362  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.5388  3.13799 2.68576 3.39478 2.33978 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0553  0.10216 0.1134  0.26242 0.03561 0.04124 0.07873 0.29709 0.\n",
      " 0.00187 0.00375 0.00469 0.00375 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 280.  38.  44.  84. 317.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "probs = [0.157 0.152 0.084 0.095 0.129 0.092 0.15  0.077 0.001 0.009 0.013 0.014\n",
      " 0.005 0.005 0.017 0.   ]\n",
      "Q_est = -6.37\n",
      "\n",
      "-> i_step = 4361\n",
      "cur_state = [1 3]\n",
      "action = 3\n",
      "reward = -1.15\n",
      "new_state = [2 3]\n",
      "[ 59. 109. 121. 280.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 280.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.12445  -6.16698  -6.17337  -6.12012\n",
      "  -6.12362  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.5388  3.13799 2.68576 3.39478 2.33978 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0553  0.10216 0.1134  0.26242 0.03561 0.04124 0.07873 0.29709 0.\n",
      " 0.00187 0.00375 0.00469 0.00375 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 280.  38.  44.  84. 317.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.142 0.138 0.083 0.104 0.103 0.113 0.172 0.072 0.001 0.015 0.016 0.016\n",
      " 0.006 0.008 0.009 0.002]\n",
      "Q_est = -6.37\n",
      "\n",
      "-> i_step = 4362\n",
      "cur_state = [2 3]\n",
      "action = 5\n",
      "reward = 1.36\n",
      "new_state = [3 5]\n",
      "[ 59. 109. 121. 280.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 280.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.12445  -6.16698  -6.17337  -6.12012\n",
      "  -6.12362  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.5388  3.13799 2.68576 3.39478 2.33978 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0553  0.10216 0.1134  0.26242 0.03561 0.04124 0.07873 0.29709 0.\n",
      " 0.00187 0.00375 0.00469 0.00375 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 280.  38.  44.  84. 317.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.151 0.149 0.082 0.101 0.129 0.102 0.145 0.074 0.    0.01  0.011 0.019\n",
      " 0.01  0.004 0.011 0.002]\n",
      "Q_est = -6.37\n",
      "\n",
      "-> i_step = 4363\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 59. 109. 121. 280.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 280.  38.  44.  84. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.12445  -6.16698  -6.17337  -6.12012\n",
      "  -6.12362  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.5388  3.13799 2.68576 3.39478 2.33978 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0553  0.10216 0.1134  0.26242 0.03561 0.04124 0.07873 0.29709 0.\n",
      " 0.00187 0.00375 0.00469 0.00375 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 280.  38.  44.  84. 317.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.14  0.151 0.113 0.091 0.128 0.105 0.135 0.078 0.    0.009 0.01  0.017\n",
      " 0.004 0.003 0.012 0.004]\n",
      "Q_est = -6.36\n",
      "\n",
      "-> i_step = 4364\n",
      "cur_state = [0 0]\n",
      "action = 6\n",
      "reward = -0.75\n",
      "new_state = [1 6]\n",
      "[ 59. 109. 121. 280.  38.  44.  85. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 280.  38.  44.  85. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.12445  -6.16698  -6.17337  -6.15311\n",
      "  -6.12362  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.5388  3.13799 2.68576 3.38826 2.33978 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05524 0.10206 0.1133  0.26217 0.03558 0.0412  0.07959 0.29682 0.\n",
      " 0.00187 0.00375 0.00468 0.00375 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 280.  38.  44.  85. 317.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.157 0.158 0.093 0.075 0.119 0.096 0.142 0.085 0.    0.02  0.011 0.02\n",
      " 0.003 0.002 0.015 0.004]\n",
      "Q_est = -6.41\n",
      "\n",
      "-> i_step = 4365\n",
      "cur_state = [1 6]\n",
      "action = 1\n",
      "reward = 1.07\n",
      "new_state = [2 1]\n",
      "[ 59. 109. 121. 280.  38.  44.  85. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 280.  38.  44.  85. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.12445  -6.16698  -6.17337  -6.15311\n",
      "  -6.12362  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.5388  3.13799 2.68576 3.38826 2.33978 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05524 0.10206 0.1133  0.26217 0.03558 0.0412  0.07959 0.29682 0.\n",
      " 0.00187 0.00375 0.00468 0.00375 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 280.  38.  44.  85. 317.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.15  0.136 0.079 0.103 0.125 0.093 0.165 0.073 0.001 0.02  0.011 0.015\n",
      " 0.005 0.004 0.015 0.005]\n",
      "Q_est = -6.41\n",
      "\n",
      "-> i_step = 4366\n",
      "cur_state = [2 1]\n",
      "action = 1\n",
      "reward = 1.45\n",
      "new_state = [3 1]\n",
      "[ 59. 109. 121. 280.  38.  44.  85. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 280.  38.  44.  85. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.12445  -6.16698  -6.17337  -6.15311\n",
      "  -6.12362  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.5388  3.13799 2.68576 3.38826 2.33978 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05524 0.10206 0.1133  0.26217 0.03558 0.0412  0.07959 0.29682 0.\n",
      " 0.00187 0.00375 0.00468 0.00375 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 280.  38.  44.  85. 317.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.151 0.151 0.086 0.103 0.136 0.106 0.144 0.062 0.    0.016 0.007 0.013\n",
      " 0.007 0.002 0.014 0.002]\n",
      "Q_est = -6.36\n",
      "\n",
      "-> i_step = 4367\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 59. 109. 121. 280.  38.  44.  85. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 280.  38.  44.  85. 317.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.12445  -6.16698  -6.17337  -6.15311\n",
      "  -6.12362  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.5388  3.13799 2.68576 3.38826 2.33978 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.12\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05524 0.10206 0.1133  0.26217 0.03558 0.0412  0.07959 0.29682 0.\n",
      " 0.00187 0.00375 0.00468 0.00375 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 280.  38.  44.  85. 317.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.154 0.135 0.076 0.1   0.109 0.107 0.137 0.11  0.    0.019 0.014 0.018\n",
      " 0.005 0.003 0.009 0.004]\n",
      "Q_est = -6.38\n",
      "\n",
      "-> i_step = 4368\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 0.07\n",
      "new_state = [1 7]\n",
      "[ 59. 109. 121. 280.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 280.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.12445  -6.16698  -6.17337  -6.15311\n",
      "  -6.12847  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.5388  3.13799 2.68576 3.38826 2.3377  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05519 0.10196 0.11319 0.26193 0.03555 0.04116 0.07951 0.29747 0.\n",
      " 0.00187 0.00374 0.00468 0.00374 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 280.  38.  44.  85. 318.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.123 0.132 0.098 0.111 0.129 0.103 0.161 0.085 0.    0.011 0.016 0.012\n",
      " 0.006 0.002 0.01  0.001]\n",
      "Q_est = -6.33\n",
      "\n",
      "-> i_step = 4369\n",
      "cur_state = [1 7]\n",
      "action = 0\n",
      "reward = -0.04\n",
      "new_state = [2 0]\n",
      "[ 59. 109. 121. 280.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 280.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.12445  -6.16698  -6.17337  -6.15311\n",
      "  -6.12847  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.5388  3.13799 2.68576 3.38826 2.3377  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05519 0.10196 0.11319 0.26193 0.03555 0.04116 0.07951 0.29747 0.\n",
      " 0.00187 0.00374 0.00468 0.00374 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 280.  38.  44.  85. 318.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.145 0.148 0.082 0.107 0.125 0.104 0.153 0.085 0.    0.015 0.01  0.007\n",
      " 0.005 0.003 0.01  0.001]\n",
      "Q_est = -6.31\n",
      "\n",
      "-> i_step = 4370\n",
      "cur_state = [2 0]\n",
      "action = 3\n",
      "reward = -0.94\n",
      "new_state = [3 3]\n",
      "[ 59. 109. 121. 280.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 280.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.12445  -6.16698  -6.17337  -6.15311\n",
      "  -6.12847  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.5388  3.13799 2.68576 3.38826 2.3377  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05519 0.10196 0.11319 0.26193 0.03555 0.04116 0.07951 0.29747 0.\n",
      " 0.00187 0.00374 0.00468 0.00374 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 280.  38.  44.  85. 318.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.152 0.142 0.091 0.084 0.148 0.106 0.148 0.07  0.    0.014 0.011 0.011\n",
      " 0.008 0.002 0.011 0.002]\n",
      "Q_est = -6.34\n",
      "\n",
      "-> i_step = 4371\n",
      "cur_state = [3 3]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 59. 109. 121. 280.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 280.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.12445  -6.16698  -6.17337  -6.15311\n",
      "  -6.12847  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.5388  3.13799 2.68576 3.38826 2.3377  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05519 0.10196 0.11319 0.26193 0.03555 0.04116 0.07951 0.29747 0.\n",
      " 0.00187 0.00374 0.00468 0.00374 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 280.  38.  44.  85. 318.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.17\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.16  0.135 0.102 0.091 0.118 0.104 0.138 0.08  0.001 0.022 0.009 0.014\n",
      " 0.001 0.004 0.015 0.006]\n",
      "Q_est = -6.40\n",
      "\n",
      "-> i_step = 4372\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -1.25\n",
      "new_state = [1 3]\n",
      "[ 59. 109. 121. 281.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 281.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.12847  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.54034 3.13799 2.68576 3.38826 2.3377  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05514 0.10187 0.11308 0.26262 0.03551 0.04112 0.07944 0.2972  0.\n",
      " 0.00187 0.00374 0.00467 0.00374 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 281.  38.  44.  85. 318.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.168 0.143 0.081 0.09  0.128 0.109 0.139 0.072 0.001 0.018 0.008 0.018\n",
      " 0.007 0.005 0.011 0.002]\n",
      "Q_est = -6.38\n",
      "\n",
      "-> i_step = 4373\n",
      "cur_state = [1 3]\n",
      "action = 1\n",
      "reward = -0.64\n",
      "new_state = [2 1]\n",
      "[ 59. 109. 121. 281.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 281.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.12847  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.54034 3.13799 2.68576 3.38826 2.3377  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05514 0.10187 0.11308 0.26262 0.03551 0.04112 0.07944 0.2972  0.\n",
      " 0.00187 0.00374 0.00467 0.00374 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 281.  38.  44.  85. 318.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.147 0.134 0.079 0.127 0.127 0.107 0.156 0.067 0.    0.021 0.008 0.011\n",
      " 0.006 0.001 0.007 0.002]\n",
      "Q_est = -6.31\n",
      "\n",
      "-> i_step = 4374\n",
      "cur_state = [2 1]\n",
      "action = 1\n",
      "reward = -1.55\n",
      "new_state = [3 1]\n",
      "[ 59. 109. 121. 281.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 281.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.12847  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.54034 3.13799 2.68576 3.38826 2.3377  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05514 0.10187 0.11308 0.26262 0.03551 0.04112 0.07944 0.2972  0.\n",
      " 0.00187 0.00374 0.00467 0.00374 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 281.  38.  44.  85. 318.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.144 0.131 0.105 0.083 0.142 0.12  0.142 0.074 0.    0.018 0.004 0.015\n",
      " 0.002 0.004 0.013 0.003]\n",
      "Q_est = -6.36\n",
      "\n",
      "-> i_step = 4375\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 59. 109. 121. 281.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 121. 281.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.12708  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.12847  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43463 2.54034 3.13799 2.68576 3.38826 2.3377  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05514 0.10187 0.11308 0.26262 0.03551 0.04112 0.07944 0.2972  0.\n",
      " 0.00187 0.00374 0.00467 0.00374 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 121. 281.  38.  44.  85. 318.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.135 0.127 0.093 0.108 0.138 0.1   0.151 0.083 0.    0.018 0.006 0.012\n",
      " 0.008 0.004 0.011 0.006]\n",
      "Q_est = -6.38\n",
      "\n",
      "-> i_step = 4376\n",
      "cur_state = [0 0]\n",
      "action = 2\n",
      "reward = -0.51\n",
      "new_state = [1 2]\n",
      "[ 59. 109. 122. 281.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 122. 281.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.12847  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43235 2.54034 3.13799 2.68576 3.38826 2.3377  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05509 0.10177 0.11391 0.26237 0.03548 0.04108 0.07937 0.29692 0.\n",
      " 0.00187 0.00373 0.00467 0.00373 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 122. 281.  38.  44.  85. 318.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.142 0.141 0.093 0.091 0.149 0.098 0.148 0.089 0.    0.013 0.013 0.009\n",
      " 0.004 0.002 0.006 0.002]\n",
      "Q_est = -6.30\n",
      "\n",
      "-> i_step = 4377\n",
      "cur_state = [1 2]\n",
      "action = 0\n",
      "reward = 0.81\n",
      "new_state = [2 0]\n",
      "[ 59. 109. 122. 281.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 122. 281.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.12847  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43235 2.54034 3.13799 2.68576 3.38826 2.3377  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05509 0.10177 0.11391 0.26237 0.03548 0.04108 0.07937 0.29692 0.\n",
      " 0.00187 0.00373 0.00467 0.00373 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 122. 281.  38.  44.  85. 318.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.162 0.143 0.091 0.116 0.107 0.094 0.143 0.085 0.    0.019 0.01  0.009\n",
      " 0.005 0.003 0.007 0.006]\n",
      "Q_est = -6.34\n",
      "\n",
      "-> i_step = 4378\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = -1.49\n",
      "new_state = [3 7]\n",
      "[ 59. 109. 122. 281.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 122. 281.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.12847  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43235 2.54034 3.13799 2.68576 3.38826 2.3377  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05509 0.10177 0.11391 0.26237 0.03548 0.04108 0.07937 0.29692 0.\n",
      " 0.00187 0.00373 0.00467 0.00373 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 122. 281.  38.  44.  85. 318.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.153 0.127 0.081 0.1   0.132 0.102 0.159 0.091 0.002 0.011 0.009 0.01\n",
      " 0.008 0.001 0.011 0.003]\n",
      "Q_est = -6.34\n",
      "\n",
      "-> i_step = 4379\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 59. 109. 122. 281.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 122. 281.  38.  44.  85. 318.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.12847  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43235 2.54034 3.13799 2.68576 3.38826 2.3377  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05509 0.10177 0.11391 0.26237 0.03548 0.04108 0.07937 0.29692 0.\n",
      " 0.00187 0.00373 0.00467 0.00373 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 122. 281.  38.  44.  85. 318.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.157 0.132 0.103 0.09  0.135 0.102 0.137 0.084 0.001 0.016 0.008 0.014\n",
      " 0.004 0.002 0.01  0.005]\n",
      "Q_est = -6.36\n",
      "\n",
      "-> i_step = 4380\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = -0.27\n",
      "new_state = [1 7]\n",
      "[ 59. 109. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.13438  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43235 2.54034 3.13799 2.68576 3.38826 2.3364  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05504 0.10168 0.11381 0.26213 0.03545 0.04104 0.07929 0.29757 0.\n",
      " 0.00187 0.00373 0.00466 0.00373 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 122. 281.  38.  44.  85. 319.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.14  0.155 0.073 0.085 0.154 0.099 0.148 0.083 0.    0.012 0.009 0.014\n",
      " 0.004 0.006 0.018 0.   ]\n",
      "Q_est = -6.38\n",
      "\n",
      "-> i_step = 4381\n",
      "cur_state = [1 7]\n",
      "action = 7\n",
      "reward = -0.64\n",
      "new_state = [2 7]\n",
      "[ 59. 109. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.13438  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43235 2.54034 3.13799 2.68576 3.38826 2.3364  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05504 0.10168 0.11381 0.26213 0.03545 0.04104 0.07929 0.29757 0.\n",
      " 0.00187 0.00373 0.00466 0.00373 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 122. 281.  38.  44.  85. 319.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.13  0.147 0.097 0.111 0.115 0.1   0.137 0.095 0.    0.017 0.012 0.02\n",
      " 0.006 0.003 0.009 0.001]\n",
      "Q_est = -6.36\n",
      "\n",
      "-> i_step = 4382\n",
      "cur_state = [2 7]\n",
      "action = 7\n",
      "reward = -0.09\n",
      "new_state = [3 7]\n",
      "[ 59. 109. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.13438  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43235 2.54034 3.13799 2.68576 3.38826 2.3364  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05504 0.10168 0.11381 0.26213 0.03545 0.04104 0.07929 0.29757 0.\n",
      " 0.00187 0.00373 0.00466 0.00373 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 122. 281.  38.  44.  85. 319.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.15  0.135 0.084 0.116 0.133 0.106 0.146 0.079 0.    0.014 0.006 0.011\n",
      " 0.004 0.004 0.01  0.002]\n",
      "Q_est = -6.32\n",
      "\n",
      "-> i_step = 4383\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 59. 109. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 109. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.12935  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.13438  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.20872 2.43235 2.54034 3.13799 2.68576 3.38826 2.3364  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05504 0.10168 0.11381 0.26213 0.03545 0.04104 0.07929 0.29757 0.\n",
      " 0.00187 0.00373 0.00466 0.00373 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 109. 122. 281.  38.  44.  85. 319.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.127 0.14  0.1   0.092 0.138 0.098 0.144 0.096 0.    0.022 0.011 0.011\n",
      " 0.004 0.001 0.01  0.006]\n",
      "Q_est = -6.36\n",
      "\n",
      "-> i_step = 4384\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 0.40\n",
      "new_state = [1 1]\n",
      "[ 59. 110. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 110. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.14143  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.13438  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.19659 2.43235 2.54034 3.13799 2.68576 3.38826 2.3364  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05499 0.10252 0.1137  0.26188 0.03541 0.04101 0.07922 0.2973  0.\n",
      " 0.00186 0.00373 0.00466 0.00373 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 110. 122. 281.  38.  44.  85. 319.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.155 0.139 0.088 0.084 0.119 0.108 0.162 0.084 0.    0.014 0.012 0.016\n",
      " 0.003 0.001 0.014 0.001]\n",
      "Q_est = -6.36\n",
      "\n",
      "-> i_step = 4385\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 1.06\n",
      "new_state = [2 5]\n",
      "[ 59. 110. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 110. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.14143  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.13438  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.19659 2.43235 2.54034 3.13799 2.68576 3.38826 2.3364  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05499 0.10252 0.1137  0.26188 0.03541 0.04101 0.07922 0.2973  0.\n",
      " 0.00186 0.00373 0.00466 0.00373 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 110. 122. 281.  38.  44.  85. 319.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.133 0.145 0.083 0.11  0.111 0.117 0.151 0.083 0.002 0.013 0.011 0.019\n",
      " 0.006 0.003 0.01  0.003]\n",
      "Q_est = -6.38\n",
      "\n",
      "-> i_step = 4386\n",
      "cur_state = [2 5]\n",
      "action = 2\n",
      "reward = 0.36\n",
      "new_state = [3 2]\n",
      "[ 59. 110. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 110. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.14143  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.13438  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.19659 2.43235 2.54034 3.13799 2.68576 3.38826 2.3364  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05499 0.10252 0.1137  0.26188 0.03541 0.04101 0.07922 0.2973  0.\n",
      " 0.00186 0.00373 0.00466 0.00373 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 110. 122. 281.  38.  44.  85. 319.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.142 0.148 0.082 0.093 0.13  0.108 0.146 0.095 0.002 0.014 0.007 0.019\n",
      " 0.003 0.002 0.007 0.002]\n",
      "Q_est = -6.33\n",
      "\n",
      "-> i_step = 4387\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 59. 110. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 59. 110. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.13372  -6.14143  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.13438  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.31264 3.19659 2.43235 2.54034 3.13799 2.68576 3.38826 2.3364  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05499 0.10252 0.1137  0.26188 0.03541 0.04101 0.07922 0.2973  0.\n",
      " 0.00186 0.00373 0.00466 0.00373 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 59. 110. 122. 281.  38.  44.  85. 319.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.143 0.142 0.081 0.094 0.139 0.111 0.145 0.077 0.    0.016 0.012 0.013\n",
      " 0.01  0.004 0.009 0.004]\n",
      "Q_est = -6.37\n",
      "\n",
      "-> i_step = 4388\n",
      "cur_state = [0 0]\n",
      "action = 0\n",
      "reward = 0.52\n",
      "new_state = [1 0]\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.13438  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.54034 3.13799 2.68576 3.38826 2.3364  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05587 0.10242 0.11359 0.26164 0.03538 0.04097 0.07914 0.29702 0.\n",
      " 0.00186 0.00372 0.00466 0.00372 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 281.  38.  44.  85. 319.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.141 0.131 0.087 0.087 0.173 0.116 0.128 0.071 0.001 0.016 0.007 0.017\n",
      " 0.007 0.001 0.011 0.006]\n",
      "Q_est = -6.39\n",
      "\n",
      "-> i_step = 4389\n",
      "cur_state = [1 0]\n",
      "action = 0\n",
      "reward = 0.99\n",
      "new_state = [2 0]\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.13438  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.54034 3.13799 2.68576 3.38826 2.3364  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05587 0.10242 0.11359 0.26164 0.03538 0.04097 0.07914 0.29702 0.\n",
      " 0.00186 0.00372 0.00466 0.00372 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 281.  38.  44.  85. 319.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.154 0.15  0.079 0.09  0.118 0.106 0.162 0.073 0.    0.015 0.016 0.013\n",
      " 0.006 0.003 0.011 0.004]\n",
      "Q_est = -6.38\n",
      "\n",
      "-> i_step = 4390\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = -1.16\n",
      "new_state = [3 7]\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.13438  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.54034 3.13799 2.68576 3.38826 2.3364  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05587 0.10242 0.11359 0.26164 0.03538 0.04097 0.07914 0.29702 0.\n",
      " 0.00186 0.00372 0.00466 0.00372 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 281.  38.  44.  85. 319.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.154 0.153 0.09  0.103 0.123 0.095 0.13  0.092 0.    0.015 0.008 0.018\n",
      " 0.005 0.004 0.005 0.005]\n",
      "Q_est = -6.35\n",
      "\n",
      "-> i_step = 4391\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 319.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.13438  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.54034 3.13799 2.68576 3.38826 2.3364  1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05587 0.10242 0.11359 0.26164 0.03538 0.04097 0.07914 0.29702 0.\n",
      " 0.00186 0.00372 0.00466 0.00372 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 281.  38.  44.  85. 319.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.163 0.119 0.093 0.099 0.145 0.09  0.154 0.082 0.    0.011 0.01  0.014\n",
      " 0.004 0.002 0.011 0.003]\n",
      "Q_est = -6.35\n",
      "\n",
      "-> i_step = 4392\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 1.72\n",
      "new_state = [1 7]\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 320.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 320.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.13403  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.54034 3.13799 2.68576 3.38826 2.33276 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05581 0.10233 0.11349 0.2614  0.03535 0.04093 0.07907 0.29767 0.\n",
      " 0.00186 0.00372 0.00465 0.00372 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 281.  38.  44.  85. 320.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.128 0.146 0.08  0.101 0.13  0.104 0.165 0.082 0.002 0.016 0.013 0.011\n",
      " 0.005 0.001 0.008 0.008]\n",
      "Q_est = -6.38\n",
      "\n",
      "-> i_step = 4393\n",
      "cur_state = [1 7]\n",
      "action = 6\n",
      "reward = -0.48\n",
      "new_state = [2 6]\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 320.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 320.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.13403  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.54034 3.13799 2.68576 3.38826 2.33276 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05581 0.10233 0.11349 0.2614  0.03535 0.04093 0.07907 0.29767 0.\n",
      " 0.00186 0.00372 0.00465 0.00372 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 281.  38.  44.  85. 320.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.133 0.126 0.087 0.095 0.149 0.115 0.162 0.07  0.    0.012 0.015 0.015\n",
      " 0.002 0.004 0.012 0.003]\n",
      "Q_est = -6.37\n",
      "\n",
      "-> i_step = 4394\n",
      "cur_state = [2 6]\n",
      "action = 4\n",
      "reward = 1.84\n",
      "new_state = [3 4]\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 320.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 320.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.13403  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.54034 3.13799 2.68576 3.38826 2.33276 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05581 0.10233 0.11349 0.2614  0.03535 0.04093 0.07907 0.29767 0.\n",
      " 0.00186 0.00372 0.00465 0.00372 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 281.  38.  44.  85. 320.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.149 0.136 0.084 0.113 0.117 0.107 0.134 0.09  0.002 0.02  0.012 0.019\n",
      " 0.004 0.003 0.007 0.003]\n",
      "Q_est = -6.37\n",
      "\n",
      "-> i_step = 4395\n",
      "cur_state = [3 4]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 320.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 320.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.13403  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.54034 3.13799 2.68576 3.38826 2.33276 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05581 0.10233 0.11349 0.2614  0.03535 0.04093 0.07907 0.29767 0.\n",
      " 0.00186 0.00372 0.00465 0.00372 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 281.  38.  44.  85. 320.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.16  0.141 0.075 0.09  0.122 0.109 0.158 0.08  0.    0.014 0.01  0.015\n",
      " 0.005 0.007 0.012 0.002]\n",
      "Q_est = -6.38\n",
      "\n",
      "-> i_step = 4396\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 0.84\n",
      "new_state = [1 7]\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 321.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 321.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.13644  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.54034 3.13799 2.68576 3.38826 2.32952 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05576 0.10223 0.11338 0.26115 0.03532 0.04089 0.079   0.29833 0.\n",
      " 0.00186 0.00372 0.00465 0.00372 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 281.  38.  44.  85. 321.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.161 0.137 0.079 0.099 0.131 0.096 0.151 0.091 0.    0.017 0.008 0.013\n",
      " 0.004 0.002 0.007 0.004]\n",
      "Q_est = -6.33\n",
      "\n",
      "-> i_step = 4397\n",
      "cur_state = [1 7]\n",
      "action = 5\n",
      "reward = -0.76\n",
      "new_state = [2 5]\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 321.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 321.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.13644  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.54034 3.13799 2.68576 3.38826 2.32952 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05576 0.10223 0.11338 0.26115 0.03532 0.04089 0.079   0.29833 0.\n",
      " 0.00186 0.00372 0.00465 0.00372 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 281.  38.  44.  85. 321.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.134 0.159 0.09  0.09  0.135 0.101 0.156 0.07  0.    0.019 0.012 0.011\n",
      " 0.004 0.002 0.008 0.009]\n",
      "Q_est = -6.38\n",
      "\n",
      "-> i_step = 4398\n",
      "cur_state = [2 5]\n",
      "action = 2\n",
      "reward = -1.04\n",
      "new_state = [3 2]\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 321.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 321.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.13644  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.54034 3.13799 2.68576 3.38826 2.32952 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05576 0.10223 0.11338 0.26115 0.03532 0.04089 0.079   0.29833 0.\n",
      " 0.00186 0.00372 0.00465 0.00372 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 281.  38.  44.  85. 321.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.141 0.152 0.087 0.082 0.149 0.086 0.162 0.078 0.    0.018 0.007 0.016\n",
      " 0.009 0.001 0.01  0.002]\n",
      "Q_est = -6.36\n",
      "\n",
      "-> i_step = 4399\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 321.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 281.  38.  44.  85. 321.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.13493  -6.16698  -6.17337  -6.15311\n",
      "  -6.13644  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.54034 3.13799 2.68576 3.38826 2.32952 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05576 0.10223 0.11338 0.26115 0.03532 0.04089 0.079   0.29833 0.\n",
      " 0.00186 0.00372 0.00465 0.00372 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 281.  38.  44.  85. 321.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.157 0.151 0.071 0.087 0.13  0.101 0.149 0.097 0.    0.02  0.005 0.016\n",
      " 0.003 0.003 0.01  0.   ]\n",
      "Q_est = -6.33\n",
      "\n",
      "-> i_step = 4400\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 0.39\n",
      "new_state = [1 3]\n",
      "[ 60. 110. 122. 282.  38.  44.  85. 321.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 282.  38.  44.  85. 321.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.13955  -6.16698  -6.17337  -6.15311\n",
      "  -6.13644  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.53702 3.13799 2.68576 3.38826 2.32952 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05571 0.10214 0.11328 0.26184 0.03528 0.04085 0.07892 0.29805 0.\n",
      " 0.00186 0.00371 0.00464 0.00371 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 282.  38.  44.  85. 321.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.125 0.158 0.085 0.097 0.142 0.107 0.155 0.06  0.001 0.019 0.015 0.013\n",
      " 0.003 0.006 0.012 0.002]\n",
      "Q_est = -6.38\n",
      "\n",
      "-> i_step = 4401\n",
      "cur_state = [1 3]\n",
      "action = 5\n",
      "reward = -0.71\n",
      "new_state = [2 5]\n",
      "[ 60. 110. 122. 282.  38.  44.  85. 321.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 282.  38.  44.  85. 321.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.13955  -6.16698  -6.17337  -6.15311\n",
      "  -6.13644  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.53702 3.13799 2.68576 3.38826 2.32952 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05571 0.10214 0.11328 0.26184 0.03528 0.04085 0.07892 0.29805 0.\n",
      " 0.00186 0.00371 0.00464 0.00371 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 282.  38.  44.  85. 321.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "probs = [0.149 0.14  0.073 0.092 0.135 0.11  0.161 0.065 0.001 0.027 0.011 0.02\n",
      " 0.003 0.002 0.011 0.   ]\n",
      "Q_est = -6.38\n",
      "\n",
      "-> i_step = 4402\n",
      "cur_state = [2 5]\n",
      "action = 6\n",
      "reward = -0.49\n",
      "new_state = [3 6]\n",
      "[ 60. 110. 122. 282.  38.  44.  85. 321.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 282.  38.  44.  85. 321.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.13955  -6.16698  -6.17337  -6.15311\n",
      "  -6.13644  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.53702 3.13799 2.68576 3.38826 2.32952 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05571 0.10214 0.11328 0.26184 0.03528 0.04085 0.07892 0.29805 0.\n",
      " 0.00186 0.00371 0.00464 0.00371 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 282.  38.  44.  85. 321.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.148 0.134 0.077 0.103 0.138 0.094 0.177 0.072 0.001 0.01  0.008 0.012\n",
      " 0.006 0.006 0.011 0.003]\n",
      "Q_est = -6.36\n",
      "\n",
      "-> i_step = 4403\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 60. 110. 122. 282.  38.  44.  85. 321.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 282.  38.  44.  85. 321.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.13955  -6.16698  -6.17337  -6.15311\n",
      "  -6.13644  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.53702 3.13799 2.68576 3.38826 2.32952 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05571 0.10214 0.11328 0.26184 0.03528 0.04085 0.07892 0.29805 0.\n",
      " 0.00186 0.00371 0.00464 0.00371 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 282.  38.  44.  85. 321.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.145 0.152 0.083 0.089 0.144 0.092 0.147 0.088 0.001 0.016 0.008 0.016\n",
      " 0.006 0.001 0.009 0.003]\n",
      "Q_est = -6.35\n",
      "\n",
      "-> i_step = 4404\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 0.20\n",
      "new_state = [1 7]\n",
      "[ 60. 110. 122. 282.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 282.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.13955  -6.16698  -6.17337  -6.15311\n",
      "  -6.14084  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.53702 3.13799 2.68576 3.38826 2.32724 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05566 0.10204 0.11317 0.2616  0.03525 0.04082 0.07885 0.2987  0.\n",
      " 0.00186 0.00371 0.00464 0.00371 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 282.  38.  44.  85. 322.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.14  0.155 0.08  0.094 0.132 0.11  0.149 0.071 0.001 0.019 0.009 0.02\n",
      " 0.006 0.004 0.008 0.002]\n",
      "Q_est = -6.37\n",
      "\n",
      "-> i_step = 4405\n",
      "cur_state = [1 7]\n",
      "action = 2\n",
      "reward = -0.87\n",
      "new_state = [2 2]\n",
      "[ 60. 110. 122. 282.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 282.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.13955  -6.16698  -6.17337  -6.15311\n",
      "  -6.14084  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.53702 3.13799 2.68576 3.38826 2.32724 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05566 0.10204 0.11317 0.2616  0.03525 0.04082 0.07885 0.2987  0.\n",
      " 0.00186 0.00371 0.00464 0.00371 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 282.  38.  44.  85. 322.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.174 0.145 0.087 0.088 0.13  0.105 0.14  0.071 0.001 0.019 0.007 0.01\n",
      " 0.002 0.005 0.011 0.005]\n",
      "Q_est = -6.36\n",
      "\n",
      "-> i_step = 4406\n",
      "cur_state = [2 2]\n",
      "action = 7\n",
      "reward = -0.21\n",
      "new_state = [3 7]\n",
      "[ 60. 110. 122. 282.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 282.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.13955  -6.16698  -6.17337  -6.15311\n",
      "  -6.14084  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.53702 3.13799 2.68576 3.38826 2.32724 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05566 0.10204 0.11317 0.2616  0.03525 0.04082 0.07885 0.2987  0.\n",
      " 0.00186 0.00371 0.00464 0.00371 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 282.  38.  44.  85. 322.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.136 0.112 0.088 0.107 0.145 0.098 0.175 0.078 0.    0.016 0.012 0.015\n",
      " 0.005 0.003 0.006 0.004]\n",
      "Q_est = -6.35\n",
      "\n",
      "-> i_step = 4407\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 60. 110. 122. 282.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 282.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.13955  -6.16698  -6.17337  -6.15311\n",
      "  -6.14084  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.53702 3.13799 2.68576 3.38826 2.32724 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05566 0.10204 0.11317 0.2616  0.03525 0.04082 0.07885 0.2987  0.\n",
      " 0.00186 0.00371 0.00464 0.00371 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 282.  38.  44.  85. 322.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.139 0.108 0.102 0.088 0.159 0.096 0.166 0.075 0.    0.024 0.008 0.008\n",
      " 0.005 0.001 0.016 0.005]\n",
      "Q_est = -6.39\n",
      "\n",
      "-> i_step = 4408\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 1.37\n",
      "new_state = [1 3]\n",
      "[ 60. 110. 122. 283.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 283.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.14068  -6.16698  -6.17337  -6.15311\n",
      "  -6.14084  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.5326  3.13799 2.68576 3.38826 2.32724 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05561 0.10195 0.11307 0.26228 0.03522 0.04078 0.07878 0.29842 0.\n",
      " 0.00185 0.00371 0.00463 0.00371 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 283.  38.  44.  85. 322.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.137 0.149 0.109 0.09  0.139 0.103 0.145 0.071 0.    0.01  0.007 0.016\n",
      " 0.005 0.002 0.013 0.004]\n",
      "Q_est = -6.37\n",
      "\n",
      "-> i_step = 4409\n",
      "cur_state = [1 3]\n",
      "action = 1\n",
      "reward = 0.73\n",
      "new_state = [2 1]\n",
      "[ 60. 110. 122. 283.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 283.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.14068  -6.16698  -6.17337  -6.15311\n",
      "  -6.14084  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.5326  3.13799 2.68576 3.38826 2.32724 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05561 0.10195 0.11307 0.26228 0.03522 0.04078 0.07878 0.29842 0.\n",
      " 0.00185 0.00371 0.00463 0.00371 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 283.  38.  44.  85. 322.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.146 0.152 0.087 0.092 0.133 0.109 0.125 0.082 0.    0.013 0.02  0.015\n",
      " 0.008 0.002 0.009 0.007]\n",
      "Q_est = -6.41\n",
      "\n",
      "-> i_step = 4410\n",
      "cur_state = [2 1]\n",
      "action = 1\n",
      "reward = -1.80\n",
      "new_state = [3 1]\n",
      "[ 60. 110. 122. 283.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 283.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.14068  -6.16698  -6.17337  -6.15311\n",
      "  -6.14084  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.5326  3.13799 2.68576 3.38826 2.32724 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05561 0.10195 0.11307 0.26228 0.03522 0.04078 0.07878 0.29842 0.\n",
      " 0.00185 0.00371 0.00463 0.00371 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 283.  38.  44.  85. 322.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.143 0.145 0.093 0.082 0.126 0.095 0.154 0.086 0.    0.021 0.009 0.021\n",
      " 0.006 0.005 0.011 0.003]\n",
      "Q_est = -6.40\n",
      "\n",
      "-> i_step = 4411\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 60. 110. 122. 283.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 283.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.14068  -6.16698  -6.17337  -6.15311\n",
      "  -6.14084  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.5326  3.13799 2.68576 3.38826 2.32724 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05561 0.10195 0.11307 0.26228 0.03522 0.04078 0.07878 0.29842 0.\n",
      " 0.00185 0.00371 0.00463 0.00371 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 283.  38.  44.  85. 322.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.18\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.143 0.16  0.078 0.094 0.126 0.107 0.162 0.073 0.    0.011 0.014 0.009\n",
      " 0.005 0.004 0.009 0.005]\n",
      "Q_est = -6.35\n",
      "\n",
      "-> i_step = 4412\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 0.17\n",
      "new_state = [1 3]\n",
      "[ 60. 110. 122. 284.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 284.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.14605  -6.16698  -6.17337  -6.15311\n",
      "  -6.14084  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.52975 3.13799 2.68576 3.38826 2.32724 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05556 0.10185 0.11296 0.26296 0.03519 0.04074 0.0787  0.29815 0.\n",
      " 0.00185 0.0037  0.00463 0.0037  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 284.  38.  44.  85. 322.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.19\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.143 0.141 0.089 0.096 0.154 0.088 0.148 0.07  0.001 0.016 0.012 0.015\n",
      " 0.005 0.004 0.015 0.003]\n",
      "Q_est = -6.40\n",
      "\n",
      "-> i_step = 4413\n",
      "cur_state = [1 3]\n",
      "action = 0\n",
      "reward = -0.52\n",
      "new_state = [2 0]\n",
      "[ 60. 110. 122. 284.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 284.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.14605  -6.16698  -6.17337  -6.15311\n",
      "  -6.14084  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.52975 3.13799 2.68576 3.38826 2.32724 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05556 0.10185 0.11296 0.26296 0.03519 0.04074 0.0787  0.29815 0.\n",
      " 0.00185 0.0037  0.00463 0.0037  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 284.  38.  44.  85. 322.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.19\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.145 0.158 0.077 0.102 0.123 0.103 0.153 0.076 0.    0.017 0.008 0.018\n",
      " 0.004 0.001 0.012 0.003]\n",
      "Q_est = -6.37\n",
      "\n",
      "-> i_step = 4414\n",
      "cur_state = [2 0]\n",
      "action = 2\n",
      "reward = -1.67\n",
      "new_state = [3 2]\n",
      "[ 60. 110. 122. 284.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 284.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.14605  -6.16698  -6.17337  -6.15311\n",
      "  -6.14084  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.52975 3.13799 2.68576 3.38826 2.32724 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05556 0.10185 0.11296 0.26296 0.03519 0.04074 0.0787  0.29815 0.\n",
      " 0.00185 0.0037  0.00463 0.0037  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 60. 110. 122. 284.  38.  44.  85. 322.   0.   2.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.19\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.142 0.131 0.092 0.098 0.13  0.112 0.142 0.086 0.    0.02  0.008 0.018\n",
      " 0.005 0.005 0.01  0.001]\n",
      "Q_est = -6.37\n",
      "\n",
      "-> i_step = 4415\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 60. 110. 122. 284.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 60. 110. 122. 284.  38.  44.  85. 322.   7.   2.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.16069  -6.14143  -6.14469  -6.14605  -6.16698  -6.17337  -6.15311\n",
      "  -6.14084  -9.74843  -7.53139  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.29144 3.19659 2.43235 2.52975 3.13799 2.68576 3.38826 2.32724 1.74413\n",
      " 2.01905 2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "action_maxlcb_muhat = -6.18\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05606 0.10217 0.11212 0.2613  0.03617 0.04069 0.07866 0.29837 0.\n",
      " 0.00271 0.00362 0.00452 0.00362 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 124. 289.  40.  45.  87. 330.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.23\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.145 0.139 0.099 0.09  0.11  0.106 0.153 0.074 0.001 0.037 0.012 0.016\n",
      " 0.007 0.002 0.006 0.003]\n",
      "Q_est = -6.52\n",
      "\n",
      "-> i_step = 4518\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = -0.50\n",
      "new_state = [3 7]\n",
      "[ 62. 113. 124. 289.  40.  45.  87. 330.   7.   3.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 62. 113. 124. 289.  40.  45.  87. 330.   7.   3.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.17654  -6.1744   -6.19059  -6.20538  -6.20714\n",
      "  -6.18263  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.42612 2.51849 3.06057 2.66422 3.36901 2.32036 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.18\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05606 0.10217 0.11212 0.2613  0.03617 0.04069 0.07866 0.29837 0.\n",
      " 0.00271 0.00362 0.00452 0.00362 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 124. 289.  40.  45.  87. 330.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.23\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.148 0.129 0.089 0.08  0.144 0.103 0.14  0.084 0.002 0.03  0.013 0.015\n",
      " 0.004 0.003 0.014 0.002]\n",
      "Q_est = -6.54\n",
      "\n",
      "-> i_step = 4519\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 113. 124. 289.  40.  45.  87. 330.   7.   3.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 62. 113. 124. 289.  40.  45.  87. 330.   7.   3.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.17654  -6.1744   -6.19059  -6.20538  -6.20714\n",
      "  -6.18263  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.42612 2.51849 3.06057 2.66422 3.36901 2.32036 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.18\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05606 0.10217 0.11212 0.2613  0.03617 0.04069 0.07866 0.29837 0.\n",
      " 0.00271 0.00362 0.00452 0.00362 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 124. 289.  40.  45.  87. 330.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.23\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.125 0.128 0.092 0.101 0.122 0.107 0.157 0.083 0.    0.031 0.011 0.009\n",
      " 0.009 0.006 0.014 0.005]\n",
      "Q_est = -6.55\n",
      "\n",
      "-> i_step = 4520\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -0.84\n",
      "new_state = [1 3]\n",
      "[ 62. 113. 124. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 62. 113. 124. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.17654  -6.18307  -6.19059  -6.20538  -6.20714\n",
      "  -6.18263  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.42612 2.51846 3.06057 2.66422 3.36901 2.32036 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.18\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05601 0.10208 0.11201 0.26197 0.03613 0.04065 0.07859 0.2981  0.\n",
      " 0.00271 0.00361 0.00452 0.00361 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 124. 290.  40.  45.  87. 330.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.146 0.134 0.09  0.088 0.156 0.108 0.139 0.07  0.001 0.027 0.008 0.015\n",
      " 0.005 0.003 0.006 0.004]\n",
      "Q_est = -6.48\n",
      "\n",
      "-> i_step = 4521\n",
      "cur_state = [1 3]\n",
      "action = 6\n",
      "reward = 0.10\n",
      "new_state = [2 6]\n",
      "[ 62. 113. 124. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 62. 113. 124. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.17654  -6.18307  -6.19059  -6.20538  -6.20714\n",
      "  -6.18263  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.42612 2.51846 3.06057 2.66422 3.36901 2.32036 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.18\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05601 0.10208 0.11201 0.26197 0.03613 0.04065 0.07859 0.2981  0.\n",
      " 0.00271 0.00361 0.00452 0.00361 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 124. 290.  40.  45.  87. 330.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.152 0.122 0.088 0.091 0.127 0.104 0.13  0.092 0.    0.039 0.015 0.024\n",
      " 0.003 0.003 0.009 0.001]\n",
      "Q_est = -6.56\n",
      "\n",
      "-> i_step = 4522\n",
      "cur_state = [2 6]\n",
      "action = 5\n",
      "reward = 0.13\n",
      "new_state = [3 5]\n",
      "[ 62. 113. 124. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 62. 113. 124. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.17654  -6.18307  -6.19059  -6.20538  -6.20714\n",
      "  -6.18263  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.42612 2.51846 3.06057 2.66422 3.36901 2.32036 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.18\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05601 0.10208 0.11201 0.26197 0.03613 0.04065 0.07859 0.2981  0.\n",
      " 0.00271 0.00361 0.00452 0.00361 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 124. 290.  40.  45.  87. 330.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.122 0.147 0.098 0.097 0.13  0.11  0.147 0.086 0.    0.031 0.012 0.007\n",
      " 0.005 0.001 0.006 0.001]\n",
      "Q_est = -6.44\n",
      "\n",
      "-> i_step = 4523\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 113. 124. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ 62. 113. 124. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   6.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.17654  -6.18307  -6.19059  -6.20538  -6.20714\n",
      "  -6.18263  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -9.07801\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.42612 2.51846 3.06057 2.66422 3.36901 2.32036 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 2.06679 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.18\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05601 0.10208 0.11201 0.26197 0.03613 0.04065 0.07859 0.2981  0.\n",
      " 0.00271 0.00361 0.00452 0.00361 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 124. 290.  40.  45.  87. 330.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.144 0.143 0.089 0.073 0.137 0.094 0.156 0.087 0.001 0.035 0.014 0.011\n",
      " 0.006 0.002 0.003 0.005]\n",
      "Q_est = -6.49\n",
      "\n",
      "-> i_step = 4524\n",
      "cur_state = [0 0]\n",
      "action = 13\n",
      "reward = -2.64\n",
      "new_state = [ 1 13]\n",
      "[ 62. 113. 124. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 124. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.17654  -6.18307  -6.19059  -6.20538  -6.20714\n",
      "  -6.18263  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.42612 2.51846 3.06057 2.66422 3.36901 2.32036 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.18\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05601 0.10208 0.11201 0.26197 0.03613 0.04065 0.07859 0.2981  0.\n",
      " 0.00271 0.00361 0.00452 0.00361 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 124. 290.  40.  45.  87. 330.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14 15]\n",
      "probs = [0.138 0.148 0.088 0.079 0.138 0.109 0.133 0.077 0.    0.039 0.009 0.01\n",
      " 0.007 0.    0.021 0.004]\n",
      "Q_est = -6.60\n",
      "\n",
      "-> i_step = 4525\n",
      "cur_state = [ 1 13]\n",
      "action = 12\n",
      "reward = -6.42\n",
      "new_state = [ 2 12]\n",
      "[ 62. 113. 124. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 124. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.17654  -6.18307  -6.19059  -6.20538  -6.20714\n",
      "  -6.18263  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.42612 2.51846 3.06057 2.66422 3.36901 2.32036 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.18\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05601 0.10208 0.11201 0.26197 0.03613 0.04065 0.07859 0.2981  0.\n",
      " 0.00271 0.00361 0.00452 0.00361 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 124. 290.  40.  45.  87. 330.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.122 0.128 0.091 0.095 0.148 0.109 0.134 0.075 0.001 0.034 0.012 0.022\n",
      " 0.006 0.004 0.018 0.001]\n",
      "Q_est = -6.60\n",
      "\n",
      "-> i_step = 4526\n",
      "cur_state = [ 2 12]\n",
      "action = 14\n",
      "reward = -5.65\n",
      "new_state = [ 3 14]\n",
      "[ 62. 113. 124. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 124. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.17654  -6.18307  -6.19059  -6.20538  -6.20714\n",
      "  -6.18263  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.42612 2.51846 3.06057 2.66422 3.36901 2.32036 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.18\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05601 0.10208 0.11201 0.26197 0.03613 0.04065 0.07859 0.2981  0.\n",
      " 0.00271 0.00361 0.00452 0.00361 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 124. 290.  40.  45.  87. 330.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15]\n",
      "probs = [0.152 0.144 0.076 0.089 0.127 0.091 0.155 0.079 0.003 0.036 0.011 0.017\n",
      " 0.007 0.    0.011 0.002]\n",
      "Q_est = -6.55\n",
      "\n",
      "-> i_step = 4527\n",
      "cur_state = [ 3 14]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 113. 124. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 124. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.17654  -6.18307  -6.19059  -6.20538  -6.20714\n",
      "  -6.18263  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.42612 2.51846 3.06057 2.66422 3.36901 2.32036 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.18\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05601 0.10208 0.11201 0.26197 0.03613 0.04065 0.07859 0.2981  0.\n",
      " 0.00271 0.00361 0.00452 0.00361 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 124. 290.  40.  45.  87. 330.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.154 0.124 0.078 0.082 0.145 0.106 0.146 0.081 0.001 0.039 0.015 0.01\n",
      " 0.005 0.002 0.009 0.003]\n",
      "Q_est = -6.53\n",
      "\n",
      "-> i_step = 4528\n",
      "cur_state = [0 0]\n",
      "action = 2\n",
      "reward = 0.32\n",
      "new_state = [1 2]\n",
      "[ 62. 113. 125. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18307  -6.19059  -6.20538  -6.20714\n",
      "  -6.18263  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.51846 3.06057 2.66422 3.36901 2.32036 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.18\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05596 0.10199 0.11282 0.26173 0.0361  0.04061 0.07852 0.29783 0.\n",
      " 0.00271 0.00361 0.00451 0.00361 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 290.  40.  45.  87. 330.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.139 0.13  0.078 0.107 0.134 0.102 0.145 0.084 0.001 0.029 0.01  0.016\n",
      " 0.005 0.003 0.016 0.001]\n",
      "Q_est = -6.53\n",
      "\n",
      "-> i_step = 4529\n",
      "cur_state = [1 2]\n",
      "action = 5\n",
      "reward = -3.57\n",
      "new_state = [2 5]\n",
      "[ 62. 113. 125. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18307  -6.19059  -6.20538  -6.20714\n",
      "  -6.18263  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.51846 3.06057 2.66422 3.36901 2.32036 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.18\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05596 0.10199 0.11282 0.26173 0.0361  0.04061 0.07852 0.29783 0.\n",
      " 0.00271 0.00361 0.00451 0.00361 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 290.  40.  45.  87. 330.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.158 0.119 0.077 0.095 0.13  0.114 0.159 0.072 0.    0.029 0.009 0.011\n",
      " 0.006 0.002 0.015 0.004]\n",
      "Q_est = -6.53\n",
      "\n",
      "-> i_step = 4530\n",
      "cur_state = [2 5]\n",
      "action = 6\n",
      "reward = -0.50\n",
      "new_state = [3 6]\n",
      "[ 62. 113. 125. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18307  -6.19059  -6.20538  -6.20714\n",
      "  -6.18263  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.51846 3.06057 2.66422 3.36901 2.32036 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.18\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05596 0.10199 0.11282 0.26173 0.0361  0.04061 0.07852 0.29783 0.\n",
      " 0.00271 0.00361 0.00451 0.00361 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 290.  40.  45.  87. 330.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.143 0.133 0.08  0.091 0.125 0.105 0.156 0.077 0.001 0.028 0.011 0.021\n",
      " 0.007 0.004 0.016 0.002]\n",
      "Q_est = -6.57\n",
      "\n",
      "-> i_step = 4531\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 113. 125. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 290.  40.  45.  87. 330.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18307  -6.19059  -6.20538  -6.20714\n",
      "  -6.18263  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.51846 3.06057 2.66422 3.36901 2.32036 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.18\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05596 0.10199 0.11282 0.26173 0.0361  0.04061 0.07852 0.29783 0.\n",
      " 0.00271 0.00361 0.00451 0.00361 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 290.  40.  45.  87. 330.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.149 0.121 0.101 0.093 0.141 0.087 0.147 0.082 0.001 0.035 0.007 0.011\n",
      " 0.005 0.001 0.016 0.003]\n",
      "Q_est = -6.54\n",
      "\n",
      "-> i_step = 4532\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 0.40\n",
      "new_state = [1 7]\n",
      "[ 62. 113. 125. 290.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 290.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18307  -6.19059  -6.20538  -6.20714\n",
      "  -6.18624  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.51846 3.06057 2.66422 3.36901 2.31778 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05591 0.10189 0.11271 0.2615  0.03607 0.04058 0.07845 0.29847 0.\n",
      " 0.00271 0.00361 0.00451 0.00361 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 290.  40.  45.  87. 331.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.144 0.133 0.097 0.099 0.125 0.113 0.139 0.078 0.    0.027 0.011 0.016\n",
      " 0.005 0.001 0.009 0.003]\n",
      "Q_est = -6.49\n",
      "\n",
      "-> i_step = 4533\n",
      "cur_state = [1 7]\n",
      "action = 5\n",
      "reward = -0.78\n",
      "new_state = [2 5]\n",
      "[ 62. 113. 125. 290.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 290.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18307  -6.19059  -6.20538  -6.20714\n",
      "  -6.18624  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.51846 3.06057 2.66422 3.36901 2.31778 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05591 0.10189 0.11271 0.2615  0.03607 0.04058 0.07845 0.29847 0.\n",
      " 0.00271 0.00361 0.00451 0.00361 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 290.  40.  45.  87. 331.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.111 0.147 0.072 0.079 0.149 0.119 0.157 0.081 0.    0.029 0.011 0.018\n",
      " 0.007 0.002 0.011 0.007]\n",
      "Q_est = -6.55\n",
      "\n",
      "-> i_step = 4534\n",
      "cur_state = [2 5]\n",
      "action = 6\n",
      "reward = -0.35\n",
      "new_state = [3 6]\n",
      "[ 62. 113. 125. 290.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 290.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18307  -6.19059  -6.20538  -6.20714\n",
      "  -6.18624  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.51846 3.06057 2.66422 3.36901 2.31778 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05591 0.10189 0.11271 0.2615  0.03607 0.04058 0.07845 0.29847 0.\n",
      " 0.00271 0.00361 0.00451 0.00361 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 290.  40.  45.  87. 331.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.146 0.138 0.093 0.095 0.128 0.11  0.146 0.072 0.001 0.029 0.008 0.013\n",
      " 0.004 0.003 0.009 0.005]\n",
      "Q_est = -6.50\n",
      "\n",
      "-> i_step = 4535\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 113. 125. 290.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 290.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18307  -6.19059  -6.20538  -6.20714\n",
      "  -6.18624  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.51846 3.06057 2.66422 3.36901 2.31778 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05591 0.10189 0.11271 0.2615  0.03607 0.04058 0.07845 0.29847 0.\n",
      " 0.00271 0.00361 0.00451 0.00361 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 290.  40.  45.  87. 331.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.154 0.13  0.082 0.087 0.145 0.108 0.137 0.076 0.    0.037 0.006 0.015\n",
      " 0.007 0.004 0.008 0.004]\n",
      "Q_est = -6.53\n",
      "\n",
      "-> i_step = 4536\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 1.30\n",
      "new_state = [1 3]\n",
      "[ 62. 113. 125. 291.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 291.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18433  -6.19059  -6.20538  -6.20714\n",
      "  -6.18624  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.51422 3.06057 2.66422 3.36901 2.31778 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05586 0.1018  0.11261 0.26216 0.03604 0.04054 0.07838 0.2982  0.\n",
      " 0.0027  0.0036  0.0045  0.0036  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 291.  40.  45.  87. 331.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.134 0.127 0.086 0.102 0.152 0.1   0.143 0.082 0.002 0.037 0.008 0.008\n",
      " 0.004 0.004 0.009 0.002]\n",
      "Q_est = -6.50\n",
      "\n",
      "-> i_step = 4537\n",
      "cur_state = [1 3]\n",
      "action = 6\n",
      "reward = -1.19\n",
      "new_state = [2 6]\n",
      "[ 62. 113. 125. 291.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 291.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18433  -6.19059  -6.20538  -6.20714\n",
      "  -6.18624  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.51422 3.06057 2.66422 3.36901 2.31778 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05586 0.1018  0.11261 0.26216 0.03604 0.04054 0.07838 0.2982  0.\n",
      " 0.0027  0.0036  0.0045  0.0036  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 291.  40.  45.  87. 331.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.15  0.15  0.083 0.081 0.13  0.112 0.129 0.073 0.001 0.035 0.01  0.018\n",
      " 0.011 0.001 0.011 0.005]\n",
      "Q_est = -6.58\n",
      "\n",
      "-> i_step = 4538\n",
      "cur_state = [2 6]\n",
      "action = 5\n",
      "reward = -0.56\n",
      "new_state = [3 5]\n",
      "[ 62. 113. 125. 291.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 291.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18433  -6.19059  -6.20538  -6.20714\n",
      "  -6.18624  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.51422 3.06057 2.66422 3.36901 2.31778 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05586 0.1018  0.11261 0.26216 0.03604 0.04054 0.07838 0.2982  0.\n",
      " 0.0027  0.0036  0.0045  0.0036  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 291.  40.  45.  87. 331.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.14  0.117 0.089 0.084 0.145 0.105 0.146 0.086 0.    0.037 0.012 0.018\n",
      " 0.005 0.002 0.012 0.002]\n",
      "Q_est = -6.55\n",
      "\n",
      "-> i_step = 4539\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 113. 125. 291.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 291.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18433  -6.19059  -6.20538  -6.20714\n",
      "  -6.18624  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.51422 3.06057 2.66422 3.36901 2.31778 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05586 0.1018  0.11261 0.26216 0.03604 0.04054 0.07838 0.2982  0.\n",
      " 0.0027  0.0036  0.0045  0.0036  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 291.  40.  45.  87. 331.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.135 0.146 0.08  0.097 0.132 0.117 0.134 0.072 0.    0.028 0.015 0.014\n",
      " 0.01  0.002 0.016 0.002]\n",
      "Q_est = -6.55\n",
      "\n",
      "-> i_step = 4540\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 1.48\n",
      "new_state = [1 3]\n",
      "[ 62. 113. 125. 292.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 292.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18501  -6.19059  -6.20538  -6.20714\n",
      "  -6.18624  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.50994 3.06057 2.66422 3.36901 2.31778 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05581 0.10171 0.11251 0.26283 0.036   0.0405  0.07831 0.29793 0.\n",
      " 0.0027  0.0036  0.0045  0.0036  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 292.  40.  45.  87. 331.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.128 0.14  0.077 0.103 0.13  0.102 0.138 0.092 0.    0.037 0.013 0.01\n",
      " 0.013 0.002 0.012 0.003]\n",
      "Q_est = -6.56\n",
      "\n",
      "-> i_step = 4541\n",
      "cur_state = [1 3]\n",
      "action = 5\n",
      "reward = 1.15\n",
      "new_state = [2 5]\n",
      "[ 62. 113. 125. 292.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 292.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18501  -6.19059  -6.20538  -6.20714\n",
      "  -6.18624  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.50994 3.06057 2.66422 3.36901 2.31778 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05581 0.10171 0.11251 0.26283 0.036   0.0405  0.07831 0.29793 0.\n",
      " 0.0027  0.0036  0.0045  0.0036  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 292.  40.  45.  87. 331.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.134 0.139 0.077 0.11  0.147 0.102 0.131 0.078 0.    0.037 0.009 0.017\n",
      " 0.011 0.002 0.005 0.001]\n",
      "Q_est = -6.51\n",
      "\n",
      "-> i_step = 4542\n",
      "cur_state = [2 5]\n",
      "action = 6\n",
      "reward = -0.26\n",
      "new_state = [3 6]\n",
      "[ 62. 113. 125. 292.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 292.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18501  -6.19059  -6.20538  -6.20714\n",
      "  -6.18624  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.50994 3.06057 2.66422 3.36901 2.31778 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05581 0.10171 0.11251 0.26283 0.036   0.0405  0.07831 0.29793 0.\n",
      " 0.0027  0.0036  0.0045  0.0036  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 292.  40.  45.  87. 331.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.151 0.142 0.096 0.084 0.128 0.103 0.14  0.074 0.    0.033 0.008 0.012\n",
      " 0.009 0.003 0.012 0.005]\n",
      "Q_est = -6.54\n",
      "\n",
      "-> i_step = 4543\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 113. 125. 292.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 292.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18501  -6.19059  -6.20538  -6.20714\n",
      "  -6.18624  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.50994 3.06057 2.66422 3.36901 2.31778 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05581 0.10171 0.11251 0.26283 0.036   0.0405  0.07831 0.29793 0.\n",
      " 0.0027  0.0036  0.0045  0.0036  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 292.  40.  45.  87. 331.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.134 0.137 0.095 0.082 0.145 0.102 0.134 0.077 0.001 0.037 0.011 0.02\n",
      " 0.005 0.003 0.012 0.005]\n",
      "Q_est = -6.59\n",
      "\n",
      "-> i_step = 4544\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 0.52\n",
      "new_state = [1 3]\n",
      "[ 62. 113. 125. 293.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 293.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18893  -6.19059  -6.20538  -6.20714\n",
      "  -6.18624  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.50654 3.06057 2.66422 3.36901 2.31778 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05576 0.10162 0.11241 0.26349 0.03597 0.04047 0.07824 0.29766 0.\n",
      " 0.0027  0.0036  0.0045  0.0036  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 293.  40.  45.  87. 331.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.137 0.119 0.086 0.096 0.139 0.099 0.155 0.075 0.    0.038 0.011 0.02\n",
      " 0.006 0.002 0.011 0.006]\n",
      "Q_est = -6.59\n",
      "\n",
      "-> i_step = 4545\n",
      "cur_state = [1 3]\n",
      "action = 5\n",
      "reward = 0.65\n",
      "new_state = [2 5]\n",
      "[ 62. 113. 125. 293.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 293.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18893  -6.19059  -6.20538  -6.20714\n",
      "  -6.18624  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.50654 3.06057 2.66422 3.36901 2.31778 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05576 0.10162 0.11241 0.26349 0.03597 0.04047 0.07824 0.29766 0.\n",
      " 0.0027  0.0036  0.0045  0.0036  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 293.  40.  45.  87. 331.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.146 0.142 0.083 0.099 0.122 0.099 0.139 0.084 0.001 0.039 0.007 0.01\n",
      " 0.004 0.002 0.017 0.006]\n",
      "Q_est = -6.58\n",
      "\n",
      "-> i_step = 4546\n",
      "cur_state = [2 5]\n",
      "action = 6\n",
      "reward = -0.71\n",
      "new_state = [3 6]\n",
      "[ 62. 113. 125. 293.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 293.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18893  -6.19059  -6.20538  -6.20714\n",
      "  -6.18624  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.50654 3.06057 2.66422 3.36901 2.31778 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05576 0.10162 0.11241 0.26349 0.03597 0.04047 0.07824 0.29766 0.\n",
      " 0.0027  0.0036  0.0045  0.0036  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 293.  40.  45.  87. 331.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.137 0.13  0.09  0.08  0.121 0.106 0.166 0.075 0.001 0.033 0.008 0.024\n",
      " 0.007 0.004 0.013 0.005]\n",
      "Q_est = -6.59\n",
      "\n",
      "-> i_step = 4547\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 113. 125. 293.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 293.  40.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18893  -6.19059  -6.20538  -6.20714\n",
      "  -6.18624  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.50654 3.06057 2.66422 3.36901 2.31778 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05576 0.10162 0.11241 0.26349 0.03597 0.04047 0.07824 0.29766 0.\n",
      " 0.0027  0.0036  0.0045  0.0036  0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 293.  40.  45.  87. 331.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.127 0.137 0.084 0.098 0.122 0.111 0.135 0.094 0.001 0.031 0.009 0.023\n",
      " 0.005 0.003 0.013 0.007]\n",
      "Q_est = -6.59\n",
      "\n",
      "-> i_step = 4548\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = -0.42\n",
      "new_state = [1 4]\n",
      "[ 62. 113. 125. 293.  41.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 293.  41.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18893  -6.25405  -6.20538  -6.20714\n",
      "  -6.18624  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.50654 3.04954 2.66422 3.36901 2.31778 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05571 0.10153 0.11231 0.26325 0.03684 0.04043 0.07817 0.29739 0.\n",
      " 0.0027  0.00359 0.00449 0.00359 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 293.  41.  45.  87. 331.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.128 0.12  0.096 0.088 0.129 0.112 0.169 0.073 0.001 0.037 0.01  0.017\n",
      " 0.003 0.001 0.012 0.004]\n",
      "Q_est = -6.56\n",
      "\n",
      "-> i_step = 4549\n",
      "cur_state = [1 4]\n",
      "action = 7\n",
      "reward = 0.06\n",
      "new_state = [2 7]\n",
      "[ 62. 113. 125. 293.  41.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 293.  41.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18893  -6.25405  -6.20538  -6.20714\n",
      "  -6.18624  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.50654 3.04954 2.66422 3.36901 2.31778 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05571 0.10153 0.11231 0.26325 0.03684 0.04043 0.07817 0.29739 0.\n",
      " 0.0027  0.00359 0.00449 0.00359 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 293.  41.  45.  87. 331.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.144 0.146 0.076 0.105 0.107 0.08  0.172 0.084 0.    0.035 0.011 0.011\n",
      " 0.007 0.004 0.016 0.002]\n",
      "Q_est = -6.56\n",
      "\n",
      "-> i_step = 4550\n",
      "cur_state = [2 7]\n",
      "action = 7\n",
      "reward = 0.24\n",
      "new_state = [3 7]\n",
      "[ 62. 113. 125. 293.  41.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 293.  41.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18893  -6.25405  -6.20538  -6.20714\n",
      "  -6.18624  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.50654 3.04954 2.66422 3.36901 2.31778 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05571 0.10153 0.11231 0.26325 0.03684 0.04043 0.07817 0.29739 0.\n",
      " 0.0027  0.00359 0.00449 0.00359 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 293.  41.  45.  87. 331.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.16  0.138 0.085 0.091 0.122 0.096 0.153 0.085 0.    0.03  0.006 0.016\n",
      " 0.007 0.001 0.01  0.   ]\n",
      "Q_est = -6.49\n",
      "\n",
      "-> i_step = 4551\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 113. 125. 293.  41.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 293.  41.  45.  87. 331.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18893  -6.25405  -6.20538  -6.20714\n",
      "  -6.18624  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.50654 3.04954 2.66422 3.36901 2.31778 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05571 0.10153 0.11231 0.26325 0.03684 0.04043 0.07817 0.29739 0.\n",
      " 0.0027  0.00359 0.00449 0.00359 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 293.  41.  45.  87. 331.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.125 0.137 0.092 0.081 0.132 0.109 0.154 0.087 0.    0.035 0.011 0.012\n",
      " 0.014 0.002 0.008 0.001]\n",
      "Q_est = -6.52\n",
      "\n",
      "-> i_step = 4552\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 1.07\n",
      "new_state = [1 7]\n",
      "[ 62. 113. 125. 293.  41.  45.  87. 332.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 293.  41.  45.  87. 332.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18893  -6.25405  -6.20538  -6.20714\n",
      "  -6.18784  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.50654 3.04954 2.66422 3.36901 2.31447 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05566 0.10144 0.11221 0.26302 0.0368  0.04039 0.0781  0.29803 0.\n",
      " 0.00269 0.00359 0.00449 0.00359 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 293.  41.  45.  87. 332.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.162 0.145 0.082 0.087 0.116 0.088 0.168 0.08  0.    0.028 0.006 0.018\n",
      " 0.003 0.002 0.01  0.005]\n",
      "Q_est = -6.52\n",
      "\n",
      "-> i_step = 4553\n",
      "cur_state = [1 7]\n",
      "action = 0\n",
      "reward = -0.53\n",
      "new_state = [2 0]\n",
      "[ 62. 113. 125. 293.  41.  45.  87. 332.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 293.  41.  45.  87. 332.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18893  -6.25405  -6.20538  -6.20714\n",
      "  -6.18784  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.50654 3.04954 2.66422 3.36901 2.31447 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05566 0.10144 0.11221 0.26302 0.0368  0.04039 0.0781  0.29803 0.\n",
      " 0.00269 0.00359 0.00449 0.00359 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 293.  41.  45.  87. 332.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.155 0.146 0.088 0.08  0.112 0.108 0.146 0.089 0.    0.025 0.007 0.015\n",
      " 0.007 0.004 0.015 0.003]\n",
      "Q_est = -6.53\n",
      "\n",
      "-> i_step = 4554\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = 1.24\n",
      "new_state = [3 7]\n",
      "[ 62. 113. 125. 293.  41.  45.  87. 332.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 293.  41.  45.  87. 332.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18893  -6.25405  -6.20538  -6.20714\n",
      "  -6.18784  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.50654 3.04954 2.66422 3.36901 2.31447 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05566 0.10144 0.11221 0.26302 0.0368  0.04039 0.0781  0.29803 0.\n",
      " 0.00269 0.00359 0.00449 0.00359 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 293.  41.  45.  87. 332.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.14  0.15  0.081 0.09  0.12  0.116 0.147 0.079 0.    0.029 0.013 0.015\n",
      " 0.004 0.004 0.011 0.001]\n",
      "Q_est = -6.51\n",
      "\n",
      "-> i_step = 4555\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 113. 125. 293.  41.  45.  87. 332.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 125. 293.  41.  45.  87. 332.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.18676  -6.18893  -6.25405  -6.20538  -6.20714\n",
      "  -6.18784  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41907 2.50654 3.04954 2.66422 3.36901 2.31447 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05566 0.10144 0.11221 0.26302 0.0368  0.04039 0.0781  0.29803 0.\n",
      " 0.00269 0.00359 0.00449 0.00359 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 125. 293.  41.  45.  87. 332.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.121 0.152 0.104 0.083 0.112 0.107 0.146 0.08  0.001 0.042 0.008 0.017\n",
      " 0.009 0.001 0.013 0.004]\n",
      "Q_est = -6.60\n",
      "\n",
      "-> i_step = 4556\n",
      "cur_state = [0 0]\n",
      "action = 2\n",
      "reward = 0.08\n",
      "new_state = [1 2]\n",
      "[ 62. 113. 126. 293.  41.  45.  87. 332.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 126. 293.  41.  45.  87. 332.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.19897  -6.18893  -6.25405  -6.20538  -6.20714\n",
      "  -6.18784  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41333 2.50654 3.04954 2.66422 3.36901 2.31447 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05561 0.10135 0.113   0.26278 0.03677 0.04036 0.07803 0.29776 0.\n",
      " 0.00269 0.00359 0.00448 0.00359 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 126. 293.  41.  45.  87. 332.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.139 0.154 0.083 0.079 0.146 0.11  0.142 0.083 0.    0.018 0.012 0.014\n",
      " 0.009 0.002 0.008 0.001]\n",
      "Q_est = -6.45\n",
      "\n",
      "-> i_step = 4557\n",
      "cur_state = [1 2]\n",
      "action = 0\n",
      "reward = 0.09\n",
      "new_state = [2 0]\n",
      "[ 62. 113. 126. 293.  41.  45.  87. 332.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 126. 293.  41.  45.  87. 332.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.19897  -6.18893  -6.25405  -6.20538  -6.20714\n",
      "  -6.18784  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41333 2.50654 3.04954 2.66422 3.36901 2.31447 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05561 0.10135 0.113   0.26278 0.03677 0.04036 0.07803 0.29776 0.\n",
      " 0.00269 0.00359 0.00448 0.00359 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 126. 293.  41.  45.  87. 332.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14 15]\n",
      "probs = [0.115 0.152 0.086 0.098 0.139 0.091 0.157 0.084 0.    0.04  0.009 0.012\n",
      " 0.006 0.    0.01  0.001]\n",
      "Q_est = -6.52\n",
      "\n",
      "-> i_step = 4558\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = 0.99\n",
      "new_state = [3 7]\n",
      "[ 62. 113. 126. 293.  41.  45.  87. 332.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 126. 293.  41.  45.  87. 332.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.19897  -6.18893  -6.25405  -6.20538  -6.20714\n",
      "  -6.18784  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41333 2.50654 3.04954 2.66422 3.36901 2.31447 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05561 0.10135 0.113   0.26278 0.03677 0.04036 0.07803 0.29776 0.\n",
      " 0.00269 0.00359 0.00448 0.00359 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 126. 293.  41.  45.  87. 332.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.144 0.16  0.088 0.083 0.133 0.087 0.16  0.066 0.    0.035 0.012 0.014\n",
      " 0.003 0.001 0.012 0.002]\n",
      "Q_est = -6.53\n",
      "\n",
      "-> i_step = 4559\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 113. 126. 293.  41.  45.  87. 332.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 126. 293.  41.  45.  87. 332.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.19897  -6.18893  -6.25405  -6.20538  -6.20714\n",
      "  -6.18784  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41333 2.50654 3.04954 2.66422 3.36901 2.31447 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.19\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05561 0.10135 0.113   0.26278 0.03677 0.04036 0.07803 0.29776 0.\n",
      " 0.00269 0.00359 0.00448 0.00359 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 126. 293.  41.  45.  87. 332.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.24\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.139 0.136 0.094 0.107 0.117 0.11  0.136 0.077 0.001 0.034 0.007 0.015\n",
      " 0.007 0.002 0.014 0.004]\n",
      "Q_est = -6.57\n",
      "\n",
      "-> i_step = 4560\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = -0.87\n",
      "new_state = [1 7]\n",
      "[ 62. 113. 126. 293.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 126. 293.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.19897  -6.18893  -6.25405  -6.20538  -6.20714\n",
      "  -6.19527  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41333 2.50654 3.04954 2.66422 3.36901 2.31495 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05556 0.10125 0.1129  0.26254 0.03674 0.04032 0.07796 0.29839 0.\n",
      " 0.00269 0.00358 0.00448 0.00358 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 126. 293.  41.  45.  87. 333.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.152 0.141 0.097 0.115 0.1   0.093 0.166 0.069 0.    0.026 0.006 0.02\n",
      " 0.006 0.003 0.003 0.003]\n",
      "Q_est = -6.47\n",
      "\n",
      "-> i_step = 4561\n",
      "cur_state = [1 7]\n",
      "action = 6\n",
      "reward = 0.32\n",
      "new_state = [2 6]\n",
      "[ 62. 113. 126. 293.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 126. 293.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.19897  -6.18893  -6.25405  -6.20538  -6.20714\n",
      "  -6.19527  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41333 2.50654 3.04954 2.66422 3.36901 2.31495 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05556 0.10125 0.1129  0.26254 0.03674 0.04032 0.07796 0.29839 0.\n",
      " 0.00269 0.00358 0.00448 0.00358 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 126. 293.  41.  45.  87. 333.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.152 0.157 0.088 0.078 0.102 0.111 0.145 0.081 0.    0.035 0.01  0.019\n",
      " 0.006 0.003 0.008 0.005]\n",
      "Q_est = -6.56\n",
      "\n",
      "-> i_step = 4562\n",
      "cur_state = [2 6]\n",
      "action = 5\n",
      "reward = 0.29\n",
      "new_state = [3 5]\n",
      "[ 62. 113. 126. 293.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 126. 293.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.19897  -6.18893  -6.25405  -6.20538  -6.20714\n",
      "  -6.19527  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41333 2.50654 3.04954 2.66422 3.36901 2.31495 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05556 0.10125 0.1129  0.26254 0.03674 0.04032 0.07796 0.29839 0.\n",
      " 0.00269 0.00358 0.00448 0.00358 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 126. 293.  41.  45.  87. 333.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.134 0.146 0.093 0.083 0.133 0.098 0.15  0.072 0.001 0.035 0.014 0.016\n",
      " 0.008 0.001 0.015 0.001]\n",
      "Q_est = -6.58\n",
      "\n",
      "-> i_step = 4563\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 113. 126. 293.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 126. 293.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.19897  -6.18893  -6.25405  -6.20538  -6.20714\n",
      "  -6.19527  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41333 2.50654 3.04954 2.66422 3.36901 2.31495 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05556 0.10125 0.1129  0.26254 0.03674 0.04032 0.07796 0.29839 0.\n",
      " 0.00269 0.00358 0.00448 0.00358 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 126. 293.  41.  45.  87. 333.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.131 0.128 0.087 0.095 0.134 0.107 0.158 0.078 0.    0.041 0.004 0.011\n",
      " 0.006 0.001 0.011 0.008]\n",
      "Q_est = -6.57\n",
      "\n",
      "-> i_step = 4564\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 1.07\n",
      "new_state = [1 3]\n",
      "[ 62. 113. 126. 294.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 126. 294.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.19897  -6.19095  -6.25405  -6.20538  -6.20714\n",
      "  -6.19527  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41333 2.50252 3.04954 2.66422 3.36901 2.31495 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05551 0.10116 0.1128  0.26321 0.03671 0.04029 0.07789 0.29812 0.\n",
      " 0.00269 0.00358 0.00448 0.00358 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 126. 294.  41.  45.  87. 333.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.157 0.153 0.07  0.091 0.134 0.111 0.145 0.067 0.    0.038 0.005 0.009\n",
      " 0.001 0.003 0.009 0.007]\n",
      "Q_est = -6.53\n",
      "\n",
      "-> i_step = 4565\n",
      "cur_state = [1 3]\n",
      "action = 5\n",
      "reward = 0.31\n",
      "new_state = [2 5]\n",
      "[ 62. 113. 126. 294.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 126. 294.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.19897  -6.19095  -6.25405  -6.20538  -6.20714\n",
      "  -6.19527  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41333 2.50252 3.04954 2.66422 3.36901 2.31495 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05551 0.10116 0.1128  0.26321 0.03671 0.04029 0.07789 0.29812 0.\n",
      " 0.00269 0.00358 0.00448 0.00358 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 126. 294.  41.  45.  87. 333.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.13  0.141 0.087 0.102 0.122 0.119 0.157 0.074 0.001 0.03  0.009 0.012\n",
      " 0.004 0.001 0.007 0.004]\n",
      "Q_est = -6.49\n",
      "\n",
      "-> i_step = 4566\n",
      "cur_state = [2 5]\n",
      "action = 6\n",
      "reward = -0.99\n",
      "new_state = [3 6]\n",
      "[ 62. 113. 126. 294.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 126. 294.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.19897  -6.19095  -6.25405  -6.20538  -6.20714\n",
      "  -6.19527  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41333 2.50252 3.04954 2.66422 3.36901 2.31495 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05551 0.10116 0.1128  0.26321 0.03671 0.04029 0.07789 0.29812 0.\n",
      " 0.00269 0.00358 0.00448 0.00358 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 126. 294.  41.  45.  87. 333.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.147 0.131 0.096 0.079 0.124 0.109 0.164 0.07  0.    0.04  0.01  0.009\n",
      " 0.005 0.002 0.01  0.004]\n",
      "Q_est = -6.54\n",
      "\n",
      "-> i_step = 4567\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 113. 126. 294.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 126. 294.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.19897  -6.19095  -6.25405  -6.20538  -6.20714\n",
      "  -6.19527  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41333 2.50252 3.04954 2.66422 3.36901 2.31495 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05551 0.10116 0.1128  0.26321 0.03671 0.04029 0.07789 0.29812 0.\n",
      " 0.00269 0.00358 0.00448 0.00358 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 126. 294.  41.  45.  87. 333.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14 15]\n",
      "probs = [0.143 0.123 0.088 0.092 0.129 0.104 0.166 0.069 0.    0.032 0.013 0.016\n",
      " 0.009 0.    0.012 0.004]\n",
      "Q_est = -6.56\n",
      "\n",
      "-> i_step = 4568\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 0.39\n",
      "new_state = [1 3]\n",
      "[ 62. 113. 126. 295.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 126. 295.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.19897  -6.19527  -6.25405  -6.20538  -6.20714\n",
      "  -6.19527  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41333 2.49937 3.04954 2.66422 3.36901 2.31495 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05546 0.10107 0.1127  0.26386 0.03667 0.04025 0.07782 0.29785 0.\n",
      " 0.00268 0.00358 0.00447 0.00358 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 126. 295.  41.  45.  87. 333.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.155 0.136 0.072 0.088 0.134 0.108 0.152 0.08  0.001 0.037 0.01  0.007\n",
      " 0.003 0.002 0.013 0.002]\n",
      "Q_est = -6.53\n",
      "\n",
      "-> i_step = 4569\n",
      "cur_state = [1 3]\n",
      "action = 5\n",
      "reward = -2.39\n",
      "new_state = [2 5]\n",
      "[ 62. 113. 126. 295.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 126. 295.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.19897  -6.19527  -6.25405  -6.20538  -6.20714\n",
      "  -6.19527  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41333 2.49937 3.04954 2.66422 3.36901 2.31495 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05546 0.10107 0.1127  0.26386 0.03667 0.04025 0.07782 0.29785 0.\n",
      " 0.00268 0.00358 0.00447 0.00358 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 126. 295.  41.  45.  87. 333.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.141 0.123 0.103 0.082 0.132 0.107 0.15  0.082 0.    0.04  0.01  0.009\n",
      " 0.009 0.001 0.01  0.001]\n",
      "Q_est = -6.53\n",
      "\n",
      "-> i_step = 4570\n",
      "cur_state = [2 5]\n",
      "action = 6\n",
      "reward = 0.28\n",
      "new_state = [3 6]\n",
      "[ 62. 113. 126. 295.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 126. 295.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.19897  -6.19527  -6.25405  -6.20538  -6.20714\n",
      "  -6.19527  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41333 2.49937 3.04954 2.66422 3.36901 2.31495 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05546 0.10107 0.1127  0.26386 0.03667 0.04025 0.07782 0.29785 0.\n",
      " 0.00268 0.00358 0.00447 0.00358 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 126. 295.  41.  45.  87. 333.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.124 0.138 0.079 0.089 0.142 0.11  0.142 0.083 0.001 0.034 0.01  0.016\n",
      " 0.007 0.006 0.014 0.005]\n",
      "Q_est = -6.60\n",
      "\n",
      "-> i_step = 4571\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 113. 126. 295.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 113. 126. 295.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.19382  -6.19897  -6.19527  -6.25405  -6.20538  -6.20714\n",
      "  -6.19527  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.17184 2.41333 2.49937 3.04954 2.66422 3.36901 2.31495 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05546 0.10107 0.1127  0.26386 0.03667 0.04025 0.07782 0.29785 0.\n",
      " 0.00268 0.00358 0.00447 0.00358 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 113. 126. 295.  41.  45.  87. 333.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14 15]\n",
      "probs = [0.128 0.127 0.107 0.085 0.12  0.094 0.162 0.088 0.    0.039 0.007 0.017\n",
      " 0.004 0.    0.02  0.002]\n",
      "Q_est = -6.60\n",
      "\n",
      "-> i_step = 4572\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 0.70\n",
      "new_state = [1 1]\n",
      "[ 62. 114. 126. 295.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 114. 126. 295.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.20236  -6.19897  -6.19527  -6.25405  -6.20538  -6.20714\n",
      "  -6.19527  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.1592  2.41333 2.49937 3.04954 2.66422 3.36901 2.31495 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05541 0.10188 0.1126  0.26363 0.03664 0.04021 0.07775 0.29759 0.\n",
      " 0.00268 0.00357 0.00447 0.00357 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 114. 126. 295.  41.  45.  87. 333.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.135 0.152 0.088 0.084 0.126 0.098 0.151 0.075 0.    0.038 0.008 0.014\n",
      " 0.007 0.002 0.016 0.006]\n",
      "Q_est = -6.61\n",
      "\n",
      "-> i_step = 4573\n",
      "cur_state = [1 1]\n",
      "action = 6\n",
      "reward = 0.21\n",
      "new_state = [2 6]\n",
      "[ 62. 114. 126. 295.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 114. 126. 295.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.20236  -6.19897  -6.19527  -6.25405  -6.20538  -6.20714\n",
      "  -6.19527  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.1592  2.41333 2.49937 3.04954 2.66422 3.36901 2.31495 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05541 0.10188 0.1126  0.26363 0.03664 0.04021 0.07775 0.29759 0.\n",
      " 0.00268 0.00357 0.00447 0.00357 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 114. 126. 295.  41.  45.  87. 333.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.152 0.135 0.076 0.092 0.129 0.078 0.159 0.1   0.    0.032 0.012 0.015\n",
      " 0.008 0.001 0.007 0.004]\n",
      "Q_est = -6.52\n",
      "\n",
      "-> i_step = 4574\n",
      "cur_state = [2 6]\n",
      "action = 5\n",
      "reward = 0.11\n",
      "new_state = [3 5]\n",
      "[ 62. 114. 126. 295.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 114. 126. 295.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.20236  -6.19897  -6.19527  -6.25405  -6.20538  -6.20714\n",
      "  -6.19527  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.1592  2.41333 2.49937 3.04954 2.66422 3.36901 2.31495 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05541 0.10188 0.1126  0.26363 0.03664 0.04021 0.07775 0.29759 0.\n",
      " 0.00268 0.00357 0.00447 0.00357 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 114. 126. 295.  41.  45.  87. 333.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.143 0.14  0.099 0.088 0.096 0.102 0.139 0.094 0.    0.03  0.013 0.018\n",
      " 0.007 0.005 0.021 0.005]\n",
      "Q_est = -6.63\n",
      "\n",
      "-> i_step = 4575\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 114. 126. 295.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 114. 126. 295.  41.  45.  87. 333.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.20236  -6.19897  -6.19527  -6.25405  -6.20538  -6.20714\n",
      "  -6.19527  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.1592  2.41333 2.49937 3.04954 2.66422 3.36901 2.31495 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05541 0.10188 0.1126  0.26363 0.03664 0.04021 0.07775 0.29759 0.\n",
      " 0.00268 0.00357 0.00447 0.00357 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 114. 126. 295.  41.  45.  87. 333.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14 15]\n",
      "probs = [0.144 0.148 0.084 0.092 0.132 0.088 0.154 0.077 0.    0.039 0.01  0.016\n",
      " 0.005 0.    0.007 0.004]\n",
      "Q_est = -6.54\n",
      "\n",
      "-> i_step = 4576\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = -0.63\n",
      "new_state = [1 7]\n",
      "[ 62. 114. 126. 295.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 114. 126. 295.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.20236  -6.19897  -6.19527  -6.25405  -6.20538  -6.20714\n",
      "  -6.20193  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.1592  2.41333 2.49937 3.04954 2.66422 3.36901 2.31468 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05536 0.10179 0.1125  0.26339 0.03661 0.04018 0.07768 0.29821 0.\n",
      " 0.00268 0.00357 0.00446 0.00357 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 114. 126. 295.  41.  45.  87. 334.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.137 0.122 0.087 0.095 0.137 0.104 0.157 0.073 0.003 0.035 0.005 0.014\n",
      " 0.01  0.001 0.013 0.007]\n",
      "Q_est = -6.59\n",
      "\n",
      "-> i_step = 4577\n",
      "cur_state = [1 7]\n",
      "action = 2\n",
      "reward = 1.01\n",
      "new_state = [2 2]\n",
      "[ 62. 114. 126. 295.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 114. 126. 295.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.20236  -6.19897  -6.19527  -6.25405  -6.20538  -6.20714\n",
      "  -6.20193  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.1592  2.41333 2.49937 3.04954 2.66422 3.36901 2.31468 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05536 0.10179 0.1125  0.26339 0.03661 0.04018 0.07768 0.29821 0.\n",
      " 0.00268 0.00357 0.00446 0.00357 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 114. 126. 295.  41.  45.  87. 334.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.155 0.144 0.101 0.089 0.113 0.092 0.154 0.089 0.    0.028 0.008 0.015\n",
      " 0.004 0.001 0.006 0.001]\n",
      "Q_est = -6.46\n",
      "\n",
      "-> i_step = 4578\n",
      "cur_state = [2 2]\n",
      "action = 7\n",
      "reward = -0.03\n",
      "new_state = [3 7]\n",
      "[ 62. 114. 126. 295.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 114. 126. 295.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.20236  -6.19897  -6.19527  -6.25405  -6.20538  -6.20714\n",
      "  -6.20193  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.1592  2.41333 2.49937 3.04954 2.66422 3.36901 2.31468 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05536 0.10179 0.1125  0.26339 0.03661 0.04018 0.07768 0.29821 0.\n",
      " 0.00268 0.00357 0.00446 0.00357 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 114. 126. 295.  41.  45.  87. 334.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.133 0.161 0.087 0.106 0.136 0.091 0.133 0.082 0.    0.034 0.006 0.018\n",
      " 0.003 0.003 0.006 0.001]\n",
      "Q_est = -6.49\n",
      "\n",
      "-> i_step = 4579\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 114. 126. 295.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 114. 126. 295.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.20236  -6.19897  -6.19527  -6.25405  -6.20538  -6.20714\n",
      "  -6.20193  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.1592  2.41333 2.49937 3.04954 2.66422 3.36901 2.31468 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05536 0.10179 0.1125  0.26339 0.03661 0.04018 0.07768 0.29821 0.\n",
      " 0.00268 0.00357 0.00446 0.00357 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 114. 126. 295.  41.  45.  87. 334.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.151 0.133 0.098 0.115 0.108 0.1   0.143 0.074 0.    0.028 0.012 0.017\n",
      " 0.005 0.004 0.008 0.004]\n",
      "Q_est = -6.52\n",
      "\n",
      "-> i_step = 4580\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 0.96\n",
      "new_state = [1 3]\n",
      "[ 62. 114. 126. 296.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 114. 126. 296.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.20236  -6.19897  -6.19766  -6.25405  -6.20538  -6.20714\n",
      "  -6.20193  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.1592  2.41333 2.49548 3.04954 2.66422 3.36901 2.31468 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05531 0.10169 0.1124  0.26405 0.03657 0.04014 0.07761 0.29795 0.\n",
      " 0.00268 0.00357 0.00446 0.00357 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 114. 126. 296.  41.  45.  87. 334.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.142 0.144 0.094 0.082 0.148 0.1   0.142 0.071 0.001 0.041 0.006 0.012\n",
      " 0.002 0.002 0.01  0.003]\n",
      "Q_est = -6.54\n",
      "\n",
      "-> i_step = 4581\n",
      "cur_state = [1 3]\n",
      "action = 1\n",
      "reward = -2.23\n",
      "new_state = [2 1]\n",
      "[ 62. 114. 126. 296.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 114. 126. 296.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.20236  -6.19897  -6.19766  -6.25405  -6.20538  -6.20714\n",
      "  -6.20193  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.1592  2.41333 2.49548 3.04954 2.66422 3.36901 2.31468 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05531 0.10169 0.1124  0.26405 0.03657 0.04014 0.07761 0.29795 0.\n",
      " 0.00268 0.00357 0.00446 0.00357 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 114. 126. 296.  41.  45.  87. 334.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.146 0.161 0.078 0.088 0.121 0.098 0.156 0.07  0.001 0.031 0.015 0.018\n",
      " 0.002 0.002 0.012 0.001]\n",
      "Q_est = -6.54\n",
      "\n",
      "-> i_step = 4582\n",
      "cur_state = [2 1]\n",
      "action = 1\n",
      "reward = -0.14\n",
      "new_state = [3 1]\n",
      "[ 62. 114. 126. 296.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 114. 126. 296.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.20236  -6.19897  -6.19766  -6.25405  -6.20538  -6.20714\n",
      "  -6.20193  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.1592  2.41333 2.49548 3.04954 2.66422 3.36901 2.31468 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05531 0.10169 0.1124  0.26405 0.03657 0.04014 0.07761 0.29795 0.\n",
      " 0.00268 0.00357 0.00446 0.00357 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 114. 126. 296.  41.  45.  87. 334.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14 15]\n",
      "probs = [0.136 0.157 0.092 0.083 0.124 0.112 0.121 0.076 0.    0.036 0.013 0.022\n",
      " 0.011 0.    0.014 0.003]\n",
      "Q_est = -6.61\n",
      "\n",
      "-> i_step = 4583\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 114. 126. 296.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 114. 126. 296.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.20236  -6.19897  -6.19766  -6.25405  -6.20538  -6.20714\n",
      "  -6.20193  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.1592  2.41333 2.49548 3.04954 2.66422 3.36901 2.31468 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05531 0.10169 0.1124  0.26405 0.03657 0.04014 0.07761 0.29795 0.\n",
      " 0.00268 0.00357 0.00446 0.00357 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 114. 126. 296.  41.  45.  87. 334.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.153 0.139 0.102 0.093 0.126 0.101 0.137 0.079 0.    0.026 0.005 0.018\n",
      " 0.007 0.002 0.012 0.   ]\n",
      "Q_est = -6.50\n",
      "\n",
      "-> i_step = 4584\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 0.41\n",
      "new_state = [1 3]\n",
      "[ 62. 114. 126. 297.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 114. 126. 297.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.20236  -6.19897  -6.20193  -6.25405  -6.20538  -6.20714\n",
      "  -6.20193  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.1592  2.41333 2.49236 3.04954 2.66422 3.36901 2.31468 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05526 0.1016  0.1123  0.26471 0.03654 0.04011 0.07754 0.29768 0.\n",
      " 0.00267 0.00357 0.00446 0.00357 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 114. 126. 297.  41.  45.  87. 334.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.121 0.142 0.087 0.102 0.119 0.104 0.16  0.076 0.    0.039 0.009 0.02\n",
      " 0.004 0.001 0.011 0.005]\n",
      "Q_est = -6.58\n",
      "\n",
      "-> i_step = 4585\n",
      "cur_state = [1 3]\n",
      "action = 3\n",
      "reward = -0.16\n",
      "new_state = [2 3]\n",
      "[ 62. 114. 126. 297.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 114. 126. 297.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.20236  -6.19897  -6.20193  -6.25405  -6.20538  -6.20714\n",
      "  -6.20193  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.1592  2.41333 2.49236 3.04954 2.66422 3.36901 2.31468 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05526 0.1016  0.1123  0.26471 0.03654 0.04011 0.07754 0.29768 0.\n",
      " 0.00267 0.00357 0.00446 0.00357 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 114. 126. 297.  41.  45.  87. 334.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.127 0.147 0.086 0.084 0.136 0.11  0.144 0.095 0.    0.031 0.002 0.017\n",
      " 0.003 0.001 0.007 0.01 ]\n",
      "Q_est = -6.53\n",
      "\n",
      "-> i_step = 4586\n",
      "cur_state = [2 3]\n",
      "action = 5\n",
      "reward = -0.84\n",
      "new_state = [3 5]\n",
      "[ 62. 114. 126. 297.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 114. 126. 297.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.20236  -6.19897  -6.20193  -6.25405  -6.20538  -6.20714\n",
      "  -6.20193  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.1592  2.41333 2.49236 3.04954 2.66422 3.36901 2.31468 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05526 0.1016  0.1123  0.26471 0.03654 0.04011 0.07754 0.29768 0.\n",
      " 0.00267 0.00357 0.00446 0.00357 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 114. 126. 297.  41.  45.  87. 334.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.133 0.126 0.086 0.086 0.141 0.098 0.16  0.098 0.    0.02  0.009 0.012\n",
      " 0.007 0.001 0.022 0.001]\n",
      "Q_est = -6.53\n",
      "\n",
      "-> i_step = 4587\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 114. 126. 297.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 114. 126. 297.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.20236  -6.19897  -6.20193  -6.25405  -6.20538  -6.20714\n",
      "  -6.20193  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.1592  2.41333 2.49236 3.04954 2.66422 3.36901 2.31468 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05526 0.1016  0.1123  0.26471 0.03654 0.04011 0.07754 0.29768 0.\n",
      " 0.00267 0.00357 0.00446 0.00357 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 114. 126. 297.  41.  45.  87. 334.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.143 0.14  0.097 0.103 0.116 0.105 0.125 0.088 0.    0.033 0.015 0.01\n",
      " 0.005 0.003 0.011 0.006]\n",
      "Q_est = -6.55\n",
      "\n",
      "-> i_step = 4588\n",
      "cur_state = [0 0]\n",
      "action = 2\n",
      "reward = 0.42\n",
      "new_state = [1 2]\n",
      "[ 62. 114. 127. 297.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 114. 127. 297.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.20236  -6.20836  -6.20193  -6.25405  -6.20538  -6.20714\n",
      "  -6.20193  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.1592  2.40611 2.49236 3.04954 2.66422 3.36901 2.31468 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05521 0.10151 0.11309 0.26447 0.03651 0.04007 0.07747 0.29742 0.\n",
      " 0.00267 0.00356 0.00445 0.00356 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 114. 127. 297.  41.  45.  87. 334.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.145 0.137 0.087 0.083 0.116 0.093 0.165 0.092 0.    0.035 0.012 0.012\n",
      " 0.004 0.003 0.012 0.004]\n",
      "Q_est = -6.55\n",
      "\n",
      "-> i_step = 4589\n",
      "cur_state = [1 2]\n",
      "action = 6\n",
      "reward = -0.91\n",
      "new_state = [2 6]\n",
      "[ 62. 114. 127. 297.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 114. 127. 297.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.20236  -6.20836  -6.20193  -6.25405  -6.20538  -6.20714\n",
      "  -6.20193  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.1592  2.40611 2.49236 3.04954 2.66422 3.36901 2.31468 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05521 0.10151 0.11309 0.26447 0.03651 0.04007 0.07747 0.29742 0.\n",
      " 0.00267 0.00356 0.00445 0.00356 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 114. 127. 297.  41.  45.  87. 334.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.146 0.155 0.082 0.08  0.143 0.096 0.154 0.072 0.    0.032 0.006 0.016\n",
      " 0.001 0.003 0.01  0.004]\n",
      "Q_est = -6.52\n",
      "\n",
      "-> i_step = 4590\n",
      "cur_state = [2 6]\n",
      "action = 5\n",
      "reward = 0.01\n",
      "new_state = [3 5]\n",
      "[ 62. 114. 127. 297.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 114. 127. 297.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.20236  -6.20836  -6.20193  -6.25405  -6.20538  -6.20714\n",
      "  -6.20193  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.1592  2.40611 2.49236 3.04954 2.66422 3.36901 2.31468 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05521 0.10151 0.11309 0.26447 0.03651 0.04007 0.07747 0.29742 0.\n",
      " 0.00267 0.00356 0.00445 0.00356 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 114. 127. 297.  41.  45.  87. 334.   0.   3.   4.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.159 0.13  0.083 0.08  0.132 0.089 0.166 0.079 0.001 0.031 0.012 0.013\n",
      " 0.006 0.004 0.011 0.004]\n",
      "Q_est = -6.55\n",
      "\n",
      "-> i_step = 4591\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 114. 127. 297.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 114. 127. 297.  41.  45.  87. 334.   7.   3.   4.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.20236  -6.20836  -6.20193  -6.25405  -6.20538  -6.20714\n",
      "  -6.20193  -9.74843 -10.21463  -8.30076  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.1592  2.40611 2.49236 3.04954 2.66422 3.36901 2.31468 1.74413\n",
      " 4.1373  2.16683 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bset_nvisits = [ 62. 120. 130. 301.  41.  48.  89. 340.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15]\n",
      "probs = [0.124 0.141 0.079 0.092 0.141 0.121 0.15  0.075 0.002 0.036 0.005 0.012\n",
      " 0.009 0.    0.012 0.001]\n",
      "Q_est = -6.57\n",
      "\n",
      "-> i_step = 4689\n",
      "cur_state = [1 7]\n",
      "action = 6\n",
      "reward = -1.43\n",
      "new_state = [2 6]\n",
      "[ 62. 120. 130. 301.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 120. 130. 301.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.23365  -6.24205  -6.22776  -6.25405  -6.3075   -6.26121\n",
      "  -6.23174  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.0834  2.39129 2.49271 3.04954 2.64396 3.35382 2.30727 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05401 0.10453 0.11324 0.2622  0.03571 0.04181 0.07753 0.29617 0.\n",
      " 0.00261 0.00436 0.00436 0.00348 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 120. 130. 301.  41.  48.  89. 340.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.139 0.127 0.079 0.1   0.142 0.097 0.14  0.077 0.001 0.036 0.007 0.027\n",
      " 0.005 0.002 0.017 0.004]\n",
      "Q_est = -6.67\n",
      "\n",
      "-> i_step = 4690\n",
      "cur_state = [2 6]\n",
      "action = 3\n",
      "reward = -0.01\n",
      "new_state = [3 3]\n",
      "[ 62. 120. 130. 301.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 120. 130. 301.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.23365  -6.24205  -6.22776  -6.25405  -6.3075   -6.26121\n",
      "  -6.23174  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.0834  2.39129 2.49271 3.04954 2.64396 3.35382 2.30727 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05401 0.10453 0.11324 0.2622  0.03571 0.04181 0.07753 0.29617 0.\n",
      " 0.00261 0.00436 0.00436 0.00348 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 120. 130. 301.  41.  48.  89. 340.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.136 0.141 0.078 0.1   0.147 0.106 0.145 0.068 0.001 0.033 0.003 0.017\n",
      " 0.006 0.004 0.009 0.006]\n",
      "Q_est = -6.58\n",
      "\n",
      "-> i_step = 4691\n",
      "cur_state = [3 3]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 120. 130. 301.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 120. 130. 301.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.23365  -6.24205  -6.22776  -6.25405  -6.3075   -6.26121\n",
      "  -6.23174  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.0834  2.39129 2.49271 3.04954 2.64396 3.35382 2.30727 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05401 0.10453 0.11324 0.2622  0.03571 0.04181 0.07753 0.29617 0.\n",
      " 0.00261 0.00436 0.00436 0.00348 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 120. 130. 301.  41.  48.  89. 340.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.169 0.141 0.064 0.086 0.133 0.09  0.139 0.084 0.    0.038 0.004 0.018\n",
      " 0.008 0.003 0.015 0.008]\n",
      "Q_est = -6.66\n",
      "\n",
      "-> i_step = 4692\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 0.55\n",
      "new_state = [1 3]\n",
      "[ 62. 120. 130. 302.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 120. 130. 302.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.23365  -6.24205  -6.2314   -6.25405  -6.3075   -6.26121\n",
      "  -6.23174  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.0834  2.39129 2.48938 3.04954 2.64396 3.35382 2.30727 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05396 0.10444 0.11314 0.26284 0.03568 0.04178 0.07746 0.29591 0.\n",
      " 0.00261 0.00435 0.00435 0.00348 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 120. 130. 302.  41.  48.  89. 340.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.156 0.135 0.077 0.092 0.114 0.094 0.156 0.082 0.002 0.034 0.009 0.019\n",
      " 0.007 0.006 0.014 0.003]\n",
      "Q_est = -6.63\n",
      "\n",
      "-> i_step = 4693\n",
      "cur_state = [1 3]\n",
      "action = 0\n",
      "reward = 0.03\n",
      "new_state = [2 0]\n",
      "[ 62. 120. 130. 302.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 120. 130. 302.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.23365  -6.24205  -6.2314   -6.25405  -6.3075   -6.26121\n",
      "  -6.23174  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.0834  2.39129 2.48938 3.04954 2.64396 3.35382 2.30727 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05396 0.10444 0.11314 0.26284 0.03568 0.04178 0.07746 0.29591 0.\n",
      " 0.00261 0.00435 0.00435 0.00348 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 120. 130. 302.  41.  48.  89. 340.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.139 0.133 0.089 0.112 0.118 0.096 0.156 0.083 0.001 0.028 0.007 0.013\n",
      " 0.008 0.004 0.009 0.004]\n",
      "Q_est = -6.55\n",
      "\n",
      "-> i_step = 4694\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = 2.28\n",
      "new_state = [3 7]\n",
      "[ 62. 120. 130. 302.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 120. 130. 302.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.23365  -6.24205  -6.2314   -6.25405  -6.3075   -6.26121\n",
      "  -6.23174  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.0834  2.39129 2.48938 3.04954 2.64396 3.35382 2.30727 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05396 0.10444 0.11314 0.26284 0.03568 0.04178 0.07746 0.29591 0.\n",
      " 0.00261 0.00435 0.00435 0.00348 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 120. 130. 302.  41.  48.  89. 340.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.139 0.133 0.087 0.094 0.138 0.095 0.148 0.085 0.001 0.029 0.007 0.021\n",
      " 0.005 0.004 0.011 0.003]\n",
      "Q_est = -6.58\n",
      "\n",
      "-> i_step = 4695\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 120. 130. 302.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 120. 130. 302.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.23365  -6.24205  -6.2314   -6.25405  -6.3075   -6.26121\n",
      "  -6.23174  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.0834  2.39129 2.48938 3.04954 2.64396 3.35382 2.30727 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05396 0.10444 0.11314 0.26284 0.03568 0.04178 0.07746 0.29591 0.\n",
      " 0.00261 0.00435 0.00435 0.00348 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 120. 130. 302.  41.  48.  89. 340.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.149 0.125 0.073 0.094 0.153 0.109 0.155 0.082 0.001 0.026 0.005 0.01\n",
      " 0.008 0.001 0.006 0.003]\n",
      "Q_est = -6.49\n",
      "\n",
      "-> i_step = 4696\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -0.68\n",
      "new_state = [1 3]\n",
      "[ 62. 120. 130. 303.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 120. 130. 303.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.23365  -6.24205  -6.23909  -6.25405  -6.3075   -6.26121\n",
      "  -6.23174  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.0834  2.39129 2.48887 3.04954 2.64396 3.35382 2.30727 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05391 0.10435 0.11304 0.26348 0.03565 0.04174 0.07739 0.29565 0.\n",
      " 0.00261 0.00435 0.00435 0.00348 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 120. 130. 303.  41.  48.  89. 340.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.132 0.123 0.084 0.086 0.128 0.112 0.172 0.084 0.    0.033 0.004 0.019\n",
      " 0.007 0.003 0.013 0.   ]\n",
      "Q_est = -6.57\n",
      "\n",
      "-> i_step = 4697\n",
      "cur_state = [1 3]\n",
      "action = 0\n",
      "reward = -0.12\n",
      "new_state = [2 0]\n",
      "[ 62. 120. 130. 303.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 120. 130. 303.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.23365  -6.24205  -6.23909  -6.25405  -6.3075   -6.26121\n",
      "  -6.23174  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.0834  2.39129 2.48887 3.04954 2.64396 3.35382 2.30727 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05391 0.10435 0.11304 0.26348 0.03565 0.04174 0.07739 0.29565 0.\n",
      " 0.00261 0.00435 0.00435 0.00348 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 120. 130. 303.  41.  48.  89. 340.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.157 0.136 0.103 0.091 0.13  0.098 0.146 0.074 0.    0.023 0.011 0.013\n",
      " 0.003 0.001 0.01  0.004]\n",
      "Q_est = -6.52\n",
      "\n",
      "-> i_step = 4698\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = 0.54\n",
      "new_state = [3 7]\n",
      "[ 62. 120. 130. 303.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 120. 130. 303.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.23365  -6.24205  -6.23909  -6.25405  -6.3075   -6.26121\n",
      "  -6.23174  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.0834  2.39129 2.48887 3.04954 2.64396 3.35382 2.30727 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05391 0.10435 0.11304 0.26348 0.03565 0.04174 0.07739 0.29565 0.\n",
      " 0.00261 0.00435 0.00435 0.00348 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 120. 130. 303.  41.  48.  89. 340.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.132 0.135 0.082 0.1   0.109 0.103 0.169 0.075 0.    0.045 0.003 0.014\n",
      " 0.012 0.005 0.013 0.003]\n",
      "Q_est = -6.64\n",
      "\n",
      "-> i_step = 4699\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 120. 130. 303.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 120. 130. 303.  41.  48.  89. 340.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.23365  -6.24205  -6.23909  -6.25405  -6.3075   -6.26121\n",
      "  -6.23174  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.0834  2.39129 2.48887 3.04954 2.64396 3.35382 2.30727 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05391 0.10435 0.11304 0.26348 0.03565 0.04174 0.07739 0.29565 0.\n",
      " 0.00261 0.00435 0.00435 0.00348 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 120. 130. 303.  41.  48.  89. 340.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.148 0.133 0.089 0.099 0.118 0.112 0.144 0.082 0.    0.03  0.006 0.02\n",
      " 0.004 0.001 0.011 0.003]\n",
      "Q_est = -6.56\n",
      "\n",
      "-> i_step = 4700\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = -0.03\n",
      "new_state = [1 7]\n",
      "[ 62. 120. 130. 303.  41.  48.  89. 341.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 120. 130. 303.  41.  48.  89. 341.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.23365  -6.24205  -6.23909  -6.25405  -6.3075   -6.26121\n",
      "  -6.23648  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.0834  2.39129 2.48887 3.04954 2.64396 3.35382 2.30554 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05387 0.10426 0.11295 0.26325 0.03562 0.0417  0.07732 0.29626 0.\n",
      " 0.00261 0.00434 0.00434 0.00348 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 120. 130. 303.  41.  48.  89. 341.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.146 0.133 0.093 0.101 0.115 0.101 0.136 0.09  0.001 0.042 0.004 0.017\n",
      " 0.006 0.002 0.008 0.005]\n",
      "Q_est = -6.60\n",
      "\n",
      "-> i_step = 4701\n",
      "cur_state = [1 7]\n",
      "action = 3\n",
      "reward = -1.31\n",
      "new_state = [2 3]\n",
      "[ 62. 120. 130. 303.  41.  48.  89. 341.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 120. 130. 303.  41.  48.  89. 341.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.23365  -6.24205  -6.23909  -6.25405  -6.3075   -6.26121\n",
      "  -6.23648  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.0834  2.39129 2.48887 3.04954 2.64396 3.35382 2.30554 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05387 0.10426 0.11295 0.26325 0.03562 0.0417  0.07732 0.29626 0.\n",
      " 0.00261 0.00434 0.00434 0.00348 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 120. 130. 303.  41.  48.  89. 341.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.149 0.148 0.08  0.082 0.112 0.098 0.155 0.081 0.    0.034 0.008 0.022\n",
      " 0.004 0.003 0.018 0.006]\n",
      "Q_est = -6.66\n",
      "\n",
      "-> i_step = 4702\n",
      "cur_state = [2 3]\n",
      "action = 5\n",
      "reward = -0.31\n",
      "new_state = [3 5]\n",
      "[ 62. 120. 130. 303.  41.  48.  89. 341.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 120. 130. 303.  41.  48.  89. 341.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.23365  -6.24205  -6.23909  -6.25405  -6.3075   -6.26121\n",
      "  -6.23648  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.0834  2.39129 2.48887 3.04954 2.64396 3.35382 2.30554 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05387 0.10426 0.11295 0.26325 0.03562 0.0417  0.07732 0.29626 0.\n",
      " 0.00261 0.00434 0.00434 0.00348 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 120. 130. 303.  41.  48.  89. 341.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.135 0.14  0.089 0.084 0.139 0.102 0.145 0.081 0.    0.039 0.008 0.014\n",
      " 0.005 0.005 0.011 0.003]\n",
      "Q_est = -6.60\n",
      "\n",
      "-> i_step = 4703\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 120. 130. 303.  41.  48.  89. 341.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 120. 130. 303.  41.  48.  89. 341.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.23365  -6.24205  -6.23909  -6.25405  -6.3075   -6.26121\n",
      "  -6.23648  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.0834  2.39129 2.48887 3.04954 2.64396 3.35382 2.30554 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05387 0.10426 0.11295 0.26325 0.03562 0.0417  0.07732 0.29626 0.\n",
      " 0.00261 0.00434 0.00434 0.00348 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 120. 130. 303.  41.  48.  89. 341.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15]\n",
      "probs = [0.147 0.118 0.092 0.111 0.118 0.097 0.161 0.078 0.002 0.035 0.005 0.017\n",
      " 0.008 0.    0.008 0.003]\n",
      "Q_est = -6.57\n",
      "\n",
      "-> i_step = 4704\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 0.61\n",
      "new_state = [1 1]\n",
      "[ 62. 121. 130. 303.  41.  48.  89. 341.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 121. 130. 303.  41.  48.  89. 341.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2428   -6.24205  -6.23909  -6.25405  -6.3075   -6.26121\n",
      "  -6.23648  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.07227 2.39129 2.48887 3.04954 2.64396 3.35382 2.30554 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05382 0.10503 0.11285 0.26302 0.03559 0.04167 0.07726 0.29601 0.\n",
      " 0.0026  0.00434 0.00434 0.00347 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 121. 130. 303.  41.  48.  89. 341.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.147 0.14  0.075 0.107 0.144 0.084 0.158 0.064 0.    0.038 0.004 0.014\n",
      " 0.008 0.001 0.013 0.003]\n",
      "Q_est = -6.59\n",
      "\n",
      "-> i_step = 4705\n",
      "cur_state = [1 1]\n",
      "action = 1\n",
      "reward = 0.58\n",
      "new_state = [2 1]\n",
      "[ 62. 121. 130. 303.  41.  48.  89. 341.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 121. 130. 303.  41.  48.  89. 341.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2428   -6.24205  -6.23909  -6.25405  -6.3075   -6.26121\n",
      "  -6.23648  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.07227 2.39129 2.48887 3.04954 2.64396 3.35382 2.30554 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05382 0.10503 0.11285 0.26302 0.03559 0.04167 0.07726 0.29601 0.\n",
      " 0.0026  0.00434 0.00434 0.00347 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 121. 130. 303.  41.  48.  89. 341.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.137 0.139 0.094 0.095 0.123 0.097 0.167 0.082 0.    0.023 0.005 0.017\n",
      " 0.003 0.005 0.01  0.003]\n",
      "Q_est = -6.53\n",
      "\n",
      "-> i_step = 4706\n",
      "cur_state = [2 1]\n",
      "action = 1\n",
      "reward = -0.50\n",
      "new_state = [3 1]\n",
      "[ 62. 121. 130. 303.  41.  48.  89. 341.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 121. 130. 303.  41.  48.  89. 341.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2428   -6.24205  -6.23909  -6.25405  -6.3075   -6.26121\n",
      "  -6.23648  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.07227 2.39129 2.48887 3.04954 2.64396 3.35382 2.30554 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05382 0.10503 0.11285 0.26302 0.03559 0.04167 0.07726 0.29601 0.\n",
      " 0.0026  0.00434 0.00434 0.00347 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 121. 130. 303.  41.  48.  89. 341.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.14  0.142 0.094 0.084 0.138 0.095 0.15  0.082 0.    0.04  0.005 0.016\n",
      " 0.005 0.002 0.004 0.003]\n",
      "Q_est = -6.55\n",
      "\n",
      "-> i_step = 4707\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 121. 130. 303.  41.  48.  89. 341.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 121. 130. 303.  41.  48.  89. 341.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2428   -6.24205  -6.23909  -6.25405  -6.3075   -6.26121\n",
      "  -6.23648  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.07227 2.39129 2.48887 3.04954 2.64396 3.35382 2.30554 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05382 0.10503 0.11285 0.26302 0.03559 0.04167 0.07726 0.29601 0.\n",
      " 0.0026  0.00434 0.00434 0.00347 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 121. 130. 303.  41.  48.  89. 341.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14]\n",
      "probs = [0.168 0.112 0.101 0.091 0.124 0.116 0.134 0.076 0.    0.03  0.004 0.019\n",
      " 0.01  0.    0.015 0.   ]\n",
      "Q_est = -6.58\n",
      "\n",
      "-> i_step = 4708\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = -0.11\n",
      "new_state = [1 7]\n",
      "[ 62. 121. 130. 303.  41.  48.  89. 342.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 121. 130. 303.  41.  48.  89. 342.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2428   -6.24205  -6.23909  -6.25405  -6.3075   -6.26121\n",
      "  -6.24144  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.07227 2.39129 2.48887 3.04954 2.64396 3.35382 2.30399 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05377 0.10494 0.11275 0.26279 0.03556 0.04163 0.07719 0.29662 0.\n",
      " 0.0026  0.00434 0.00434 0.00347 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 121. 130. 303.  41.  48.  89. 342.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.142 0.141 0.073 0.084 0.133 0.106 0.154 0.086 0.    0.041 0.006 0.013\n",
      " 0.006 0.002 0.009 0.004]\n",
      "Q_est = -6.59\n",
      "\n",
      "-> i_step = 4709\n",
      "cur_state = [1 7]\n",
      "action = 7\n",
      "reward = 1.15\n",
      "new_state = [2 7]\n",
      "[ 62. 121. 130. 303.  41.  48.  89. 342.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 121. 130. 303.  41.  48.  89. 342.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2428   -6.24205  -6.23909  -6.25405  -6.3075   -6.26121\n",
      "  -6.24144  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.07227 2.39129 2.48887 3.04954 2.64396 3.35382 2.30399 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05377 0.10494 0.11275 0.26279 0.03556 0.04163 0.07719 0.29662 0.\n",
      " 0.0026  0.00434 0.00434 0.00347 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 121. 130. 303.  41.  48.  89. 342.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "probs = [0.139 0.127 0.089 0.098 0.126 0.113 0.143 0.087 0.001 0.034 0.005 0.008\n",
      " 0.007 0.006 0.017 0.   ]\n",
      "Q_est = -6.58\n",
      "\n",
      "-> i_step = 4710\n",
      "cur_state = [2 7]\n",
      "action = 7\n",
      "reward = 0.64\n",
      "new_state = [3 7]\n",
      "[ 62. 121. 130. 303.  41.  48.  89. 342.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 121. 130. 303.  41.  48.  89. 342.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2428   -6.24205  -6.23909  -6.25405  -6.3075   -6.26121\n",
      "  -6.24144  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.07227 2.39129 2.48887 3.04954 2.64396 3.35382 2.30399 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05377 0.10494 0.11275 0.26279 0.03556 0.04163 0.07719 0.29662 0.\n",
      " 0.0026  0.00434 0.00434 0.00347 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 121. 130. 303.  41.  48.  89. 342.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.145 0.13  0.086 0.097 0.14  0.09  0.141 0.088 0.001 0.037 0.003 0.02\n",
      " 0.006 0.001 0.012 0.003]\n",
      "Q_est = -6.60\n",
      "\n",
      "-> i_step = 4711\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 121. 130. 303.  41.  48.  89. 342.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 121. 130. 303.  41.  48.  89. 342.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2428   -6.24205  -6.23909  -6.25405  -6.3075   -6.26121\n",
      "  -6.24144  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.07227 2.39129 2.48887 3.04954 2.64396 3.35382 2.30399 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05377 0.10494 0.11275 0.26279 0.03556 0.04163 0.07719 0.29662 0.\n",
      " 0.0026  0.00434 0.00434 0.00347 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 121. 130. 303.  41.  48.  89. 342.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.138 0.132 0.081 0.084 0.142 0.1   0.161 0.08  0.001 0.037 0.008 0.015\n",
      " 0.004 0.005 0.01  0.002]\n",
      "Q_est = -6.58\n",
      "\n",
      "-> i_step = 4712\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -0.44\n",
      "new_state = [1 3]\n",
      "[ 62. 121. 130. 304.  41.  48.  89. 342.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 121. 130. 304.  41.  48.  89. 342.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2428   -6.24205  -6.24596  -6.25405  -6.3075   -6.26121\n",
      "  -6.24144  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.07227 2.39129 2.48764 3.04954 2.64396 3.35382 2.30399 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05373 0.10485 0.11265 0.26343 0.03553 0.04159 0.07712 0.29636 0.\n",
      " 0.0026  0.00433 0.00433 0.00347 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 121. 130. 304.  41.  48.  89. 342.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.156 0.146 0.075 0.103 0.113 0.091 0.143 0.094 0.    0.032 0.008 0.022\n",
      " 0.003 0.001 0.008 0.005]\n",
      "Q_est = -6.58\n",
      "\n",
      "-> i_step = 4713\n",
      "cur_state = [1 3]\n",
      "action = 6\n",
      "reward = -1.38\n",
      "new_state = [2 6]\n",
      "[ 62. 121. 130. 304.  41.  48.  89. 342.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 121. 130. 304.  41.  48.  89. 342.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2428   -6.24205  -6.24596  -6.25405  -6.3075   -6.26121\n",
      "  -6.24144  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.07227 2.39129 2.48764 3.04954 2.64396 3.35382 2.30399 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05373 0.10485 0.11265 0.26343 0.03553 0.04159 0.07712 0.29636 0.\n",
      " 0.0026  0.00433 0.00433 0.00347 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 121. 130. 304.  41.  48.  89. 342.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.149 0.131 0.081 0.096 0.129 0.108 0.153 0.079 0.    0.039 0.006 0.016\n",
      " 0.005 0.001 0.007 0.   ]\n",
      "Q_est = -6.55\n",
      "\n",
      "-> i_step = 4714\n",
      "cur_state = [2 6]\n",
      "action = 5\n",
      "reward = -1.85\n",
      "new_state = [3 5]\n",
      "[ 62. 121. 130. 304.  41.  48.  89. 342.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 121. 130. 304.  41.  48.  89. 342.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2428   -6.24205  -6.24596  -6.25405  -6.3075   -6.26121\n",
      "  -6.24144  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.07227 2.39129 2.48764 3.04954 2.64396 3.35382 2.30399 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05373 0.10485 0.11265 0.26343 0.03553 0.04159 0.07712 0.29636 0.\n",
      " 0.0026  0.00433 0.00433 0.00347 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 121. 130. 304.  41.  48.  89. 342.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.16  0.136 0.083 0.079 0.122 0.091 0.172 0.085 0.    0.028 0.008 0.015\n",
      " 0.01  0.001 0.007 0.003]\n",
      "Q_est = -6.54\n",
      "\n",
      "-> i_step = 4715\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 121. 130. 304.  41.  48.  89. 342.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 121. 130. 304.  41.  48.  89. 342.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2428   -6.24205  -6.24596  -6.25405  -6.3075   -6.26121\n",
      "  -6.24144  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.07227 2.39129 2.48764 3.04954 2.64396 3.35382 2.30399 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05373 0.10485 0.11265 0.26343 0.03553 0.04159 0.07712 0.29636 0.\n",
      " 0.0026  0.00433 0.00433 0.00347 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 121. 130. 304.  41.  48.  89. 342.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.151 0.142 0.088 0.093 0.128 0.112 0.136 0.075 0.    0.032 0.004 0.015\n",
      " 0.003 0.004 0.017 0.   ]\n",
      "Q_est = -6.57\n",
      "\n",
      "-> i_step = 4716\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 0.63\n",
      "new_state = [1 7]\n",
      "[ 62. 121. 130. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 121. 130. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2428   -6.24205  -6.24596  -6.25405  -6.3075   -6.26121\n",
      "  -6.2442   -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.07227 2.39129 2.48764 3.04954 2.64396 3.35382 2.3012  1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05368 0.10476 0.11255 0.2632  0.0355  0.04156 0.07706 0.29697 0.\n",
      " 0.0026  0.00433 0.00433 0.00346 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 121. 130. 304.  41.  48.  89. 343.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.151 0.144 0.097 0.101 0.141 0.084 0.136 0.075 0.    0.035 0.005 0.013\n",
      " 0.004 0.001 0.011 0.002]\n",
      "Q_est = -6.55\n",
      "\n",
      "-> i_step = 4717\n",
      "cur_state = [1 7]\n",
      "action = 7\n",
      "reward = -0.25\n",
      "new_state = [2 7]\n",
      "[ 62. 121. 130. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 121. 130. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2428   -6.24205  -6.24596  -6.25405  -6.3075   -6.26121\n",
      "  -6.2442   -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.07227 2.39129 2.48764 3.04954 2.64396 3.35382 2.3012  1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05368 0.10476 0.11255 0.2632  0.0355  0.04156 0.07706 0.29697 0.\n",
      " 0.0026  0.00433 0.00433 0.00346 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 121. 130. 304.  41.  48.  89. 343.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.14  0.157 0.092 0.079 0.129 0.092 0.15  0.081 0.    0.038 0.006 0.014\n",
      " 0.007 0.001 0.012 0.002]\n",
      "Q_est = -6.58\n",
      "\n",
      "-> i_step = 4718\n",
      "cur_state = [2 7]\n",
      "action = 7\n",
      "reward = 0.57\n",
      "new_state = [3 7]\n",
      "[ 62. 121. 130. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 121. 130. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2428   -6.24205  -6.24596  -6.25405  -6.3075   -6.26121\n",
      "  -6.2442   -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.07227 2.39129 2.48764 3.04954 2.64396 3.35382 2.3012  1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05368 0.10476 0.11255 0.2632  0.0355  0.04156 0.07706 0.29697 0.\n",
      " 0.0026  0.00433 0.00433 0.00346 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 121. 130. 304.  41.  48.  89. 343.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.124 0.141 0.084 0.112 0.132 0.105 0.154 0.08  0.    0.031 0.006 0.014\n",
      " 0.008 0.003 0.004 0.002]\n",
      "Q_est = -6.52\n",
      "\n",
      "-> i_step = 4719\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 121. 130. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 121. 130. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2428   -6.24205  -6.24596  -6.25405  -6.3075   -6.26121\n",
      "  -6.2442   -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.07227 2.39129 2.48764 3.04954 2.64396 3.35382 2.3012  1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05368 0.10476 0.11255 0.2632  0.0355  0.04156 0.07706 0.29697 0.\n",
      " 0.0026  0.00433 0.00433 0.00346 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 121. 130. 304.  41.  48.  89. 343.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.142 0.115 0.091 0.097 0.147 0.109 0.144 0.072 0.    0.039 0.008 0.021\n",
      " 0.005 0.001 0.007 0.002]\n",
      "Q_est = -6.58\n",
      "\n",
      "-> i_step = 4720\n",
      "cur_state = [0 0]\n",
      "action = 2\n",
      "reward = -0.34\n",
      "new_state = [1 2]\n",
      "[ 62. 121. 131. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 121. 131. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2428   -6.25689  -6.24596  -6.25405  -6.3075   -6.26121\n",
      "  -6.2442   -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.07227 2.38814 2.48764 3.04954 2.64396 3.35382 2.3012  1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05363 0.10467 0.11332 0.26298 0.03547 0.04152 0.07699 0.29671 0.\n",
      " 0.0026  0.00433 0.00433 0.00346 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 121. 131. 304.  41.  48.  89. 343.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.16  0.141 0.097 0.087 0.121 0.091 0.141 0.077 0.    0.035 0.009 0.017\n",
      " 0.006 0.001 0.013 0.004]\n",
      "Q_est = -6.61\n",
      "\n",
      "-> i_step = 4721\n",
      "cur_state = [1 2]\n",
      "action = 5\n",
      "reward = -1.86\n",
      "new_state = [2 5]\n",
      "[ 62. 121. 131. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 121. 131. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2428   -6.25689  -6.24596  -6.25405  -6.3075   -6.26121\n",
      "  -6.2442   -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.07227 2.38814 2.48764 3.04954 2.64396 3.35382 2.3012  1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05363 0.10467 0.11332 0.26298 0.03547 0.04152 0.07699 0.29671 0.\n",
      " 0.0026  0.00433 0.00433 0.00346 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 121. 131. 304.  41.  48.  89. 343.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.151 0.141 0.079 0.094 0.134 0.089 0.147 0.074 0.    0.04  0.005 0.024\n",
      " 0.005 0.001 0.013 0.003]\n",
      "Q_est = -6.63\n",
      "\n",
      "-> i_step = 4722\n",
      "cur_state = [2 5]\n",
      "action = 2\n",
      "reward = -0.29\n",
      "new_state = [3 2]\n",
      "[ 62. 121. 131. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 121. 131. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2428   -6.25689  -6.24596  -6.25405  -6.3075   -6.26121\n",
      "  -6.2442   -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.07227 2.38814 2.48764 3.04954 2.64396 3.35382 2.3012  1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05363 0.10467 0.11332 0.26298 0.03547 0.04152 0.07699 0.29671 0.\n",
      " 0.0026  0.00433 0.00433 0.00346 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 121. 131. 304.  41.  48.  89. 343.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.145 0.12  0.098 0.088 0.125 0.106 0.148 0.087 0.    0.032 0.004 0.024\n",
      " 0.003 0.003 0.014 0.003]\n",
      "Q_est = -6.61\n",
      "\n",
      "-> i_step = 4723\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 121. 131. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 121. 131. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2428   -6.25689  -6.24596  -6.25405  -6.3075   -6.26121\n",
      "  -6.2442   -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.07227 2.38814 2.48764 3.04954 2.64396 3.35382 2.3012  1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05363 0.10467 0.11332 0.26298 0.03547 0.04152 0.07699 0.29671 0.\n",
      " 0.0026  0.00433 0.00433 0.00346 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 121. 131. 304.  41.  48.  89. 343.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.125 0.132 0.087 0.093 0.132 0.1   0.171 0.084 0.001 0.033 0.008 0.008\n",
      " 0.006 0.002 0.014 0.004]\n",
      "Q_est = -6.58\n",
      "\n",
      "-> i_step = 4724\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 0.21\n",
      "new_state = [1 1]\n",
      "[ 62. 122. 131. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.24596  -6.25405  -6.3075   -6.26121\n",
      "  -6.2442   -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.48764 3.04954 2.64396 3.35382 2.3012  1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05359 0.10545 0.11322 0.26275 0.03544 0.04149 0.07692 0.29646 0.\n",
      " 0.00259 0.00432 0.00432 0.00346 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 304.  41.  48.  89. 343.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.162 0.124 0.082 0.086 0.118 0.096 0.153 0.083 0.002 0.044 0.007 0.015\n",
      " 0.009 0.001 0.013 0.005]\n",
      "Q_est = -6.66\n",
      "\n",
      "-> i_step = 4725\n",
      "cur_state = [1 1]\n",
      "action = 4\n",
      "reward = 0.53\n",
      "new_state = [2 4]\n",
      "[ 62. 122. 131. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.24596  -6.25405  -6.3075   -6.26121\n",
      "  -6.2442   -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.48764 3.04954 2.64396 3.35382 2.3012  1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05359 0.10545 0.11322 0.26275 0.03544 0.04149 0.07692 0.29646 0.\n",
      " 0.00259 0.00432 0.00432 0.00346 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 304.  41.  48.  89. 343.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.13  0.133 0.092 0.09  0.123 0.098 0.164 0.074 0.001 0.044 0.006 0.013\n",
      " 0.007 0.001 0.022 0.002]\n",
      "Q_est = -6.67\n",
      "\n",
      "-> i_step = 4726\n",
      "cur_state = [2 4]\n",
      "action = 1\n",
      "reward = 0.94\n",
      "new_state = [3 1]\n",
      "[ 62. 122. 131. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.24596  -6.25405  -6.3075   -6.26121\n",
      "  -6.2442   -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.48764 3.04954 2.64396 3.35382 2.3012  1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05359 0.10545 0.11322 0.26275 0.03544 0.04149 0.07692 0.29646 0.\n",
      " 0.00259 0.00432 0.00432 0.00346 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 304.  41.  48.  89. 343.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.132 0.129 0.088 0.088 0.137 0.097 0.167 0.09  0.    0.032 0.01  0.01\n",
      " 0.007 0.002 0.009 0.002]\n",
      "Q_est = -6.54\n",
      "\n",
      "-> i_step = 4727\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 122. 131. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 304.  41.  48.  89. 343.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.24596  -6.25405  -6.3075   -6.26121\n",
      "  -6.2442   -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.48764 3.04954 2.64396 3.35382 2.3012  1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.24\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05359 0.10545 0.11322 0.26275 0.03544 0.04149 0.07692 0.29646 0.\n",
      " 0.00259 0.00432 0.00432 0.00346 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 304.  41.  48.  89. 343.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.135 0.134 0.092 0.088 0.126 0.097 0.146 0.078 0.    0.041 0.008 0.02\n",
      " 0.012 0.007 0.012 0.004]\n",
      "Q_est = -6.67\n",
      "\n",
      "-> i_step = 4728\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = -0.84\n",
      "new_state = [1 7]\n",
      "[ 62. 122. 131. 304.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 304.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.24596  -6.25405  -6.3075   -6.26121\n",
      "  -6.25124  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.48764 3.04954 2.64396 3.35382 2.30155 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.25\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05354 0.10535 0.11313 0.26252 0.03541 0.04145 0.07686 0.29706 0.\n",
      " 0.00259 0.00432 0.00432 0.00345 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 304.  41.  48.  89. 344.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.151 0.12  0.083 0.082 0.134 0.104 0.148 0.084 0.001 0.034 0.01  0.02\n",
      " 0.009 0.004 0.012 0.004]\n",
      "Q_est = -6.64\n",
      "\n",
      "-> i_step = 4729\n",
      "cur_state = [1 7]\n",
      "action = 2\n",
      "reward = -0.36\n",
      "new_state = [2 2]\n",
      "[ 62. 122. 131. 304.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 304.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.24596  -6.25405  -6.3075   -6.26121\n",
      "  -6.25124  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.48764 3.04954 2.64396 3.35382 2.30155 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.25\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05354 0.10535 0.11313 0.26252 0.03541 0.04145 0.07686 0.29706 0.\n",
      " 0.00259 0.00432 0.00432 0.00345 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 304.  41.  48.  89. 344.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.145 0.137 0.068 0.089 0.118 0.111 0.15  0.091 0.    0.039 0.006 0.021\n",
      " 0.008 0.002 0.013 0.002]\n",
      "Q_est = -6.63\n",
      "\n",
      "-> i_step = 4730\n",
      "cur_state = [2 2]\n",
      "action = 2\n",
      "reward = -0.04\n",
      "new_state = [3 2]\n",
      "[ 62. 122. 131. 304.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 304.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.24596  -6.25405  -6.3075   -6.26121\n",
      "  -6.25124  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.48764 3.04954 2.64396 3.35382 2.30155 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.25\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05354 0.10535 0.11313 0.26252 0.03541 0.04145 0.07686 0.29706 0.\n",
      " 0.00259 0.00432 0.00432 0.00345 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 304.  41.  48.  89. 344.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.177 0.13  0.096 0.088 0.121 0.086 0.143 0.076 0.    0.033 0.008 0.018\n",
      " 0.005 0.003 0.013 0.003]\n",
      "Q_est = -6.60\n",
      "\n",
      "-> i_step = 4731\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 122. 131. 304.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 304.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.24596  -6.25405  -6.3075   -6.26121\n",
      "  -6.25124  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.48764 3.04954 2.64396 3.35382 2.30155 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.25\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05354 0.10535 0.11313 0.26252 0.03541 0.04145 0.07686 0.29706 0.\n",
      " 0.00259 0.00432 0.00432 0.00345 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 304.  41.  48.  89. 344.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.122 0.139 0.088 0.098 0.133 0.117 0.13  0.074 0.001 0.028 0.009 0.023\n",
      " 0.014 0.001 0.017 0.006]\n",
      "Q_est = -6.67\n",
      "\n",
      "-> i_step = 4732\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 1.72\n",
      "new_state = [1 3]\n",
      "[ 62. 122. 131. 305.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 305.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.2457   -6.25405  -6.3075   -6.26121\n",
      "  -6.25124  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.48357 3.04954 2.64396 3.35382 2.30155 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.25\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05349 0.10526 0.11303 0.26316 0.03538 0.04142 0.07679 0.29681 0.\n",
      " 0.00259 0.00431 0.00431 0.00345 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 305.  41.  48.  89. 344.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.123 0.148 0.079 0.097 0.141 0.104 0.142 0.077 0.    0.034 0.009 0.017\n",
      " 0.009 0.003 0.01  0.007]\n",
      "Q_est = -6.62\n",
      "\n",
      "-> i_step = 4733\n",
      "cur_state = [1 3]\n",
      "action = 3\n",
      "reward = -1.85\n",
      "new_state = [2 3]\n",
      "[ 62. 122. 131. 305.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 305.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.2457   -6.25405  -6.3075   -6.26121\n",
      "  -6.25124  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.48357 3.04954 2.64396 3.35382 2.30155 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.25\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05349 0.10526 0.11303 0.26316 0.03538 0.04142 0.07679 0.29681 0.\n",
      " 0.00259 0.00431 0.00431 0.00345 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 305.  41.  48.  89. 344.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.149 0.119 0.094 0.103 0.144 0.094 0.127 0.089 0.001 0.034 0.003 0.021\n",
      " 0.01  0.001 0.009 0.002]\n",
      "Q_est = -6.58\n",
      "\n",
      "-> i_step = 4734\n",
      "cur_state = [2 3]\n",
      "action = 5\n",
      "reward = -1.57\n",
      "new_state = [3 5]\n",
      "[ 62. 122. 131. 305.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 305.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.2457   -6.25405  -6.3075   -6.26121\n",
      "  -6.25124  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.48357 3.04954 2.64396 3.35382 2.30155 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.25\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05349 0.10526 0.11303 0.26316 0.03538 0.04142 0.07679 0.29681 0.\n",
      " 0.00259 0.00431 0.00431 0.00345 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 305.  41.  48.  89. 344.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.155 0.141 0.091 0.091 0.114 0.083 0.161 0.092 0.001 0.02  0.006 0.024\n",
      " 0.004 0.001 0.013 0.003]\n",
      "Q_est = -6.56\n",
      "\n",
      "-> i_step = 4735\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 122. 131. 305.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 305.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.2457   -6.25405  -6.3075   -6.26121\n",
      "  -6.25124  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.48357 3.04954 2.64396 3.35382 2.30155 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.25\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05349 0.10526 0.11303 0.26316 0.03538 0.04142 0.07679 0.29681 0.\n",
      " 0.00259 0.00431 0.00431 0.00345 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 305.  41.  48.  89. 344.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.161 0.125 0.094 0.093 0.154 0.093 0.131 0.081 0.    0.029 0.005 0.014\n",
      " 0.006 0.003 0.011 0.   ]\n",
      "Q_est = -6.53\n",
      "\n",
      "-> i_step = 4736\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -0.40\n",
      "new_state = [1 3]\n",
      "[ 62. 122. 131. 306.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 306.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.25242  -6.25405  -6.3075   -6.26121\n",
      "  -6.25124  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.48228 3.04954 2.64396 3.35382 2.30155 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.25\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05345 0.10517 0.11293 0.26379 0.03534 0.04138 0.07672 0.29655 0.\n",
      " 0.00259 0.00431 0.00431 0.00345 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 306.  41.  48.  89. 344.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.155 0.137 0.075 0.078 0.116 0.107 0.163 0.082 0.    0.033 0.001 0.013\n",
      " 0.009 0.005 0.019 0.007]\n",
      "Q_est = -6.65\n",
      "\n",
      "-> i_step = 4737\n",
      "cur_state = [1 3]\n",
      "action = 1\n",
      "reward = -1.25\n",
      "new_state = [2 1]\n",
      "[ 62. 122. 131. 306.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 306.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.25242  -6.25405  -6.3075   -6.26121\n",
      "  -6.25124  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.48228 3.04954 2.64396 3.35382 2.30155 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.25\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05345 0.10517 0.11293 0.26379 0.03534 0.04138 0.07672 0.29655 0.\n",
      " 0.00259 0.00431 0.00431 0.00345 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 306.  41.  48.  89. 344.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.168 0.135 0.082 0.091 0.133 0.091 0.145 0.069 0.    0.039 0.004 0.017\n",
      " 0.007 0.005 0.014 0.   ]\n",
      "Q_est = -6.61\n",
      "\n",
      "-> i_step = 4738\n",
      "cur_state = [2 1]\n",
      "action = 7\n",
      "reward = -0.14\n",
      "new_state = [3 7]\n",
      "[ 62. 122. 131. 306.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 306.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.25242  -6.25405  -6.3075   -6.26121\n",
      "  -6.25124  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.48228 3.04954 2.64396 3.35382 2.30155 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.25\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05345 0.10517 0.11293 0.26379 0.03534 0.04138 0.07672 0.29655 0.\n",
      " 0.00259 0.00431 0.00431 0.00345 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 306.  41.  48.  89. 344.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14 15]\n",
      "probs = [0.158 0.133 0.093 0.095 0.139 0.1   0.158 0.066 0.    0.028 0.003 0.009\n",
      " 0.004 0.    0.012 0.002]\n",
      "Q_est = -6.51\n",
      "\n",
      "-> i_step = 4739\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 122. 131. 306.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 306.  41.  48.  89. 344.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.25242  -6.25405  -6.3075   -6.26121\n",
      "  -6.25124  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.48228 3.04954 2.64396 3.35382 2.30155 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.25\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05345 0.10517 0.11293 0.26379 0.03534 0.04138 0.07672 0.29655 0.\n",
      " 0.00259 0.00431 0.00431 0.00345 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 306.  41.  48.  89. 344.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.30\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.131 0.133 0.089 0.096 0.145 0.097 0.149 0.078 0.    0.04  0.005 0.013\n",
      " 0.012 0.001 0.008 0.003]\n",
      "Q_est = -6.59\n",
      "\n",
      "-> i_step = 4740\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = -1.71\n",
      "new_state = [1 7]\n",
      "[ 62. 122. 131. 306.  41.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 306.  41.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.25242  -6.25405  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.48228 3.04954 2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]Bset_probs = [0.0534  0.10508 0.11283 0.26357 0.03531 0.04134 0.07666 0.29716 0.\n",
      " 0.00258 0.00431 0.00431 0.00345 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 306.  41.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.151 0.131 0.07  0.096 0.139 0.098 0.146 0.08  0.001 0.035 0.007 0.02\n",
      " 0.009 0.004 0.01  0.003]\n",
      "Q_est = -6.61\n",
      "\n",
      "-> i_step = 4741\n",
      "cur_state = [1 7]\n",
      "action = 6\n",
      "reward = -0.27\n",
      "new_state = [2 6]\n",
      "[ 62. 122. 131. 306.  41.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 306.  41.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.25242  -6.25405  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.48228 3.04954 2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0534  0.10508 0.11283 0.26357 0.03531 0.04134 0.07666 0.29716 0.\n",
      " 0.00258 0.00431 0.00431 0.00345 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 306.  41.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.169 0.122 0.081 0.093 0.117 0.087 0.163 0.071 0.002 0.035 0.006 0.017\n",
      " 0.008 0.004 0.02  0.005]\n",
      "Q_est = -6.68\n",
      "\n",
      "-> i_step = 4742\n",
      "cur_state = [2 6]\n",
      "action = 3\n",
      "reward = 0.01\n",
      "new_state = [3 3]\n",
      "[ 62. 122. 131. 306.  41.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 306.  41.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.25242  -6.25405  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.48228 3.04954 2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0534  0.10508 0.11283 0.26357 0.03531 0.04134 0.07666 0.29716 0.\n",
      " 0.00258 0.00431 0.00431 0.00345 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 306.  41.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.158 0.133 0.091 0.083 0.13  0.083 0.174 0.078 0.    0.033 0.004 0.011\n",
      " 0.005 0.002 0.012 0.003]\n",
      "Q_est = -6.56\n",
      "\n",
      "-> i_step = 4743\n",
      "cur_state = [3 3]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 122. 131. 306.  41.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 306.  41.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.25242  -6.25405  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.48228 3.04954 2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0534  0.10508 0.11283 0.26357 0.03531 0.04134 0.07666 0.29716 0.\n",
      " 0.00258 0.00431 0.00431 0.00345 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 306.  41.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.144 0.153 0.091 0.094 0.129 0.099 0.14  0.079 0.    0.031 0.002 0.013\n",
      " 0.006 0.003 0.013 0.003]\n",
      "Q_est = -6.56\n",
      "\n",
      "-> i_step = 4744\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 0.70\n",
      "new_state = [1 3]\n",
      "[ 62. 122. 131. 307.  41.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 307.  41.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.25551  -6.25405  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.47882 3.04954 2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05336 0.10499 0.11274 0.2642  0.03528 0.04131 0.07659 0.2969  0.\n",
      " 0.00258 0.0043  0.0043  0.00344 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 307.  41.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.175 0.115 0.097 0.083 0.138 0.09  0.158 0.065 0.    0.041 0.006 0.013\n",
      " 0.006 0.002 0.008 0.003]\n",
      "Q_est = -6.58\n",
      "\n",
      "-> i_step = 4745\n",
      "cur_state = [1 3]\n",
      "action = 0\n",
      "reward = -1.10\n",
      "new_state = [2 0]\n",
      "[ 62. 122. 131. 307.  41.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 307.  41.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.25551  -6.25405  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.47882 3.04954 2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05336 0.10499 0.11274 0.2642  0.03528 0.04131 0.07659 0.2969  0.\n",
      " 0.00258 0.0043  0.0043  0.00344 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 307.  41.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.138 0.128 0.101 0.089 0.129 0.094 0.162 0.082 0.    0.039 0.008 0.012\n",
      " 0.005 0.003 0.009 0.001]\n",
      "Q_est = -6.57\n",
      "\n",
      "-> i_step = 4746\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = 0.81\n",
      "new_state = [3 7]\n",
      "[ 62. 122. 131. 307.  41.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 307.  41.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.25551  -6.25405  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.47882 3.04954 2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05336 0.10499 0.11274 0.2642  0.03528 0.04131 0.07659 0.2969  0.\n",
      " 0.00258 0.0043  0.0043  0.00344 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 307.  41.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15]\n",
      "probs = [0.136 0.136 0.089 0.085 0.133 0.098 0.171 0.076 0.001 0.028 0.009 0.016\n",
      " 0.009 0.    0.012 0.001]\n",
      "Q_est = -6.56\n",
      "\n",
      "-> i_step = 4747\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 122. 131. 307.  41.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 307.  41.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.25551  -6.25405  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.47882 3.04954 2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05336 0.10499 0.11274 0.2642  0.03528 0.04131 0.07659 0.2969  0.\n",
      " 0.00258 0.0043  0.0043  0.00344 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 307.  41.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.145 0.136 0.072 0.091 0.156 0.103 0.136 0.078 0.    0.034 0.008 0.02\n",
      " 0.005 0.002 0.012 0.002]\n",
      "Q_est = -6.60\n",
      "\n",
      "-> i_step = 4748\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = 0.45\n",
      "new_state = [1 4]\n",
      "[ 62. 122. 131. 307.  42.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 307.  42.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.25551  -6.29371  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.47882 3.0237  2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05331 0.1049  0.11264 0.26397 0.03611 0.04127 0.07653 0.29665 0.\n",
      " 0.00258 0.0043  0.0043  0.00344 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 307.  42.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.145 0.141 0.083 0.084 0.135 0.091 0.16  0.078 0.001 0.039 0.004 0.013\n",
      " 0.008 0.005 0.01  0.003]\n",
      "Q_est = -6.60\n",
      "\n",
      "-> i_step = 4749\n",
      "cur_state = [1 4]\n",
      "action = 7\n",
      "reward = 0.26\n",
      "new_state = [2 7]\n",
      "[ 62. 122. 131. 307.  42.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 307.  42.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.25551  -6.29371  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.47882 3.0237  2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05331 0.1049  0.11264 0.26397 0.03611 0.04127 0.07653 0.29665 0.\n",
      " 0.00258 0.0043  0.0043  0.00344 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 307.  42.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.147 0.136 0.089 0.088 0.132 0.097 0.155 0.09  0.001 0.03  0.004 0.013\n",
      " 0.006 0.002 0.008 0.002]\n",
      "Q_est = -6.53\n",
      "\n",
      "-> i_step = 4750\n",
      "cur_state = [2 7]\n",
      "action = 7\n",
      "reward = 0.98\n",
      "new_state = [3 7]\n",
      "[ 62. 122. 131. 307.  42.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 307.  42.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.25551  -6.29371  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.47882 3.0237  2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05331 0.1049  0.11264 0.26397 0.03611 0.04127 0.07653 0.29665 0.\n",
      " 0.00258 0.0043  0.0043  0.00344 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 307.  42.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.141 0.13  0.103 0.071 0.126 0.109 0.157 0.083 0.    0.029 0.008 0.016\n",
      " 0.01  0.001 0.012 0.004]\n",
      "Q_est = -6.59\n",
      "\n",
      "-> i_step = 4751\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 122. 131. 307.  42.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 122. 131. 307.  42.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.25505  -6.25689  -6.25551  -6.29371  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.06261 2.38814 2.47882 3.0237  2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05331 0.1049  0.11264 0.26397 0.03611 0.04127 0.07653 0.29665 0.\n",
      " 0.00258 0.0043  0.0043  0.00344 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 122. 131. 307.  42.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.156 0.133 0.098 0.084 0.122 0.104 0.151 0.07  0.001 0.028 0.011 0.019\n",
      " 0.003 0.001 0.016 0.003]\n",
      "Q_est = -6.61\n",
      "\n",
      "-> i_step = 4752\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 1.18\n",
      "new_state = [1 1]\n",
      "[ 62. 123. 131. 307.  42.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 123. 131. 307.  42.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2592   -6.25689  -6.25551  -6.29371  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.05048 2.38814 2.47882 3.0237  2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05326 0.10567 0.11254 0.26375 0.03608 0.04124 0.07646 0.29639 0.\n",
      " 0.00258 0.0043  0.0043  0.00344 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 123. 131. 307.  42.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15]\n",
      "probs = [0.161 0.149 0.082 0.079 0.123 0.111 0.137 0.076 0.002 0.045 0.003 0.017\n",
      " 0.003 0.    0.008 0.004]\n",
      "Q_est = -6.61\n",
      "\n",
      "-> i_step = 4753\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 1.55\n",
      "new_state = [2 5]\n",
      "[ 62. 123. 131. 307.  42.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 123. 131. 307.  42.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2592   -6.25689  -6.25551  -6.29371  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.05048 2.38814 2.47882 3.0237  2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05326 0.10567 0.11254 0.26375 0.03608 0.04124 0.07646 0.29639 0.\n",
      " 0.00258 0.0043  0.0043  0.00344 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 123. 131. 307.  42.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.145 0.124 0.096 0.103 0.123 0.086 0.162 0.088 0.    0.039 0.006 0.013\n",
      " 0.004 0.001 0.009 0.001]\n",
      "Q_est = -6.56\n",
      "\n",
      "-> i_step = 4754\n",
      "cur_state = [2 5]\n",
      "action = 2\n",
      "reward = 1.86\n",
      "new_state = [3 2]\n",
      "[ 62. 123. 131. 307.  42.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 123. 131. 307.  42.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2592   -6.25689  -6.25551  -6.29371  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.05048 2.38814 2.47882 3.0237  2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05326 0.10567 0.11254 0.26375 0.03608 0.04124 0.07646 0.29639 0.\n",
      " 0.00258 0.0043  0.0043  0.00344 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 123. 131. 307.  42.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.142 0.132 0.077 0.096 0.129 0.108 0.163 0.08  0.002 0.033 0.005 0.012\n",
      " 0.007 0.002 0.011 0.001]\n",
      "Q_est = -6.56\n",
      "\n",
      "-> i_step = 4755\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 123. 131. 307.  42.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 123. 131. 307.  42.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2592   -6.25689  -6.25551  -6.29371  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.05048 2.38814 2.47882 3.0237  2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05326 0.10567 0.11254 0.26375 0.03608 0.04124 0.07646 0.29639 0.\n",
      " 0.00258 0.0043  0.0043  0.00344 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 123. 131. 307.  42.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.135 0.137 0.086 0.107 0.133 0.098 0.145 0.085 0.    0.03  0.004 0.015\n",
      " 0.004 0.004 0.012 0.005]\n",
      "Q_est = -6.58\n",
      "\n",
      "-> i_step = 4756\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = -0.82\n",
      "new_state = [1 4]\n",
      "[ 62. 123. 131. 307.  43.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 123. 131. 307.  43.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2592   -6.25689  -6.25551  -6.36108  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.05048 2.38814 2.47882 3.02005 2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05322 0.10558 0.11245 0.26352 0.03691 0.0412  0.07639 0.29614 0.\n",
      " 0.00258 0.00429 0.00429 0.00343 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 123. 131. 307.  43.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.134 0.115 0.087 0.091 0.121 0.104 0.158 0.098 0.    0.04  0.001 0.016\n",
      " 0.008 0.005 0.016 0.006]\n",
      "Q_est = -6.67\n",
      "\n",
      "-> i_step = 4757\n",
      "cur_state = [1 4]\n",
      "action = 7\n",
      "reward = -1.61\n",
      "new_state = [2 7]\n",
      "[ 62. 123. 131. 307.  43.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 123. 131. 307.  43.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2592   -6.25689  -6.25551  -6.36108  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.05048 2.38814 2.47882 3.02005 2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05322 0.10558 0.11245 0.26352 0.03691 0.0412  0.07639 0.29614 0.\n",
      " 0.00258 0.00429 0.00429 0.00343 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 123. 131. 307.  43.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.142 0.134 0.081 0.112 0.12  0.11  0.133 0.077 0.    0.042 0.006 0.014\n",
      " 0.008 0.002 0.014 0.005]\n",
      "Q_est = -6.66\n",
      "\n",
      "-> i_step = 4758\n",
      "cur_state = [2 7]\n",
      "action = 7\n",
      "reward = -2.22\n",
      "new_state = [3 7]\n",
      "[ 62. 123. 131. 307.  43.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 123. 131. 307.  43.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2592   -6.25689  -6.25551  -6.36108  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.05048 2.38814 2.47882 3.02005 2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05322 0.10558 0.11245 0.26352 0.03691 0.0412  0.07639 0.29614 0.\n",
      " 0.00258 0.00429 0.00429 0.00343 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 123. 131. 307.  43.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.131 0.118 0.08  0.113 0.11  0.095 0.171 0.091 0.    0.056 0.001 0.017\n",
      " 0.004 0.002 0.01  0.001]\n",
      "Q_est = -6.65\n",
      "\n",
      "-> i_step = 4759\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 62. 123. 131. 307.  43.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 123. 131. 307.  43.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2592   -6.25689  -6.25551  -6.36108  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.05048 2.38814 2.47882 3.02005 2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05322 0.10558 0.11245 0.26352 0.03691 0.0412  0.07639 0.29614 0.\n",
      " 0.00258 0.00429 0.00429 0.00343 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 123. 131. 307.  43.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.149 0.126 0.075 0.09  0.134 0.094 0.178 0.073 0.    0.029 0.008 0.02\n",
      " 0.005 0.003 0.013 0.003]\n",
      "Q_est = -6.61\n",
      "\n",
      "-> i_step = 4760\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 0.77\n",
      "new_state = [1 3]\n",
      "[ 62. 123. 131. 308.  43.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 123. 131. 308.  43.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2592   -6.25689  -6.25836  -6.36108  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.05048 2.38814 2.4753  3.02005 2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05317 0.10549 0.11235 0.26415 0.03688 0.04117 0.07633 0.29588 0.\n",
      " 0.00257 0.00429 0.00429 0.00343 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 123. 131. 308.  43.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.153 0.139 0.087 0.107 0.115 0.09  0.152 0.082 0.    0.033 0.006 0.014\n",
      " 0.004 0.005 0.01  0.003]\n",
      "Q_est = -6.58\n",
      "\n",
      "-> i_step = 4761\n",
      "cur_state = [1 3]\n",
      "action = 5\n",
      "reward = 1.12\n",
      "new_state = [2 5]\n",
      "[ 62. 123. 131. 308.  43.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 123. 131. 308.  43.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2592   -6.25689  -6.25836  -6.36108  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.05048 2.38814 2.4753  3.02005 2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05317 0.10549 0.11235 0.26415 0.03688 0.04117 0.07633 0.29588 0.\n",
      " 0.00257 0.00429 0.00429 0.00343 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 123. 131. 308.  43.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.132 0.135 0.079 0.111 0.126 0.109 0.138 0.067 0.    0.036 0.007 0.025\n",
      " 0.01  0.005 0.017 0.003]\n",
      "Q_est = -6.70\n",
      "\n",
      "-> i_step = 4762\n",
      "cur_state = [2 5]\n",
      "action = 2\n",
      "reward = 1.80\n",
      "new_state = [3 2]\n",
      "[ 62. 123. 131. 308.  43.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 62. 123. 131. 308.  43.  48.  89. 345.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.25902  -6.2592   -6.25689  -6.25836  -6.36108  -6.3075   -6.26121\n",
      "  -6.26076  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.28489 3.05048 2.38814 2.4753  3.02005 2.64396 3.35382 2.30498 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.26\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05317 0.10549 0.11235 0.26415 0.03688 0.04117 0.07633 0.29588 0.\n",
      " 0.00257 0.00429 0.00429 0.00343 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 62. 123. 131. 308.  43.  48.  89. 345.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ -6.29695  -6.30114  -6.3068   -6.30102  -6.36108  -6.3075   -6.31418\n",
      "  -6.30381  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.27238 3.02806 2.37125 2.48295 3.02005 2.64396 3.3356  2.30254 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05299 0.10597 0.11354 0.26325 0.03616 0.04037 0.07653 0.29689 0.\n",
      " 0.00252 0.00421 0.00421 0.00336 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 63. 126. 135. 313.  43.  48.  91. 353.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.35\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.158 0.135 0.088 0.104 0.118 0.099 0.141 0.074 0.001 0.039 0.005 0.018\n",
      " 0.003 0.003 0.01  0.004]\n",
      "Q_est = -6.65\n",
      "\n",
      "-> i_step = 4853\n",
      "cur_state = [1 2]\n",
      "action = 0\n",
      "reward = -0.11\n",
      "new_state = [2 0]\n",
      "[ 63. 126. 135. 313.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 63. 126. 135. 313.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.29695  -6.30114  -6.3068   -6.30102  -6.36108  -6.3075   -6.31418\n",
      "  -6.30381  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.27238 3.02806 2.37125 2.48295 3.02005 2.64396 3.3356  2.30254 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05299 0.10597 0.11354 0.26325 0.03616 0.04037 0.07653 0.29689 0.\n",
      " 0.00252 0.00421 0.00421 0.00336 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 63. 126. 135. 313.  43.  48.  91. 353.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.35\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.151 0.15  0.089 0.089 0.114 0.085 0.149 0.085 0.    0.043 0.005 0.013\n",
      " 0.009 0.003 0.011 0.004]\n",
      "Q_est = -6.67\n",
      "\n",
      "-> i_step = 4854\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = 1.22\n",
      "new_state = [3 7]\n",
      "[ 63. 126. 135. 313.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 63. 126. 135. 313.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.29695  -6.30114  -6.3068   -6.30102  -6.36108  -6.3075   -6.31418\n",
      "  -6.30381  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.27238 3.02806 2.37125 2.48295 3.02005 2.64396 3.3356  2.30254 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05299 0.10597 0.11354 0.26325 0.03616 0.04037 0.07653 0.29689 0.\n",
      " 0.00252 0.00421 0.00421 0.00336 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 63. 126. 135. 313.  43.  48.  91. 353.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.35\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.142 0.149 0.082 0.098 0.115 0.095 0.151 0.076 0.    0.036 0.008 0.021\n",
      " 0.005 0.005 0.013 0.004]\n",
      "Q_est = -6.68\n",
      "\n",
      "-> i_step = 4855\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 63. 126. 135. 313.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 63. 126. 135. 313.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.29695  -6.30114  -6.3068   -6.30102  -6.36108  -6.3075   -6.31418\n",
      "  -6.30381  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.27238 3.02806 2.37125 2.48295 3.02005 2.64396 3.3356  2.30254 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05299 0.10597 0.11354 0.26325 0.03616 0.04037 0.07653 0.29689 0.\n",
      " 0.00252 0.00421 0.00421 0.00336 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 63. 126. 135. 313.  43.  48.  91. 353.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.35\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.138 0.131 0.079 0.077 0.12  0.114 0.161 0.071 0.001 0.055 0.006 0.017\n",
      " 0.011 0.004 0.011 0.004]\n",
      "Q_est = -6.74\n",
      "\n",
      "-> i_step = 4856\n",
      "cur_state = [0 0]\n",
      "action = 0\n",
      "reward = 0.37\n",
      "new_state = [1 0]\n",
      "[ 64. 126. 135. 313.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 126. 135. 313.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.30114  -6.3068   -6.30102  -6.36108  -6.3075   -6.31418\n",
      "  -6.30381  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.02806 2.37125 2.48295 3.02005 2.64396 3.3356  2.30254 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05378 0.10588 0.11345 0.26303 0.03613 0.04034 0.07647 0.29664 0.\n",
      " 0.00252 0.0042  0.0042  0.00336 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 126. 135. 313.  43.  48.  91. 353.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.35\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.135 0.128 0.075 0.119 0.121 0.111 0.139 0.082 0.001 0.037 0.006 0.016\n",
      " 0.009 0.002 0.015 0.004]\n",
      "Q_est = -6.69\n",
      "\n",
      "-> i_step = 4857\n",
      "cur_state = [1 0]\n",
      "action = 0\n",
      "reward = -1.51\n",
      "new_state = [2 0]\n",
      "[ 64. 126. 135. 313.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 126. 135. 313.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.30114  -6.3068   -6.30102  -6.36108  -6.3075   -6.31418\n",
      "  -6.30381  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.02806 2.37125 2.48295 3.02005 2.64396 3.3356  2.30254 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05378 0.10588 0.11345 0.26303 0.03613 0.04034 0.07647 0.29664 0.\n",
      " 0.00252 0.0042  0.0042  0.00336 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 126. 135. 313.  43.  48.  91. 353.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.35\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 14 15]\n",
      "probs = [0.144 0.128 0.095 0.088 0.133 0.089 0.157 0.087 0.    0.035 0.01  0.013\n",
      " 0.004 0.    0.015 0.002]\n",
      "Q_est = -6.64\n",
      "\n",
      "-> i_step = 4858\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = -0.09\n",
      "new_state = [3 7]\n",
      "[ 64. 126. 135. 313.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 126. 135. 313.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.30114  -6.3068   -6.30102  -6.36108  -6.3075   -6.31418\n",
      "  -6.30381  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.02806 2.37125 2.48295 3.02005 2.64396 3.3356  2.30254 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05378 0.10588 0.11345 0.26303 0.03613 0.04034 0.07647 0.29664 0.\n",
      " 0.00252 0.0042  0.0042  0.00336 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 126. 135. 313.  43.  48.  91. 353.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.35\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.153 0.132 0.077 0.088 0.126 0.093 0.142 0.085 0.001 0.047 0.008 0.016\n",
      " 0.008 0.003 0.015 0.006]\n",
      "Q_est = -6.74\n",
      "\n",
      "-> i_step = 4859\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 64. 126. 135. 313.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 126. 135. 313.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.30114  -6.3068   -6.30102  -6.36108  -6.3075   -6.31418\n",
      "  -6.30381  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.02806 2.37125 2.48295 3.02005 2.64396 3.3356  2.30254 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05378 0.10588 0.11345 0.26303 0.03613 0.04034 0.07647 0.29664 0.\n",
      " 0.00252 0.0042  0.0042  0.00336 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 126. 135. 313.  43.  48.  91. 353.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.35\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.148 0.136 0.089 0.089 0.131 0.111 0.148 0.066 0.    0.032 0.007 0.02\n",
      " 0.007 0.006 0.01  0.   ]\n",
      "Q_est = -6.63\n",
      "\n",
      "-> i_step = 4860\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 0.12\n",
      "new_state = [1 3]\n",
      "[ 64. 126. 135. 314.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 126. 135. 314.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.30114  -6.3068   -6.30577  -6.36108  -6.3075   -6.31418\n",
      "  -6.30381  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.02806 2.37125 2.48041 3.02005 2.64396 3.3356  2.30254 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05374 0.10579 0.11335 0.26364 0.0361  0.0403  0.07641 0.29639 0.\n",
      " 0.00252 0.0042  0.0042  0.00336 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 126. 135. 314.  43.  48.  91. 353.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.35\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.123 0.122 0.089 0.115 0.125 0.117 0.134 0.091 0.001 0.042 0.002 0.02\n",
      " 0.005 0.002 0.008 0.004]\n",
      "Q_est = -6.66\n",
      "\n",
      "-> i_step = 4861\n",
      "cur_state = [1 3]\n",
      "action = 6\n",
      "reward = -0.87\n",
      "new_state = [2 6]\n",
      "[ 64. 126. 135. 314.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 126. 135. 314.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.30114  -6.3068   -6.30577  -6.36108  -6.3075   -6.31418\n",
      "  -6.30381  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.02806 2.37125 2.48041 3.02005 2.64396 3.3356  2.30254 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05374 0.10579 0.11335 0.26364 0.0361  0.0403  0.07641 0.29639 0.\n",
      " 0.00252 0.0042  0.0042  0.00336 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 126. 135. 314.  43.  48.  91. 353.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.35\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.148 0.121 0.086 0.09  0.123 0.094 0.156 0.086 0.    0.038 0.005 0.017\n",
      " 0.009 0.004 0.017 0.006]\n",
      "Q_est = -6.72\n",
      "\n",
      "-> i_step = 4862\n",
      "cur_state = [2 6]\n",
      "action = 6\n",
      "reward = -1.24\n",
      "new_state = [3 6]\n",
      "[ 64. 126. 135. 314.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 126. 135. 314.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.30114  -6.3068   -6.30577  -6.36108  -6.3075   -6.31418\n",
      "  -6.30381  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.02806 2.37125 2.48041 3.02005 2.64396 3.3356  2.30254 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05374 0.10579 0.11335 0.26364 0.0361  0.0403  0.07641 0.29639 0.\n",
      " 0.00252 0.0042  0.0042  0.00336 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 126. 135. 314.  43.  48.  91. 353.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.35\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.138 0.139 0.09  0.095 0.101 0.11  0.165 0.083 0.    0.04  0.003 0.016\n",
      " 0.003 0.001 0.012 0.004]\n",
      "Q_est = -6.65\n",
      "\n",
      "-> i_step = 4863\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 64. 126. 135. 314.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 126. 135. 314.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.30114  -6.3068   -6.30577  -6.36108  -6.3075   -6.31418\n",
      "  -6.30381  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.02806 2.37125 2.48041 3.02005 2.64396 3.3356  2.30254 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05374 0.10579 0.11335 0.26364 0.0361  0.0403  0.07641 0.29639 0.\n",
      " 0.00252 0.0042  0.0042  0.00336 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 126. 135. 314.  43.  48.  91. 353.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.35\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.123 0.131 0.083 0.098 0.127 0.11  0.154 0.072 0.    0.036 0.011 0.025\n",
      " 0.006 0.003 0.019 0.002]\n",
      "Q_est = -6.73\n",
      "\n",
      "-> i_step = 4864\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 0.20\n",
      "new_state = [1 1]\n",
      "[ 64. 127. 135. 314.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 135. 314.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.3068   -6.30577  -6.36108  -6.3075   -6.31418\n",
      "  -6.30381  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37125 2.48041 3.02005 2.64396 3.3356  2.30254 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05369 0.10654 0.11326 0.26342 0.03607 0.04027 0.07634 0.29614 0.\n",
      " 0.00252 0.00419 0.00419 0.00336 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 135. 314.  43.  48.  91. 353.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.35\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.124 0.126 0.087 0.101 0.132 0.096 0.168 0.087 0.    0.035 0.003 0.014\n",
      " 0.005 0.002 0.013 0.007]\n",
      "Q_est = -6.66\n",
      "\n",
      "-> i_step = 4865\n",
      "cur_state = [1 1]\n",
      "action = 6\n",
      "reward = -0.67\n",
      "new_state = [2 6]\n",
      "[ 64. 127. 135. 314.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 135. 314.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.3068   -6.30577  -6.36108  -6.3075   -6.31418\n",
      "  -6.30381  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37125 2.48041 3.02005 2.64396 3.3356  2.30254 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05369 0.10654 0.11326 0.26342 0.03607 0.04027 0.07634 0.29614 0.\n",
      " 0.00252 0.00419 0.00419 0.00336 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 135. 314.  43.  48.  91. 353.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.35\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.13  0.127 0.086 0.099 0.131 0.103 0.153 0.089 0.001 0.031 0.007 0.015\n",
      " 0.008 0.001 0.016 0.003]\n",
      "Q_est = -6.66\n",
      "\n",
      "-> i_step = 4866\n",
      "cur_state = [2 6]\n",
      "action = 5\n",
      "reward = -0.45\n",
      "new_state = [3 5]\n",
      "[ 64. 127. 135. 314.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 135. 314.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.3068   -6.30577  -6.36108  -6.3075   -6.31418\n",
      "  -6.30381  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37125 2.48041 3.02005 2.64396 3.3356  2.30254 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05369 0.10654 0.11326 0.26342 0.03607 0.04027 0.07634 0.29614 0.\n",
      " 0.00252 0.00419 0.00419 0.00336 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 135. 314.  43.  48.  91. 353.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.35\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.127 0.139 0.092 0.104 0.108 0.099 0.165 0.069 0.    0.039 0.01  0.024\n",
      " 0.009 0.003 0.01  0.002]\n",
      "Q_est = -6.69\n",
      "\n",
      "-> i_step = 4867\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 64. 127. 135. 314.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 135. 314.  43.  48.  91. 353.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.3068   -6.30577  -6.36108  -6.3075   -6.31418\n",
      "  -6.30381  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37125 2.48041 3.02005 2.64396 3.3356  2.30254 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05369 0.10654 0.11326 0.26342 0.03607 0.04027 0.07634 0.29614 0.\n",
      " 0.00252 0.00419 0.00419 0.00336 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 135. 314.  43.  48.  91. 353.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.35\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.142 0.134 0.079 0.084 0.128 0.115 0.136 0.087 0.    0.032 0.009 0.021\n",
      " 0.011 0.003 0.019 0.   ]\n",
      "Q_est = -6.70\n",
      "\n",
      "-> i_step = 4868\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 0.14\n",
      "new_state = [1 7]\n",
      "[ 64. 127. 135. 314.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 135. 314.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.3068   -6.30577  -6.36108  -6.3075   -6.31418\n",
      "  -6.30774  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37125 2.48041 3.02005 2.64396 3.3356  2.30047 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.31\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05365 0.10645 0.11316 0.2632  0.03604 0.04023 0.07628 0.29673 0.\n",
      " 0.00251 0.00419 0.00419 0.00335 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 135. 314.  43.  48.  91. 354.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.35\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.141 0.12  0.074 0.095 0.148 0.109 0.141 0.091 0.    0.025 0.005 0.014\n",
      " 0.006 0.003 0.023 0.005]\n",
      "Q_est = -6.68\n",
      "\n",
      "-> i_step = 4869\n",
      "cur_state = [1 7]\n",
      "action = 6\n",
      "reward = -0.60\n",
      "new_state = [2 6]\n",
      "[ 64. 127. 135. 314.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 135. 314.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.3068   -6.30577  -6.36108  -6.3075   -6.31418\n",
      "  -6.30774  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37125 2.48041 3.02005 2.64396 3.3356  2.30047 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.31\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05365 0.10645 0.11316 0.2632  0.03604 0.04023 0.07628 0.29673 0.\n",
      " 0.00251 0.00419 0.00419 0.00335 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 135. 314.  43.  48.  91. 354.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.35\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.176 0.113 0.084 0.102 0.116 0.093 0.145 0.083 0.    0.048 0.003 0.011\n",
      " 0.004 0.002 0.013 0.007]\n",
      "Q_est = -6.70\n",
      "\n",
      "-> i_step = 4870\n",
      "cur_state = [2 6]\n",
      "action = 5\n",
      "reward = 0.75\n",
      "new_state = [3 5]\n",
      "[ 64. 127. 135. 314.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 135. 314.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.3068   -6.30577  -6.36108  -6.3075   -6.31418\n",
      "  -6.30774  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37125 2.48041 3.02005 2.64396 3.3356  2.30047 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.31\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05365 0.10645 0.11316 0.2632  0.03604 0.04023 0.07628 0.29673 0.\n",
      " 0.00251 0.00419 0.00419 0.00335 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 135. 314.  43.  48.  91. 354.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.35\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.156 0.116 0.078 0.101 0.104 0.112 0.148 0.091 0.001 0.039 0.011 0.02\n",
      " 0.009 0.002 0.009 0.003]\n",
      "Q_est = -6.68\n",
      "\n",
      "-> i_step = 4871\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 64. 127. 135. 314.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 135. 314.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.3068   -6.30577  -6.36108  -6.3075   -6.31418\n",
      "  -6.30774  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37125 2.48041 3.02005 2.64396 3.3356  2.30047 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.31\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05365 0.10645 0.11316 0.2632  0.03604 0.04023 0.07628 0.29673 0.\n",
      " 0.00251 0.00419 0.00419 0.00335 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 135. 314.  43.  48.  91. 354.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.35\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.141 0.112 0.088 0.093 0.126 0.119 0.145 0.101 0.    0.032 0.008 0.015\n",
      " 0.008 0.001 0.008 0.003]\n",
      "Q_est = -6.61\n",
      "\n",
      "-> i_step = 4872\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -0.43\n",
      "new_state = [1 3]\n",
      "[ 64. 127. 135. 315.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 135. 315.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.3068   -6.31225  -6.36108  -6.3075   -6.31418\n",
      "  -6.30774  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37125 2.47914 3.02005 2.64396 3.3356  2.30047 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.31\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0536  0.10637 0.11307 0.26382 0.03601 0.0402  0.07621 0.29648 0.\n",
      " 0.00251 0.00419 0.00419 0.00335 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 135. 315.  43.  48.  91. 354.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.14  0.14  0.078 0.094 0.128 0.101 0.162 0.072 0.003 0.039 0.006 0.016\n",
      " 0.004 0.002 0.011 0.004]\n",
      "Q_est = -6.66\n",
      "\n",
      "-> i_step = 4873\n",
      "cur_state = [1 3]\n",
      "action = 1\n",
      "reward = -0.43\n",
      "new_state = [2 1]\n",
      "[ 64. 127. 135. 315.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 135. 315.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.3068   -6.31225  -6.36108  -6.3075   -6.31418\n",
      "  -6.30774  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37125 2.47914 3.02005 2.64396 3.3356  2.30047 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.31\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0536  0.10637 0.11307 0.26382 0.03601 0.0402  0.07621 0.29648 0.\n",
      " 0.00251 0.00419 0.00419 0.00335 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 135. 315.  43.  48.  91. 354.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.15  0.116 0.086 0.092 0.13  0.096 0.149 0.087 0.    0.047 0.011 0.017\n",
      " 0.009 0.002 0.007 0.001]\n",
      "Q_est = -6.67\n",
      "\n",
      "-> i_step = 4874\n",
      "cur_state = [2 1]\n",
      "action = 1\n",
      "reward = -1.26\n",
      "new_state = [3 1]\n",
      "[ 64. 127. 135. 315.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 135. 315.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.3068   -6.31225  -6.36108  -6.3075   -6.31418\n",
      "  -6.30774  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37125 2.47914 3.02005 2.64396 3.3356  2.30047 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.31\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0536  0.10637 0.11307 0.26382 0.03601 0.0402  0.07621 0.29648 0.\n",
      " 0.00251 0.00419 0.00419 0.00335 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 135. 315.  43.  48.  91. 354.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.155 0.13  0.082 0.097 0.121 0.09  0.144 0.084 0.    0.044 0.004 0.018\n",
      " 0.007 0.008 0.013 0.003]\n",
      "Q_est = -6.71\n",
      "\n",
      "-> i_step = 4875\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 64. 127. 135. 315.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 135. 315.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.3068   -6.31225  -6.36108  -6.3075   -6.31418\n",
      "  -6.30774  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37125 2.47914 3.02005 2.64396 3.3356  2.30047 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.31\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0536  0.10637 0.11307 0.26382 0.03601 0.0402  0.07621 0.29648 0.\n",
      " 0.00251 0.00419 0.00419 0.00335 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 135. 315.  43.  48.  91. 354.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.135 0.133 0.079 0.096 0.139 0.102 0.152 0.076 0.    0.04  0.007 0.018\n",
      " 0.006 0.001 0.014 0.002]\n",
      "Q_est = -6.68\n",
      "\n",
      "-> i_step = 4876\n",
      "cur_state = [0 0]\n",
      "action = 2\n",
      "reward = -0.78\n",
      "new_state = [1 2]\n",
      "[ 64. 127. 136. 315.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 136. 315.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.32418  -6.31225  -6.36108  -6.3075   -6.31418\n",
      "  -6.30774  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37113 2.47914 3.02005 2.64396 3.3356  2.30047 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.31\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05356 0.10628 0.11381 0.2636  0.03598 0.04017 0.07615 0.29623 0.\n",
      " 0.00251 0.00418 0.00418 0.00335 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 136. 315.  43.  48.  91. 354.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.17  0.125 0.077 0.091 0.122 0.108 0.133 0.072 0.    0.036 0.015 0.016\n",
      " 0.013 0.004 0.011 0.007]\n",
      "Q_est = -6.72\n",
      "\n",
      "-> i_step = 4877\n",
      "cur_state = [1 2]\n",
      "action = 0\n",
      "reward = -0.02\n",
      "new_state = [2 0]\n",
      "[ 64. 127. 136. 315.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 136. 315.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.32418  -6.31225  -6.36108  -6.3075   -6.31418\n",
      "  -6.30774  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37113 2.47914 3.02005 2.64396 3.3356  2.30047 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.31\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05356 0.10628 0.11381 0.2636  0.03598 0.04017 0.07615 0.29623 0.\n",
      " 0.00251 0.00418 0.00418 0.00335 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 136. 315.  43.  48.  91. 354.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.146 0.121 0.09  0.093 0.098 0.109 0.156 0.092 0.001 0.04  0.008 0.018\n",
      " 0.009 0.004 0.012 0.003]\n",
      "Q_est = -6.69\n",
      "\n",
      "-> i_step = 4878\n",
      "cur_state = [2 0]\n",
      "action = 1\n",
      "reward = 0.15\n",
      "new_state = [3 1]\n",
      "[ 64. 127. 136. 315.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 136. 315.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.32418  -6.31225  -6.36108  -6.3075   -6.31418\n",
      "  -6.30774  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37113 2.47914 3.02005 2.64396 3.3356  2.30047 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.31\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05356 0.10628 0.11381 0.2636  0.03598 0.04017 0.07615 0.29623 0.\n",
      " 0.00251 0.00418 0.00418 0.00335 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 136. 315.  43.  48.  91. 354.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.139 0.121 0.088 0.096 0.12  0.114 0.148 0.074 0.003 0.046 0.008 0.017\n",
      " 0.008 0.002 0.012 0.004]\n",
      "Q_est = -6.72\n",
      "\n",
      "-> i_step = 4879\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 64. 127. 136. 315.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 136. 315.  43.  48.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.32418  -6.31225  -6.36108  -6.3075   -6.31418\n",
      "  -6.30774  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37113 2.47914 3.02005 2.64396 3.3356  2.30047 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.31\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05356 0.10628 0.11381 0.2636  0.03598 0.04017 0.07615 0.29623 0.\n",
      " 0.00251 0.00418 0.00418 0.00335 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 136. 315.  43.  48.  91. 354.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.148 0.115 0.092 0.088 0.122 0.093 0.154 0.085 0.    0.041 0.012 0.02\n",
      " 0.007 0.003 0.016 0.004]\n",
      "Q_est = -6.73\n",
      "\n",
      "-> i_step = 4880\n",
      "cur_state = [0 0]\n",
      "action = 5\n",
      "reward = 1.00\n",
      "new_state = [1 5]\n",
      "[ 64. 127. 136. 315.  43.  49.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 136. 315.  43.  49.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.32418  -6.31225  -6.36108  -6.3245   -6.31418\n",
      "  -6.30774  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37113 2.47914 3.02005 2.61949 3.3356  2.30047 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.31\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05351 0.10619 0.11371 0.26338 0.03595 0.04097 0.07609 0.29599 0.\n",
      " 0.00251 0.00418 0.00418 0.00334 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 136. 315.  43.  49.  91. 354.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.143 0.133 0.088 0.103 0.138 0.101 0.13  0.088 0.    0.035 0.005 0.014\n",
      " 0.004 0.003 0.011 0.004]\n",
      "Q_est = -6.64\n",
      "\n",
      "-> i_step = 4881\n",
      "cur_state = [1 5]\n",
      "action = 2\n",
      "reward = -0.99\n",
      "new_state = [2 2]\n",
      "[ 64. 127. 136. 315.  43.  49.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 136. 315.  43.  49.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.32418  -6.31225  -6.36108  -6.3245   -6.31418\n",
      "  -6.30774  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37113 2.47914 3.02005 2.61949 3.3356  2.30047 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.31\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05351 0.10619 0.11371 0.26338 0.03595 0.04097 0.07609 0.29599 0.\n",
      " 0.00251 0.00418 0.00418 0.00334 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 136. 315.  43.  49.  91. 354.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.147 0.142 0.094 0.091 0.129 0.094 0.136 0.081 0.002 0.036 0.004 0.015\n",
      " 0.009 0.002 0.013 0.005]\n",
      "Q_est = -6.68\n",
      "\n",
      "-> i_step = 4882\n",
      "cur_state = [2 2]\n",
      "action = 2\n",
      "reward = 0.58\n",
      "new_state = [3 2]\n",
      "[ 64. 127. 136. 315.  43.  49.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 136. 315.  43.  49.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.32418  -6.31225  -6.36108  -6.3245   -6.31418\n",
      "  -6.30774  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37113 2.47914 3.02005 2.61949 3.3356  2.30047 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.31\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05351 0.10619 0.11371 0.26338 0.03595 0.04097 0.07609 0.29599 0.\n",
      " 0.00251 0.00418 0.00418 0.00334 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 136. 315.  43.  49.  91. 354.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.124 0.134 0.093 0.096 0.131 0.106 0.151 0.079 0.001 0.037 0.009 0.021\n",
      " 0.004 0.005 0.006 0.003]\n",
      "Q_est = -6.65\n",
      "\n",
      "-> i_step = 4883\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 64. 127. 136. 315.  43.  49.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 136. 315.  43.  49.  91. 354.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.32418  -6.31225  -6.36108  -6.3245   -6.31418\n",
      "  -6.30774  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37113 2.47914 3.02005 2.61949 3.3356  2.30047 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.31\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05351 0.10619 0.11371 0.26338 0.03595 0.04097 0.07609 0.29599 0.\n",
      " 0.00251 0.00418 0.00418 0.00334 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 136. 315.  43.  49.  91. 354.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.153 0.129 0.078 0.091 0.121 0.089 0.175 0.069 0.    0.046 0.01  0.016\n",
      " 0.003 0.004 0.011 0.005]\n",
      "Q_est = -6.70\n",
      "\n",
      "-> i_step = 4884\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = -1.27\n",
      "new_state = [1 7]\n",
      "[ 64. 127. 136. 315.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 136. 315.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.32418  -6.31225  -6.36108  -6.3245   -6.31418\n",
      "  -6.31562  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37113 2.47914 3.02005 2.61949 3.3356  2.30201 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05347 0.1061  0.11362 0.26316 0.03592 0.04094 0.07602 0.29657 0.\n",
      " 0.00251 0.00418 0.00418 0.00334 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 136. 315.  43.  49.  91. 355.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.139 0.121 0.073 0.089 0.14  0.117 0.135 0.089 0.    0.044 0.004 0.022\n",
      " 0.007 0.001 0.016 0.003]\n",
      "Q_est = -6.73\n",
      "\n",
      "-> i_step = 4885\n",
      "cur_state = [1 7]\n",
      "action = 6\n",
      "reward = -1.39\n",
      "new_state = [2 6]\n",
      "[ 64. 127. 136. 315.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 136. 315.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.32418  -6.31225  -6.36108  -6.3245   -6.31418\n",
      "  -6.31562  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37113 2.47914 3.02005 2.61949 3.3356  2.30201 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05347 0.1061  0.11362 0.26316 0.03592 0.04094 0.07602 0.29657 0.\n",
      " 0.00251 0.00418 0.00418 0.00334 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 136. 315.  43.  49.  91. 355.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.155 0.129 0.086 0.096 0.133 0.092 0.148 0.092 0.    0.023 0.006 0.014\n",
      " 0.009 0.002 0.011 0.004]\n",
      "Q_est = -6.60\n",
      "\n",
      "-> i_step = 4886\n",
      "cur_state = [2 6]\n",
      "action = 5\n",
      "reward = 1.90\n",
      "new_state = [3 5]\n",
      "[ 64. 127. 136. 315.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 136. 315.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.32418  -6.31225  -6.36108  -6.3245   -6.31418\n",
      "  -6.31562  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37113 2.47914 3.02005 2.61949 3.3356  2.30201 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05347 0.1061  0.11362 0.26316 0.03592 0.04094 0.07602 0.29657 0.\n",
      " 0.00251 0.00418 0.00418 0.00334 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 136. 315.  43.  49.  91. 355.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.146 0.125 0.067 0.111 0.114 0.102 0.153 0.09  0.    0.042 0.004 0.015\n",
      " 0.008 0.004 0.013 0.006]\n",
      "Q_est = -6.70\n",
      "\n",
      "-> i_step = 4887\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 64. 127. 136. 315.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 136. 315.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.32418  -6.31225  -6.36108  -6.3245   -6.31418\n",
      "  -6.31562  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37113 2.47914 3.02005 2.61949 3.3356  2.30201 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05347 0.1061  0.11362 0.26316 0.03592 0.04094 0.07602 0.29657 0.\n",
      " 0.00251 0.00418 0.00418 0.00334 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 136. 315.  43.  49.  91. 355.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.159 0.12  0.085 0.091 0.135 0.093 0.157 0.078 0.002 0.031 0.005 0.025\n",
      " 0.01  0.001 0.003 0.005]\n",
      "Q_est = -6.64\n",
      "\n",
      "-> i_step = 4888\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 0.45\n",
      "new_state = [1 3]\n",
      "[ 64. 127. 136. 316.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 136. 316.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.32418  -6.31593  -6.36108  -6.3245   -6.31418\n",
      "  -6.31562  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37113 2.47607 3.02005 2.61949 3.3356  2.30201 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05342 0.10601 0.11352 0.26377 0.03589 0.0409  0.07596 0.29633 0.\n",
      " 0.0025  0.00417 0.00417 0.00334 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 136. 316.  43.  49.  91. 355.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.135 0.138 0.089 0.104 0.122 0.11  0.145 0.077 0.    0.032 0.003 0.013\n",
      " 0.008 0.007 0.014 0.003]\n",
      "Q_est = -6.65\n",
      "\n",
      "-> i_step = 4889\n",
      "cur_state = [1 3]\n",
      "action = 5\n",
      "reward = 0.49\n",
      "new_state = [2 5]\n",
      "[ 64. 127. 136. 316.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 136. 316.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.32418  -6.31593  -6.36108  -6.3245   -6.31418\n",
      "  -6.31562  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37113 2.47607 3.02005 2.61949 3.3356  2.30201 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05342 0.10601 0.11352 0.26377 0.03589 0.0409  0.07596 0.29633 0.\n",
      " 0.0025  0.00417 0.00417 0.00334 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 136. 316.  43.  49.  91. 355.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.148 0.115 0.079 0.098 0.128 0.119 0.153 0.075 0.    0.041 0.006 0.012\n",
      " 0.01  0.001 0.013 0.002]\n",
      "Q_est = -6.67\n",
      "\n",
      "-> i_step = 4890\n",
      "cur_state = [2 5]\n",
      "action = 2\n",
      "reward = 0.01\n",
      "new_state = [3 2]\n",
      "[ 64. 127. 136. 316.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 136. 316.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.32418  -6.31593  -6.36108  -6.3245   -6.31418\n",
      "  -6.31562  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37113 2.47607 3.02005 2.61949 3.3356  2.30201 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05342 0.10601 0.11352 0.26377 0.03589 0.0409  0.07596 0.29633 0.\n",
      " 0.0025  0.00417 0.00417 0.00334 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 136. 316.  43.  49.  91. 355.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.147 0.12  0.076 0.099 0.126 0.104 0.148 0.073 0.001 0.054 0.008 0.015\n",
      " 0.007 0.001 0.019 0.002]\n",
      "Q_est = -6.76\n",
      "\n",
      "-> i_step = 4891\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 64. 127. 136. 316.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 127. 136. 316.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.31291  -6.32418  -6.31593  -6.36108  -6.3245   -6.31418\n",
      "  -6.31562  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.019   2.37113 2.47607 3.02005 2.61949 3.3356  2.30201 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05342 0.10601 0.11352 0.26377 0.03589 0.0409  0.07596 0.29633 0.\n",
      " 0.0025  0.00417 0.00417 0.00334 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 127. 136. 316.  43.  49.  91. 355.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.148 0.139 0.1   0.077 0.133 0.097 0.145 0.076 0.    0.037 0.006 0.016\n",
      " 0.005 0.004 0.015 0.002]\n",
      "Q_est = -6.67\n",
      "\n",
      "-> i_step = 4892\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -0.07\n",
      "new_state = [1 1]\n",
      "[ 64. 128. 136. 316.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 128. 136. 316.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.32673  -6.32418  -6.31593  -6.36108  -6.3245   -6.31418\n",
      "  -6.31562  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.01122 2.37113 2.47607 3.02005 2.61949 3.3356  2.30201 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05338 0.10676 0.11343 0.26355 0.03586 0.04087 0.0759  0.29608 0.\n",
      " 0.0025  0.00417 0.00417 0.00334 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 128. 136. 316.  43.  49.  91. 355.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.149 0.132 0.073 0.101 0.132 0.084 0.152 0.083 0.    0.046 0.005 0.02\n",
      " 0.004 0.002 0.012 0.005]\n",
      "Q_est = -6.71\n",
      "\n",
      "-> i_step = 4893\n",
      "cur_state = [1 1]\n",
      "action = 1\n",
      "reward = 0.12\n",
      "new_state = [2 1]\n",
      "[ 64. 128. 136. 316.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 128. 136. 316.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.32673  -6.32418  -6.31593  -6.36108  -6.3245   -6.31418\n",
      "  -6.31562  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.01122 2.37113 2.47607 3.02005 2.61949 3.3356  2.30201 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05338 0.10676 0.11343 0.26355 0.03586 0.04087 0.0759  0.29608 0.\n",
      " 0.0025  0.00417 0.00417 0.00334 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 128. 136. 316.  43.  49.  91. 355.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14]\n",
      "probs = [0.143 0.131 0.073 0.103 0.13  0.101 0.148 0.085 0.    0.044 0.006 0.016\n",
      " 0.005 0.003 0.012 0.   ]\n",
      "Q_est = -6.66\n",
      "\n",
      "-> i_step = 4894\n",
      "cur_state = [2 1]\n",
      "action = 1\n",
      "reward = -0.11\n",
      "new_state = [3 1]\n",
      "[ 64. 128. 136. 316.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 128. 136. 316.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.32673  -6.32418  -6.31593  -6.36108  -6.3245   -6.31418\n",
      "  -6.31562  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.01122 2.37113 2.47607 3.02005 2.61949 3.3356  2.30201 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05338 0.10676 0.11343 0.26355 0.03586 0.04087 0.0759  0.29608 0.\n",
      " 0.0025  0.00417 0.00417 0.00334 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 128. 136. 316.  43.  49.  91. 355.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.148 0.142 0.083 0.108 0.124 0.088 0.149 0.071 0.001 0.03  0.008 0.023\n",
      " 0.002 0.006 0.012 0.005]\n",
      "Q_est = -6.68\n",
      "\n",
      "-> i_step = 4895\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 64. 128. 136. 316.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 128. 136. 316.  43.  49.  91. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.32673  -6.32418  -6.31593  -6.36108  -6.3245   -6.31418\n",
      "  -6.31562  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.01122 2.37113 2.47607 3.02005 2.61949 3.3356  2.30201 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05338 0.10676 0.11343 0.26355 0.03586 0.04087 0.0759  0.29608 0.\n",
      " 0.0025  0.00417 0.00417 0.00334 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 128. 136. 316.  43.  49.  91. 355.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.137 0.114 0.099 0.088 0.135 0.117 0.125 0.089 0.    0.036 0.005 0.019\n",
      " 0.007 0.006 0.021 0.002]\n",
      "Q_est = -6.73\n",
      "\n",
      "-> i_step = 4896\n",
      "cur_state = [0 0]\n",
      "action = 6\n",
      "reward = -0.47\n",
      "new_state = [1 6]\n",
      "[ 64. 128. 136. 316.  43.  49.  92. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 128. 136. 316.  43.  49.  92. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.32673  -6.32418  -6.31593  -6.36108  -6.3245   -6.33966\n",
      "  -6.31562  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.01122 2.37113 2.47607 3.02005 2.61949 3.32631 2.30201 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05333 0.10667 0.11333 0.26333 0.03583 0.04083 0.07667 0.29583 0.\n",
      " 0.0025  0.00417 0.00417 0.00333 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 128. 136. 316.  43.  49.  92. 355.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.145 0.141 0.073 0.11  0.115 0.075 0.144 0.095 0.002 0.045 0.007 0.027\n",
      " 0.005 0.002 0.011 0.003]\n",
      "Q_est = -6.73\n",
      "\n",
      "-> i_step = 4897\n",
      "cur_state = [1 6]\n",
      "action = 1\n",
      "reward = 0.80\n",
      "new_state = [2 1]\n",
      "[ 64. 128. 136. 316.  43.  49.  92. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 128. 136. 316.  43.  49.  92. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.32673  -6.32418  -6.31593  -6.36108  -6.3245   -6.33966\n",
      "  -6.31562  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.01122 2.37113 2.47607 3.02005 2.61949 3.32631 2.30201 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05333 0.10667 0.11333 0.26333 0.03583 0.04083 0.07667 0.29583 0.\n",
      " 0.0025  0.00417 0.00417 0.00333 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 128. 136. 316.  43.  49.  92. 355.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.156 0.13  0.076 0.089 0.132 0.09  0.174 0.074 0.001 0.034 0.008 0.017\n",
      " 0.006 0.002 0.008 0.003]\n",
      "Q_est = -6.64\n",
      "\n",
      "-> i_step = 4898\n",
      "cur_state = [2 1]\n",
      "action = 1\n",
      "reward = 0.14\n",
      "new_state = [3 1]\n",
      "[ 64. 128. 136. 316.  43.  49.  92. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 128. 136. 316.  43.  49.  92. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.32673  -6.32418  -6.31593  -6.36108  -6.3245   -6.33966\n",
      "  -6.31562  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.01122 2.37113 2.47607 3.02005 2.61949 3.32631 2.30201 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05333 0.10667 0.11333 0.26333 0.03583 0.04083 0.07667 0.29583 0.\n",
      " 0.0025  0.00417 0.00417 0.00333 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 128. 136. 316.  43.  49.  92. 355.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.138 0.139 0.092 0.1   0.126 0.097 0.155 0.072 0.    0.036 0.006 0.013\n",
      " 0.007 0.003 0.01  0.006]\n",
      "Q_est = -6.66\n",
      "\n",
      "-> i_step = 4899\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 64. 128. 136. 316.  43.  49.  92. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 128. 136. 316.  43.  49.  92. 355.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.32673  -6.32418  -6.31593  -6.36108  -6.3245   -6.33966\n",
      "  -6.31562  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.01122 2.37113 2.47607 3.02005 2.61949 3.32631 2.30201 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05333 0.10667 0.11333 0.26333 0.03583 0.04083 0.07667 0.29583 0.\n",
      " 0.0025  0.00417 0.00417 0.00333 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 128. 136. 316.  43.  49.  92. 355.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.137 0.142 0.094 0.086 0.148 0.092 0.153 0.076 0.    0.029 0.007 0.01\n",
      " 0.007 0.002 0.012 0.005]\n",
      "Q_est = -6.63\n",
      "\n",
      "-> i_step = 4900\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = -1.75\n",
      "new_state = [1 7]\n",
      "[ 64. 128. 136. 316.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 128. 136. 316.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.32673  -6.32418  -6.31593  -6.36108  -6.3245   -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.01122 2.37113 2.47607 3.02005 2.61949 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05329 0.10658 0.11324 0.26311 0.0358  0.0408  0.0766  0.29642 0.\n",
      " 0.0025  0.00416 0.00416 0.00333 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 128. 136. 316.  43.  49.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.144 0.133 0.072 0.096 0.134 0.119 0.136 0.087 0.001 0.035 0.003 0.012\n",
      " 0.003 0.009 0.014 0.002]\n",
      "Q_est = -6.65\n",
      "\n",
      "-> i_step = 4901\n",
      "cur_state = [1 7]\n",
      "action = 0\n",
      "reward = -0.01\n",
      "new_state = [2 0]\n",
      "[ 64. 128. 136. 316.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 128. 136. 316.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.32673  -6.32418  -6.31593  -6.36108  -6.3245   -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.01122 2.37113 2.47607 3.02005 2.61949 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05329 0.10658 0.11324 0.26311 0.0358  0.0408  0.0766  0.29642 0.\n",
      " 0.0025  0.00416 0.00416 0.00333 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 128. 136. 316.  43.  49.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.141 0.116 0.082 0.098 0.144 0.104 0.147 0.081 0.    0.03  0.009 0.015\n",
      " 0.006 0.005 0.016 0.006]\n",
      "Q_est = -6.69\n",
      "\n",
      "-> i_step = 4902\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = 0.86\n",
      "new_state = [3 7]\n",
      "[ 64. 128. 136. 316.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 128. 136. 316.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.32673  -6.32418  -6.31593  -6.36108  -6.3245   -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.01122 2.37113 2.47607 3.02005 2.61949 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05329 0.10658 0.11324 0.26311 0.0358  0.0408  0.0766  0.29642 0.\n",
      " 0.0025  0.00416 0.00416 0.00333 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 128. 136. 316.  43.  49.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.158 0.119 0.082 0.085 0.132 0.1   0.152 0.085 0.002 0.043 0.008 0.017\n",
      " 0.001 0.002 0.013 0.001]\n",
      "Q_est = -6.68\n",
      "\n",
      "-> i_step = 4903\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 64. 128. 136. 316.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 128. 136. 316.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.32673  -6.32418  -6.31593  -6.36108  -6.3245   -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.01122 2.37113 2.47607 3.02005 2.61949 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05329 0.10658 0.11324 0.26311 0.0358  0.0408  0.0766  0.29642 0.\n",
      " 0.0025  0.00416 0.00416 0.00333 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 128. 136. 316.  43.  49.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.145 0.119 0.088 0.105 0.118 0.109 0.147 0.082 0.    0.038 0.004 0.025\n",
      " 0.004 0.002 0.012 0.002]\n",
      "Q_est = -6.68\n",
      "\n",
      "-> i_step = 4904\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 1.15\n",
      "new_state = [1 3]\n",
      "[ 64. 128. 136. 317.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 128. 136. 317.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.32673  -6.32418  -6.31739  -6.36108  -6.3245   -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.01122 2.37113 2.4723  3.02005 2.61949 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05324 0.10649 0.11314 0.26373 0.03577 0.04077 0.07654 0.29617 0.\n",
      " 0.0025  0.00416 0.00416 0.00333 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 128. 136. 317.  43.  49.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "probs = [0.128 0.133 0.076 0.099 0.137 0.101 0.164 0.076 0.001 0.037 0.003 0.022\n",
      " 0.011 0.003 0.009 0.   ]\n",
      "Q_est = -6.66\n",
      "\n",
      "-> i_step = 4905\n",
      "cur_state = [1 3]\n",
      "action = 5\n",
      "reward = -0.08\n",
      "new_state = [2 5]\n",
      "[ 64. 128. 136. 317.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 128. 136. 317.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.32673  -6.32418  -6.31739  -6.36108  -6.3245   -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.01122 2.37113 2.4723  3.02005 2.61949 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05324 0.10649 0.11314 0.26373 0.03577 0.04077 0.07654 0.29617 0.\n",
      " 0.0025  0.00416 0.00416 0.00333 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 128. 136. 317.  43.  49.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.14  0.11  0.094 0.096 0.137 0.079 0.169 0.09  0.    0.028 0.008 0.018\n",
      " 0.006 0.005 0.015 0.005]\n",
      "Q_est = -6.68\n",
      "\n",
      "-> i_step = 4906\n",
      "cur_state = [2 5]\n",
      "action = 2\n",
      "reward = -1.99\n",
      "new_state = [3 2]\n",
      "[ 64. 128. 136. 317.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 128. 136. 317.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.32673  -6.32418  -6.31739  -6.36108  -6.3245   -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.01122 2.37113 2.4723  3.02005 2.61949 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05324 0.10649 0.11314 0.26373 0.03577 0.04077 0.07654 0.29617 0.\n",
      " 0.0025  0.00416 0.00416 0.00333 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 128. 136. 317.  43.  49.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.137 0.12  0.075 0.101 0.12  0.119 0.161 0.08  0.001 0.034 0.006 0.018\n",
      " 0.006 0.004 0.011 0.007]\n",
      "Q_est = -6.69\n",
      "\n",
      "-> i_step = 4907\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 64. 128. 136. 317.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 128. 136. 317.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.32673  -6.32418  -6.31739  -6.36108  -6.3245   -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.01122 2.37113 2.4723  3.02005 2.61949 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05324 0.10649 0.11314 0.26373 0.03577 0.04077 0.07654 0.29617 0.\n",
      " 0.0025  0.00416 0.00416 0.00333 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 128. 136. 317.  43.  49.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.168 0.126 0.075 0.099 0.12  0.091 0.17  0.069 0.    0.035 0.003 0.02\n",
      " 0.004 0.002 0.013 0.005]\n",
      "Q_est = -6.68\n",
      "\n",
      "-> i_step = 4908\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -1.92\n",
      "new_state = [1 3]\n",
      "[ 64. 128. 136. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 128. 136. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.32673  -6.32418  -6.32848  -6.36108  -6.3245   -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.01122 2.37113 2.4763  3.02005 2.61949 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0532  0.1064  0.11305 0.26434 0.03574 0.04073 0.07648 0.29593 0.\n",
      " 0.00249 0.00416 0.00416 0.00333 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 128. 136. 318.  43.  49.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.16  0.117 0.099 0.11  0.121 0.106 0.13  0.063 0.    0.04  0.005 0.02\n",
      " 0.005 0.004 0.014 0.006]\n",
      "Q_est = -6.72\n",
      "\n",
      "-> i_step = 4909\n",
      "cur_state = [1 3]\n",
      "action = 1\n",
      "reward = -1.19\n",
      "new_state = [2 1]\n",
      "[ 64. 128. 136. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 128. 136. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.32673  -6.32418  -6.32848  -6.36108  -6.3245   -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.01122 2.37113 2.4763  3.02005 2.61949 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0532  0.1064  0.11305 0.26434 0.03574 0.04073 0.07648 0.29593 0.\n",
      " 0.00249 0.00416 0.00416 0.00333 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 128. 136. 318.  43.  49.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.166 0.125 0.085 0.107 0.108 0.102 0.144 0.078 0.    0.035 0.007 0.013\n",
      " 0.008 0.005 0.014 0.003]\n",
      "Q_est = -6.67\n",
      "\n",
      "-> i_step = 4910\n",
      "cur_state = [2 1]\n",
      "action = 1\n",
      "reward = 1.36\n",
      "new_state = [3 1]\n",
      "[ 64. 128. 136. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 128. 136. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.32673  -6.32418  -6.32848  -6.36108  -6.3245   -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.01122 2.37113 2.4763  3.02005 2.61949 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0532  0.1064  0.11305 0.26434 0.03574 0.04073 0.07648 0.29593 0.\n",
      " 0.00249 0.00416 0.00416 0.00333 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 128. 136. 318.  43.  49.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.119 0.138 0.102 0.088 0.134 0.106 0.144 0.084 0.    0.035 0.008 0.015\n",
      " 0.009 0.004 0.012 0.002]\n",
      "Q_est = -6.66\n",
      "\n",
      "-> i_step = 4911\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 64. 128. 136. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 64. 128. 136. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.32152  -6.32673  -6.32418  -6.32848  -6.36108  -6.3245   -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.25256 3.01122 2.37113 2.4763  3.02005 2.61949 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0532  0.1064  0.11305 0.26434 0.03574 0.04073 0.07648 0.29593 0.\n",
      " 0.00249 0.00416 0.00416 0.00333 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 64. 128. 136. 318.  43.  49.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.143 0.139 0.093 0.091 0.134 0.086 0.153 0.071 0.001 0.041 0.007 0.015\n",
      " 0.006 0.004 0.013 0.003]\n",
      "Q_est = -6.69\n",
      "\n",
      "-> i_step = 4912\n",
      "cur_state = [0 0]\n",
      "action = 0\n",
      "reward = -0.06\n",
      "new_state = [1 0]\n",
      "[ 65. 128. 136. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 65. 128. 136. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.35228  -6.32673  -6.32418  -6.32848  -6.36108  -6.3245   -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.23681 3.01122 2.37113 2.4763  3.02005 2.61949 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05399 0.10631 0.11296 0.26412 0.03571 0.0407  0.07641 0.29568 0.\n",
      " 0.00249 0.00415 0.00415 0.00332 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 65. 128. 136. 318.  43.  49.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.153 0.129 0.084 0.084 0.111 0.125 0.146 0.074 0.    0.038 0.009 0.015\n",
      " 0.01  0.002 0.014 0.006]\n",
      "Q_est = -6.72\n",
      "\n",
      "-> i_step = 4913\n",
      "cur_state = [1 0]\n",
      "action = 5\n",
      "reward = -0.07\n",
      "new_state = [2 5]\n",
      "[ 65. 128. 136. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 65. 128. 136. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.35228  -6.32673  -6.32418  -6.32848  -6.36108  -6.3245   -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.23681 3.01122 2.37113 2.4763  3.02005 2.61949 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05399 0.10631 0.11296 0.26412 0.03571 0.0407  0.07641 0.29568 0.\n",
      " 0.00249 0.00415 0.00415 0.00332 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 65. 128. 136. 318.  43.  49.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.152 0.131 0.074 0.096 0.112 0.113 0.16  0.082 0.001 0.039 0.004 0.012\n",
      " 0.005 0.002 0.013 0.004]\n",
      "Q_est = -6.67\n",
      "\n",
      "-> i_step = 4914\n",
      "cur_state = [2 5]\n",
      "action = 2\n",
      "reward = 0.02\n",
      "new_state = [3 2]\n",
      "[ 65. 128. 136. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 65. 128. 136. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.35228  -6.32673  -6.32418  -6.32848  -6.36108  -6.3245   -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.23681 3.01122 2.37113 2.4763  3.02005 2.61949 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05399 0.10631 0.11296 0.26412 0.03571 0.0407  0.07641 0.29568 0.\n",
      " 0.00249 0.00415 0.00415 0.00332 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 65. 128. 136. 318.  43.  49.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.147 0.129 0.066 0.101 0.119 0.107 0.145 0.083 0.    0.045 0.006 0.029\n",
      " 0.007 0.001 0.014 0.001]\n",
      "Q_est = -6.74\n",
      "\n",
      "-> i_step = 4915\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 65. 128. 136. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 65. 128. 136. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.35228  -6.32673  -6.32418  -6.32848  -6.36108  -6.3245   -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.23681 3.01122 2.37113 2.4763  3.02005 2.61949 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05399 0.10631 0.11296 0.26412 0.03571 0.0407  0.07641 0.29568 0.\n",
      " 0.00249 0.00415 0.00415 0.00332 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 65. 128. 136. 318.  43.  49.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.135 0.141 0.089 0.113 0.118 0.094 0.138 0.078 0.001 0.044 0.006 0.017\n",
      " 0.009 0.001 0.014 0.002]\n",
      "Q_est = -6.71\n",
      "\n",
      "-> i_step = 4916\n",
      "cur_state = [0 0]\n",
      "action = 2\n",
      "reward = 0.76\n",
      "new_state = [1 2]\n",
      "[ 65. 128. 137. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 65. 128. 137. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.35228  -6.32673  -6.33014  -6.32848  -6.36108  -6.3245   -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.23681 3.01122 2.36348 2.4763  3.02005 2.61949 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05394 0.10622 0.11369 0.2639  0.03568 0.04066 0.07635 0.29544 0.\n",
      " 0.00249 0.00415 0.00415 0.00332 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 65. 128. 137. 318.  43.  49.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.133 0.132 0.096 0.094 0.12  0.123 0.143 0.079 0.    0.029 0.007 0.014\n",
      " 0.01  0.003 0.013 0.004]\n",
      "Q_est = -6.66\n",
      "\n",
      "-> i_step = 4917\n",
      "cur_state = [1 2]\n",
      "action = 7\n",
      "reward = 1.01\n",
      "new_state = [2 7]\n",
      "[ 65. 128. 137. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 65. 128. 137. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.35228  -6.32673  -6.33014  -6.32848  -6.36108  -6.3245   -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.23681 3.01122 2.36348 2.4763  3.02005 2.61949 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05394 0.10622 0.11369 0.2639  0.03568 0.04066 0.07635 0.29544 0.\n",
      " 0.00249 0.00415 0.00415 0.00332 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 65. 128. 137. 318.  43.  49.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.132 0.133 0.093 0.087 0.128 0.124 0.143 0.081 0.    0.032 0.007 0.018\n",
      " 0.005 0.003 0.01  0.004]\n",
      "Q_est = -6.65\n",
      "\n",
      "-> i_step = 4918\n",
      "cur_state = [2 7]\n",
      "action = 5\n",
      "reward = -0.56\n",
      "new_state = [3 5]\n",
      "[ 65. 128. 137. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 65. 128. 137. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.35228  -6.32673  -6.33014  -6.32848  -6.36108  -6.3245   -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.23681 3.01122 2.36348 2.4763  3.02005 2.61949 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05394 0.10622 0.11369 0.2639  0.03568 0.04066 0.07635 0.29544 0.\n",
      " 0.00249 0.00415 0.00415 0.00332 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 65. 128. 137. 318.  43.  49.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.131 0.131 0.083 0.09  0.154 0.083 0.153 0.088 0.    0.035 0.008 0.017\n",
      " 0.006 0.007 0.009 0.005]\n",
      "Q_est = -6.68\n",
      "\n",
      "-> i_step = 4919\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 65. 128. 137. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 65. 128. 137. 318.  43.  49.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.35228  -6.32673  -6.33014  -6.32848  -6.36108  -6.3245   -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.23681 3.01122 2.36348 2.4763  3.02005 2.61949 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05394 0.10622 0.11369 0.2639  0.03568 0.04066 0.07635 0.29544 0.\n",
      " 0.00249 0.00415 0.00415 0.00332 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 65. 128. 137. 318.  43.  49.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.134 0.13  0.085 0.083 0.122 0.121 0.147 0.095 0.001 0.037 0.009 0.015\n",
      " 0.006 0.004 0.008 0.003]\n",
      "Q_est = -6.66\n",
      "\n",
      "-> i_step = 4920\n",
      "cur_state = [0 0]\n",
      "action = 5\n",
      "reward = -0.95\n",
      "new_state = [1 5]\n",
      "[ 65. 128. 137. 318.  43.  50.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 65. 128. 137. 318.  43.  50.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.35228  -6.32673  -6.33014  -6.32848  -6.36108  -6.38038  -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.23681 3.01122 2.36348 2.4763  3.02005 2.62249 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0539  0.10614 0.1136  0.26368 0.03566 0.04146 0.07629 0.29519 0.\n",
      " 0.00249 0.00415 0.00415 0.00332 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 65. 128. 137. 318.  43.  50.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.38\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.144 0.141 0.088 0.081 0.142 0.087 0.16  0.07  0.    0.038 0.011 0.014\n",
      " 0.01  0.003 0.008 0.003]\n",
      "Q_est = -6.67\n",
      "\n",
      "-> i_step = 4921\n",
      "cur_state = [1 5]\n",
      "action = 5\n",
      "reward = 0.19\n",
      "new_state = [2 5]\n",
      "[ 65. 128. 137. 318.  43.  50.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 65. 128. 137. 318.  43.  50.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.35228  -6.32673  -6.33014  -6.32848  -6.36108  -6.38038  -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.23681 3.01122 2.36348 2.4763  3.02005 2.62249 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0539  0.10614 0.1136  0.26368 0.03566 0.04146 0.07629 0.29519 0.\n",
      " 0.00249 0.00415 0.00415 0.00332 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 65. 128. 137. 318.  43.  50.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.38\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.147 0.134 0.087 0.091 0.097 0.109 0.157 0.088 0.    0.038 0.008 0.014\n",
      " 0.01  0.003 0.014 0.003]\n",
      "Q_est = -6.70\n",
      "\n",
      "-> i_step = 4922\n",
      "cur_state = [2 5]\n",
      "action = 2\n",
      "reward = -0.19\n",
      "new_state = [3 2]\n",
      "[ 65. 128. 137. 318.  43.  50.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 65. 128. 137. 318.  43.  50.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.35228  -6.32673  -6.33014  -6.32848  -6.36108  -6.38038  -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.23681 3.01122 2.36348 2.4763  3.02005 2.62249 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0539  0.10614 0.1136  0.26368 0.03566 0.04146 0.07629 0.29519 0.\n",
      " 0.00249 0.00415 0.00415 0.00332 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 65. 128. 137. 318.  43.  50.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.38\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.142 0.127 0.095 0.1   0.13  0.103 0.126 0.095 0.002 0.032 0.006 0.019\n",
      " 0.005 0.005 0.01  0.003]\n",
      "Q_est = -6.66\n",
      "\n",
      "-> i_step = 4923\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 65. 128. 137. 318.  43.  50.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 65. 128. 137. 318.  43.  50.  92. 356.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.35228  -6.32673  -6.33014  -6.32848  -6.36108  -6.38038  -6.33966\n",
      "  -6.32485  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.23681 3.01122 2.36348 2.4763  3.02005 2.62249 3.32631 2.30533 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.0539  0.10614 0.1136  0.26368 0.03566 0.04146 0.07629 0.29519 0.\n",
      " 0.00249 0.00415 0.00415 0.00332 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 65. 128. 137. 318.  43.  50.  92. 356.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.38\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "probs = [0.125 0.13  0.093 0.103 0.148 0.09  0.163 0.068 0.001 0.03  0.005 0.016\n",
      " 0.01  0.003 0.014 0.001]\n",
      "Q_est = -6.66\n",
      "\n",
      "-> i_step = 4924\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 0.20\n",
      "new_state = [1 7]\n",
      "[ 65. 128. 137. 318.  43.  50.  92. 357.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 65. 128. 137. 318.  43.  50.  92. 357.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.35228  -6.32673  -6.33014  -6.32848  -6.36108  -6.38038  -6.33966\n",
      "  -6.32856  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.23681 3.01122 2.36348 2.4763  3.02005 2.62249 3.32631 2.30317 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.33\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05385 0.10605 0.1135  0.26346 0.03563 0.04143 0.07622 0.29577 0.\n",
      " 0.00249 0.00414 0.00414 0.00331 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 65. 128. 137. 318.  43.  50.  92. 357.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.38\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "probs = [0.127 0.134 0.078 0.091 0.125 0.116 0.156 0.084 0.003 0.033 0.006 0.017\n",
      " 0.007 0.005 0.018 0.   ]\n",
      "Q_est = -6.70\n",
      "\n",
      "-> i_step = 4925\n",
      "cur_state = [1 7]\n",
      "action = 2\n",
      "reward = 1.02\n",
      "new_state = [2 2]\n",
      "[ 65. 128. 137. 318.  43.  50.  92. 357.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 65. 128. 137. 318.  43.  50.  92. 357.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.35228  -6.32673  -6.33014  -6.32848  -6.36108  -6.38038  -6.33966\n",
      "  -6.32856  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.23681 3.01122 2.36348 2.4763  3.02005 2.62249 3.32631 2.30317 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 7\n",
      "action_maxlcb_muhat = -6.33\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Bset_probs = [0.05385 0.10605 0.1135  0.26346 0.03563 0.04143 0.07622 0.29577 0.\n",
      " 0.00249 0.00414 0.00414 0.00331 0.      0.      0.     ]\n",
      "Bset_nvisits = [ 65. 128. 137. 318.  43.  50.  92. 357.   0.   3.   5.   5.   4.   0.\n",
      "   0.   0.]\n",
      "Q_est = -6.38\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15]\n",
      "probs = [0.137 0.121 0.076 0.091 0.131 0.111 0.152 0.095 0.    0.037 0.007 0.02\n",
      " 0.006 0.003 0.01  0.003]\n",
      "Q_est = -6.68\n",
      "\n",
      "-> i_step = 4926\n",
      "cur_state = [2 2]\n",
      "action = 2\n",
      "reward = -0.20\n",
      "new_state = [3 2]\n",
      "[ 65. 128. 137. 318.  43.  50.  92. 357.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ 65. 128. 137. 318.  43.  50.  92. 357.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "[ -6.35228  -6.32673  -6.33014  -6.32848  -6.36108  -6.38038  -6.33966\n",
      "  -6.32856  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839]\n",
      "[3.23681 3.01122 2.36348 2.4763  3.02005 2.62249 3.32631 2.30317 1.74413\n",
      " 4.1373  2.03338 3.23985 2.34721 1.92406 4.28778 3.71933]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_episode_start_sigmahat = 1250.0000\n",
      "last_episode_reward_per_step = -10.0000\n",
      "last_episode_estim_start_muhat = -7.0276\n",
      "it takes 3.5325\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "tdqm_disable = True\n",
    "\n",
    "# params\n",
    "num_trials = 200\n",
    "num_steps_train = 5000\n",
    "num_episodes_eval = 100\n",
    "\n",
    "lr_sched_type = \"linear\"\n",
    "lr_sched_fn = create_lr_sched_fn(lr_sched_type, lr=0.7)\n",
    "\n",
    "max_eps = 1.0\n",
    "min_eps = 1.0\n",
    "decay_rate = 0.0001\n",
    "eps_sched_type = \"poly\"\n",
    "eps_sched_fn = create_eps_sched_fn(eps_sched_type, min_eps, max_eps, decay_rate)\n",
    "\n",
    "# create gym env\n",
    "env_id = \"gym_examples/NNWorldEnv01-v1\"\n",
    "env_scheme = \"two_island\"\n",
    "gamma = 0.95\n",
    "\n",
    "num_depths = 4\n",
    "num_widths = 16\n",
    "num_actions = num_widths\n",
    "terminal_reward = -10.0\n",
    "\n",
    "reward_dist = \"normal\"\n",
    "problem_instance = \"multi_gap_nonlinear\"\n",
    "action_max_mu = 0.0\n",
    "action_sigma = 1.0\n",
    "action_sigmas = action_sigma*np.ones(num_actions)\n",
    "gap_splits = [0.5]\n",
    "gap_deltas = [5.0]\n",
    "bandit_problem = BanditProblem(\n",
    "    problem_instance, reward_dist, num_actions, action_max_mu, \n",
    "    action_sigmas=action_sigmas, gap_splits=gap_splits, gap_deltas=gap_deltas)\n",
    "print(f\"action_mus = {bandit_problem.action_mus}\")\n",
    "print(f\"action_sigmas = {bandit_problem.action_sigmas}\")\n",
    "\n",
    "action_max_mu = bandit_problem.action_mus[0]\n",
    "optimal_num_steps = num_depths\n",
    "optimal_vstar = terminal_reward*gamma**(optimal_num_steps-1) \\\n",
    "    + action_max_mu*np.sum([gamma**k for k in range(optimal_num_steps-1)])\n",
    "optimal_reward_per_step = (terminal_reward + action_max_mu*(optimal_num_steps-1))/optimal_num_steps  \n",
    "print(f\"optimal_num_steps = {optimal_num_steps}\")\n",
    "print(f\"optimal_reward_per_step = {optimal_reward_per_step}\")\n",
    "print(f\"optimal_vstar = {optimal_vstar}\")\n",
    "\n",
    "env = gym.make(env_id, num_depths=num_depths, num_widths=num_widths, \n",
    "               bandit_problem=bandit_problem, terminal_reward=terminal_reward)\n",
    "env_wrapped = FlattenObservation(env)\n",
    "cur_state, info = env_wrapped.reset()\n",
    "\n",
    "manager = multiprocessing.Manager()\n",
    "episode_start_sigmahats_list = manager.list()\n",
    "episode_rewards_list = manager.list()\n",
    "episode_vstar_est_list = manager.list()\n",
    "Q_table_list = manager.list()\n",
    "Q_nvisits_list = manager.list()    \n",
    "\n",
    "def run_trial(i_trial, args):\n",
    "\n",
    "    random.seed(10000+i_trial)\n",
    "    np.random.seed(10000+i_trial)\n",
    "\n",
    "    # env = gym.make(env_id, size=gridworld_size)\n",
    "    # env_wrapped = FlattenObservation(env)\n",
    "    # env_wrapped.reset(seed=10000+i_trial)\n",
    "\n",
    "    # lr_sched_fn = create_lr_sched_fn(lr_sched_type)\n",
    "    # eps_sched_fn = create_eps_sched_fn(eps_sched_type, min_eps, max_eps, decay_rate)\n",
    "    q_algo = create_q_algo(args[\"est_name\"])\n",
    "\n",
    "    Q_table, Q_nvisits, stats = q_algo(\n",
    "        env_wrapped, num_actions, num_steps_train,\n",
    "        gamma, lr_sched_fn, eps_sched_fn, tdqm_disable, args)\n",
    "\n",
    "    episode_start_sigmahats, episode_rewards, episode_vstar_est= zip(*stats)\n",
    "    episode_start_sigmahats_list.append(episode_start_sigmahats)\n",
    "    episode_rewards_list.append(episode_rewards)\n",
    "    episode_vstar_est_list.append(episode_vstar_est)\n",
    "    Q_table_list.append(Q_table)\n",
    "    Q_nvisits_list.append(Q_nvisits)\n",
    "\n",
    "args = dict()\n",
    "args[\"action_sigma\"] = action_sigma\n",
    "args[\"haver_alpha\"] = 2.0\n",
    "args[\"haver_delta\"] = 0.05\n",
    "args[\"haver_const\"] = 1.0\n",
    "args[\"weightedms_num_data\"] = 1000\n",
    "args[\"num_depths\"] = num_depths\n",
    "args[\"env_scheme\"] = env_scheme\n",
    "\n",
    "pool = multiprocessing.Pool()\n",
    "\n",
    "episode_start_sigmahats_dict = defaultdict()\n",
    "episode_rewards_dict = defaultdict()\n",
    "episode_vstar_est_dict = defaultdict()\n",
    "episode_vstar_est_bias_dict = defaultdict()\n",
    "episode_vstar_est_var_dict = defaultdict()\n",
    "episode_vstar_est_mse_dict = defaultdict()\n",
    "Q_table_dict = defaultdict()\n",
    "Q_nvisits_dict = defaultdict()\n",
    "\n",
    "haver_const_ary = [1.0]\n",
    "haver_name_ary = [f\"haver_{x}\" for x in haver_const_ary]\n",
    "haver3_name_ary = [f\"haver3_{x}\" for x in haver_const_ary]\n",
    "\n",
    "est_name_ary = [\"max\", \"weightedms\"]\n",
    "# est_name_ary = haver_name_ary + est_name_ary \n",
    "# est_name_ary = est_name_ary + haver_name_ary\n",
    "est_name_ary = est_name_ary + haver3_name_ary\n",
    "est_name_ary = [\"haver3_1.0\", \"weightedms\"]\n",
    "for est_name in est_name_ary:\n",
    "    start_time = time.time()\n",
    "    print(f\"\\n-> est_name = {est_name}\")\n",
    "    if \"haver\" in est_name:\n",
    "        elems = est_name.split(\"_\")\n",
    "        args[\"est_name\"] = elems[0]\n",
    "        args[\"haver_const\"] = float(elems[-1])\n",
    "        print(f\"haver_const = {args['haver_const']}\")\n",
    "    else:\n",
    "        args[\"est_name\"] = est_name\n",
    "    \n",
    "    pool.starmap(run_trial, [(i, args) for i in range(num_trials)])\n",
    "\n",
    "    episode_start_sigmahats_ary = np.hstack([episode_start_sigmahats_list])\n",
    "    episode_rewards_ary = np.hstack([episode_rewards_list])\n",
    "    episode_vstar_est_ary = np.hstack([episode_vstar_est_list])\n",
    "\n",
    "    episode_start_sigmahats_dict[est_name] = np.mean(episode_start_sigmahats_ary, 0)\n",
    "    episode_rewards_dict[est_name] = np.mean(episode_rewards_ary, 0)\n",
    "    episode_vstar_est_dict[est_name] = np.mean(episode_vstar_est_ary, 0)\n",
    "    print(f\"last_episode_start_sigmahat = {episode_start_sigmahats_dict[est_name][-1]:.4f}\")\n",
    "    print(f\"last_episode_reward_per_step = {episode_rewards_dict[est_name][-1]:.4f}\")\n",
    "    print(f\"last_episode_estim_start_muhat = {episode_vstar_est_dict[est_name][-1]:.4f}\")\n",
    "    \n",
    "    episode_vstar_est_bias_dict[est_name] = np.mean(episode_vstar_est_ary - optimal_vstar, 0)\n",
    "    episode_vstar_est_var_dict[est_name] = np.var(episode_vstar_est_ary - optimal_vstar, 0, ddof=1)\n",
    "    episode_vstar_est_mse_dict[est_name] = \\\n",
    "        episode_vstar_est_bias_dict[est_name]**2 \\\n",
    "        + episode_vstar_est_var_dict[est_name]\n",
    "    \n",
    "    # Q_table_dict[est_name] = np.mean(np.stack(Q_table_list), 0)\n",
    "    # Q_nvisits_dict[est_name] = np.mean(np.stack(Q_nvisits_list), 0)\n",
    "    # print(np.stack(Q_table_list).shape)\n",
    "    Q_table_dict[est_name] = np.stack(Q_table_list)[0,:,:,:]\n",
    "    Q_nvisits_dict[est_name] = np.stack(Q_nvisits_list)[0,:,:,:]\n",
    "    # print(Q_table_list[0][0,0,:])\n",
    "    # print(Q_table_list[1][0,0,:])\n",
    "    # print(Q_table_ary)\n",
    "    # stop\n",
    "                           \n",
    "    episode_start_sigmahats_list[:] = []\n",
    "    episode_rewards_list[:] = []\n",
    "    episode_vstar_est_list[:] = []\n",
    "    Q_table_list[:] = []\n",
    "    Q_nvisits_list[:] = []\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"it takes {end_time-start_time:0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdfeb72d-1e21-4c0f-bfd6-66ab5dac4bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x1200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, axes = fig, axes = plt.subplots(\n",
    "        nrows=5, ncols=1, sharex=True, sharey=False, figsize=(8,12))\n",
    "# axes = [axes]\n",
    "\n",
    "x_ary = np.linspace(4000, num_steps_train-1, num=100, dtype=np.int32)\n",
    "# est_name_ary = [\"weightedms\"]\n",
    "est_name_ary_unwanted = []\n",
    "est_name_ary_wanted = [est_name for est_name in est_name_ary[:8] \\\n",
    "                 if est_name not in est_name_ary_unwanted]\n",
    "for est_name in est_name_ary_wanted:\n",
    "    # axes[0].plot(x_ary, episode_rewards_dict[est_name][x_ary], label=est_name)\n",
    "    y_ary = running_avg(episode_rewards_dict[est_name][x_ary], 100)\n",
    "    axes[0].plot(\n",
    "        x_ary, y_ary, label=est_name)\n",
    "    axes[1].plot(x_ary, episode_vstar_est_dict[est_name][x_ary], label=est_name)\n",
    "    axes[2].plot(x_ary, episode_vstar_est_mse_dict[est_name][x_ary], label=est_name)\n",
    "    axes[3].plot(x_ary, episode_vstar_est_bias_dict[est_name][x_ary], label=est_name)\n",
    "    axes[4].plot(x_ary, episode_vstar_est_var_dict[est_name][x_ary], label=est_name)\n",
    "\n",
    "axes[0].axhline(y=optimal_reward_per_step, color=\"black\")\n",
    "axes[1].axhline(y=optimal_vstar, color=\"black\")\n",
    "axes[0].set_title(f\"reward_per_step, K={num_actions}, num_depths={num_depths}, sigma={action_sigma},\"\n",
    "                    f\" delta={gap_deltas[0]}\")\n",
    "axes[1].set_title(\"vstar_est\")\n",
    "axes[2].set_title(\"vstar_est_mse\")\n",
    "axes[3].set_title(\"vstar_est_bias\")\n",
    "axes[4].set_title(\"vstar_est_var\")\n",
    "# axes[0].legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "axes[1].legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "# axes[2].legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "262b601f-0e05-4e14-bf6e-b8b8d348a72a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x1200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, axes = fig, axes = plt.subplots(\n",
    "        nrows=5, ncols=1, sharex=True, sharey=False, figsize=(8,12))\n",
    "# axes = [axes]\n",
    "\n",
    "x_ary = np.linspace(4000, num_steps_train-1, num=100, dtype=np.int32)\n",
    "# est_name_ary = [\"weightedms\"]\n",
    "est_name_ary_unwanted = [\"weightedms\", \"weightedms2\"]\n",
    "est_name_ary_wanted = [est_name for est_name in est_name_ary[:8] \\\n",
    "                 if est_name not in est_name_ary_unwanted]\n",
    "for est_name in est_name_ary_wanted:\n",
    "    # axes[0].plot(x_ary, episode_rewards_dict[est_name][x_ary], label=est_name)\n",
    "    y_ary = running_avg(episode_rewards_dict[est_name][x_ary], 100)\n",
    "    axes[0].plot(\n",
    "        x_ary, y_ary, label=est_name)\n",
    "    axes[1].plot(x_ary, episode_vstar_est_dict[est_name][x_ary], label=est_name)\n",
    "    axes[2].plot(x_ary, episode_vstar_est_mse_dict[est_name][x_ary], label=est_name)\n",
    "    axes[3].plot(x_ary, episode_vstar_est_bias_dict[est_name][x_ary], label=est_name)\n",
    "    axes[4].plot(x_ary, episode_vstar_est_var_dict[est_name][x_ary], label=est_name)\n",
    "\n",
    "axes[0].axhline(y=optimal_reward_per_step, color=\"black\")\n",
    "axes[1].axhline(y=optimal_vstar, color=\"black\")\n",
    "axes[0].set_title(f\"reward_per_step, K={num_actions}, num_depths={num_depths}, sigma={action_sigma},\"\n",
    "                    f\" delta={gap_deltas[0]}\")\n",
    "axes[1].set_title(\"vstar_est\")\n",
    "axes[2].set_title(\"vstar_est_mse\")\n",
    "axes[3].set_title(\"vstar_est_bias\")\n",
    "axes[4].set_title(\"vstar_est_var\")\n",
    "# axes[0].legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "axes[1].legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "# axes[2].legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27c3344b-55df-4701-b41a-01ef27b88cd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> est_name = haver3_1.0\n",
      "0 0: [ -6.38829  -6.35606  -6.35238  -6.35552  -6.36108  -6.38038  -6.35435\n",
      "  -6.35927  -9.74843 -10.21463  -8.60837  -9.90666  -9.16375  -8.99574\n",
      " -12.50688 -13.09839], \n",
      "     [ 66. 131. 138. 324.  43.  50.  93. 363.   7.   3.   5.   5.   4.   7.\n",
      "   7.   4.]\n",
      "0 1: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 2: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 3: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 4: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 5: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 6: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 7: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 8: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 9: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 10: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 11: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 12: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 13: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 14: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 15: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1 0: [-8.77897 -9.42604 -8.77648 -8.69448 -8.69086 -8.77048 -8.68014 -8.69192\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.     ], \n",
      "     [17.  1.  2. 11. 11.  5.  7. 12.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "1 1: [-8.3793  -8.49479 -8.74897 -8.46885 -8.49349 -8.38365 -8.39102 -8.6076\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.     ], \n",
      "     [ 6.  5.  5. 18.  8. 42. 33. 14.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "1 2: [ -8.32283  -8.33939  -8.33201  -8.33377 -10.49988  -8.30736  -8.32013\n",
      "  -8.23594   0.        0.        0.        0.        0.        0.\n",
      "   0.        0.     ], \n",
      "     [26.  4.  7. 16.  1. 40. 18. 26.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "1 3: [-8.36888 -8.36381 -8.40246 -8.34799 -9.67477 -8.359   -8.36634 -8.38352\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.     ], \n",
      "     [ 33. 109.   6.  36.   2.  59.  69.  10.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "1 4: [-8.95235 -8.83009 -9.04243 -8.70181 -8.77196 -8.79769 -9.05695 -8.99571\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.     ], \n",
      "     [ 6.  1.  4. 15.  5.  4.  2.  6.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "1 5: [-9.26954 -9.66131 -8.52989 -8.68497 -9.86605 -8.41431 -8.85344 -8.40209\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.     ], \n",
      "     [ 3.  3.  9.  5.  1. 24.  1.  4.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "1 6: [-8.58803 -8.5888  -8.65009 -8.57858 -8.75382 -9.05708 -8.73616 -8.72281\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.     ], \n",
      "     [26. 29.  5. 13.  7.  4.  5.  4.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "1 7: [-8.31331 -8.26073 -8.2638  -8.30781 -8.96848 -8.26651 -8.2602  -8.2616\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.     ], \n",
      "     [ 24.  25.  38.  20.   4.  51. 133.  68.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "1 8: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.      -19.47242  -8.27627  -5.42823 -21.56898  -6.4672   -9.65824\n",
      "   0.       -7.09606], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "1 9: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.      -10.27641   0.        0.        0.        0.\n",
      " -11.0263    0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 2. 0.]\n",
      "1 10: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.       -4.47466   0.      -18.81034   0.        0.        0.\n",
      " -10.57501  -6.41301], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 2. 1.]\n",
      "1 11: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.      -17.8479   -6.2968  -17.24403   0.       -9.58105   0.\n",
      " -19.1436    0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0.]\n",
      "1 12: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.      -11.42423   0.       -5.38627   0.       -8.4816\n",
      "   0.       -9.42385], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "1 13: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.      -18.52081   0.      -17.87363 -17.74234 -15.10129  -6.1678\n",
      " -17.49163   0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 2. 1. 0.]\n",
      "1 14: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.      -19.19007  -7.90355 -19.40608 -18.54032 -15.05876  -9.1848\n",
      " -18.89235   0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "1 15: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        0.        0.      -11.27855   0.\n",
      "   0.      -10.98302], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 1.]\n",
      "2 0: [-9.804   -9.4388  -9.82556 -9.60237 -9.40425 -9.37545 -9.30882 -9.23255\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.     ], \n",
      "     [  1.   3.   7.   5.   4.   3.   7. 111.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "2 1: [ -9.62152  -9.45344  -9.98217  -9.70113  -9.59515 -10.06153  -9.60259\n",
      "  -9.70939   0.        0.        0.        0.        0.        0.\n",
      "   0.        0.     ], \n",
      "     [ 6. 46.  3.  8. 75.  5. 32.  2.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "2 2: [-9.49828 -9.22655 -8.99089 -9.25495 -9.37736 -9.24896 -9.37343 -9.30918\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.     ], \n",
      "     [ 5. 15. 22.  4.  6.  4.  3. 17.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "2 3: [ -9.52133  -9.66921  -9.46673 -10.38647  -9.45144  -9.4263   -9.81118\n",
      "  -9.45855   0.        0.        0.        0.        0.        0.\n",
      "   0.        0.     ], \n",
      "     [19.  5. 10.  3.  4. 76.  4. 13.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "2 4: [ -9.35655  -9.17794  -9.46761 -10.27624  -9.75827 -11.00947  -9.60892\n",
      "  -9.65381   0.        0.        0.        0.        0.        0.\n",
      "   0.        0.     ], \n",
      "     [3. 9. 7. 3. 3. 2. 9. 3. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "2 5: [-9.80587 -9.5292  -9.39036 -9.46907 -9.46511 -9.75783 -9.40864 -9.98772\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.     ], \n",
      "     [  6.   9.  78.  12.   4.   5. 114.   1.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "2 6: [ -9.66303 -10.05532  -9.52375  -9.42492  -9.6736   -9.34475  -9.43414\n",
      " -10.44554   0.        0.        0.        0.        0.        0.\n",
      "   0.        0.     ], \n",
      "     [  3.   3.   2.  36.   6. 204.   8.   6.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "2 7: [ -9.48425  -9.38943  -9.57475 -10.77173  -9.96531 -10.77208  -9.38918\n",
      "  -9.29434   0.        0.        0.        0.        0.        0.\n",
      "   0.        0.     ], \n",
      "     [19. 58.  4.  4.  3.  3.  7. 46.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "2 8: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.      -15.87478 -14.39187   0.        0.      -14.85469 -15.16408\n",
      " -13.23088   0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0.]\n",
      "2 9: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.      -14.80827   0.       -9.80162   0.       -9.77198\n",
      "   0.        0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 2. 0. 2. 0. 0.]\n",
      "2 10: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.      -13.99412 -16.06985 -14.38619 -14.85974\n",
      "   0.      -14.7155 ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1.]\n",
      "2 11: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.      -13.95258 -15.34878   0.        0.      -13.38339 -15.46646\n",
      "   0.        0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0.]\n",
      "2 12: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.      -11.2561   -4.90373 -14.20046 -14.76254 -14.41817\n",
      " -15.15157   0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 1. 1. 1. 1. 1. 0.]\n",
      "2 13: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.      -13.67966 -14.65491   0.       -9.8972    0.\n",
      "   0.      -14.43795], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 2. 0. 0. 1.]\n",
      "2 14: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.      -13.01856 -15.40481 -14.1852    0.      -15.32296 -14.20501\n",
      " -14.39807  -5.28098], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "2 15: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.       -3.69595   0.      -13.3018  -15.33491   0.        0.\n",
      "  -4.06403   0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0.]\n",
      "3 0: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [62.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "3 1: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [148.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "3 2: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [133.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "3 3: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [75.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "3 4: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [105.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "3 5: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [302.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "3 6: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [184.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "3 7: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [199.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "3 8: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 9: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [7. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 10: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [5. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 11: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [5. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 12: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [7. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 13: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [7. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 14: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 15: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "-> est_name = weightedms\n",
      "0 0: [ -6.28778  -6.27479  -6.27647  -7.44642  -6.27577  -6.29855  -6.28731\n",
      "  -6.27942  -9.90231  -8.21138  -9.87504 -10.69564 -10.3764   -9.30776\n",
      " -12.15853  -8.5871 ], \n",
      "     [ 79. 756.  60.   6.  87. 100.  66.  56.   4.   2.   9.   3.   4.   8.\n",
      "   5.   5.]\n",
      "0 1: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 2: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 3: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 4: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 5: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 6: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 7: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 8: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 9: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 10: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 11: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 12: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 13: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 14: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 15: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1 0: [-9.29376 -8.51685 -8.40335 -8.45957 -8.49398 -8.64267 -8.60481 -8.5408\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.     ], \n",
      "     [ 5. 26. 10. 22.  4.  2.  6.  4.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "1 1: [-8.37271 -8.21753 -8.22593 -8.22054 -8.22776 -8.21999 -9.1168  -8.30366\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.     ], \n",
      "     [ 17. 104. 124. 173.  22. 281.   9.  26.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "1 2: [ -9.17006  -8.55905  -8.85572  -8.14673  -8.95616  -9.29822  -8.26716\n",
      " -10.33285   0.        0.        0.        0.        0.        0.\n",
      "   0.        0.     ], \n",
      "     [ 2.  3.  2. 31.  2.  1. 18.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "1 3: [-10.5023    0.       -8.97864   0.       -8.64771  -7.22593  -8.26017\n",
      "   0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.     ], \n",
      "     [1. 0. 2. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1 4: [-8.81626 -8.51477 -8.42427 -8.17319 -8.22325 -8.43321 -8.42211 -8.34993\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.     ], \n",
      "     [ 5.  3.  1. 41. 20. 13.  3.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "1 5: [-8.52855 -8.62977 -8.75841 -8.54487 -8.69169 -8.56245 -8.6838  -8.72866\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.     ], \n",
      "     [ 9.  9.  4. 27.  4. 39.  4.  4.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "1 6: [-8.51529 -8.45833 -8.56745 -8.5646  -9.93519 -8.43052 -9.14169 -8.43023\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.     ], \n",
      "     [ 7.  2. 17.  7.  1. 22.  3.  7.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "1 7: [-8.8034  -8.53668 -8.58453 -8.31784 -9.40448 -8.25778 -9.43905 -9.02963\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.     ], \n",
      "     [ 4.  4.  2.  6.  2. 35.  2.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "1 8: [ 0.       0.       0.       0.       0.       0.       0.       0.\n",
      " -6.19145  0.       0.       0.      -6.4672  -8.89195  0.       0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 2. 0. 0.]\n",
      "1 9: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.      -12.03099   0.        0.        0.        0.\n",
      "  -5.13391   0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      "1 10: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.      -10.09816 -19.39014 -10.98402  -7.1614   -7.9715   -9.73434\n",
      " -19.34731  -6.41301], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 2. 1. 1. 1. 1. 1.]\n",
      "1 11: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.       -9.87901 -12.41332   0.      -10.19815   0.        0.\n",
      "   0.        0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0.]\n",
      "1 12: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.       -8.27842  -4.45965 -18.51278   0.        0.        0.\n",
      " -17.3658    0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0.]\n",
      "1 13: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.      -16.36636 -10.85976  -9.9104   -7.4732\n",
      "   0.       -8.42317], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 2. 3. 0. 1.]\n",
      "1 14: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.      -14.22171   0.       -8.64702   0.        0.\n",
      " -19.93822   0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 1. 0.]\n",
      "1 15: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.       -7.76993  -9.93226   0.       -4.82904   0.       -8.97736\n",
      " -18.88389   0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0.]\n",
      "2 0: [-10.42142  -9.46733 -10.58863  -9.47514 -10.01309  -9.35223  -9.35448\n",
      "  -9.37719   0.        0.        0.        0.        0.        0.\n",
      "   0.        0.     ], \n",
      "     [ 2. 12.  2.  4.  2.  6. 19.  3.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "2 1: [-9.52106 -9.8587  -9.65634 -9.89739 -9.51999 -9.89486 -9.5241  -9.54162\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.     ], \n",
      "     [25.  6.  3.  3. 79.  4. 28.  3.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "2 2: [ -9.8486   -9.45527 -10.01691  -9.5277  -10.43732  -9.37875  -9.58096\n",
      " -10.1198    0.        0.        0.        0.        0.        0.\n",
      "   0.        0.     ], \n",
      "     [ 3. 61.  5.  4.  5. 72. 11.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "2 3: [-9.36441 -9.53704 -9.89663 -9.37618 -9.8359  -9.34952 -9.83572 -9.35164\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.     ], \n",
      "     [ 41.   8.   3.  40.   2. 159.   6.  48.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "2 4: [ -9.74335  -9.54265  -9.69061  -9.46024  -9.10303  -9.78579  -9.62479\n",
      " -10.22176   0.        0.        0.        0.        0.        0.\n",
      "   0.        0.     ], \n",
      "     [ 6.  1.  4.  2. 35.  4.  2.  2.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "2 5: [-9.64473 -9.78858 -9.47003 -9.64641 -9.47581 -9.46442 -9.46266 -9.46364\n",
      "  0.       0.       0.       0.       0.       0.       0.       0.     ], \n",
      "     [  3.   3. 184.   8.  17.   7.  97.  75.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "2 6: [ -9.72489  -9.69425  -9.92935 -10.17649  -9.72789  -9.68167  -9.72011\n",
      "  -9.48784   0.        0.        0.        0.        0.        0.\n",
      "   0.        0.     ], \n",
      "     [ 1.  3.  3.  2.  4.  4.  3. 26.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "2 7: [ -9.83369 -10.17477 -10.11714  -9.59803  -9.21524  -9.32772  -9.24284\n",
      " -11.36381   0.        0.        0.        0.        0.        0.\n",
      "   0.        0.     ], \n",
      "     [ 1.  3.  3.  5. 22.  4.  5.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "2 8: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.      -15.82914 -15.00335 -14.08134   0.      -13.61121   0.\n",
      "   0.       -3.90119], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1.]\n",
      "2 9: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.      -15.17536   0.        0.       -8.60519 -14.4814    0.\n",
      "   0.        0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 2. 3. 0. 0. 0.]\n",
      "2 10: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.      -14.68624   0.        0.      -13.29803 -14.85375 -12.59869\n",
      "   0.        0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0.]\n",
      "2 11: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.      -14.9508   -4.21201 -13.14974   0.        0.       -7.01366\n",
      "   0.        0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 4. 1. 1. 0. 0. 1. 0. 0.]\n",
      "2 12: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.       -4.90373   0.      -15.96645 -13.77371\n",
      "   0.        0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 2. 1. 0. 0.]\n",
      "2 13: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.       -3.63823 -15.95721 -16.11304   0.       -4.94096 -15.57404\n",
      " -15.49617   0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 2. 0.]\n",
      "2 14: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.      -15.41667 -14.13504 -14.42296   0.        0.\n",
      " -14.62285   0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 2. 1. 0. 0. 1. 0.]\n",
      "2 15: [  0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        0.      -14.54341   0.        0.\n",
      "  -4.06403   0.     ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "3 0: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [82.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "3 1: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [97.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "3 2: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [207.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "3 3: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [68.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "3 4: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [166.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "3 5: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [260.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "3 6: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [171.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "3 7: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [159.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "3 8: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [8. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 9: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 10: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 11: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [5. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 12: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [8. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 13: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 14: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 15: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for est_name in est_name_ary:\n",
    "    print(f\"\\n-> est_name = {est_name}\")\n",
    "    Q_table = Q_table_dict[est_name]\n",
    "    Q_nvisits = Q_nvisits_dict[est_name]\n",
    "    for i_row in range(num_depths):\n",
    "        for j_col in range(num_actions):\n",
    "            print(f\"{i_row} {j_col}: {Q_table[i_row,j_col]}, \\n     {Q_nvisits[i_row,j_col]}\")\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
