{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "383e247e-5b67-4df9-a315-54c8a84b0d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configs:\n",
    "    # Env\n",
    "    env_id=\"NNWorld01-v01\", \n",
    "     - once in the goal state, each action ends the episode and returns a reward of 5\n",
    "     - no clear episodes, continuously train the agent with num_train_steps, \n",
    "       if the agent reaches terminal, just reset environment and keep training \n",
    "     - try to immitate the bandit experiments\n",
    "    # Params\n",
    "    eps_sched_fn=poly(0.5), lr_sched_fn=poly(0.8)\n",
    "    # Algos\n",
    "    haver2, action_sigma=adaptive(1), haver_delta=0.01, haver_const=varied\n",
    "Status:\n",
    "\"\"\"\n",
    "\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_palette(\"tab20\")\n",
    "colors = sns.color_palette(\"bright\")\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm \n",
    "import multiprocessing\n",
    "\n",
    "# import gymnasium as gym\n",
    "import gym\n",
    "import gym_examples\n",
    "from gym.wrappers import FlattenObservation\n",
    "\n",
    "from algos import *\n",
    "from bandit_problem import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "470972cc-8018-41a5-a4f2-dd2b76cec119",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_mus = [ 0.  0.  0.  0.  0.  0.  0.  0. -5. -5. -5. -5. -5. -5. -5. -5.]\n",
      "action_sigmas = [10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      "optimal_num_steps = 4\n",
      "optimal_reward_per_step = -2.5\n",
      "optimal_vstar = -8.573749999999999\n",
      "\n",
      "-> est_name = haver3_1.0\n",
      "haver_const = 1.0\n",
      "\n",
      "-> i_step = 4000\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = 10.62\n",
      "new_state = [1 4]\n",
      "[ 37. 342.   6. 147. 268.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 268.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.53  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.28 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 268.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.77\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.05 0.1  0.11 0.17 0.09 0.13 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.68\n",
      "\n",
      "-> i_step = 4001\n",
      "cur_state = [1 4]\n",
      "action = 0\n",
      "reward = -12.26\n",
      "new_state = [2 0]\n",
      "[ 37. 342.   6. 147. 268.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 268.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.53  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.28 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 268.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.77\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.11 0.09 0.04 0.08 0.1  0.17 0.12 0.13 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.68\n",
      "\n",
      "-> i_step = 4002\n",
      "cur_state = [2 0]\n",
      "action = 0\n",
      "reward = -0.97\n",
      "new_state = [3 0]\n",
      "[ 37. 342.   6. 147. 268.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 268.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.53  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.28 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 268.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.77\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.04 0.09 0.11 0.16 0.09 0.14 0.   0.   0.01 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.74\n",
      "\n",
      "-> i_step = 4003\n",
      "cur_state = [3 0]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 342.   6. 147. 268.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 268.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.53  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.28 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 268.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.77\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.11 0.09 0.04 0.09 0.13 0.17 0.1  0.14 0.   0.   0.01 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.55\n",
      "\n",
      "-> i_step = 4004\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = 10.41\n",
      "new_state = [1 4]\n",
      "[ 37. 342.   6. 147. 269.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 269.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.5   -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.27 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 269.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.77\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.1  0.1  0.05 0.09 0.1  0.19 0.1  0.13 0.   0.   0.01 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.60\n",
      "\n",
      "-> i_step = 4005\n",
      "cur_state = [1 4]\n",
      "action = 0\n",
      "reward = 1.73\n",
      "new_state = [2 0]\n",
      "[ 37. 342.   6. 147. 269.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 269.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.5   -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.27 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 269.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.77\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.11 0.04 0.09 0.11 0.15 0.08 0.13 0.   0.   0.03 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.76\n",
      "\n",
      "-> i_step = 4006\n",
      "cur_state = [2 0]\n",
      "action = 1\n",
      "reward = 8.75\n",
      "new_state = [3 1]\n",
      "[ 37. 342.   6. 147. 269.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 269.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.5   -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.27 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 269.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.77\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.05 0.07 0.11 0.15 0.09 0.17 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.80\n",
      "\n",
      "-> i_step = 4007\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 342.   6. 147. 269.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 269.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.5   -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.27 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 269.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.77\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.09 0.1  0.06 0.07 0.12 0.17 0.1  0.13 0.   0.   0.01 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.64\n",
      "\n",
      "-> i_step = 4008\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = -3.06\n",
      "new_state = [1 4]\n",
      "[ 37. 342.   6. 147. 270.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 270.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.53  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.25 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 270.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.78\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.08 0.11 0.05 0.09 0.1  0.15 0.1  0.14 0.   0.01 0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.82\n",
      "\n",
      "-> i_step = 4009\n",
      "cur_state = [1 4]\n",
      "action = 0\n",
      "reward = -7.57\n",
      "new_state = [2 0]\n",
      "[ 37. 342.   6. 147. 270.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 270.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.53  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.25 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 270.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.78\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.08 0.09 0.05 0.09 0.11 0.17 0.11 0.14 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.72\n",
      "\n",
      "-> i_step = 4010\n",
      "cur_state = [2 0]\n",
      "action = 1\n",
      "reward = -1.92\n",
      "new_state = [3 1]\n",
      "[ 37. 342.   6. 147. 270.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 270.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.53  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.25 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 270.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.78\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.09 0.11 0.05 0.07 0.12 0.16 0.11 0.14 0.   0.   0.02 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.75\n",
      "\n",
      "-> i_step = 4011\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 342.   6. 147. 270.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 270.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.53  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.25 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 270.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.78\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.09 0.1  0.06 0.07 0.12 0.18 0.08 0.14 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.77\n",
      "\n",
      "-> i_step = 4012\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = 17.83\n",
      "new_state = [1 4]\n",
      "[ 37. 342.   6. 147. 271.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 271.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.48  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.26 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 271.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.76\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.08 0.06 0.1  0.12 0.17 0.11 0.11 0.   0.   0.01 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.63\n",
      "\n",
      "-> i_step = 4013\n",
      "cur_state = [1 4]\n",
      "action = 6\n",
      "reward = 5.30\n",
      "new_state = [2 6]\n",
      "[ 37. 342.   6. 147. 271.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 271.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.48  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.26 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 271.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.76\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.09 0.09 0.04 0.08 0.12 0.19 0.1  0.12 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.75\n",
      "\n",
      "-> i_step = 4014\n",
      "cur_state = [2 6]\n",
      "action = 6\n",
      "reward = 8.52\n",
      "new_state = [3 6]\n",
      "[ 37. 342.   6. 147. 271.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 271.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.48  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.26 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 271.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.76\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.11 0.05 0.09 0.1  0.17 0.11 0.12 0.   0.   0.02 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.69\n",
      "\n",
      "-> i_step = 4015\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 342.   6. 147. 271.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 271.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.48  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.26 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 271.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.76\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.05 0.06 0.12 0.16 0.1  0.14 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.70\n",
      "\n",
      "-> i_step = 4016\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = 0.46\n",
      "new_state = [1 4]\n",
      "[ 37. 342.   6. 147. 272.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 272.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.49  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.24 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 272.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.76\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.07 0.06 0.09 0.1  0.17 0.09 0.15 0.   0.   0.02 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.73\n",
      "\n",
      "-> i_step = 4017\n",
      "cur_state = [1 4]\n",
      "action = 6\n",
      "reward = -19.58\n",
      "new_state = [2 6]\n",
      "[ 37. 342.   6. 147. 272.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 272.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.49  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.24 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 272.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.76\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.11 0.05 0.1  0.1  0.18 0.09 0.13 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.70\n",
      "\n",
      "-> i_step = 4018\n",
      "cur_state = [2 6]\n",
      "action = 6\n",
      "reward = -16.46\n",
      "new_state = [3 6]\n",
      "[ 37. 342.   6. 147. 272.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 272.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.49  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.24 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 272.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.76\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.09 0.1  0.06 0.1  0.09 0.16 0.1  0.13 0.   0.   0.02 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.74\n",
      "\n",
      "-> i_step = 4019\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 342.   6. 147. 272.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 272.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.49  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.24 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 272.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.76\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.06 0.09 0.12 0.18 0.09 0.13 0.   0.   0.01 0.06 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -4.66\n",
      "\n",
      "-> i_step = 4020\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = -0.04\n",
      "new_state = [1 4]\n",
      "[ 37. 342.   6. 147. 273.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 273.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.51  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.23 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 273.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.77\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "probs = [0.1  0.1  0.05 0.09 0.1  0.18 0.1  0.12 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.81\n",
      "\n",
      "-> i_step = 4021\n",
      "cur_state = [1 4]\n",
      "action = 0\n",
      "reward = 0.69\n",
      "new_state = [2 0]\n",
      "[ 37. 342.   6. 147. 273.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 273.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.51  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.23 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 273.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.77\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.09 0.1  0.04 0.08 0.12 0.15 0.12 0.14 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.68\n",
      "\n",
      "-> i_step = 4022\n",
      "cur_state = [2 0]\n",
      "action = 1\n",
      "reward = -20.52\n",
      "new_state = [3 1]\n",
      "[ 37. 342.   6. 147. 273.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 273.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.51  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.23 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 273.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.77\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.09 0.08 0.05 0.09 0.11 0.17 0.1  0.15 0.   0.   0.02 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.73\n",
      "\n",
      "-> i_step = 4023\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 342.   6. 147. 273.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 273.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.51  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.23 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 273.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.77\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.13 0.1  0.05 0.07 0.1  0.17 0.11 0.14 0.   0.   0.02 0.04 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -4.61\n",
      "\n",
      "-> i_step = 4024\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = -0.93\n",
      "new_state = [1 4]\n",
      "[ 37. 342.   6. 147. 274.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 274.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.53  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.21 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 274.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.77\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.09 0.09 0.06 0.1  0.11 0.17 0.1  0.14 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.68\n",
      "\n",
      "-> i_step = 4025\n",
      "cur_state = [1 4]\n",
      "action = 0\n",
      "reward = 2.65\n",
      "new_state = [2 0]\n",
      "[ 37. 342.   6. 147. 274.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 274.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.53  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.21 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 274.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.77\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.09 0.09 0.06 0.1  0.09 0.19 0.1  0.12 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.80\n",
      "\n",
      "-> i_step = 4026\n",
      "cur_state = [2 0]\n",
      "action = 0\n",
      "reward = 3.95\n",
      "new_state = [3 0]\n",
      "[ 37. 342.   6. 147. 274.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 274.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.53  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.21 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 274.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.77\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.09 0.1  0.04 0.11 0.09 0.18 0.11 0.14 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.67\n",
      "\n",
      "-> i_step = 4027\n",
      "cur_state = [3 0]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 342.   6. 147. 274.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 274.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.53  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.21 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 274.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.77\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.06 0.1  0.1  0.14 0.1  0.12 0.   0.   0.02 0.06 0.   0.1\n",
      " 0.01 0.  ]\n",
      "Q_est = -4.95\n",
      "\n",
      "-> i_step = 4028\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = -1.77\n",
      "new_state = [1 4]\n",
      "[ 37. 342.   6. 147. 275.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 275.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.55  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.2  14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.28 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 275.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.78\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.09 0.12 0.04 0.1  0.11 0.16 0.1  0.11 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.73\n",
      "\n",
      "-> i_step = 4029\n",
      "cur_state = [1 4]\n",
      "action = 0\n",
      "reward = 3.24\n",
      "new_state = [2 0]\n",
      "[ 37. 342.   6. 147. 275.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 275.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.55  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.2  14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.28 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 275.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.78\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.05 0.09 0.09 0.15 0.11 0.14 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.65\n",
      "\n",
      "-> i_step = 4030\n",
      "cur_state = [2 0]\n",
      "action = 0\n",
      "reward = -3.28\n",
      "new_state = [3 0]\n",
      "[ 37. 342.   6. 147. 275.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 275.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.55  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.2  14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.28 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 275.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.78\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.05 0.1  0.11 0.15 0.09 0.14 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.73\n",
      "\n",
      "-> i_step = 4031\n",
      "cur_state = [3 0]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 342.   6. 147. 275.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 275.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.55  -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.2  14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.28 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 275.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.78\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.05 0.09 0.09 0.17 0.11 0.14 0.   0.   0.02 0.05 0.   0.06\n",
      " 0.   0.  ]\n",
      "Q_est = -4.63\n",
      "\n",
      "-> i_step = 4032\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = -9.18\n",
      "new_state = [1 4]\n",
      "[ 37. 342.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.6   -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.21 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.28 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 276.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.79\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.09 0.11 0.06 0.09 0.11 0.16 0.09 0.13 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.76\n",
      "\n",
      "-> i_step = 4033\n",
      "cur_state = [1 4]\n",
      "action = 0\n",
      "reward = 2.74\n",
      "new_state = [2 0]\n",
      "[ 37. 342.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.6   -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.21 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.28 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 276.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.79\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.05 0.1  0.1  0.18 0.1  0.12 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.76\n",
      "\n",
      "-> i_step = 4034\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = 21.21\n",
      "new_state = [3 7]\n",
      "[ 37. 342.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.6   -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.21 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.28 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 276.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.79\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.05 0.08 0.1  0.16 0.11 0.14 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.65\n",
      "\n",
      "-> i_step = 4035\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 342.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 342.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.6   -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.21 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.28 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 342.   6. 147. 276.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.79\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.12 0.12 0.05 0.1  0.11 0.16 0.09 0.11 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.66\n",
      "\n",
      "-> i_step = 4036\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 4.53\n",
      "new_state = [1 1]\n",
      "[ 37. 343.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 343.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.6   -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.6   8.95 10.17 11.21 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.28 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 343.   6. 147. 276.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.79\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.05 0.09 0.1  0.16 0.09 0.16 0.   0.   0.02 0.06 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -4.68\n",
      "\n",
      "-> i_step = 4037\n",
      "cur_state = [1 1]\n",
      "action = 1\n",
      "reward = -9.45\n",
      "new_state = [2 1]\n",
      "[ 37. 343.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 343.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.6   -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.6   8.95 10.17 11.21 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.28 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 343.   6. 147. 276.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.79\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.11 0.11 0.05 0.08 0.1  0.17 0.11 0.14 0.   0.   0.02 0.03 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.55\n",
      "\n",
      "-> i_step = 4038\n",
      "cur_state = [2 1]\n",
      "action = 6\n",
      "reward = 10.44\n",
      "new_state = [3 6]\n",
      "[ 37. 343.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 343.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.6   -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.6   8.95 10.17 11.21 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.28 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 343.   6. 147. 276.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.79\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.12 0.06 0.09 0.1  0.17 0.1  0.11 0.   0.01 0.01 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.58\n",
      "\n",
      "-> i_step = 4039\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 343.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 343.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.55  -5.19  -3.59  -3.6   -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.6   8.95 10.17 11.21 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.55\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.28 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 343.   6. 147. 276.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.79\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.11 0.04 0.09 0.09 0.16 0.13 0.11 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.66\n",
      "\n",
      "-> i_step = 4040\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -2.42\n",
      "new_state = [1 1]\n",
      "[ 37. 344.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 344.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.57  -5.19  -3.59  -3.6   -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.21 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.57\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.28 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 344.   6. 147. 276.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.80\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.06 0.08 0.1  0.19 0.1  0.13 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.77\n",
      "\n",
      "-> i_step = 4041\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 0.34\n",
      "new_state = [2 5]\n",
      "[ 37. 344.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 344.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.57  -5.19  -3.59  -3.6   -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.21 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.57\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.28 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 344.   6. 147. 276.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.80\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.05 0.1  0.1  0.15 0.1  0.13 0.   0.   0.02 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.73\n",
      "\n",
      "-> i_step = 4042\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -3.04\n",
      "new_state = [3 5]\n",
      "[ 37. 344.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 344.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.57  -5.19  -3.59  -3.6   -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.21 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.57\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.28 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 344.   6. 147. 276.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.80\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.1  0.1  0.06 0.1  0.1  0.17 0.1  0.12 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.69\n",
      "\n",
      "-> i_step = 4043\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 344.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 344.   6. 147. 276.  48.  26.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.57  -5.19  -3.59  -3.6   -3.66  -3.56  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.21 14.83 10.77 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.57\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.28 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 344.   6. 147. 276.  48.  26.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.80\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.05 0.1  0.12 0.15 0.1  0.13 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.67\n",
      "\n",
      "-> i_step = 4044\n",
      "cur_state = [0 0]\n",
      "action = 6\n",
      "reward = 3.25\n",
      "new_state = [1 6]\n",
      "[ 37. 344.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 344.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.57  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.57\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.28 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 344.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.80\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.09 0.12 0.15 0.09 0.15 0.   0.01 0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.63\n",
      "\n",
      "-> i_step = 4045\n",
      "cur_state = [1 6]\n",
      "action = 1\n",
      "reward = 9.47\n",
      "new_state = [2 1]\n",
      "[ 37. 344.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 344.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.57  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.57\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.28 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 344.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.80\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.12 0.04 0.08 0.1  0.16 0.09 0.14 0.   0.   0.01 0.05 0.   0.1\n",
      " 0.01 0.  ]\n",
      "Q_est = -4.75\n",
      "\n",
      "-> i_step = 4046\n",
      "cur_state = [2 1]\n",
      "action = 6\n",
      "reward = 24.13\n",
      "new_state = [3 6]\n",
      "[ 37. 344.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 344.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.57  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.57\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.28 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 344.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.80\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.11 0.11 0.06 0.1  0.11 0.16 0.08 0.12 0.   0.   0.02 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.74\n",
      "\n",
      "-> i_step = 4047\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 344.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 344.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.57  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.57\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.28 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 344.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.80\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.05 0.09 0.13 0.17 0.1  0.12 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.73\n",
      "\n",
      "-> i_step = 4048\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 20.48\n",
      "new_state = [1 1]\n",
      "[ 37. 345.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 345.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.52  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.52\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 345.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.78\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.11 0.09 0.05 0.09 0.12 0.17 0.09 0.14 0.   0.   0.01 0.03 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.59\n",
      "\n",
      "-> i_step = 4049\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 9.27\n",
      "new_state = [2 5]\n",
      "[ 37. 345.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 345.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.52  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.52\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 345.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.78\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.09 0.11 0.04 0.1  0.12 0.18 0.09 0.13 0.   0.   0.03 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.73\n",
      "\n",
      "-> i_step = 4050\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 14.92\n",
      "new_state = [3 5]\n",
      "[ 37. 345.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 345.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.52  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.52\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 345.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.78\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "probs = [0.11 0.09 0.05 0.07 0.12 0.15 0.1  0.13 0.   0.   0.02 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.84\n",
      "\n",
      "-> i_step = 4051\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 345.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 345.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.52  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.52\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 345.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.78\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.09 0.1  0.05 0.1  0.11 0.18 0.09 0.13 0.   0.   0.02 0.04 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -4.66\n",
      "\n",
      "-> i_step = 4052\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -11.94\n",
      "new_state = [1 1]\n",
      "[ 37. 346.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 346.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.56  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.63  8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.56\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 346.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.80\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.03 0.09 0.11 0.17 0.09 0.14 0.   0.01 0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.69\n",
      "\n",
      "-> i_step = 4053\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 1.92\n",
      "new_state = [2 5]\n",
      "[ 37. 346.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 346.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.56  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.63  8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.56\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 346.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.80\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.07 0.06 0.09 0.11 0.18 0.1  0.14 0.   0.   0.02 0.04 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -4.59\n",
      "\n",
      "-> i_step = 4054\n",
      "cur_state = [2 5]\n",
      "action = 7\n",
      "reward = 3.73\n",
      "new_state = [3 7]\n",
      "[ 37. 346.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 346.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.56  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.63  8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.56\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 346.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.80\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.05 0.09 0.12 0.16 0.09 0.13 0.   0.   0.01 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.69\n",
      "\n",
      "-> i_step = 4055\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 346.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 346.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.56  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.63  8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.56\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 346.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.80\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.05 0.1  0.09 0.18 0.1  0.13 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.72\n",
      "\n",
      "-> i_step = 4056\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 5.92\n",
      "new_state = [1 1]\n",
      "[ 37. 347.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 347.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.56  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.56\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 347.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.79\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.06 0.1  0.11 0.16 0.1  0.12 0.   0.   0.02 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.72\n",
      "\n",
      "-> i_step = 4057\n",
      "cur_state = [1 1]\n",
      "action = 0\n",
      "reward = -4.67\n",
      "new_state = [2 0]\n",
      "[ 37. 347.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 347.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.56  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.56\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 347.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.79\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.1  0.1  0.06 0.09 0.13 0.17 0.09 0.13 0.   0.   0.01 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.62\n",
      "\n",
      "-> i_step = 4058\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = -6.32\n",
      "new_state = [3 7]\n",
      "[ 37. 347.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 347.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.56  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.56\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 347.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.79\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.11 0.04 0.09 0.1  0.17 0.11 0.13 0.   0.   0.02 0.04 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -4.57\n",
      "\n",
      "-> i_step = 4059\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 347.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 347.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.56  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.61  8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.56\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.34 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 347.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.79\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.04 0.1  0.09 0.16 0.09 0.14 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.76\n",
      "\n",
      "-> i_step = 4060\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 1.56\n",
      "new_state = [1 1]\n",
      "[ 37. 348.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 348.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.56  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.6   8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.56\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 348.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.79\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.05 0.08 0.12 0.19 0.09 0.13 0.   0.   0.01 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.67\n",
      "\n",
      "-> i_step = 4061\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -4.76\n",
      "new_state = [2 5]\n",
      "[ 37. 348.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 348.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.56  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.6   8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.56\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 348.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.79\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.11 0.05 0.08 0.09 0.18 0.1  0.14 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.70\n",
      "\n",
      "-> i_step = 4062\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -0.38\n",
      "new_state = [3 5]\n",
      "[ 37. 348.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 348.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.56  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.6   8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.56\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 348.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.79\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.04 0.1  0.08 0.15 0.1  0.13 0.   0.   0.03 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.90\n",
      "\n",
      "-> i_step = 4063\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 348.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 348.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.56  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.6   8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.56\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 348.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.79\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.05 0.08 0.1  0.16 0.11 0.13 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.67\n",
      "\n",
      "-> i_step = 4064\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -5.14\n",
      "new_state = [1 1]\n",
      "[ 37. 349.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 349.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.59  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.59\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 349.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.80\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.1  0.1  0.15 0.09 0.14 0.   0.   0.01 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.66\n",
      "\n",
      "-> i_step = 4065\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 4.28\n",
      "new_state = [2 5]\n",
      "[ 37. 349.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 349.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.59  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.59\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 349.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.80\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.11 0.05 0.08 0.1  0.2  0.09 0.12 0.   0.   0.01 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.74\n",
      "\n",
      "-> i_step = 4066\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 7.59\n",
      "new_state = [3 5]\n",
      "[ 37. 349.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 349.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.59  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.59\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 349.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.80\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.1  0.11 0.04 0.09 0.1  0.17 0.1  0.14 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.61\n",
      "\n",
      "-> i_step = 4067\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 349.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 349.   6. 147. 276.  48.  27.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.59  -5.19  -3.59  -3.6   -3.66  -3.58  -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.21 14.83 10.56 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.59\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 349.   6. 147. 276.  48.  27.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.80\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.11 0.04 0.09 0.1  0.17 0.09 0.14 0.   0.   0.02 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.78\n",
      "\n",
      "-> i_step = 4068\n",
      "cur_state = [0 0]\n",
      "action = 6\n",
      "reward = -2.57\n",
      "new_state = [1 6]\n",
      "[ 37. 349.   6. 147. 276.  48.  28.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 349.   6. 147. 276.  48.  28.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.59  -5.19  -3.59  -3.6   -3.66  -3.8   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.21 14.83 10.44 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.59\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 349.   6. 147. 276.  48.  28.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.81\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.05 0.08 0.13 0.19 0.1  0.11 0.   0.   0.01 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.62\n",
      "\n",
      "-> i_step = 4069\n",
      "cur_state = [1 6]\n",
      "action = 1\n",
      "reward = -22.24\n",
      "new_state = [2 1]\n",
      "[ 37. 349.   6. 147. 276.  48.  28.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 349.   6. 147. 276.  48.  28.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.59  -5.19  -3.59  -3.6   -3.66  -3.8   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.21 14.83 10.44 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.59\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 349.   6. 147. 276.  48.  28.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.81\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "probs = [0.11 0.1  0.05 0.08 0.11 0.17 0.09 0.13 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.74\n",
      "\n",
      "-> i_step = 4070\n",
      "cur_state = [2 1]\n",
      "action = 6\n",
      "reward = 0.06\n",
      "new_state = [3 6]\n",
      "[ 37. 349.   6. 147. 276.  48.  28.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 349.   6. 147. 276.  48.  28.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.59  -5.19  -3.59  -3.6   -3.66  -3.8   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.21 14.83 10.44 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.59\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 349.   6. 147. 276.  48.  28.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.81\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.05 0.09 0.11 0.17 0.09 0.13 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.71\n",
      "\n",
      "-> i_step = 4071\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 349.   6. 147. 276.  48.  28.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 349.   6. 147. 276.  48.  28.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.59  -5.19  -3.59  -3.6   -3.66  -3.8   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.21 14.83 10.44 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.59\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 349.   6. 147. 276.  48.  28.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.81\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.06 0.08 0.12 0.15 0.07 0.14 0.   0.   0.01 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.73\n",
      "\n",
      "-> i_step = 4072\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 5.76\n",
      "new_state = [1 3]\n",
      "[ 37. 349.   6. 148. 276.  48.  28.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 349.   6. 148. 276.  48.  28.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.59  -5.19  -3.57  -3.6   -3.66  -3.8   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.14 11.21 14.83 10.44 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.59\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 349.   6. 148. 276.  48.  28.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.81\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.1  0.1  0.06 0.09 0.1  0.16 0.09 0.14 0.   0.   0.02 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.75\n",
      "\n",
      "-> i_step = 4073\n",
      "cur_state = [1 3]\n",
      "action = 6\n",
      "reward = -5.69\n",
      "new_state = [2 6]\n",
      "[ 37. 349.   6. 148. 276.  48.  28.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 349.   6. 148. 276.  48.  28.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.59  -5.19  -3.57  -3.6   -3.66  -3.8   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.14 11.21 14.83 10.44 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.59\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 349.   6. 148. 276.  48.  28.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.81\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.09 0.12 0.06 0.09 0.12 0.16 0.09 0.13 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.69\n",
      "\n",
      "-> i_step = 4074\n",
      "cur_state = [2 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q_est = -4.88\n",
      "\n",
      "-> i_step = 4173\n",
      "cur_state = [1 3]\n",
      "action = 6\n",
      "reward = -0.44\n",
      "new_state = [2 6]\n",
      "[ 37. 362.   6. 155. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 155. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.6   -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.13 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 155. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.91\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.05 0.1  0.1  0.17 0.09 0.12 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.93\n",
      "\n",
      "-> i_step = 4174\n",
      "cur_state = [2 6]\n",
      "action = 4\n",
      "reward = 1.91\n",
      "new_state = [3 4]\n",
      "[ 37. 362.   6. 155. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 155. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.6   -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.13 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 155. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.91\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.11 0.09 0.06 0.08 0.11 0.16 0.1  0.12 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.92\n",
      "\n",
      "-> i_step = 4175\n",
      "cur_state = [3 4]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 362.   6. 155. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 155. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.6   -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.13 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 155. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.91\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.04 0.1  0.1  0.17 0.09 0.15 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.78\n",
      "\n",
      "-> i_step = 4176\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 6.76\n",
      "new_state = [1 3]\n",
      "[ 37. 362.   6. 156. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 156. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.57  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.1  11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 156. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.91\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.14 0.11 0.04 0.09 0.11 0.14 0.09 0.13 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.87\n",
      "\n",
      "-> i_step = 4177\n",
      "cur_state = [1 3]\n",
      "action = 6\n",
      "reward = 7.62\n",
      "new_state = [2 6]\n",
      "[ 37. 362.   6. 156. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 156. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.57  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.1  11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 156. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.91\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.04 0.11 0.1  0.17 0.08 0.12 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -4.95\n",
      "\n",
      "-> i_step = 4178\n",
      "cur_state = [2 6]\n",
      "action = 4\n",
      "reward = -0.06\n",
      "new_state = [3 4]\n",
      "[ 37. 362.   6. 156. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 156. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.57  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.1  11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 156. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.91\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.05 0.1  0.12 0.16 0.08 0.13 0.   0.   0.01 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.79\n",
      "\n",
      "-> i_step = 4179\n",
      "cur_state = [3 4]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 362.   6. 156. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 156. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.57  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.1  11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 156. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.91\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.09 0.08 0.04 0.09 0.11 0.19 0.09 0.15 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.81\n",
      "\n",
      "-> i_step = 4180\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 6.33\n",
      "new_state = [1 3]\n",
      "[ 37. 362.   6. 157. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 157. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.56  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.07 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 157. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.90\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.11 0.05 0.08 0.11 0.15 0.1  0.13 0.   0.   0.01 0.04 0.   0.1\n",
      " 0.01 0.  ]\n",
      "Q_est = -4.84\n",
      "\n",
      "-> i_step = 4181\n",
      "cur_state = [1 3]\n",
      "action = 6\n",
      "reward = 10.61\n",
      "new_state = [2 6]\n",
      "[ 37. 362.   6. 157. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 157. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.56  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.07 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 157. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.90\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.08 0.04 0.09 0.11 0.15 0.1  0.14 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.94\n",
      "\n",
      "-> i_step = 4182\n",
      "cur_state = [2 6]\n",
      "action = 4\n",
      "reward = 11.44\n",
      "new_state = [3 4]\n",
      "[ 37. 362.   6. 157. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 157. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.56  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.07 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 157. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.90\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.04 0.1  0.12 0.17 0.1  0.13 0.   0.   0.01 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.71\n",
      "\n",
      "-> i_step = 4183\n",
      "cur_state = [3 4]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 362.   6. 157. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 157. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.56  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.07 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 157. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.90\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.05 0.1  0.11 0.17 0.09 0.13 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.81\n",
      "\n",
      "-> i_step = 4184\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 16.97\n",
      "new_state = [1 3]\n",
      "[ 37. 362.   6. 158. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 158. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.47  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.1  11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 158. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.89\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.06 0.08 0.11 0.17 0.08 0.16 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.72\n",
      "\n",
      "-> i_step = 4185\n",
      "cur_state = [1 3]\n",
      "action = 6\n",
      "reward = -8.52\n",
      "new_state = [2 6]\n",
      "[ 37. 362.   6. 158. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 158. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.47  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.1  11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 158. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.89\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.1  0.11 0.04 0.09 0.1  0.16 0.1  0.13 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.83\n",
      "\n",
      "-> i_step = 4186\n",
      "cur_state = [2 6]\n",
      "action = 4\n",
      "reward = -13.35\n",
      "new_state = [3 4]\n",
      "[ 37. 362.   6. 158. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 158. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.47  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.1  11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 158. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.89\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.11 0.1  0.04 0.1  0.12 0.17 0.08 0.15 0.   0.   0.01 0.05 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -4.71\n",
      "\n",
      "-> i_step = 4187\n",
      "cur_state = [3 4]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 362.   6. 158. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 158. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.47  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.1  11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 158. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.89\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.11 0.04 0.09 0.11 0.16 0.1  0.13 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.79\n",
      "\n",
      "-> i_step = 4188\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 10.30\n",
      "new_state = [1 3]\n",
      "[ 37. 362.   6. 159. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 159. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.43  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.08 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 159. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.88\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.05 0.1  0.12 0.15 0.09 0.13 0.   0.   0.01 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.84\n",
      "\n",
      "-> i_step = 4189\n",
      "cur_state = [1 3]\n",
      "action = 6\n",
      "reward = -15.95\n",
      "new_state = [2 6]\n",
      "[ 37. 362.   6. 159. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 159. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.43  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.08 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 159. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.88\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.05 0.08 0.1  0.17 0.08 0.13 0.   0.   0.02 0.06 0.   0.11\n",
      " 0.   0.  ]\n",
      "Q_est = -5.02\n",
      "\n",
      "-> i_step = 4190\n",
      "cur_state = [2 6]\n",
      "action = 4\n",
      "reward = 0.08\n",
      "new_state = [3 4]\n",
      "[ 37. 362.   6. 159. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 159. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.43  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.08 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 159. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.88\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.11 0.06 0.1  0.1  0.16 0.08 0.14 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.76\n",
      "\n",
      "-> i_step = 4191\n",
      "cur_state = [3 4]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 362.   6. 159. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 159. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.43  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.08 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 159. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.88\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.09 0.09 0.06 0.1  0.1  0.17 0.09 0.14 0.   0.   0.02 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.99\n",
      "\n",
      "-> i_step = 4192\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -18.71\n",
      "new_state = [1 3]\n",
      "[ 37. 362.   6. 160. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 160. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.57  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.2  11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 160. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.91\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.1  0.09 0.06 0.1  0.12 0.15 0.08 0.15 0.   0.   0.01 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.71\n",
      "\n",
      "-> i_step = 4193\n",
      "cur_state = [1 3]\n",
      "action = 6\n",
      "reward = -6.08\n",
      "new_state = [2 6]\n",
      "[ 37. 362.   6. 160. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 160. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.57  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.2  11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 160. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.91\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.05 0.1  0.1  0.15 0.09 0.13 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.90\n",
      "\n",
      "-> i_step = 4194\n",
      "cur_state = [2 6]\n",
      "action = 4\n",
      "reward = 16.25\n",
      "new_state = [3 4]\n",
      "[ 37. 362.   6. 160. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 160. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.57  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.2  11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 160. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.91\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.05 0.09 0.1  0.17 0.08 0.14 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.01 0.  ]\n",
      "Q_est = -4.86\n",
      "\n",
      "-> i_step = 4195\n",
      "cur_state = [3 4]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 362.   6. 160. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 160. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.57  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.2  11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 160. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.91\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.05 0.1  0.11 0.16 0.09 0.13 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.80\n",
      "\n",
      "-> i_step = 4196\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 6.10\n",
      "new_state = [1 3]\n",
      "[ 37. 362.   6. 161. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 161. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.56  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 161. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.90\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.09 0.1  0.05 0.08 0.1  0.17 0.09 0.13 0.   0.   0.02 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.01\n",
      "\n",
      "-> i_step = 4197\n",
      "cur_state = [1 3]\n",
      "action = 6\n",
      "reward = 2.81\n",
      "new_state = [2 6]\n",
      "[ 37. 362.   6. 161. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 161. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.56  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 161. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.90\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.09 0.1  0.16 0.08 0.14 0.   0.   0.01 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.83\n",
      "\n",
      "-> i_step = 4198\n",
      "cur_state = [2 6]\n",
      "action = 4\n",
      "reward = -16.10\n",
      "new_state = [3 4]\n",
      "[ 37. 362.   6. 161. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 161. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.56  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 161. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.90\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "probs = [0.1  0.1  0.06 0.1  0.1  0.18 0.08 0.13 0.   0.   0.03 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.83\n",
      "\n",
      "-> i_step = 4199\n",
      "cur_state = [3 4]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 362.   6. 161. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 161. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.56  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 161. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.90\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.05 0.08 0.11 0.16 0.09 0.14 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.84\n",
      "\n",
      "-> i_step = 4200\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -5.80\n",
      "new_state = [1 3]\n",
      "[ 37. 362.   6. 162. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 162. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.61  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 162. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.91\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.04 0.09 0.11 0.18 0.09 0.14 0.   0.   0.01 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.76\n",
      "\n",
      "-> i_step = 4201\n",
      "cur_state = [1 3]\n",
      "action = 6\n",
      "reward = 7.04\n",
      "new_state = [2 6]\n",
      "[ 37. 362.   6. 162. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 162. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.61  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 162. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.91\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.06 0.07 0.12 0.17 0.09 0.12 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.91\n",
      "\n",
      "-> i_step = 4202\n",
      "cur_state = [2 6]\n",
      "action = 4\n",
      "reward = 5.99\n",
      "new_state = [3 4]\n",
      "[ 37. 362.   6. 162. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 162. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.61  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 162. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.91\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.05 0.08 0.1  0.17 0.08 0.15 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.87\n",
      "\n",
      "-> i_step = 4203\n",
      "cur_state = [3 4]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 362.   6. 162. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 162. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.61  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.17 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 162. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.91\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.11 0.07 0.1  0.1  0.16 0.09 0.12 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.01 0.  ]\n",
      "Q_est = -4.88\n",
      "\n",
      "-> i_step = 4204\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 3.60\n",
      "new_state = [1 3]\n",
      "[ 37. 362.   6. 163. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 163. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.61  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.14 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 163. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.91\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.05 0.07 0.12 0.16 0.09 0.14 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.95\n",
      "\n",
      "-> i_step = 4205\n",
      "cur_state = [1 3]\n",
      "action = 6\n",
      "reward = 18.43\n",
      "new_state = [2 6]\n",
      "[ 37. 362.   6. 163. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 163. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.61  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.14 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 163. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.91\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.04 0.08 0.11 0.15 0.09 0.14 0.   0.   0.01 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.91\n",
      "\n",
      "-> i_step = 4206\n",
      "cur_state = [2 6]\n",
      "action = 4\n",
      "reward = 8.65\n",
      "new_state = [3 4]\n",
      "[ 37. 362.   6. 163. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 163. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.61  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.14 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 163. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.91\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.07 0.1  0.09 0.17 0.09 0.12 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.89\n",
      "\n",
      "-> i_step = 4207\n",
      "cur_state = [3 4]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 362.   6. 163. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 163. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.61  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.14 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 163. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.91\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.11 0.08 0.06 0.1  0.12 0.16 0.09 0.13 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.85\n",
      "\n",
      "-> i_step = 4208\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -4.12\n",
      "new_state = [1 3]\n",
      "[ 37. 362.   6. 164. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 164. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.66  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.12 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 164. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.92\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.11 0.06 0.11 0.1  0.17 0.09 0.13 0.   0.   0.02 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.80\n",
      "\n",
      "-> i_step = 4209\n",
      "cur_state = [1 3]\n",
      "action = 6\n",
      "reward = 1.15\n",
      "new_state = [2 6]\n",
      "[ 37. 362.   6. 164. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 164. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.66  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.12 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 164. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.92\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.11 0.05 0.09 0.11 0.16 0.09 0.12 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.85\n",
      "\n",
      "-> i_step = 4210\n",
      "cur_state = [2 6]\n",
      "action = 4\n",
      "reward = -13.36\n",
      "new_state = [3 4]\n",
      "[ 37. 362.   6. 164. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 164. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.66  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.12 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 164. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.92\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.04 0.11 0.1  0.17 0.09 0.12 0.   0.   0.01 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.93\n",
      "\n",
      "-> i_step = 4211\n",
      "cur_state = [3 4]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 362.   6. 164. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 164. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.66  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.12 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 164. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.92\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.05 0.09 0.12 0.17 0.09 0.12 0.   0.   0.01 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.93\n",
      "\n",
      "-> i_step = 4212\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -17.96\n",
      "new_state = [1 3]\n",
      "[ 37. 362.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.79  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.23 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 165. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.94\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.13 0.1  0.06 0.09 0.1  0.17 0.08 0.12 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.85\n",
      "\n",
      "-> i_step = 4213\n",
      "cur_state = [1 3]\n",
      "action = 6\n",
      "reward = -18.74\n",
      "new_state = [2 6]\n",
      "[ 37. 362.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.79  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.23 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 165. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.94\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "probs = [0.12 0.11 0.04 0.08 0.12 0.15 0.09 0.14 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.81\n",
      "\n",
      "-> i_step = 4214\n",
      "cur_state = [2 6]\n",
      "action = 4\n",
      "reward = -7.51\n",
      "new_state = [3 4]\n",
      "[ 37. 362.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.79  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.23 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 165. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.94\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.11 0.05 0.1  0.11 0.17 0.08 0.13 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.81\n",
      "\n",
      "-> i_step = 4215\n",
      "cur_state = [3 4]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 37. 362.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 37. 362.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -3.72  -3.72  -5.19  -3.79  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.21 10.59  8.95 10.23 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 37. 362.   6. 165. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.94\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.11 0.05 0.09 0.11 0.17 0.08 0.13 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.89\n",
      "\n",
      "-> i_step = 4216\n",
      "cur_state = [0 0]\n",
      "action = 0\n",
      "reward = -20.80\n",
      "new_state = [1 0]\n",
      "[ 38. 362.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 362.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.72  -5.19  -3.79  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 362.   6. 165. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.96\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.04 0.1  0.1  0.16 0.08 0.14 0.   0.01 0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.98\n",
      "\n",
      "-> i_step = 4217\n",
      "cur_state = [1 0]\n",
      "action = 4\n",
      "reward = -1.11\n",
      "new_state = [2 4]\n",
      "[ 38. 362.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 362.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.72  -5.19  -3.79  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 362.   6. 165. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.96\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.11 0.11 0.06 0.09 0.11 0.16 0.09 0.13 0.   0.   0.01 0.05 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -4.84\n",
      "\n",
      "-> i_step = 4218\n",
      "cur_state = [2 4]\n",
      "action = 3\n",
      "reward = -21.06\n",
      "new_state = [3 3]\n",
      "[ 38. 362.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 362.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.72  -5.19  -3.79  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 362.   6. 165. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.96\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.05 0.08 0.11 0.18 0.09 0.14 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.91\n",
      "\n",
      "-> i_step = 4219\n",
      "cur_state = [3 3]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 362.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 362.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.72  -5.19  -3.79  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 362.   6. 165. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.96\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.11 0.07 0.08 0.1  0.17 0.09 0.14 0.   0.01 0.02 0.03 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.91\n",
      "\n",
      "-> i_step = 4220\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -5.91\n",
      "new_state = [1 1]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.75  -5.19  -3.79  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.75\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 363.   6. 165. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.97\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.05 0.1  0.1  0.16 0.11 0.13 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.94\n",
      "\n",
      "-> i_step = 4221\n",
      "cur_state = [1 1]\n",
      "action = 7\n",
      "reward = 8.06\n",
      "new_state = [2 7]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.75  -5.19  -3.79  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.75\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 363.   6. 165. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.97\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.05 0.08 0.09 0.16 0.09 0.13 0.   0.   0.02 0.06 0.   0.11\n",
      " 0.   0.  ]\n",
      "Q_est = -5.14\n",
      "\n",
      "-> i_step = 4222\n",
      "cur_state = [2 7]\n",
      "action = 5\n",
      "reward = 5.55\n",
      "new_state = [3 5]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.75  -5.19  -3.79  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.75\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 363.   6. 165. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.97\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.09 0.11 0.16 0.09 0.13 0.   0.   0.02 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.98\n",
      "\n",
      "-> i_step = 4223\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  92.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.75  -5.19  -3.79  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.26 14.86 10.27 12.88  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.75\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 363.   6. 165. 279.  49.  29.  92.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.97\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.06 0.1  0.1  0.14 0.09 0.13 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.04\n",
      "\n",
      "-> i_step = 4224\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 15.05\n",
      "new_state = [1 7]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  93.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  93.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.75  -5.19  -3.79  -3.75  -4.    -3.9   -3.6  -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.26 14.86 10.27 12.86  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.75\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 363.   6. 165. 279.  49.  29.  93.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.96\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.08 0.12 0.16 0.08 0.13 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.89\n",
      "\n",
      "-> i_step = 4225\n",
      "cur_state = [1 7]\n",
      "action = 6\n",
      "reward = -7.16\n",
      "new_state = [2 6]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  93.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  93.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.75  -5.19  -3.79  -3.75  -4.    -3.9   -3.6  -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.26 14.86 10.27 12.86  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.75\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 363.   6. 165. 279.  49.  29.  93.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.96\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.05 0.1  0.1  0.17 0.11 0.14 0.   0.   0.01 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.79\n",
      "\n",
      "-> i_step = 4226\n",
      "cur_state = [2 6]\n",
      "action = 4\n",
      "reward = -5.62\n",
      "new_state = [3 4]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  93.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  93.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.75  -5.19  -3.79  -3.75  -4.    -3.9   -3.6  -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.26 14.86 10.27 12.86  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.75\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 363.   6. 165. 279.  49.  29.  93.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.96\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.13 0.08 0.04 0.09 0.12 0.16 0.09 0.12 0.   0.   0.01 0.04 0.   0.1\n",
      " 0.01 0.  ]\n",
      "Q_est = -4.93\n",
      "\n",
      "-> i_step = 4227\n",
      "cur_state = [3 4]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  93.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  93.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.75  -5.19  -3.79  -3.75  -4.    -3.9   -3.6  -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.26 14.86 10.27 12.86  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.75\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 363.   6. 165. 279.  49.  29.  93.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.96\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.04 0.08 0.11 0.17 0.1  0.14 0.   0.   0.01 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.92\n",
      "\n",
      "-> i_step = 4228\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = -8.15\n",
      "new_state = [1 7]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  94.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  94.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.75  -5.19  -3.79  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.26 14.86 10.27 12.85  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.75\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 363.   6. 165. 279.  49.  29.  94.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.97\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.08 0.04 0.08 0.11 0.18 0.1  0.15 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -4.92\n",
      "\n",
      "-> i_step = 4229\n",
      "cur_state = [1 7]\n",
      "action = 2\n",
      "reward = -0.02\n",
      "new_state = [2 2]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  94.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  94.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.75  -5.19  -3.79  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.26 14.86 10.27 12.85  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.75\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 363.   6. 165. 279.  49.  29.  94.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.97\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.08 0.05 0.1  0.11 0.16 0.1  0.12 0.   0.   0.02 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.00\n",
      "\n",
      "-> i_step = 4230\n",
      "cur_state = [2 2]\n",
      "action = 6\n",
      "reward = -10.31\n",
      "new_state = [3 6]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  94.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  94.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.75  -5.19  -3.79  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.26 14.86 10.27 12.85  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.75\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 363.   6. 165. 279.  49.  29.  94.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.97\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.05 0.09 0.12 0.16 0.1  0.14 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.01 0.  ]\n",
      "Q_est = -4.95\n",
      "\n",
      "-> i_step = 4231\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  94.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  94.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.75  -5.19  -3.79  -3.75  -4.    -3.9   -3.73 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.26 14.86 10.27 12.85  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.75\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 363.   6. 165. 279.  49.  29.  94.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.97\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.11 0.08 0.06 0.08 0.11 0.19 0.09 0.14 0.   0.   0.01 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.85\n",
      "\n",
      "-> i_step = 4232\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = -7.66\n",
      "new_state = [1 7]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.75  -5.19  -3.79  -3.75  -4.    -3.9   -3.85 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.26 14.86 10.27 12.83  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.75\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 363.   6. 165. 279.  49.  29.  95.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.98\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.07 0.1  0.18 0.1  0.13 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -4.89\n",
      "\n",
      "-> i_step = 4233\n",
      "cur_state = [1 7]\n",
      "action = 0\n",
      "reward = 16.00\n",
      "new_state = [2 0]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.75  -5.19  -3.79  -3.75  -4.    -3.9   -3.85 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.26 14.86 10.27 12.83  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.75\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 363.   6. 165. 279.  49.  29.  95.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.98\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.1  0.11 0.06 0.09 0.1  0.15 0.1  0.15 0.   0.   0.01 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.76\n",
      "\n",
      "-> i_step = 4234\n",
      "cur_state = [2 0]\n",
      "action = 0\n",
      "reward = -5.59\n",
      "new_state = [3 0]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.75  -5.19  -3.79  -3.75  -4.    -3.9   -3.85 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.26 14.86 10.27 12.83  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.75\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 363.   6. 165. 279.  49.  29.  95.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.98\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.05 0.09 0.13 0.16 0.08 0.14 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.87\n",
      "\n",
      "-> i_step = 4235\n",
      "cur_state = [3 0]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 363.   6. 165. 279.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.75  -5.19  -3.79  -3.75  -4.    -3.9   -3.85 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.26 14.86 10.27 12.83  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.75\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 363.   6. 165. 279.  49.  29.  95.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.98\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.11 0.1  0.05 0.1  0.12 0.16 0.08 0.14 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.92\n",
      "\n",
      "-> i_step = 4236\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = -4.82\n",
      "new_state = [1 4]\n",
      "[ 38. 363.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 363.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.75  -5.19  -3.79  -3.78  -4.    -3.9   -3.85 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.25 14.86 10.27 12.83  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.75\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 363.   6. 165. 280.  49.  29.  95.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.99\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.08 0.06 0.07 0.12 0.17 0.1  0.14 0.   0.   0.01 0.04 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -4.85\n",
      "\n",
      "-> i_step = 4237\n",
      "cur_state = [1 4]\n",
      "action = 0\n",
      "reward = -3.41\n",
      "new_state = [2 0]\n",
      "[ 38. 363.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 363.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.75  -5.19  -3.79  -3.78  -4.    -3.9   -3.85 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.25 14.86 10.27 12.83  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.75\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 363.   6. 165. 280.  49.  29.  95.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.99\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "probs = [0.11 0.09 0.06 0.11 0.12 0.15 0.09 0.13 0.   0.   0.01 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.85\n",
      "\n",
      "-> i_step = 4238\n",
      "cur_state = [2 0]\n",
      "action = 1\n",
      "reward = 11.35\n",
      "new_state = [3 1]\n",
      "[ 38. 363.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 363.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.75  -5.19  -3.79  -3.78  -4.    -3.9   -3.85 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.25 14.86 10.27 12.83  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.75\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 363.   6. 165. 280.  49.  29.  95.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.99\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.06 0.09 0.1  0.17 0.1  0.14 0.   0.   0.02 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.95\n",
      "\n",
      "-> i_step = 4239\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 363.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 363.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.75  -5.19  -3.79  -3.78  -4.    -3.9   -3.85 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.59  8.95 10.23 11.25 14.86 10.27 12.83  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.75\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 363.   6. 165. 280.  49.  29.  95.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.99\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.08 0.03 0.09 0.11 0.18 0.09 0.15 0.   0.   0.02 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.97\n",
      "\n",
      "-> i_step = 4240\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 5.43\n",
      "new_state = [1 1]\n",
      "[ 38. 364.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 364.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.74  -5.19  -3.79  -3.78  -4.    -3.9   -3.85 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.57  8.95 10.23 11.25 14.86 10.27 12.83  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.74\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 364.   6. 165. 280.  49.  29.  95.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.99\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "probs = [0.12 0.09 0.06 0.09 0.12 0.16 0.09 0.13 0.   0.   0.02 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.89\n",
      "\n",
      "-> i_step = 4241\n",
      "cur_state = [1 1]\n",
      "action = 7\n",
      "reward = -11.61\n",
      "new_state = [2 7]\n",
      "[ 38. 364.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 364.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.74  -5.19  -3.79  -3.78  -4.    -3.9   -3.85 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.57  8.95 10.23 11.25 14.86 10.27 12.83  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.74\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 364.   6. 165. 280.  49.  29.  95.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.99\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.09 0.11 0.16 0.08 0.14 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.02\n",
      "\n",
      "-> i_step = 4242\n",
      "cur_state = [2 7]\n",
      "action = 5\n",
      "reward = -8.20\n",
      "new_state = [3 5]\n",
      "[ 38. 364.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 364.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.74  -5.19  -3.79  -3.78  -4.    -3.9   -3.85 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.57  8.95 10.23 11.25 14.86 10.27 12.83  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.74\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 364.   6. 165. 280.  49.  29.  95.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.99\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.11 0.1  0.06 0.09 0.11 0.15 0.09 0.13 0.   0.   0.01 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.00\n",
      "\n",
      "-> i_step = 4243\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 364.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 364.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.74  -5.19  -3.79  -3.78  -4.    -3.9   -3.85 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.57  8.95 10.23 11.25 14.86 10.27 12.83  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.74\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 364.   6. 165. 280.  49.  29.  95.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -3.99\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.15 0.09 0.05 0.09 0.09 0.16 0.09 0.12 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.89\n",
      "\n",
      "-> i_step = 4244\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -6.59\n",
      "new_state = [1 1]\n",
      "[ 38. 365.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 365.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.77  -5.19  -3.79  -3.78  -4.    -3.9   -3.85 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.57  8.95 10.23 11.25 14.86 10.27 12.83  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.77\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 365.   6. 165. 280.  49.  29.  95.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.00\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.04 0.09 0.11 0.17 0.09 0.14 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.95\n",
      "\n",
      "-> i_step = 4245\n",
      "cur_state = [1 1]\n",
      "action = 1\n",
      "reward = -20.87\n",
      "new_state = [2 1]\n",
      "[ 38. 365.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 365.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.77  -5.19  -3.79  -3.78  -4.    -3.9   -3.85 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.57  8.95 10.23 11.25 14.86 10.27 12.83  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.77\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 365.   6. 165. 280.  49.  29.  95.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.00\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.11 0.05 0.1  0.11 0.16 0.1  0.11 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.90\n",
      "\n",
      "-> i_step = 4246\n",
      "cur_state = [2 1]\n",
      "action = 6\n",
      "reward = -5.54\n",
      "new_state = [3 6]\n",
      "[ 38. 365.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 365.   6. 165. 280.  49.  29.  95.   4.   4.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.77  -5.19  -3.79  -3.78  -4.    -3.9   -3.85 -16.83  -9.43\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.57  8.95 10.23 11.25 14.86 10.27 12.83  6.91  5.12  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.77\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.16 0.27 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 365.   6. 165. 280.  49.  29.  95.   0.   4.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.00\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.11 0.05 0.08 0.12 0.16 0.07 0.12 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.94\n",
      "\n",
      "-> i_step = 4247"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.36 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 166. 285.  49.  29.  95.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.07\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.07 0.07 0.12 0.18 0.07 0.12 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.07\n",
      "\n",
      "-> i_step = 4349\n",
      "cur_state = [1 4]\n",
      "action = 0\n",
      "reward = -13.68\n",
      "new_state = [2 0]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  95.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  95.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.86  -3.89  -4.    -3.9   -3.85 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.23 11.26 14.86 10.27 12.83  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.36 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 166. 285.  49.  29.  95.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.07\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.09 0.1  0.06 0.08 0.12 0.17 0.08 0.12 0.   0.   0.02 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.19\n",
      "\n",
      "-> i_step = 4350\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = 15.43\n",
      "new_state = [3 7]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  95.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  95.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.86  -3.89  -4.    -3.9   -3.85 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.23 11.26 14.86 10.27 12.83  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.36 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 166. 285.  49.  29.  95.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.07\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.07 0.09 0.19 0.09 0.14 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -4.97\n",
      "\n",
      "-> i_step = 4351\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  95.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  95.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.86  -3.89  -4.    -3.9   -3.85 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.23 11.26 14.86 10.27 12.83  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.36 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 166. 285.  49.  29.  95.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.07\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.05 0.1  0.1  0.15 0.09 0.16 0.   0.   0.01 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.85\n",
      "\n",
      "-> i_step = 4352\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 10.11\n",
      "new_state = [1 7]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  96.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  96.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.86  -3.89  -4.    -3.9   -3.78 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.23 11.26 14.86 10.27 12.79  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.36 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 166. 285.  49.  29.  96.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.06\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.11 0.09 0.07 0.09 0.12 0.16 0.1  0.12 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.95\n",
      "\n",
      "-> i_step = 4353\n",
      "cur_state = [1 7]\n",
      "action = 0\n",
      "reward = -8.88\n",
      "new_state = [2 0]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  96.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  96.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.86  -3.89  -4.    -3.9   -3.78 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.23 11.26 14.86 10.27 12.79  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.36 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 166. 285.  49.  29.  96.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.06\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13]\n",
      "probs = [0.12 0.09 0.05 0.1  0.09 0.15 0.09 0.13 0.   0.   0.03 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.06\n",
      "\n",
      "-> i_step = 4354\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = -5.24\n",
      "new_state = [3 7]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  96.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  96.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.86  -3.89  -4.    -3.9   -3.78 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.23 11.26 14.86 10.27 12.79  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.36 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 166. 285.  49.  29.  96.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.06\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.06 0.09 0.12 0.15 0.09 0.13 0.   0.   0.02 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.91\n",
      "\n",
      "-> i_step = 4355\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  96.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  96.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.86  -3.89  -4.    -3.9   -3.78 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.23 11.26 14.86 10.27 12.79  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.36 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 166. 285.  49.  29.  96.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.06\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.07 0.06 0.09 0.09 0.18 0.1  0.13 0.   0.01 0.02 0.04 0.   0.11\n",
      " 0.   0.  ]\n",
      "Q_est = -5.05\n",
      "\n",
      "-> i_step = 4356\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 7.96new_state = [1 7]\n",
      "\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  97.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  97.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.86  -3.89  -4.    -3.9   -3.73 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.23 11.26 14.86 10.27 12.73  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.36 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 166. 285.  49.  29.  97.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.06\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.11 0.1  0.05 0.09 0.12 0.15 0.09 0.13 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.94\n",
      "\n",
      "-> i_step = 4357\n",
      "cur_state = [1 7]\n",
      "action = 0\n",
      "reward = 3.16\n",
      "new_state = [2 0]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  97.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  97.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.86  -3.89  -4.    -3.9   -3.73 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.23 11.26 14.86 10.27 12.73  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.36 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 166. 285.  49.  29.  97.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.06\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.06 0.08 0.1  0.18 0.1  0.13 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.98\n",
      "\n",
      "-> i_step = 4358\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = 12.99\n",
      "new_state = [3 7]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  97.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  97.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.86  -3.89  -4.    -3.9   -3.73 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.23 11.26 14.86 10.27 12.73  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.36 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 166. 285.  49.  29.  97.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.06\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.05 0.08 0.11 0.17 0.1  0.12 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.98\n",
      "\n",
      "-> i_step = 4359\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  97.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  97.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.86  -3.89  -4.    -3.9   -3.73 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.23 11.26 14.86 10.27 12.73  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.36 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 166. 285.  49.  29.  97.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.06\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.1  0.09 0.05 0.11 0.1  0.15 0.09 0.15 0.   0.   0.02 0.07 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.08\n",
      "\n",
      "-> i_step = 4360\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = -5.44\n",
      "new_state = [1 7]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  98.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  98.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.86  -3.89  -4.    -3.9   -3.82 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.23 11.26 14.86 10.27 12.69  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 166. 285.  49.  29.  98.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.07\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.05 0.1  0.1  0.16 0.08 0.15 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.93\n",
      "\n",
      "-> i_step = 4361\n",
      "cur_state = [1 7]\n",
      "action = 0\n",
      "reward = -19.92\n",
      "new_state = [2 0]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  98.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  98.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.86  -3.89  -4.    -3.9   -3.82 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.23 11.26 14.86 10.27 12.69  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 166. 285.  49.  29.  98.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.07\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "probs = [0.11 0.07 0.06 0.08 0.12 0.15 0.1  0.15 0.   0.   0.01 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.95\n",
      "\n",
      "-> i_step = 4362\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = -0.94\n",
      "new_state = [3 7]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  98.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  98.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.86  -3.89  -4.    -3.9   -3.82 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.23 11.26 14.86 10.27 12.69  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 166. 285.  49.  29.  98.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.07\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.05 0.08 0.11 0.16 0.1  0.15 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.00\n",
      "\n",
      "-> i_step = 4363\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  98.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  98.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.86  -3.89  -4.    -3.9   -3.82 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.23 11.26 14.86 10.27 12.69  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 166. 285.  49.  29.  98.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.07\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.11 0.09 0.04 0.1  0.12 0.14 0.09 0.16 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.96\n",
      "\n",
      "-> i_step = 4364\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = -5.12\n",
      "new_state = [1 7]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.86  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.23 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 166. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.07\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.11 0.04 0.09 0.1  0.17 0.1  0.13 0.   0.   0.01 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.94\n",
      "\n",
      "-> i_step = 4365\n",
      "cur_state = [1 7]\n",
      "action = 0\n",
      "reward = -4.50\n",
      "new_state = [2 0]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.86  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.23 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 166. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.07\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.1  0.09 0.06 0.1  0.1  0.16 0.09 0.13 0.   0.   0.01 0.07 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.18\n",
      "\n",
      "-> i_step = 4366\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = -3.85\n",
      "new_state = [3 7]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.86  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.23 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 166. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.07\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.11 0.05 0.09 0.1  0.15 0.09 0.13 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.97\n",
      "\n",
      "-> i_step = 4367\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 166. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.86  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.23 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 166. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.07\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "probs = [0.11 0.09 0.06 0.09 0.12 0.15 0.09 0.14 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.04\n",
      "\n",
      "-> i_step = 4368\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 5.94\n",
      "new_state = [1 3]\n",
      "[ 38. 384.   6. 167. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 167. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.84  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.2  11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 167. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.07\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.09 0.09 0.05 0.09 0.12 0.14 0.11 0.15 0.   0.   0.01 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.89\n",
      "\n",
      "-> i_step = 4369\n",
      "cur_state = [1 3]\n",
      "action = 6\n",
      "reward = 8.31\n",
      "new_state = [2 6]\n",
      "[ 38. 384.   6. 167. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 167. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.84  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.2  11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 167. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.07\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.07 0.08 0.1  0.16 0.08 0.12 0.   0.   0.02 0.06 0.   0.1\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.22\n",
      "\n",
      "-> i_step = 4370\n",
      "cur_state = [2 6]\n",
      "action = 4\n",
      "reward = -11.52\n",
      "new_state = [3 4]\n",
      "[ 38. 384.   6. 167. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 167. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.84  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.2  11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 167. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.07\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "probs = [0.12 0.1  0.05 0.09 0.1  0.17 0.09 0.13 0.   0.   0.01 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.92\n",
      "\n",
      "-> i_step = 4371\n",
      "cur_state = [3 4]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 384.   6. 167. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 167. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.84  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.2  11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 167. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.07\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.08 0.06 0.1  0.12 0.17 0.09 0.11 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.12\n",
      "\n",
      "-> i_step = 4372\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -15.24\n",
      "new_state = [1 3]\n",
      "[ 38. 384.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.09\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.06 0.08 0.11 0.17 0.09 0.12 0.   0.   0.02 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.13\n",
      "\n",
      "-> i_step = 4373\n",
      "cur_state = [1 3]\n",
      "action = 6\n",
      "reward = -27.43\n",
      "new_state = [2 6]\n",
      "[ 38. 384.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.09\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.05 0.09 0.11 0.19 0.09 0.14 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.96\n",
      "\n",
      "-> i_step = 4374\n",
      "cur_state = [2 6]\n",
      "action = 3\n",
      "reward = 2.25\n",
      "new_state = [3 3]\n",
      "[ 38. 384.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.09\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.06 0.09 0.11 0.16 0.09 0.14 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.99\n",
      "\n",
      "-> i_step = 4375\n",
      "cur_state = [3 3]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 384.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 384.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.04 0.35 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 384.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.09\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.07 0.09 0.1  0.17 0.09 0.13 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.06\n",
      "\n",
      "-> i_step = 4376\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 0.06\n",
      "new_state = [1 1]\n",
      "[ 38. 385.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 385.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.53  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.35 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 385.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.09\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.06 0.09 0.11 0.14 0.1  0.15 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.08\n",
      "\n",
      "-> i_step = 4377\n",
      "cur_state = [1 1]\n",
      "action = 6\n",
      "reward = -11.76\n",
      "new_state = [2 6]\n",
      "[ 38. 385.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 385.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.53  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.35 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 385.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.09\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.12 0.05 0.08 0.1  0.16 0.11 0.13 0.   0.   0.02 0.04 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -4.91\n",
      "\n",
      "-> i_step = 4378\n",
      "cur_state = [2 6]\n",
      "action = 7\n",
      "reward = 11.94\n",
      "new_state = [3 7]\n",
      "[ 38. 385.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 385.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.53  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.35 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 385.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.09\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13]\n",
      "probs = [0.11 0.09 0.05 0.08 0.11 0.19 0.08 0.13 0.   0.   0.02 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.97\n",
      "\n",
      "-> i_step = 4379\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 385.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 385.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.87  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.53  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.87\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.35 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 385.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.09\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.09 0.1  0.16 0.09 0.13 0.   0.   0.02 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.05\n",
      "\n",
      "-> i_step = 4380\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 11.97\n",
      "new_state = [1 1]\n",
      "[ 38. 386.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 386.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.85  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.52  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.85\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 386.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.08\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.1  0.1  0.06 0.09 0.12 0.15 0.09 0.13 0.   0.   0.03 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.99\n",
      "\n",
      "-> i_step = 4381\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -7.52\n",
      "new_state = [2 5]\n",
      "[ 38. 386.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 386.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.85  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.52  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.85\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 386.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.08\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.08 0.11 0.15 0.1  0.13 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.04\n",
      "\n",
      "-> i_step = 4382\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 11.17\n",
      "new_state = [3 5]\n",
      "[ 38. 386.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 386.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.85  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.52  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.85\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 386.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.08\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.09 0.1  0.04 0.1  0.13 0.18 0.09 0.13 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.00\n",
      "\n",
      "-> i_step = 4383\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 386.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 386.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.85  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.52  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.85\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 386.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.08\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.09 0.11 0.05 0.08 0.09 0.17 0.08 0.15 0.   0.   0.02 0.05 0.   0.11\n",
      " 0.   0.  ]\n",
      "Q_est = -5.13\n",
      "\n",
      "-> i_step = 4384\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 20.00\n",
      "new_state = [1 1]\n",
      "[ 38. 387.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 387.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.81  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.81\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 387.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.07\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.11 0.06 0.11 0.09 0.17 0.1  0.12 0.   0.   0.02 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.87\n",
      "\n",
      "-> i_step = 4385\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 17.67\n",
      "new_state = [2 5]\n",
      "[ 38. 387.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 387.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.81  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.81\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 387.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.07\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.06 0.12 0.11 0.13 0.1  0.12 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.01\n",
      "\n",
      "-> i_step = 4386\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 7.77\n",
      "new_state = [3 5]\n",
      "[ 38. 387.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 387.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.81  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.81\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 387.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.07\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.05 0.09 0.1  0.17 0.09 0.12 0.   0.   0.01 0.05 0.   0.11\n",
      " 0.   0.  ]\n",
      "Q_est = -5.07\n",
      "\n",
      "-> i_step = 4387\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 387.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 387.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.81  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.81\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 387.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.07\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.09 0.11 0.15 0.1  0.13 0.   0.   0.01 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.93\n",
      "\n",
      "-> i_step = 4388\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 15.24\n",
      "new_state = [1 1]\n",
      "[ 38. 388.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 388.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.78  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.78\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 388.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.06\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.05 0.09 0.1  0.16 0.1  0.14 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.96\n",
      "\n",
      "-> i_step = 4389\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -6.89\n",
      "new_state = [2 5]\n",
      "[ 38. 388.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 388.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.78  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.78\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 388.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.06\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.09 0.1  0.05 0.07 0.12 0.18 0.07 0.14 0.   0.   0.01 0.05 0.   0.1\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.08\n",
      "\n",
      "-> i_step = 4390\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 0.37\n",
      "new_state = [3 5]\n",
      "[ 38. 388.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 388.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.78  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.78\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 388.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.06\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.09 0.09 0.05 0.08 0.13 0.17 0.1  0.14 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.96\n",
      "\n",
      "-> i_step = 4391\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 388.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 388.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.78  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.54  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.78\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 388.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.06\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.11 0.06 0.08 0.11 0.16 0.09 0.14 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.97\n",
      "\n",
      "-> i_step = 4392\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 9.50\n",
      "new_state = [1 1]\n",
      "[ 38. 389.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 389.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.77  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.53  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.77\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 389.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.05\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.05 0.09 0.1  0.16 0.11 0.13 0.   0.   0.02 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.04\n",
      "\n",
      "-> i_step = 4393\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -5.40\n",
      "new_state = [2 5]\n",
      "[ 38. 389.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 389.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.77  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.53  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.77\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 389.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.05\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "probs = [0.11 0.09 0.05 0.09 0.11 0.14 0.09 0.14 0.   0.   0.01 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.01\n",
      "\n",
      "-> i_step = 4394\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -7.62\n",
      "new_state = [3 5]\n",
      "[ 38. 389.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 389.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.77  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.53  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.77\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 389.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.05\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.1  0.09 0.06 0.1  0.09 0.17 0.1  0.11 0.   0.   0.02 0.06 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.12\n",
      "\n",
      "-> i_step = 4395\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 389.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 389.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.77  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.53  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.77\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 389.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.05\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.1  0.13 0.07 0.06 0.11 0.16 0.08 0.13 0.   0.   0.02 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.08\n",
      "\n",
      "-> i_step = 4396\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 1.15\n",
      "new_state = [1 1]\n",
      "[ 38. 390.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 390.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.77  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.52  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.77\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 390.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.05\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.04 0.09 0.12 0.16 0.09 0.12 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.93\n",
      "\n",
      "-> i_step = 4397\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 12.47\n",
      "new_state = [2 5]\n",
      "[ 38. 390.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 390.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.77  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.52  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.77\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 390.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.05\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.05 0.1  0.1  0.15 0.09 0.13 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.02\n",
      "\n",
      "-> i_step = 4398\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -6.17\n",
      "new_state = [3 5]\n",
      "[ 38. 390.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 390.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.77  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.52  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.77\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 390.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.05\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.11 0.05 0.09 0.11 0.17 0.09 0.12 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.99\n",
      "\n",
      "-> i_step = 4399\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 390.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 390.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.77  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.52  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.77\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 390.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.05\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.07 0.1  0.11 0.17 0.1  0.1  0.   0.   0.02 0.05 0.   0.08\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.06\n",
      "\n",
      "-> i_step = 4400\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 9.89\n",
      "new_state = [1 1]\n",
      "[ 38. 391.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 391.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.76  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.51  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.76\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 391.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.05\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.12 0.1  0.05 0.11 0.09 0.16 0.09 0.14 0.   0.   0.02 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.85\n",
      "\n",
      "-> i_step = 4401\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 6.77\n",
      "new_state = [2 5]\n",
      "[ 38. 391.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 391.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.76  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.51  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.76\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 391.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.05\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.05 0.1  0.1  0.17 0.09 0.12 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.04\n",
      "\n",
      "-> i_step = 4402\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -14.99\n",
      "new_state = [3 5]\n",
      "[ 38. 391.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 391.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.76  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.51  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.76\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 391.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.05\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.05 0.1  0.1  0.17 0.09 0.13 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.97\n",
      "\n",
      "-> i_step = 4403\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 391.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 391.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.76  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.51  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.76\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 391.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.05\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.08 0.1  0.17 0.1  0.13 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.96\n",
      "\n",
      "-> i_step = 4404\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 1.88\n",
      "new_state = [1 1]\n",
      "[ 38. 392.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 392.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.76  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.5   8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.76\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 392.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.05\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.1  0.09 0.04 0.09 0.09 0.18 0.09 0.14 0.   0.   0.02 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.98\n",
      "\n",
      "-> i_step = 4405\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 7.13\n",
      "new_state = [2 5]\n",
      "[ 38. 392.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 392.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.76  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.5   8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.76\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 392.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.05\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.07 0.09 0.1  0.17 0.09 0.12 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.03\n",
      "\n",
      "-> i_step = 4406\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -4.71\n",
      "new_state = [3 5]\n",
      "[ 38. 392.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 392.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.76  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.5   8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.76\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 392.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.05\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13]\n",
      "probs = [0.12 0.1  0.05 0.1  0.09 0.16 0.09 0.12 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.02\n",
      "\n",
      "-> i_step = 4407\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 392.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 392.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.76  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.5   8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.76\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 392.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.05\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.13 0.09 0.06 0.08 0.1  0.19 0.07 0.12 0.   0.   0.01 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.07\n",
      "\n",
      "-> i_step = 4408\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 11.36\n",
      "new_state = [1 1]\n",
      "[ 38. 393.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 393.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.74  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.49  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.74\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 393.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.04\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.05 0.09 0.1  0.15 0.09 0.14 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.07\n",
      "\n",
      "-> i_step = 4409\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -26.24\n",
      "new_state = [2 5]\n",
      "[ 38. 393.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 393.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.74  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.49  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.74\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 393.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.04\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.07 0.09 0.13 0.15 0.08 0.12 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.03\n",
      "\n",
      "-> i_step = 4410\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -10.65\n",
      "new_state = [3 5]\n",
      "[ 38. 393.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 393.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.74  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.49  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.74\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 393.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.04\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.06 0.09 0.1  0.2  0.09 0.11 0.   0.   0.02 0.06 0.   0.08\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.12\n",
      "\n",
      "-> i_step = 4411\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 393.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 393.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.74  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.49  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.74\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 393.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.04\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.14 0.11 0.04 0.07 0.1  0.15 0.09 0.12 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.09\n",
      "\n",
      "-> i_step = 4412\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 11.94\n",
      "new_state = [1 1]\n",
      "[ 38. 394.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 394.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.72  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.49  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 394.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "probs = [0.12 0.1  0.05 0.09 0.1  0.17 0.11 0.12 0.   0.   0.02 0.05 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -4.93\n",
      "\n",
      "-> i_step = 4413\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -17.86\n",
      "new_state = [2 5]\n",
      "[ 38. 394.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 394.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.72  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.49  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 394.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13]\n",
      "probs = [0.1  0.09 0.06 0.1  0.12 0.16 0.09 0.13 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.91\n",
      "\n",
      "-> i_step = 4414\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -9.39\n",
      "new_state = [3 5]\n",
      "[ 38. 394.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 394.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.72  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.49  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 394.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.11 0.05 0.09 0.1  0.16 0.09 0.13 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.96\n",
      "\n",
      "-> i_step = 4415\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 394.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 394.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.72  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.49  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 394.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.09 0.1  0.14 0.09 0.14 0.   0.   0.02 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.06\n",
      "\n",
      "-> i_step = 4416\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 2.32\n",
      "new_state = [1 1]\n",
      "[ 38. 395.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 395.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.72  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.47  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 395.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.1  0.11 0.05 0.09 0.1  0.16 0.1  0.14 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.97\n",
      "\n",
      "-> i_step = 4417\n",
      "cur_state = [1 1]\n",
      "action = 7\n",
      "reward = 6.40\n",
      "new_state = [2 7]\n",
      "[ 38. 395.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 395.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.72  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.47  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 395.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.1  0.1  0.05 0.09 0.1  0.17 0.1  0.13 0.   0.   0.02 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.05\n",
      "\n",
      "-> i_step = 4418\n",
      "cur_state = [2 7]\n",
      "action = 7\n",
      "reward = 10.82\n",
      "new_state = [3 7]\n",
      "[ 38. 395.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 395.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.72  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.47  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 395.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.1  0.12 0.14 0.1  0.13 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.92\n",
      "\n",
      "-> i_step = 4419\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 395.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 395.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.72  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.47  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.72\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 395.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.1  0.09 0.05 0.1  0.12 0.17 0.1  0.11 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.97\n",
      "\n",
      "-> i_step = 4420\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 10.25\n",
      "new_state = [1 1]\n",
      "[ 38. 396.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 396.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.71  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.47  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.71\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 396.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.11 0.07 0.09 0.09 0.18 0.08 0.12 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -4.97\n",
      "\n",
      "-> i_step = 4421\n",
      "cur_state = [1 1]\n",
      "action = 7\n",
      "reward = -12.02\n",
      "new_state = [2 7]\n",
      "[ 38. 396.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 396.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.71  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.47  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.71\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 396.   6. 168. 285.  49.  29.  99.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.03\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.07 0.07 0.11 0.18 0.08 0.13 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.98\n",
      "\n",
      "-> i_step = 4422\n",
      "cur_state = [2 7]\n",
      "action = 7\n",
      "reward = -3.18\n",
      "new_state = [3 7]\n",
      "[ 38. 396.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 396.   6. 168. 285.  49.  29.  99.   4.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.71  -5.19  -3.95  -3.89  -4.    -3.9   -3.91 -16.83  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.47  8.95 10.27 11.26 14.86 10.27 12.66  6.91  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.71\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.36 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 38. 411.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 411.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.92  -5.19  -3.95  -3.92  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.44  8.95 10.27 11.18 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.92\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 411.   6. 168. 291.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.05 0.09 0.1  0.17 0.09 0.14 0.   0.   0.01 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.15\n",
      "\n",
      "-> i_step = 4520\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 13.19\n",
      "new_state = [1 1]\n",
      "[ 38. 412.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 412.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.89  -5.19  -3.95  -3.92  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.44  8.95 10.27 11.18 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.89\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 412.   6. 168. 291.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.13\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.08 0.05 0.1  0.1  0.17 0.1  0.13 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.08\n",
      "\n",
      "-> i_step = 4521\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -9.93\n",
      "new_state = [2 5]\n",
      "[ 38. 412.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 412.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.89  -5.19  -3.95  -3.92  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.44  8.95 10.27 11.18 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.89\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 412.   6. 168. 291.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.13\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.06 0.09 0.1  0.15 0.08 0.13 0.   0.   0.02 0.07 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.26\n",
      "\n",
      "-> i_step = 4522\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -3.56\n",
      "new_state = [3 5]\n",
      "[ 38. 412.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 412.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.89  -5.19  -3.95  -3.92  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.44  8.95 10.27 11.18 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.89\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 412.   6. 168. 291.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.13\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.09 0.11 0.17 0.08 0.13 0.   0.   0.01 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.03\n",
      "\n",
      "-> i_step = 4523\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 412.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 412.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.89  -5.19  -3.95  -3.92  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.44  8.95 10.27 11.18 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.89\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 412.   6. 168. 291.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.13\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.1  0.07 0.06 0.1  0.12 0.17 0.08 0.13 0.   0.   0.02 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.15\n",
      "\n",
      "-> i_step = 4524\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 10.94\n",
      "new_state = [1 1]\n",
      "[ 38. 413.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 413.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.88  -5.19  -3.95  -3.92  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.43  8.95 10.27 11.18 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.88\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 413.   6. 168. 291.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.09 0.11 0.06 0.09 0.12 0.16 0.1  0.11 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.11\n",
      "\n",
      "-> i_step = 4525\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -10.61\n",
      "new_state = [2 5]\n",
      "[ 38. 413.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 413.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.88  -5.19  -3.95  -3.92  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.43  8.95 10.27 11.18 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.88\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 413.   6. 168. 291.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.1  0.1  0.18 0.08 0.13 0.   0.   0.02 0.05 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -5.04\n",
      "\n",
      "-> i_step = 4526\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -16.57\n",
      "new_state = [3 5]\n",
      "[ 38. 413.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 413.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.88  -5.19  -3.95  -3.92  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.43  8.95 10.27 11.18 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.88\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 413.   6. 168. 291.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.05 0.11 0.13 0.15 0.08 0.12 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.17\n",
      "\n",
      "-> i_step = 4527\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 413.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 413.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.88  -5.19  -3.95  -3.92  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.43  8.95 10.27 11.18 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.88\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 413.   6. 168. 291.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.09 0.09 0.07 0.09 0.1  0.18 0.08 0.14 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.07\n",
      "\n",
      "-> i_step = 4528\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -7.07\n",
      "new_state = [1 1]\n",
      "[ 38. 414.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 414.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.9   -5.19  -3.95  -3.92  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.43  8.95 10.27 11.18 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.90\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 414.   6. 168. 291.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.13\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.05 0.09 0.1  0.17 0.09 0.13 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.03\n",
      "\n",
      "-> i_step = 4529\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 13.64\n",
      "new_state = [2 5]\n",
      "[ 38. 414.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 414.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.9   -5.19  -3.95  -3.92  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.43  8.95 10.27 11.18 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.90\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 414.   6. 168. 291.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.13\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.06 0.1  0.12 0.16 0.08 0.14 0.   0.   0.01 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.00\n",
      "\n",
      "-> i_step = 4530\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 27.04\n",
      "new_state = [3 5]\n",
      "[ 38. 414.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 414.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.9   -5.19  -3.95  -3.92  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.43  8.95 10.27 11.18 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.90\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 414.   6. 168. 291.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.13\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.11 0.07 0.04 0.1  0.12 0.18 0.08 0.12 0.   0.   0.01 0.06 0.   0.1\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.20\n",
      "\n",
      "-> i_step = 4531\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 414.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 414.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.9   -5.19  -3.95  -3.92  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.43  8.95 10.27 11.18 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.90\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 414.   6. 168. 291.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.13\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.08 0.06 0.09 0.1  0.18 0.11 0.14 0.   0.   0.02 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.97\n",
      "\n",
      "-> i_step = 4532\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 7.81\n",
      "new_state = [1 1]\n",
      "[ 38. 415.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 415.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.89  -5.19  -3.95  -3.92  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.42  8.95 10.27 11.18 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.89\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 415.   6. 168. 291.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.13\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.09 0.12 0.16 0.09 0.12 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.08\n",
      "\n",
      "-> i_step = 4533\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -11.88\n",
      "new_state = [2 5]\n",
      "[ 38. 415.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 415.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.89  -5.19  -3.95  -3.92  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.42  8.95 10.27 11.18 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.89\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 415.   6. 168. 291.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.13\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.14 0.1  0.06 0.09 0.1  0.15 0.08 0.14 0.   0.   0.01 0.05 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -4.96\n",
      "\n",
      "-> i_step = 4534\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -12.73\n",
      "new_state = [3 5]\n",
      "[ 38. 415.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 415.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.89  -5.19  -3.95  -3.92  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.42  8.95 10.27 11.18 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.89\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 415.   6. 168. 291.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.13\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "probs = [0.11 0.1  0.04 0.09 0.14 0.16 0.09 0.12 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.05\n",
      "\n",
      "-> i_step = 4535\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 415.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 415.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.89  -5.19  -3.95  -3.92  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.42  8.95 10.27 11.18 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.89\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 415.   6. 168. 291.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.13\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.11 0.06 0.09 0.1  0.17 0.09 0.12 0.   0.   0.02 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.20\n",
      "\n",
      "-> i_step = 4536\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -16.30\n",
      "new_state = [1 1]\n",
      "[ 38. 416.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 416.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.94  -5.19  -3.95  -3.92  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.46  8.95 10.27 11.18 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.94\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 416.   6. 168. 291.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.05 0.08 0.1  0.16 0.1  0.14 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.11\n",
      "\n",
      "-> i_step = 4537\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -3.30\n",
      "new_state = [2 5]\n",
      "[ 38. 416.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 416.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.94  -5.19  -3.95  -3.92  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.46  8.95 10.27 11.18 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.94\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 416.   6. 168. 291.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.06 0.09 0.13 0.17 0.08 0.11 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.11\n",
      "\n",
      "-> i_step = 4538\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 4.49\n",
      "new_state = [3 5]\n",
      "[ 38. 416.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 416.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.94  -5.19  -3.95  -3.92  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.46  8.95 10.27 11.18 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.94\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 416.   6. 168. 291.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.11 0.05 0.08 0.11 0.15 0.08 0.15 0.   0.   0.02 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.02\n",
      "\n",
      "-> i_step = 4539\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 416.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 416.   6. 168. 291.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.94  -5.19  -3.95  -3.92  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.46  8.95 10.27 11.18 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.94\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 416.   6. 168. 291.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.11 0.1  0.15 0.09 0.12 0.   0.   0.02 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.16\n",
      "\n",
      "-> i_step = 4540\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = 1.77\n",
      "new_state = [1 4]\n",
      "[ 38. 416.   6. 168. 292.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 416.   6. 168. 292.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.94  -5.19  -3.95  -3.93  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.46  8.95 10.27 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.94\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 416.   6. 168. 292.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.15\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.11 0.1  0.05 0.09 0.09 0.18 0.07 0.15 0.   0.   0.02 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -4.98\n",
      "\n",
      "-> i_step = 4541\n",
      "cur_state = [1 4]\n",
      "action = 0\n",
      "reward = 9.52\n",
      "new_state = [2 0]\n",
      "[ 38. 416.   6. 168. 292.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 416.   6. 168. 292.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.94  -5.19  -3.95  -3.93  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.46  8.95 10.27 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.94\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 416.   6. 168. 292.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.15\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "probs = [0.12 0.11 0.05 0.09 0.09 0.15 0.09 0.12 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.12\n",
      "\n",
      "-> i_step = 4542\n",
      "cur_state = [2 0]\n",
      "action = 1\n",
      "reward = -5.14\n",
      "new_state = [3 1]\n",
      "[ 38. 416.   6. 168. 292.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 416.   6. 168. 292.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.94  -5.19  -3.95  -3.93  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.46  8.95 10.27 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.94\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 416.   6. 168. 292.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.15\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13]\n",
      "probs = [0.12 0.09 0.05 0.09 0.11 0.18 0.09 0.15 0.   0.   0.01 0.04 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -4.93\n",
      "\n",
      "-> i_step = 4543\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 416.   6. 168. 292.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 416.   6. 168. 292.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.94  -5.19  -3.95  -3.93  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.46  8.95 10.27 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.94\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 416.   6. 168. 292.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.15\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.12 0.08 0.06 0.1  0.1  0.16 0.07 0.13 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.12\n",
      "\n",
      "-> i_step = 4544\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = 10.31\n",
      "new_state = [1 4]\n",
      "[ 38. 416.   6. 168. 293.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 416.   6. 168. 293.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.94  -5.19  -3.95  -3.91  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.46  8.95 10.27 11.15 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.94\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 416.   6. 168. 293.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.05 0.1  0.12 0.17 0.08 0.13 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.07\n",
      "\n",
      "-> i_step = 4545\n",
      "cur_state = [1 4]\n",
      "action = 0\n",
      "reward = -8.41\n",
      "new_state = [2 0]\n",
      "[ 38. 416.   6. 168. 293.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 416.   6. 168. 293.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.94  -5.19  -3.95  -3.91  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.46  8.95 10.27 11.15 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.94\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 416.   6. 168. 293.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.08 0.07 0.1  0.1  0.16 0.09 0.14 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.10\n",
      "\n",
      "-> i_step = 4546\n",
      "cur_state = [2 0]\n",
      "action = 1\n",
      "reward = 2.48\n",
      "new_state = [3 1]\n",
      "[ 38. 416.   6. 168. 293.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 416.   6. 168. 293.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.94  -5.19  -3.95  -3.91  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.46  8.95 10.27 11.15 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.94\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 416.   6. 168. 293.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.11 0.06 0.09 0.11 0.16 0.08 0.12 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.14\n",
      "\n",
      "-> i_step = 4547\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 416.   6. 168. 293.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 416.   6. 168. 293.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.94  -5.19  -3.95  -3.91  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.46  8.95 10.27 11.15 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.94\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 416.   6. 168. 293.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.05 0.11 0.1  0.15 0.09 0.14 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.03\n",
      "\n",
      "-> i_step = 4548\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = -10.36\n",
      "new_state = [1 4]\n",
      "[ 38. 416.   6. 168. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 416.   6. 168. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.94  -5.19  -3.95  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.46  8.95 10.27 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.94\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 416.   6. 168. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.15\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.08 0.1  0.04 0.11 0.11 0.18 0.09 0.11 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.16\n",
      "\n",
      "-> i_step = 4549\n",
      "cur_state = [1 4]\n",
      "action = 0\n",
      "reward = -2.71\n",
      "new_state = [2 0]\n",
      "[ 38. 416.   6. 168. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 416.   6. 168. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.94  -5.19  -3.95  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.46  8.95 10.27 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.94\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 416.   6. 168. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.15\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.05 0.09 0.11 0.16 0.07 0.15 0.   0.   0.01 0.04 0.   0.11\n",
      " 0.   0.  ]\n",
      "Q_est = -5.11\n",
      "\n",
      "-> i_step = 4550\n",
      "cur_state = [2 0]\n",
      "action = 1\n",
      "reward = -9.78\n",
      "new_state = [3 1]\n",
      "[ 38. 416.   6. 168. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 416.   6. 168. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.94  -5.19  -3.95  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.46  8.95 10.27 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.94\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 416.   6. 168. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.15\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.05 0.09 0.11 0.18 0.08 0.14 0.   0.   0.02 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.03\n",
      "\n",
      "-> i_step = 4551\n",
      "cur_state = [3 1]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 416.   6. 168. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 416.   6. 168. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.94  -5.19  -3.95  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.46  8.95 10.27 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.94\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 416.   6. 168. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.15\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.04 0.08 0.1  0.18 0.08 0.15 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.09\n",
      "\n",
      "-> i_step = 4552\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -1.87\n",
      "new_state = [1 1]\n",
      "[ 38. 417.   6. 168. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 168. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.95  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.27 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 168. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.16\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.05 0.08 0.1  0.15 0.08 0.14 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.18\n",
      "\n",
      "-> i_step = 4553\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 11.60\n",
      "new_state = [2 5]\n",
      "[ 38. 417.   6. 168. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 168. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.95  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.27 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 168. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.16\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.07 0.1  0.1  0.15 0.08 0.14 0.   0.   0.02 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.15\n",
      "\n",
      "-> i_step = 4554\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -1.63\n",
      "new_state = [3 5]\n",
      "[ 38. 417.   6. 168. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 168. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.95  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.27 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 168. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.16\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.05 0.09 0.13 0.19 0.08 0.12 0.   0.   0.02 0.04 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -4.96\n",
      "\n",
      "-> i_step = 4555\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 417.   6. 168. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 168. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.95  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.27 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 168. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.16\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.09 0.1  0.15 0.07 0.13 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.26\n",
      "\n",
      "-> i_step = 4556\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 9.63\n",
      "new_state = [1 3]\n",
      "[ 38. 417.   6. 169. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 169. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.92  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.25 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 169. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.15\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "probs = [0.11 0.08 0.06 0.11 0.1  0.17 0.08 0.14 0.   0.   0.01 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.02\n",
      "\n",
      "-> i_step = 4557\n",
      "cur_state = [1 3]\n",
      "action = 3\n",
      "reward = 3.48\n",
      "new_state = [2 3]\n",
      "[ 38. 417.   6. 169. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 169. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.92  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.25 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 169. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.15\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.06 0.08 0.11 0.16 0.08 0.14 0.   0.   0.02 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.18\n",
      "\n",
      "-> i_step = 4558\n",
      "cur_state = [2 3]\n",
      "action = 2\n",
      "reward = -4.38\n",
      "new_state = [3 2]\n",
      "[ 38. 417.   6. 169. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 169. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.92  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.25 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 169. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.15\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.04 0.09 0.08 0.17 0.08 0.14 0.   0.   0.02 0.07 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.27\n",
      "\n",
      "-> i_step = 4559\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 417.   6. 169. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 169. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.92  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.25 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 169. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.15\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.08 0.06 0.09 0.11 0.17 0.09 0.14 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.06\n",
      "\n",
      "-> i_step = 4560\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 14.07\n",
      "new_state = [1 3]\n",
      "[ 38. 417.   6. 170. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 170. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.85  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.26 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 170. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.05 0.09 0.1  0.16 0.08 0.13 0.   0.   0.02 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.18\n",
      "\n",
      "-> i_step = 4561\n",
      "cur_state = [1 3]\n",
      "action = 3\n",
      "reward = 24.54\n",
      "new_state = [2 3]\n",
      "[ 38. 417.   6. 170. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 170. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.85  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.26 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 170. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.06 0.1  0.09 0.16 0.09 0.12 0.   0.   0.02 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.23\n",
      "\n",
      "-> i_step = 4562\n",
      "cur_state = [2 3]\n",
      "action = 2\n",
      "reward = -10.22\n",
      "new_state = [3 2]\n",
      "[ 38. 417.   6. 170. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 170. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.85  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.26 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 170. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.12 0.05 0.09 0.12 0.16 0.09 0.12 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.97\n",
      "\n",
      "-> i_step = 4563\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 417.   6. 170. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 170. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.85  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.26 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 170. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.09 0.1  0.18 0.1  0.11 0.   0.   0.01 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.05\n",
      "\n",
      "-> i_step = 4564\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 17.66\n",
      "new_state = [1 3]\n",
      "[ 38. 417.   6. 171. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 171. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.77  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.28 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 171. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.13\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "probs = [0.12 0.09 0.05 0.1  0.1  0.17 0.1  0.12 0.   0.   0.01 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.11\n",
      "\n",
      "-> i_step = 4565\n",
      "cur_state = [1 3]\n",
      "action = 3\n",
      "reward = -5.40\n",
      "new_state = [2 3]\n",
      "[ 38. 417.   6. 171. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 171. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.77  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.28 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 171. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.13\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.05 0.1  0.11 0.19 0.08 0.12 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.04\n",
      "\n",
      "-> i_step = 4566\n",
      "cur_state = [2 3]\n",
      "action = 2\n",
      "reward = 5.63\n",
      "new_state = [3 2]\n",
      "[ 38. 417.   6. 171. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 171. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.77  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.28 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 171. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.13\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.04 0.1  0.09 0.17 0.08 0.15 0.   0.   0.01 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.06\n",
      "\n",
      "-> i_step = 4567\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 417.   6. 171. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 171. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.77  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.28 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 171. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.13\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.08 0.05 0.09 0.1  0.18 0.09 0.13 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.10\n",
      "\n",
      "-> i_step = 4568\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 9.03\n",
      "new_state = [1 3]\n",
      "[ 38. 417.   6. 172. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 172. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.74  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.26 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 172. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.08 0.06 0.1  0.11 0.16 0.1  0.13 0.   0.   0.03 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.07\n",
      "\n",
      "-> i_step = 4569\n",
      "cur_state = [1 3]\n",
      "action = 3\n",
      "reward = 15.74\n",
      "new_state = [2 3]\n",
      "[ 38. 417.   6. 172. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 172. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.74  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.26 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 172. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.13 0.1  0.05 0.09 0.11 0.17 0.08 0.11 0.   0.   0.02 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.14\n",
      "\n",
      "-> i_step = 4570\n",
      "cur_state = [2 3]\n",
      "action = 2\n",
      "reward = 5.81\n",
      "new_state = [3 2]\n",
      "[ 38. 417.   6. 172. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 172. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.74  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.26 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 172. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.08 0.1  0.19 0.1  0.14 0.   0.   0.02 0.03 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.91\n",
      "\n",
      "-> i_step = 4571\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 417.   6. 172. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 172. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.74  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.26 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 172. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.12\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.06 0.08 0.11 0.19 0.09 0.13 0.   0.   0.02 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.02\n",
      "\n",
      "-> i_step = 4572\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -13.89\n",
      "new_state = [1 3]\n",
      "[ 38. 417.   6. 173. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 173. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.84  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.32 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 173. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.06 0.1  0.1  0.17 0.09 0.11 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.03\n",
      "\n",
      "-> i_step = 4573\n",
      "cur_state = [1 3]\n",
      "action = 3\n",
      "reward = -24.36\n",
      "new_state = [2 3]\n",
      "[ 38. 417.   6. 173. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 173. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.84  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.32 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 173. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.13 0.08 0.05 0.1  0.12 0.19 0.08 0.12 0.   0.   0.02 0.04 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -4.97\n",
      "\n",
      "-> i_step = 4574\n",
      "cur_state = [2 3]\n",
      "action = 2\n",
      "reward = 5.42\n",
      "new_state = [3 2]\n",
      "[ 38. 417.   6. 173. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 173. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.84  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.32 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 173. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.09 0.12 0.17 0.08 0.14 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.05\n",
      "\n",
      "-> i_step = 4575\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 417.   6. 173. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 173. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.84  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.32 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 173. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.11 0.11 0.04 0.1  0.1  0.18 0.09 0.13 0.   0.   0.02 0.06 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -5.07\n",
      "\n",
      "-> i_step = 4576\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -4.87\n",
      "new_state = [1 3]\n",
      "[ 38. 417.   6. 174. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 174. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.89  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.31 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 174. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.15\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.09 0.12 0.05 0.09 0.1  0.18 0.08 0.13 0.   0.   0.02 0.05 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -5.04\n",
      "\n",
      "-> i_step = 4577\n",
      "cur_state = [1 3]\n",
      "action = 3\n",
      "reward = 7.27\n",
      "new_state = [2 3]\n",
      "[ 38. 417.   6. 174. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 174. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.89  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.31 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 174. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.15\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.04 0.09 0.11 0.16 0.08 0.14 0.   0.   0.02 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.17\n",
      "\n",
      "-> i_step = 4578\n",
      "cur_state = [2 3]\n",
      "action = 2\n",
      "reward = -13.23\n",
      "new_state = [3 2]\n",
      "[ 38. 417.   6. 174. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 174. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.89  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.31 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 174. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.15\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.06 0.09 0.13 0.15 0.07 0.15 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.12\n",
      "\n",
      "-> i_step = 4579\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 417.   6. 174. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 174. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.89  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.31 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 174. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.15\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.13 0.1  0.06 0.08 0.09 0.16 0.1  0.13 0.   0.   0.01 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.08\n",
      "\n",
      "-> i_step = 4580\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 11.69\n",
      "new_state = [1 3]\n",
      "[ 38. 417.   6. 175. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 175. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.84  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.3  11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 175. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.05 0.09 0.12 0.15 0.1  0.11 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.09\n",
      "\n",
      "-> i_step = 4581\n",
      "cur_state = [1 3]\n",
      "action = 5\n",
      "reward = 2.03\n",
      "new_state = [2 5]\n",
      "[ 38. 417.   6. 175. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 175. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.84  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.3  11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 175. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.13 0.1  0.04 0.1  0.1  0.16 0.09 0.12 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.07\n",
      "\n",
      "-> i_step = 4582\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 2.70\n",
      "new_state = [3 5]\n",
      "[ 38. 417.   6. 175. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 175. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.84  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.3  11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 175. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.1  0.1  0.05 0.07 0.12 0.18 0.09 0.12 0.   0.   0.02 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.22\n",
      "\n",
      "-> i_step = 4583\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 417.   6. 175. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 175. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.84  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.3  11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 175. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.06 0.1  0.1  0.15 0.09 0.13 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.17\n",
      "\n",
      "-> i_step = 4584\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 16.37\n",
      "new_state = [1 3]\n",
      "[ 38. 417.   6. 176. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 176. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.77  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.31 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 176. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.13\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.1  0.09 0.06 0.1  0.11 0.17 0.08 0.12 0.   0.   0.01 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.15\n",
      "\n",
      "-> i_step = 4585\n",
      "cur_state = [1 3]\n",
      "action = 3\n",
      "reward = -1.12\n",
      "new_state = [2 3]\n",
      "[ 38. 417.   6. 176. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 176. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.77  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.31 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 176. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.13\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.04 0.1  0.12 0.17 0.09 0.12 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.99\n",
      "\n",
      "-> i_step = 4586\n",
      "cur_state = [2 3]\n",
      "action = 2\n",
      "reward = -4.69\n",
      "new_state = [3 2]\n",
      "[ 38. 417.   6. 176. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 176. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.77  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.31 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 176. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.13\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13]\n",
      "probs = [0.12 0.09 0.05 0.11 0.1  0.16 0.09 0.13 0.   0.   0.03 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.11\n",
      "\n",
      "-> i_step = 4587\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 417.   6. 176. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 176. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.77  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.31 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.15 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 176. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.13\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.11 0.1  0.07 0.1  0.1  0.15 0.08 0.13 0.   0.   0.02 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.07\n",
      "\n",
      "-> i_step = 4588\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -11.48\n",
      "new_state = [1 3]\n",
      "[ 38. 417.   6. 177. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 177. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.85  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.35 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 177. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.09 0.09 0.05 0.09 0.12 0.15 0.08 0.15 0.   0.   0.02 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.20\n",
      "\n",
      "-> i_step = 4589\n",
      "cur_state = [1 3]\n",
      "action = 3\n",
      "reward = 2.52\n",
      "new_state = [2 3]\n",
      "[ 38. 417.   6. 177. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 177. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.85  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.35 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 177. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.12 0.1  0.05 0.09 0.12 0.16 0.1  0.12 0.   0.   0.02 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -4.95\n",
      "\n",
      "-> i_step = 4590\n",
      "cur_state = [2 3]\n",
      "action = 2\n",
      "reward = -4.16\n",
      "new_state = [3 2]\n",
      "[ 38. 417.   6. 177. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 177. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.85  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.35 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 177. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.12 0.08 0.06 0.09 0.1  0.16 0.09 0.14 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.04\n",
      "\n",
      "-> i_step = 4591\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 417.   6. 177. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 177. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.85  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.35 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 177. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.14\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.11 0.04 0.09 0.11 0.16 0.08 0.13 0.   0.   0.01 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.10\n",
      "\n",
      "-> i_step = 4592\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -8.64\n",
      "new_state = [1 3]\n",
      "[ 38. 417.   6. 178. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 178. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ -4.4   -3.95  -5.19  -3.92  -3.96  -4.    -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.7 ]\n",
      "[11.82 10.45  8.95 10.36 11.16 14.86 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  3.13]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -3.95\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 417.   6. 178. 294.  49.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.15\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.1  0.1  0.17 0.09 0.11 0.   0.   0.01 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.06\n",
      "\n",
      "-> i_step = 4593\n",
      "cur_state = [1 3]\n",
      "action = 3\n",
      "reward = -12.32\n",
      "new_state = [2 3]\n",
      "[ 38. 417.   6. 178. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]\n",
      "[ 38. 417.   6. 178. 294.  49.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   3.]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reward = 2.26\n",
      "new_state = [2 5]\n",
      "[ 38. 427.   6. 185. 300.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 427.   6. 185. 300.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.05  -5.19  -4.14  -4.05  -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.38  8.95 10.42 11.13 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 427.   6. 185. 300.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.13 0.1  0.07 0.08 0.12 0.18 0.07 0.12 0.   0.   0.02 0.04 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -5.10\n",
      "\n",
      "-> i_step = 4694\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 10.07\n",
      "new_state = [3 5]\n",
      "[ 38. 427.   6. 185. 300.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 427.   6. 185. 300.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.05  -5.19  -4.14  -4.05  -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.38  8.95 10.42 11.13 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 427.   6. 185. 300.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13]\n",
      "probs = [0.1  0.11 0.04 0.08 0.12 0.17 0.09 0.12 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.21\n",
      "\n",
      "-> i_step = 4695\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 427.   6. 185. 300.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 427.   6. 185. 300.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.05  -5.19  -4.14  -4.05  -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.38  8.95 10.42 11.13 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.05\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 427.   6. 185. 300.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.25\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.11 0.05 0.08 0.11 0.15 0.1  0.14 0.   0.   0.01 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.15\n",
      "\n",
      "-> i_step = 4696\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -10.99\n",
      "new_state = [1 1]\n",
      "[ 38. 428.   6. 185. 300.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 428.   6. 185. 300.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.08  -5.19  -4.14  -4.05  -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.13 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.08\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 428.   6. 185. 300.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.26\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.14 0.1  0.06 0.08 0.1  0.17 0.09 0.12 0.   0.   0.02 0.05 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -5.12\n",
      "\n",
      "-> i_step = 4697\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -2.29\n",
      "new_state = [2 5]\n",
      "[ 38. 428.   6. 185. 300.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 428.   6. 185. 300.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.08  -5.19  -4.14  -4.05  -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.13 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.08\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 428.   6. 185. 300.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.26\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.05 0.09 0.1  0.16 0.1  0.13 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.22\n",
      "\n",
      "-> i_step = 4698\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -1.71\n",
      "new_state = [3 5]\n",
      "[ 38. 428.   6. 185. 300.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 428.   6. 185. 300.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.08  -5.19  -4.14  -4.05  -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.13 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.08\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 428.   6. 185. 300.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.26\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.05 0.1  0.11 0.14 0.12 0.13 0.   0.   0.02 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.24\n",
      "\n",
      "-> i_step = 4699\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 428.   6. 185. 300.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 428.   6. 185. 300.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.08  -5.19  -4.14  -4.05  -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.13 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.08\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 428.   6. 185. 300.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.26\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.09 0.12 0.15 0.09 0.13 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.17\n",
      "\n",
      "-> i_step = 4700\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = 3.63\n",
      "new_state = [1 4]\n",
      "[ 38. 428.   6. 185. 301.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 428.   6. 185. 301.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.08  -5.19  -4.14  -4.05  -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.11 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.08\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 428.   6. 185. 301.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.26\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.11 0.09 0.06 0.09 0.11 0.16 0.09 0.15 0.   0.   0.01 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.17\n",
      "\n",
      "-> i_step = 4701\n",
      "cur_state = [1 4]\n",
      "action = 0\n",
      "reward = 2.59\n",
      "new_state = [2 0]\n",
      "[ 38. 428.   6. 185. 301.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 428.   6. 185. 301.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.08  -5.19  -4.14  -4.05  -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.11 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.08\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 428.   6. 185. 301.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.26\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.04 0.09 0.13 0.16 0.09 0.12 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.15\n",
      "\n",
      "-> i_step = 4702\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = 16.69\n",
      "new_state = [3 7]\n",
      "[ 38. 428.   6. 185. 301.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 428.   6. 185. 301.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.08  -5.19  -4.14  -4.05  -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.11 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.08\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 428.   6. 185. 301.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.26\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.11 0.09 0.05 0.08 0.09 0.18 0.09 0.15 0.   0.   0.02 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.13\n",
      "\n",
      "-> i_step = 4703\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 428.   6. 185. 301.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 428.   6. 185. 301.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.08  -5.19  -4.14  -4.05  -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.11 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.08\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 428.   6. 185. 301.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.26\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.11 0.12 0.15 0.07 0.12 0.   0.   0.01 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.23\n",
      "\n",
      "-> i_step = 4704\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = 6.18\n",
      "new_state = [1 4]\n",
      "[ 38. 428.   6. 185. 302.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 428.   6. 185. 302.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.08  -5.19  -4.14  -4.04  -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.09 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.08\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 428.   6. 185. 302.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.26\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.1  0.09 0.06 0.1  0.11 0.17 0.09 0.12 0.   0.01 0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.18\n",
      "\n",
      "-> i_step = 4705\n",
      "cur_state = [1 4]\n",
      "action = 0\n",
      "reward = -15.47\n",
      "new_state = [2 0]\n",
      "[ 38. 428.   6. 185. 302.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 428.   6. 185. 302.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.08  -5.19  -4.14  -4.04  -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.09 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.08\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 428.   6. 185. 302.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.26\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.11 0.05 0.08 0.09 0.17 0.09 0.12 0.   0.   0.01 0.06 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.26\n",
      "\n",
      "-> i_step = 4706\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = 0.05\n",
      "new_state = [3 7]\n",
      "[ 38. 428.   6. 185. 302.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 428.   6. 185. 302.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.08  -5.19  -4.14  -4.04  -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.09 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.08\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 428.   6. 185. 302.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.26\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.08 0.09 0.16 0.1  0.14 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.16\n",
      "\n",
      "-> i_step = 4707\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 428.   6. 185. 302.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 428.   6. 185. 302.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.08  -5.19  -4.14  -4.04  -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.09 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.08\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 428.   6. 185. 302.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.26\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.04 0.08 0.1  0.17 0.1  0.14 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.20\n",
      "\n",
      "-> i_step = 4708\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = -11.72\n",
      "new_state = [1 4]\n",
      "[ 38. 428.   6. 185. 303.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 428.   6. 185. 303.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.08  -5.19  -4.14  -4.1   -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.11 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.08\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 428.   6. 185. 303.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.27\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.05 0.09 0.11 0.19 0.1  0.12 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.12\n",
      "\n",
      "-> i_step = 4709\n",
      "cur_state = [1 4]\n",
      "action = 7\n",
      "reward = -0.94\n",
      "new_state = [2 7]\n",
      "[ 38. 428.   6. 185. 303.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 428.   6. 185. 303.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.08  -5.19  -4.14  -4.1   -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.11 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.08\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 428.   6. 185. 303.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.27\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.05 0.08 0.11 0.15 0.09 0.14 0.   0.   0.01 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.22\n",
      "\n",
      "-> i_step = 4710\n",
      "cur_state = [2 7]\n",
      "action = 5\n",
      "reward = 7.03\n",
      "new_state = [3 5]\n",
      "[ 38. 428.   6. 185. 303.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 428.   6. 185. 303.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.08  -5.19  -4.14  -4.1   -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.11 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.08\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 428.   6. 185. 303.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.27\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.04 0.1  0.11 0.14 0.09 0.13 0.   0.   0.01 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.18\n",
      "\n",
      "-> i_step = 4711\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 428.   6. 185. 303.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 428.   6. 185. 303.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.08  -5.19  -4.14  -4.1   -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.11 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.08\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 428.   6. 185. 303.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.27\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.11 0.09 0.06 0.1  0.11 0.14 0.09 0.11 0.   0.   0.02 0.05 0.   0.11\n",
      " 0.   0.  ]\n",
      "Q_est = -5.30\n",
      "\n",
      "-> i_step = 4712\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -6.79\n",
      "new_state = [1 1]\n",
      "[ 38. 429.   6. 185. 303.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 429.   6. 185. 303.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.1   -5.19  -4.14  -4.1   -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.11 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.10\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 429.   6. 185. 303.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.28\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.1  0.1  0.05 0.09 0.12 0.17 0.09 0.11 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.30\n",
      "\n",
      "-> i_step = 4713\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -20.65\n",
      "new_state = [2 5]\n",
      "[ 38. 429.   6. 185. 303.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 429.   6. 185. 303.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.1   -5.19  -4.14  -4.1   -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.11 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.10\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 429.   6. 185. 303.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.28\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.08 0.07 0.09 0.09 0.16 0.1  0.13 0.   0.01 0.02 0.05 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.30\n",
      "\n",
      "-> i_step = 4714\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 8.57\n",
      "new_state = [3 5]\n",
      "[ 38. 429.   6. 185. 303.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 429.   6. 185. 303.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.1   -5.19  -4.14  -4.1   -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.11 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.10\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 429.   6. 185. 303.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.28\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.05 0.09 0.08 0.17 0.09 0.14 0.   0.   0.02 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.28\n",
      "\n",
      "-> i_step = 4715\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 429.   6. 185. 303.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 429.   6. 185. 303.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.1   -5.19  -4.14  -4.1   -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.11 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.10\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 429.   6. 185. 303.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.28\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.04 0.1  0.12 0.16 0.09 0.13 0.   0.   0.01 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.06\n",
      "\n",
      "-> i_step = 4716\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = -8.42\n",
      "new_state = [1 4]\n",
      "[ 38. 429.   6. 185. 304.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 429.   6. 185. 304.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.1   -5.19  -4.14  -4.14  -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.11 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.10\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 429.   6. 185. 304.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.05 0.09 0.12 0.15 0.07 0.15 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.18\n",
      "\n",
      "-> i_step = 4717\n",
      "cur_state = [1 4]\n",
      "action = 0\n",
      "reward = -8.19\n",
      "new_state = [2 0]\n",
      "[ 38. 429.   6. 185. 304.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 429.   6. 185. 304.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.1   -5.19  -4.14  -4.14  -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.11 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.10\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 429.   6. 185. 304.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.08 0.05 0.1  0.13 0.19 0.08 0.13 0.   0.   0.02 0.05 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -5.11\n",
      "\n",
      "-> i_step = 4718\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = -4.05\n",
      "new_state = [3 7]\n",
      "[ 38. 429.   6. 185. 304.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 429.   6. 185. 304.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.1   -5.19  -4.14  -4.14  -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.11 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.10\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 429.   6. 185. 304.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.05 0.1  0.1  0.15 0.09 0.14 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.11\n",
      "\n",
      "-> i_step = 4719\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 429.   6. 185. 304.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 429.   6. 185. 304.  50.  30. 100.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.1   -5.19  -4.14  -4.14  -4.24  -4.28  -4.1  -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.11 14.81 10.3  12.74  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.10\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 429.   6. 185. 304.  50.  30. 100.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.14 0.08 0.06 0.09 0.1  0.17 0.09 0.12 0.   0.   0.02 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.14\n",
      "\n",
      "-> i_step = 4720\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = -0.19\n",
      "new_state = [1 7]\n",
      "[ 38. 429.   6. 185. 304.  50.  30. 101.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 429.   6. 185. 304.  50.  30. 101.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.1   -5.19  -4.14  -4.14  -4.24  -4.28  -4.13 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.11 14.81 10.3  12.68  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.10\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 429.   6. 185. 304.  50.  30. 101.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.12 0.1  0.06 0.08 0.1  0.17 0.1  0.12 0.   0.   0.02 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.21\n",
      "\n",
      "-> i_step = 4721\n",
      "cur_state = [1 7]\n",
      "action = 0\n",
      "reward = 1.03\n",
      "new_state = [2 0]\n",
      "[ 38. 429.   6. 185. 304.  50.  30. 101.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 429.   6. 185. 304.  50.  30. 101.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.1   -5.19  -4.14  -4.14  -4.24  -4.28  -4.13 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.11 14.81 10.3  12.68  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.10\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 429.   6. 185. 304.  50.  30. 101.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.09 0.1  0.17 0.08 0.14 0.   0.01 0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.14\n",
      "\n",
      "-> i_step = 4722\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = 4.14\n",
      "new_state = [3 7]\n",
      "[ 38. 429.   6. 185. 304.  50.  30. 101.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 429.   6. 185. 304.  50.  30. 101.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.1   -5.19  -4.14  -4.14  -4.24  -4.28  -4.13 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.11 14.81 10.3  12.68  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.10\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 429.   6. 185. 304.  50.  30. 101.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.12 0.1  0.05 0.09 0.11 0.18 0.08 0.13 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.19\n",
      "\n",
      "-> i_step = 4723\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 429.   6. 185. 304.  50.  30. 101.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 429.   6. 185. 304.  50.  30. 101.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.1   -5.19  -4.14  -4.14  -4.24  -4.28  -4.13 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.11 14.81 10.3  12.68  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.10\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 429.   6. 185. 304.  50.  30. 101.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.29\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.11 0.1  0.06 0.09 0.1  0.17 0.09 0.14 0.   0.   0.02 0.03 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.08\n",
      "\n",
      "-> i_step = 4724\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -17.26\n",
      "new_state = [1 1]\n",
      "[ 38. 430.   6. 185. 304.  50.  30. 101.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 430.   6. 185. 304.  50.  30. 101.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.14  -4.14  -4.24  -4.28  -4.13 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.42  8.95 10.42 11.11 14.81 10.3  12.68  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 430.   6. 185. 304.  50.  30. 101.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.08 0.12 0.16 0.07 0.13 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.29\n",
      "\n",
      "-> i_step = 4725\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -4.95\n",
      "new_state = [2 5]\n",
      "[ 38. 430.   6. 185. 304.  50.  30. 101.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 430.   6. 185. 304.  50.  30. 101.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.14  -4.14  -4.24  -4.28  -4.13 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.42  8.95 10.42 11.11 14.81 10.3  12.68  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 430.   6. 185. 304.  50.  30. 101.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.09 0.09 0.06 0.1  0.11 0.16 0.08 0.13 0.   0.   0.01 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.33\n",
      "\n",
      "-> i_step = 4726\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 7.27\n",
      "new_state = [3 5]\n",
      "[ 38. 430.   6. 185. 304.  50.  30. 101.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 430.   6. 185. 304.  50.  30. 101.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.14  -4.14  -4.24  -4.28  -4.13 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.42  8.95 10.42 11.11 14.81 10.3  12.68  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 430.   6. 185. 304.  50.  30. 101.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.05 0.1  0.11 0.17 0.09 0.14 0.   0.   0.02 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.25\n",
      "\n",
      "-> i_step = 4727\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 430.   6. 185. 304.  50.  30. 101.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 430.   6. 185. 304.  50.  30. 101.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.14  -4.14  -4.24  -4.28  -4.13 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.42  8.95 10.42 11.11 14.81 10.3  12.68  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 430.   6. 185. 304.  50.  30. 101.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.31\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.05 0.1  0.1  0.18 0.09 0.13 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.13\n",
      "\n",
      "-> i_step = 4728\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = -5.62\n",
      "new_state = [1 7]\n",
      "[ 38. 430.   6. 185. 304.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 430.   6. 185. 304.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.14  -4.14  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.42  8.95 10.42 11.11 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 430.   6. 185. 304.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.32\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.09 0.09 0.16 0.08 0.13 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.33\n",
      "\n",
      "-> i_step = 4729\n",
      "cur_state = [1 7]\n",
      "action = 0\n",
      "reward = 8.35\n",
      "new_state = [2 0]\n",
      "[ 38. 430.   6. 185. 304.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 430.   6. 185. 304.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.14  -4.14  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.42  8.95 10.42 11.11 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 430.   6. 185. 304.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.32\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.08 0.08 0.1  0.1  0.15 0.09 0.11 0.   0.   0.01 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.30\n",
      "\n",
      "-> i_step = 4730\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = -14.40\n",
      "new_state = [3 7]\n",
      "[ 38. 430.   6. 185. 304.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 430.   6. 185. 304.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.14  -4.14  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.42  8.95 10.42 11.11 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 430.   6. 185. 304.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.32\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.05 0.09 0.1  0.15 0.1  0.13 0.   0.   0.01 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.26\n",
      "\n",
      "-> i_step = 4731\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 430.   6. 185. 304.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 430.   6. 185. 304.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.14  -4.14  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.42  8.95 10.42 11.11 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 430.   6. 185. 304.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.32\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.07 0.07 0.08 0.11 0.18 0.07 0.14 0.   0.   0.01 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.26\n",
      "\n",
      "-> i_step = 4732\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = 2.81\n",
      "new_state = [1 4]\n",
      "[ 38. 430.   6. 185. 305.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 430.   6. 185. 305.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.14  -4.14  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.42  8.95 10.42 11.1  14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 430.   6. 185. 305.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.32\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.05 0.09 0.1  0.19 0.08 0.14 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.18\n",
      "\n",
      "-> i_step = 4733\n",
      "cur_state = [1 4]\n",
      "action = 0\n",
      "reward = -4.44\n",
      "new_state = [2 0]\n",
      "[ 38. 430.   6. 185. 305.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 430.   6. 185. 305.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.14  -4.14  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.42  8.95 10.42 11.1  14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 430.   6. 185. 305.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.32\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.11 0.09 0.04 0.09 0.1  0.15 0.11 0.13 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.24\n",
      "\n",
      "-> i_step = 4734\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = -0.92\n",
      "new_state = [3 7]\n",
      "[ 38. 430.   6. 185. 305.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 430.   6. 185. 305.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.14  -4.14  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.42  8.95 10.42 11.1  14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 430.   6. 185. 305.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.32\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.08 0.06 0.1  0.11 0.15 0.07 0.15 0.   0.01 0.01 0.05 0.   0.1\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.27\n",
      "\n",
      "-> i_step = 4735\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 430.   6. 185. 305.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 430.   6. 185. 305.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.14  -4.14  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.42  8.95 10.42 11.1  14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 430.   6. 185. 305.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.32\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.05 0.1  0.09 0.16 0.09 0.13 0.   0.   0.02 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.33\n",
      "\n",
      "-> i_step = 4736\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = -6.57\n",
      "new_state = [1 4]\n",
      "[ 38. 430.   6. 185. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 430.   6. 185. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.14  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.42  8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 430.   6. 185. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.33\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.05 0.11 0.12 0.16 0.08 0.14 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.16\n",
      "\n",
      "-> i_step = 4737\n",
      "cur_state = [1 4]\n",
      "action = 7\n",
      "reward = -12.21\n",
      "new_state = [2 7]\n",
      "[ 38. 430.   6. 185. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 430.   6. 185. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.14  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.42  8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 430.   6. 185. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.33\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.1  0.1  0.06 0.1  0.09 0.16 0.09 0.11 0.   0.   0.02 0.06 0.   0.1\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.38\n",
      "\n",
      "-> i_step = 4738\n",
      "cur_state = [2 7]\n",
      "action = 5\n",
      "reward = 10.56\n",
      "new_state = [3 5]\n",
      "[ 38. 430.   6. 185. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 430.   6. 185. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.14  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.42  8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 430.   6. 185. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.33\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.11 0.05 0.09 0.1  0.17 0.07 0.13 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.22\n",
      "\n",
      "-> i_step = 4739\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 430.   6. 185. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 430.   6. 185. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.14  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.42  8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 430.   6. 185. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.33\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.13 0.1  0.05 0.1  0.09 0.17 0.08 0.14 0.   0.   0.03 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.20\n",
      "\n",
      "-> i_step = 4740\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -6.20\n",
      "new_state = [1 3]\n",
      "[ 38. 430.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 430.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.42  8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 430.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.34\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "probs = [0.11 0.1  0.07 0.08 0.11 0.16 0.08 0.13 0.   0.   0.02 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.25\n",
      "\n",
      "-> i_step = 4741\n",
      "cur_state = [1 3]\n",
      "action = 7\n",
      "reward = 1.64\n",
      "new_state = [2 7]\n",
      "[ 38. 430.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 430.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.42  8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 430.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.34\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.09 0.1  0.18 0.1  0.12 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.18\n",
      "\n",
      "-> i_step = 4742\n",
      "cur_state = [2 7]\n",
      "action = 5\n",
      "reward = 11.23\n",
      "new_state = [3 5]\n",
      "[ 38. 430.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 430.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.42  8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 430.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.34\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.12 0.08 0.07 0.1  0.1  0.16 0.1  0.11 0.   0.   0.02 0.04 0.   0.08\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.19\n",
      "\n",
      "-> i_step = 4743\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 430.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 430.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.42  8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 430.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.34\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.06 0.08 0.11 0.18 0.09 0.1  0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.30\n",
      "\n",
      "-> i_step = 4744\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 6.62\n",
      "new_state = [1 1]\n",
      "[ 38. 431.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 431.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.14  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.41  8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 431.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.33\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.05 0.09 0.1  0.15 0.09 0.12 0.   0.   0.01 0.07 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.43\n",
      "\n",
      "-> i_step = 4745\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -0.48\n",
      "new_state = [2 5]\n",
      "[ 38. 431.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 431.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.14  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.41  8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 431.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.33\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.06 0.1  0.1  0.15 0.08 0.15 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.28\n",
      "\n",
      "-> i_step = 4746\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -7.97\n",
      "new_state = [3 5]\n",
      "[ 38. 431.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 431.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.14  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.41  8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 431.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.33\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.07 0.08 0.1  0.17 0.1  0.11 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.19\n",
      "\n",
      "-> i_step = 4747\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 431.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 431.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.14  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.41  8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.14\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 431.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.33\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.12 0.09 0.05 0.09 0.1  0.18 0.09 0.13 0.   0.01 0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.23\n",
      "\n",
      "-> i_step = 4748\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 2.58\n",
      "new_state = [1 1]\n",
      "[ 38. 432.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 432.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.4   8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 432.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.33\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.05 0.08 0.11 0.16 0.11 0.13 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.21\n",
      "\n",
      "-> i_step = 4749\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -5.27\n",
      "new_state = [2 5]\n",
      "[ 38. 432.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 432.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.4   8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 432.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.33\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.05 0.1  0.12 0.17 0.09 0.12 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.17\n",
      "\n",
      "-> i_step = 4750\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 3.03\n",
      "new_state = [3 5]\n",
      "[ 38. 432.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 432.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.4   8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 432.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.33\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.08 0.11 0.16 0.11 0.12 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.24\n",
      "\n",
      "-> i_step = 4751\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 432.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 432.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.4   8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 432.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.33\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.08 0.05 0.1  0.1  0.17 0.09 0.14 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.22\n",
      "\n",
      "-> i_step = 4752\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 9.48\n",
      "new_state = [1 1]\n",
      "[ 38. 433.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 433.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.13  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 433.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.33\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.13 0.09 0.05 0.09 0.1  0.17 0.08 0.12 0.   0.   0.01 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.17\n",
      "\n",
      "-> i_step = 4753\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 20.80\n",
      "new_state = [2 5]\n",
      "[ 38. 433.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 433.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.13  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 433.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.33\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.05 0.09 0.1  0.17 0.09 0.12 0.   0.01 0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.29\n",
      "\n",
      "-> i_step = 4754\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 5.27\n",
      "new_state = [3 5]\n",
      "[ 38. 433.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 433.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.13  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 433.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.33\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.05 0.09 0.1  0.17 0.07 0.13 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.26\n",
      "\n",
      "-> i_step = 4755\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 433.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 433.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.13  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.13\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 433.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.33\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.06 0.08 0.1  0.17 0.09 0.12 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.17\n",
      "\n",
      "-> i_step = 4756\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -10.54\n",
      "new_state = [1 1]\n",
      "[ 38. 434.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 434.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.16  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.4   8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.16\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 434.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.34\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.1  0.07 0.06 0.11 0.09 0.19 0.08 0.13 0.   0.   0.01 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.24\n",
      "\n",
      "-> i_step = 4757\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 10.96\n",
      "new_state = [2 5]\n",
      "[ 38. 434.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 434.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.16  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.4   8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.16\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 434.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.34\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.1  0.08 0.06 0.1  0.1  0.16 0.1  0.14 0.   0.   0.02 0.05 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -5.24\n",
      "\n",
      "-> i_step = 4758\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 7.32\n",
      "new_state = [3 5]\n",
      "[ 38. 434.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 434.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.16  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.4   8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.16\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 434.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.34\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.1  0.09 0.06 0.1  0.1  0.15 0.09 0.15 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.29\n",
      "\n",
      "-> i_step = 4759\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 434.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 434.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.16  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.4   8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.16\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 434.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.34\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.11 0.09 0.05 0.09 0.11 0.18 0.09 0.12 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.26\n",
      "\n",
      "-> i_step = 4760\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 11.25\n",
      "new_state = [1 1]\n",
      "[ 38. 435.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 435.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.4   8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 435.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.33\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.05 0.1  0.1  0.16 0.09 0.13 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.25\n",
      "\n",
      "-> i_step = 4761\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -11.23\n",
      "new_state = [2 5]\n",
      "[ 38. 435.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 435.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.4   8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 435.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.33\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.04 0.11 0.11 0.16 0.1  0.12 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.28\n",
      "\n",
      "-> i_step = 4762\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 1.83\n",
      "new_state = [3 5]\n",
      "[ 38. 435.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 435.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.4   8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 435.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.33\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.09 0.11 0.06 0.09 0.11 0.15 0.1  0.13 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.27\n",
      "\n",
      "-> i_step = 4763\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 435.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 435.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.15  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.4   8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.15\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 435.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.33\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.08 0.1  0.15 0.1  0.14 0.   0.   0.01 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.24\n",
      "\n",
      "-> i_step = 4764\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -1.70\n",
      "new_state = [1 1]\n",
      "[ 38. 436.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 436.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.16  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.16\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 436.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.34\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.08 0.06 0.09 0.13 0.17 0.08 0.13 0.   0.01 0.01 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.26\n",
      "\n",
      "-> i_step = 4765\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -7.26\n",
      "new_state = [2 5]\n",
      "[ 38. 436.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 436.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.16  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.16\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 436.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.34\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.12 0.07 0.06 0.09 0.11 0.15 0.1  0.13 0.   0.   0.02 0.05 0.   0.11\n",
      " 0.   0.  ]\n",
      "Q_est = -5.27\n",
      "\n",
      "-> i_step = 4766\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -7.73\n",
      "new_state = [3 5]\n",
      "[ 38. 436.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 436.   6. 186. 306.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.16  -5.19  -4.19  -4.17  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.39  8.95 10.42 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.16\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 436.   6. 186. 306.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.34\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.08 0.05 0.1  0.1  0.16 0.09 0.11 0.   0.   0.02 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.35\n",
      "\n",
      "-> i_step = 4767\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action = 3\n",
      "reward = 16.28\n",
      "new_state = [3 3]\n",
      "[ 38. 444.   6. 187. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 444.   6. 187. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.21  -5.19  -4.2   -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.32  8.95 10.39 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.21\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 444.   6. 187. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.1  0.08 0.06 0.11 0.11 0.16 0.08 0.13 0.   0.   0.01 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.23\n",
      "\n",
      "-> i_step = 4807\n",
      "cur_state = [3 3]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 444.   6. 187. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 444.   6. 187. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.21  -5.19  -4.2   -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.32  8.95 10.39 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.21\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 444.   6. 187. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.08 0.08 0.09 0.16 0.09 0.13 0.   0.   0.03 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.30\n",
      "\n",
      "-> i_step = 4808\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 7.36\n",
      "new_state = [1 3]\n",
      "[ 38. 444.   6. 188. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 444.   6. 188. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.21  -5.19  -4.18  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.32  8.95 10.37 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.21\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 444.   6. 188. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.05 0.07 0.09 0.18 0.1  0.13 0.   0.   0.02 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.23\n",
      "\n",
      "-> i_step = 4809\n",
      "cur_state = [1 3]\n",
      "action = 6\n",
      "reward = -3.91\n",
      "new_state = [2 6]\n",
      "[ 38. 444.   6. 188. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 444.   6. 188. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.21  -5.19  -4.18  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.32  8.95 10.37 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.21\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 444.   6. 188. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.05 0.1  0.1  0.17 0.08 0.14 0.   0.   0.02 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.30\n",
      "\n",
      "-> i_step = 4810\n",
      "cur_state = [2 6]\n",
      "action = 7\n",
      "reward = 0.08\n",
      "new_state = [3 7]\n",
      "[ 38. 444.   6. 188. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 444.   6. 188. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.21  -5.19  -4.18  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.32  8.95 10.37 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.21\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 444.   6. 188. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.08 0.06 0.09 0.1  0.18 0.1  0.15 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.20\n",
      "\n",
      "-> i_step = 4811\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 444.   6. 188. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 444.   6. 188. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.21  -5.19  -4.18  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.32  8.95 10.37 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.21\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 444.   6. 188. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.06 0.09 0.12 0.17 0.08 0.13 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.28\n",
      "\n",
      "-> i_step = 4812\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -1.32\n",
      "new_state = [1 3]\n",
      "[ 38. 444.   6. 189. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 444.   6. 189. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.21  -5.19  -4.2   -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.32  8.95 10.35 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.21\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 444.   6. 189. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.06 0.08 0.1  0.19 0.09 0.13 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.21\n",
      "\n",
      "-> i_step = 4813\n",
      "cur_state = [1 3]\n",
      "action = 6\n",
      "reward = -8.14\n",
      "new_state = [2 6]\n",
      "[ 38. 444.   6. 189. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 444.   6. 189. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.21  -5.19  -4.2   -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.32  8.95 10.35 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.21\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 444.   6. 189. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.08 0.06 0.08 0.1  0.17 0.08 0.13 0.   0.   0.02 0.05 0.   0.11\n",
      " 0.   0.  ]\n",
      "Q_est = -5.38\n",
      "\n",
      "-> i_step = 4814\n",
      "cur_state = [2 6]\n",
      "action = 7\n",
      "reward = 5.79\n",
      "new_state = [3 7]\n",
      "[ 38. 444.   6. 189. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 444.   6. 189. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.21  -5.19  -4.2   -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.32  8.95 10.35 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.21\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 444.   6. 189. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.05 0.1  0.11 0.14 0.09 0.14 0.   0.   0.01 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.33\n",
      "\n",
      "-> i_step = 4815\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 444.   6. 189. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 444.   6. 189. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.21  -5.19  -4.2   -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.32  8.95 10.35 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.21\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 444.   6. 189. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.36\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.09 0.09 0.06 0.09 0.11 0.18 0.1  0.12 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.23\n",
      "\n",
      "-> i_step = 4816\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -17.71\n",
      "new_state = [1 3]\n",
      "[ 38. 444.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 444.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.21  -5.19  -4.31  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.32  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.21\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 444.   6. 190. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.38\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.07 0.07 0.08 0.17 0.09 0.13 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.30\n",
      "\n",
      "-> i_step = 4817\n",
      "cur_state = [1 3]\n",
      "action = 3\n",
      "reward = 18.28\n",
      "new_state = [2 3]\n",
      "[ 38. 444.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 444.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.21  -5.19  -4.31  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.32  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.21\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 444.   6. 190. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.38\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.04 0.09 0.1  0.18 0.1  0.13 0.   0.   0.03 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.15\n",
      "\n",
      "-> i_step = 4818\n",
      "cur_state = [2 3]\n",
      "action = 2\n",
      "reward = -5.02\n",
      "new_state = [3 2]\n",
      "[ 38. 444.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 444.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.21  -5.19  -4.31  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.32  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.21\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 444.   6. 190. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.38\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.06 0.08 0.11 0.17 0.08 0.13 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.31\n",
      "\n",
      "-> i_step = 4819\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 444.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 444.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.21  -5.19  -4.31  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.32  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.21\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 444.   6. 190. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.38\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.08 0.06 0.1  0.1  0.15 0.09 0.12 0.   0.   0.02 0.05 0.   0.11\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.39\n",
      "\n",
      "-> i_step = 4820\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 17.61\n",
      "new_state = [1 1]\n",
      "[ 38. 445.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 445.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.17  -5.19  -4.31  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.33  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.17\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 445.   6. 190. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.12 0.06 0.08 0.11 0.16 0.07 0.12 0.   0.   0.01 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.14\n",
      "\n",
      "-> i_step = 4821\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 13.65\n",
      "new_state = [2 5]\n",
      "[ 38. 445.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 445.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.17  -5.19  -4.31  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.33  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.17\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 445.   6. 190. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.06 0.09 0.12 0.15 0.08 0.13 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.25\n",
      "\n",
      "-> i_step = 4822\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -1.23\n",
      "new_state = [3 5]\n",
      "[ 38. 445.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 445.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.17  -5.19  -4.31  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.33  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.17\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 445.   6. 190. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.13 0.09 0.05 0.08 0.08 0.17 0.1  0.13 0.   0.   0.02 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.28\n",
      "\n",
      "-> i_step = 4823\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 445.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 445.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.17  -5.19  -4.31  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.33  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.17\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 445.   6. 190. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.08 0.07 0.1  0.09 0.15 0.1  0.14 0.   0.01 0.01 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.31\n",
      "\n",
      "-> i_step = 4824\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -7.43\n",
      "new_state = [1 1]\n",
      "[ 38. 446.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 446.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.2   -5.19  -4.31  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.33  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 446.   6. 190. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.38\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.12 0.09 0.06 0.09 0.11 0.15 0.09 0.14 0.   0.   0.03 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.21\n",
      "\n",
      "-> i_step = 4825\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 16.94\n",
      "new_state = [2 5]\n",
      "[ 38. 446.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 446.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.2   -5.19  -4.31  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.33  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 446.   6. 190. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.38\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.06 0.08 0.11 0.16 0.1  0.13 0.   0.   0.02 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.36\n",
      "\n",
      "-> i_step = 4826\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 6.21\n",
      "new_state = [3 5]\n",
      "[ 38. 446.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 446.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.2   -5.19  -4.31  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.33  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 446.   6. 190. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.38\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.05 0.1  0.1  0.18 0.09 0.13 0.   0.   0.01 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.26\n",
      "\n",
      "-> i_step = 4827\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 446.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 446.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.2   -5.19  -4.31  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.33  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.20\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 446.   6. 190. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.38\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.05 0.1  0.09 0.17 0.09 0.15 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.18\n",
      "\n",
      "-> i_step = 4828\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 10.10\n",
      "new_state = [1 1]\n",
      "[ 38. 447.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 447.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.18  -5.19  -4.31  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.33  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.18\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 447.   6. 190. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.11 0.09 0.05 0.09 0.08 0.17 0.08 0.14 0.   0.   0.03 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.38\n",
      "\n",
      "-> i_step = 4829\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -16.96\n",
      "new_state = [2 5]\n",
      "[ 38. 447.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 447.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.18  -5.19  -4.31  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.33  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.18\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 447.   6. 190. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.06 0.07 0.11 0.16 0.1  0.14 0.   0.   0.02 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.27\n",
      "\n",
      "-> i_step = 4830\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -4.77\n",
      "new_state = [3 5]\n",
      "[ 38. 447.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 447.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.18  -5.19  -4.31  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.33  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.18\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 447.   6. 190. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.07 0.1  0.1  0.14 0.1  0.11 0.   0.   0.03 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.35\n",
      "\n",
      "-> i_step = 4831\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 447.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 447.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.18  -5.19  -4.31  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.33  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.18\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 447.   6. 190. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.37\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.08 0.06 0.09 0.12 0.16 0.09 0.12 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.38\n",
      "\n",
      "-> i_step = 4832\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -18.11\n",
      "new_state = [1 1]\n",
      "[ 38. 448.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 448.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.23  -5.19  -4.31  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.36  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 448.   6. 190. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.39\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.12 0.1  0.05 0.1  0.11 0.15 0.08 0.14 0.   0.   0.02 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.21\n",
      "\n",
      "-> i_step = 4833\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -0.00\n",
      "new_state = [2 5]\n",
      "[ 38. 448.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 448.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.23  -5.19  -4.31  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.36  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 448.   6. 190. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.39\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.11 0.1  0.05 0.09 0.12 0.16 0.1  0.12 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.22\n",
      "\n",
      "-> i_step = 4834\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -10.87\n",
      "new_state = [3 5]\n",
      "[ 38. 448.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 448.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.23  -5.19  -4.31  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.36  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 448.   6. 190. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.39\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.04 0.11 0.11 0.16 0.09 0.14 0.   0.   0.01 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.26\n",
      "\n",
      "-> i_step = 4835\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 448.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 448.   6. 190. 307.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.23  -5.19  -4.31  -4.21  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.36  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 448.   6. 190. 307.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.39\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.05 0.11 0.1  0.17 0.09 0.14 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.16\n",
      "\n",
      "-> i_step = 4836\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = -6.63\n",
      "new_state = [1 4]\n",
      "[ 38. 448.   6. 190. 308.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 448.   6. 190. 308.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.23  -5.19  -4.31  -4.24  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.36  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 448.   6. 190. 308.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.40\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.05 0.09 0.1  0.17 0.09 0.13 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.33\n",
      "\n",
      "-> i_step = 4837\n",
      "cur_state = [1 4]\n",
      "action = 1\n",
      "reward = -15.74\n",
      "new_state = [2 1]\n",
      "[ 38. 448.   6. 190. 308.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 448.   6. 190. 308.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.23  -5.19  -4.31  -4.24  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.36  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 448.   6. 190. 308.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.40\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.14 0.1  0.05 0.1  0.11 0.15 0.08 0.11 0.   0.   0.01 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.22\n",
      "\n",
      "-> i_step = 4838\n",
      "cur_state = [2 1]\n",
      "action = 2\n",
      "reward = 2.39\n",
      "new_state = [3 2]\n",
      "[ 38. 448.   6. 190. 308.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 448.   6. 190. 308.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.23  -5.19  -4.31  -4.24  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.36  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 448.   6. 190. 308.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.40\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.11 0.1  0.04 0.08 0.1  0.17 0.09 0.12 0.   0.   0.02 0.07 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.41\n",
      "\n",
      "-> i_step = 4839\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 448.   6. 190. 308.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 448.   6. 190. 308.  50.  30. 102.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.23  -5.19  -4.31  -4.24  -4.24  -4.28  -4.22 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.36  8.95 10.43 11.09 14.81 10.3  12.65  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.01 0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 448.   6. 190. 308.  50.  30. 102.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.40\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.14 0.08 0.05 0.1  0.11 0.15 0.07 0.12 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.33\n",
      "\n",
      "-> i_step = 4840\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = -7.20\n",
      "new_state = [1 7]\n",
      "[ 38. 448.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 448.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.23  -5.19  -4.31  -4.24  -4.24  -4.28  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.36  8.95 10.43 11.09 14.81 10.3  12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.02 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 448.   6. 190. 308.  50.  30. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.41\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.05 0.09 0.11 0.15 0.07 0.15 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.30\n",
      "\n",
      "-> i_step = 4841\n",
      "cur_state = [1 7]\n",
      "action = 0\n",
      "reward = -10.23\n",
      "new_state = [2 0]\n",
      "[ 38. 448.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 448.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.23  -5.19  -4.31  -4.24  -4.24  -4.28  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.36  8.95 10.43 11.09 14.81 10.3  12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.02 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 448.   6. 190. 308.  50.  30. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.41\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.08 0.09 0.07 0.1  0.1  0.17 0.1  0.14 0.   0.   0.02 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.21\n",
      "\n",
      "-> i_step = 4842\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = 19.40\n",
      "new_state = [3 7]\n",
      "[ 38. 448.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 448.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.23  -5.19  -4.31  -4.24  -4.24  -4.28  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.36  8.95 10.43 11.09 14.81 10.3  12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.02 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 448.   6. 190. 308.  50.  30. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.41\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.12 0.05 0.09 0.1  0.17 0.09 0.12 0.   0.   0.02 0.05 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -5.27\n",
      "\n",
      "-> i_step = 4843\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 448.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 448.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.23  -5.19  -4.31  -4.24  -4.24  -4.28  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.36  8.95 10.43 11.09 14.81 10.3  12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.02 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 448.   6. 190. 308.  50.  30. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.41\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.05 0.09 0.12 0.16 0.09 0.12 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.22\n",
      "\n",
      "-> i_step = 4844\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 3.32\n",
      "new_state = [1 1]\n",
      "[ 38. 449.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 449.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.23  -5.19  -4.31  -4.24  -4.24  -4.28  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.35  8.95 10.43 11.09 14.81 10.3  12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.02 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 449.   6. 190. 308.  50.  30. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.41\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.12 0.08 0.06 0.1  0.1  0.18 0.1  0.11 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.21\n",
      "\n",
      "-> i_step = 4845\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -10.21\n",
      "new_state = [2 5]\n",
      "[ 38. 449.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 449.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.23  -5.19  -4.31  -4.24  -4.24  -4.28  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.35  8.95 10.43 11.09 14.81 10.3  12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.02 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 449.   6. 190. 308.  50.  30. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.41\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.07 0.1  0.1  0.13 0.09 0.13 0.   0.01 0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.36\n",
      "\n",
      "-> i_step = 4846\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 11.84\n",
      "new_state = [3 5]\n",
      "[ 38. 449.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 449.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.23  -5.19  -4.31  -4.24  -4.24  -4.28  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.35  8.95 10.43 11.09 14.81 10.3  12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.02 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 449.   6. 190. 308.  50.  30. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.41\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.11 0.06 0.08 0.1  0.17 0.09 0.14 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.28\n",
      "\n",
      "-> i_step = 4847\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 449.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 449.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.23  -5.19  -4.31  -4.24  -4.24  -4.28  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.35  8.95 10.43 11.09 14.81 10.3  12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.23\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.02 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 449.   6. 190. 308.  50.  30. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.41\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.06 0.11 0.1  0.17 0.08 0.13 0.   0.   0.02 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.35\n",
      "\n",
      "-> i_step = 4848\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -26.79\n",
      "new_state = [1 1]\n",
      "[ 38. 450.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 450.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.3   -5.19  -4.31  -4.24  -4.24  -4.28  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.09 14.81 10.3  12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.02 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 450.   6. 190. 308.  50.  30. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.43\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "probs = [0.11 0.1  0.07 0.09 0.11 0.16 0.09 0.12 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.19\n",
      "\n",
      "-> i_step = 4849\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -12.80\n",
      "new_state = [2 5]\n",
      "[ 38. 450.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 450.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.3   -5.19  -4.31  -4.24  -4.24  -4.28  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.09 14.81 10.3  12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.02 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 450.   6. 190. 308.  50.  30. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.43\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.1  0.11 0.15 0.1  0.11 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.29\n",
      "\n",
      "-> i_step = 4850\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 19.24\n",
      "new_state = [3 5]\n",
      "[ 38. 450.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 450.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.3   -5.19  -4.31  -4.24  -4.24  -4.28  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.09 14.81 10.3  12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.02 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 450.   6. 190. 308.  50.  30. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.43\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.08 0.07 0.09 0.1  0.17 0.08 0.13 0.   0.   0.02 0.06 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.42\n",
      "\n",
      "-> i_step = 4851\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 450.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 450.   6. 190. 308.  50.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.3   -5.19  -4.31  -4.24  -4.24  -4.28  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.09 14.81 10.3  12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.02 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 450.   6. 190. 308.  50.  30. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.43\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.12 0.09 0.05 0.1  0.11 0.16 0.07 0.14 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.27\n",
      "\n",
      "-> i_step = 4852\n",
      "cur_state = [0 0]\n",
      "action = 5\n",
      "reward = -0.34\n",
      "new_state = [1 5]\n",
      "[ 38. 450.   6. 190. 308.  51.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 450.   6. 190. 308.  51.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.3   -5.19  -4.31  -4.24  -4.32  -4.28  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.09 14.67 10.3  12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.02 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 450.   6. 190. 308.  51.  30. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.44\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.12 0.08 0.06 0.09 0.1  0.17 0.1  0.13 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.30\n",
      "\n",
      "-> i_step = 4853\n",
      "cur_state = [1 5]\n",
      "action = 1\n",
      "reward = -3.23\n",
      "new_state = [2 1]\n",
      "[ 38. 450.   6. 190. 308.  51.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 450.   6. 190. 308.  51.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.3   -5.19  -4.31  -4.24  -4.32  -4.28  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.09 14.67 10.3  12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.02 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 450.   6. 190. 308.  51.  30. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.44\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.07 0.08 0.1  0.16 0.09 0.13 0.   0.   0.02 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.42\n",
      "\n",
      "-> i_step = 4854\n",
      "cur_state = [2 1]\n",
      "action = 5\n",
      "reward = -2.84\n",
      "new_state = [3 5]\n",
      "[ 38. 450.   6. 190. 308.  51.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 450.   6. 190. 308.  51.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.3   -5.19  -4.31  -4.24  -4.32  -4.28  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.09 14.67 10.3  12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.02 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 450.   6. 190. 308.  51.  30. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.44\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.12 0.1  0.05 0.08 0.1  0.15 0.1  0.14 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.31\n",
      "\n",
      "-> i_step = 4855\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 450.   6. 190. 308.  51.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 450.   6. 190. 308.  51.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.3   -5.19  -4.31  -4.24  -4.32  -4.28  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.09 14.67 10.3  12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.02 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 450.   6. 190. 308.  51.  30. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.44\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.09 0.11 0.16 0.09 0.14 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.31\n",
      "\n",
      "-> i_step = 4856\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = -14.23\n",
      "new_state = [1 4]\n",
      "[ 38. 450.   6. 190. 309.  51.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 450.   6. 190. 309.  51.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.3   -5.19  -4.31  -4.3   -4.32  -4.28  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.12 14.67 10.3  12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.02 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 450.   6. 190. 309.  51.  30. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.45\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.04 0.1  0.11 0.17 0.1  0.13 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.21\n",
      "\n",
      "-> i_step = 4857\n",
      "cur_state = [1 4]\n",
      "action = 0\n",
      "reward = 8.21\n",
      "new_state = [2 0]\n",
      "[ 38. 450.   6. 190. 309.  51.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 450.   6. 190. 309.  51.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.3   -5.19  -4.31  -4.3   -4.32  -4.28  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.12 14.67 10.3  12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.02 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 450.   6. 190. 309.  51.  30. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.45\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.08 0.06 0.09 0.1  0.15 0.08 0.14 0.   0.   0.03 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.39\n",
      "\n",
      "-> i_step = 4858\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = 10.08\n",
      "new_state = [3 7]\n",
      "[ 38. 450.   6. 190. 309.  51.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 450.   6. 190. 309.  51.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.3   -5.19  -4.31  -4.3   -4.32  -4.28  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.12 14.67 10.3  12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.02 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 450.   6. 190. 309.  51.  30. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.45\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.07 0.1  0.1  0.16 0.09 0.13 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.32\n",
      "\n",
      "-> i_step = 4859\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 450.   6. 190. 309.  51.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 450.   6. 190. 309.  51.  30. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.3   -5.19  -4.31  -4.3   -4.32  -4.28  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.12 14.67 10.3  12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.02 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 450.   6. 190. 309.  51.  30. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.45\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.08 0.06 0.1  0.1  0.16 0.1  0.13 0.   0.   0.02 0.03 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.20\n",
      "\n",
      "-> i_step = 4860\n",
      "cur_state = [0 0]\n",
      "action = 6\n",
      "reward = -7.52\n",
      "new_state = [1 6]\n",
      "[ 38. 450.   6. 190. 309.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 450.   6. 190. 309.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.3   -5.19  -4.31  -4.3   -4.32  -4.65  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.12 14.67 10.34 12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 450.   6. 190. 309.  51.  31. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.46\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.12 0.08 0.07 0.1  0.11 0.17 0.08 0.13 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.22\n",
      "\n",
      "-> i_step = 4861\n",
      "cur_state = [1 6]\n",
      "action = 1\n",
      "reward = -4.51\n",
      "new_state = [2 1]\n",
      "[ 38. 450.   6. 190. 309.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 450.   6. 190. 309.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.3   -5.19  -4.31  -4.3   -4.32  -4.65  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.12 14.67 10.34 12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 450.   6. 190. 309.  51.  31. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.46\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.07 0.11 0.14 0.1  0.13 0.   0.   0.02 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.37\n",
      "\n",
      "-> i_step = 4862\n",
      "cur_state = [2 1]\n",
      "action = 2\n",
      "reward = 9.44\n",
      "new_state = [3 2]\n",
      "[ 38. 450.   6. 190. 309.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 450.   6. 190. 309.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.3   -5.19  -4.31  -4.3   -4.32  -4.65  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.12 14.67 10.34 12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 450.   6. 190. 309.  51.  31. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.46\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.05 0.09 0.1  0.18 0.09 0.12 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.35\n",
      "\n",
      "-> i_step = 4863\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 450.   6. 190. 309.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 450.   6. 190. 309.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.3   -5.19  -4.31  -4.3   -4.32  -4.65  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.12 14.67 10.34 12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.30\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 450.   6. 190. 309.  51.  31. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.46\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.09 0.1  0.17 0.09 0.12 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.29\n",
      "\n",
      "-> i_step = 4864\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -9.41\n",
      "new_state = [1 1]\n",
      "[ 38. 451.   6. 190. 309.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 451.   6. 190. 309.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.33  -5.19  -4.31  -4.3   -4.32  -4.65  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.12 14.67 10.34 12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.33\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 451.   6. 190. 309.  51.  31. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.47\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.06 0.08 0.11 0.18 0.1  0.12 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.32\n",
      "\n",
      "-> i_step = 4865\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -2.70\n",
      "new_state = [2 5]\n",
      "[ 38. 451.   6. 190. 309.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 451.   6. 190. 309.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.33  -5.19  -4.31  -4.3   -4.32  -4.65  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.12 14.67 10.34 12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.33\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 451.   6. 190. 309.  51.  31. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.47\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.13 0.09 0.05 0.09 0.11 0.16 0.09 0.12 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.37\n",
      "\n",
      "-> i_step = 4866\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -4.92\n",
      "new_state = [3 5]\n",
      "[ 38. 451.   6. 190. 309.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 451.   6. 190. 309.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.33  -5.19  -4.31  -4.3   -4.32  -4.65  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.12 14.67 10.34 12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.33\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 451.   6. 190. 309.  51.  31. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.47\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.08 0.06 0.09 0.11 0.16 0.07 0.14 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.32\n",
      "\n",
      "-> i_step = 4867\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 451.   6. 190. 309.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 451.   6. 190. 309.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.33  -5.19  -4.31  -4.3   -4.32  -4.65  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.12 14.67 10.34 12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.33\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 451.   6. 190. 309.  51.  31. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.47\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.11 0.06 0.11 0.1  0.15 0.08 0.12 0.   0.   0.01 0.06 0.   0.08\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.42\n",
      "\n",
      "-> i_step = 4868\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = -4.07\n",
      "new_state = [1 4]\n",
      "[ 38. 451.   6. 190. 310.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 451.   6. 190. 310.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.33  -5.19  -4.31  -4.32  -4.32  -4.65  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.11 14.67 10.34 12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.33\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 451.   6. 190. 310.  51.  31. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.48\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.1  0.12 0.19 0.08 0.12 0.   0.   0.02 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.17\n",
      "\n",
      "-> i_step = 4869\n",
      "cur_state = [1 4]\n",
      "action = 0\n",
      "reward = 0.87\n",
      "new_state = [2 0]\n",
      "[ 38. 451.   6. 190. 310.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 451.   6. 190. 310.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.33  -5.19  -4.31  -4.32  -4.32  -4.65  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.11 14.67 10.34 12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.33\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 451.   6. 190. 310.  51.  31. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.48\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.13 0.1  0.06 0.09 0.1  0.17 0.08 0.13 0.   0.   0.03 0.03 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.24\n",
      "\n",
      "-> i_step = 4870\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = -11.44\n",
      "new_state = [3 7]\n",
      "[ 38. 451.   6. 190. 310.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 451.   6. 190. 310.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.33  -5.19  -4.31  -4.32  -4.32  -4.65  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.11 14.67 10.34 12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.33\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 451.   6. 190. 310.  51.  31. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.48\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.1  0.11 0.16 0.07 0.12 0.   0.   0.02 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.44\n",
      "\n",
      "-> i_step = 4871\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 451.   6. 190. 310.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 451.   6. 190. 310.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.33  -5.19  -4.31  -4.32  -4.32  -4.65  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.43 11.11 14.67 10.34 12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.33\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 451.   6. 190. 310.  51.  31. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.48\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.06 0.09 0.1  0.18 0.08 0.13 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.31\n",
      "\n",
      "-> i_step = 4872\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -8.56\n",
      "new_state = [1 3]\n",
      "[ 38. 451.   6. 191. 310.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 451.   6. 191. 310.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.33  -5.19  -4.38  -4.32  -4.32  -4.65  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.44 11.11 14.67 10.34 12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.33\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 451.   6. 191. 310.  51.  31. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.49\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.08 0.09 0.16 0.08 0.14 0.   0.   0.01 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.39\n",
      "\n",
      "-> i_step = 4873\n",
      "cur_state = [1 3]\n",
      "action = 3\n",
      "reward = -5.91\n",
      "new_state = [2 3]\n",
      "[ 38. 451.   6. 191. 310.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 451.   6. 191. 310.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.33  -5.19  -4.38  -4.32  -4.32  -4.65  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.44 11.11 14.67 10.34 12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.33\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 451.   6. 191. 310.  51.  31. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.49\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.06 0.09 0.1  0.15 0.09 0.13 0.   0.   0.03 0.06 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -5.43\n",
      "\n",
      "-> i_step = 4874\n",
      "cur_state = [2 3]\n",
      "action = 2\n",
      "reward = 7.23\n",
      "new_state = [3 2]\n",
      "[ 38. 451.   6. 191. 310.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 451.   6. 191. 310.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.33  -5.19  -4.38  -4.32  -4.32  -4.65  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.44 11.11 14.67 10.34 12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.33\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 451.   6. 191. 310.  51.  31. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.49\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.11 0.05 0.1  0.09 0.13 0.1  0.14 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.39\n",
      "\n",
      "-> i_step = 4875\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 451.   6. 191. 310.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 451.   6. 191. 310.  51.  31. 103.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.33  -5.19  -4.38  -4.32  -4.32  -4.65  -4.32 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.44 11.11 14.67 10.34 12.63  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.33\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 451.   6. 191. 310.  51.  31. 103.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.49\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.11 0.1  0.05 0.09 0.11 0.15 0.1  0.14 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.27\n",
      "\n",
      "-> i_step = 4876\n",
      "cur_state = [0 0]\n",
      "action = 7\n",
      "reward = 4.13\n",
      "new_state = [1 7]\n",
      "[ 38. 451.   6. 191. 310.  51.  31. 104.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 451.   6. 191. 310.  51.  31. 104.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.33  -5.19  -4.38  -4.32  -4.32  -4.65  -4.31 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.44 11.11 14.67 10.34 12.57  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.33\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 451.   6. 191. 310.  51.  31. 104.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.49\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.12 0.09 0.07 0.1  0.1  0.15 0.09 0.13 0.   0.   0.02 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.36\n",
      "\n",
      "-> i_step = 4877\n",
      "cur_state = [1 7]\n",
      "action = 0\n",
      "reward = -13.50\n",
      "new_state = [2 0]\n",
      "[ 38. 451.   6. 191. 310.  51.  31. 104.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 451.   6. 191. 310.  51.  31. 104.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.33  -5.19  -4.38  -4.32  -4.32  -4.65  -4.31 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.44 11.11 14.67 10.34 12.57  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.33\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 451.   6. 191. 310.  51.  31. 104.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.49\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "probs = [0.11 0.09 0.07 0.1  0.1  0.19 0.08 0.12 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.27\n",
      "\n",
      "-> i_step = 4878\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = -1.11\n",
      "new_state = [3 7]\n",
      "[ 38. 451.   6. 191. 310.  51.  31. 104.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 451.   6. 191. 310.  51.  31. 104.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.33  -5.19  -4.38  -4.32  -4.32  -4.65  -4.31 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.44 11.11 14.67 10.34 12.57  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.33\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 451.   6. 191. 310.  51.  31. 104.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.49\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.11 0.08 0.06 0.1  0.11 0.17 0.07 0.14 0.   0.   0.02 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.39\n",
      "\n",
      "-> i_step = 4879\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 451.   6. 191. 310.  51.  31. 104.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 451.   6. 191. 310.  51.  31. 104.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.33  -5.19  -4.38  -4.32  -4.32  -4.65  -4.31 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.44 11.11 14.67 10.34 12.57  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.33\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.04 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 451.   6. 191. 310.  51.  31. 104.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.49\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.05 0.11 0.1  0.16 0.09 0.13 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.34\n",
      "\n",
      "-> i_step = 4880\n",
      "cur_state = [0 0]\n",
      "action = 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action = 6\n",
      "reward = 6.63\n",
      "new_state = [3 6]\n",
      "[ 38. 451.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 451.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.33  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.33\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 451.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.54\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.07 0.09 0.1  0.17 0.07 0.13 0.   0.   0.02 0.07 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.66\n",
      "\n",
      "-> i_step = 4911\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 451.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 451.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.33  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.44  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.33\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 451.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.54\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13]\n",
      "probs = [0.12 0.1  0.05 0.09 0.1  0.14 0.08 0.13 0.   0.   0.02 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.52\n",
      "\n",
      "-> i_step = 4912\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -12.25\n",
      "new_state = [1 1]\n",
      "[ 38. 452.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 452.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.36  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.46  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.36\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 452.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.55\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.07 0.1  0.1  0.15 0.08 0.14 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.44\n",
      "\n",
      "-> i_step = 4913\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 2.50\n",
      "new_state = [2 5]\n",
      "[ 38. 452.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 452.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.36  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.46  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.36\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 452.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.55\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.13 0.08 0.06 0.1  0.09 0.15 0.08 0.13 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.50\n",
      "\n",
      "-> i_step = 4914\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 7.32\n",
      "new_state = [3 5]\n",
      "[ 38. 452.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 452.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.36  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.46  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.36\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 452.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.55\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.05 0.1  0.09 0.14 0.1  0.13 0.   0.01 0.03 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.54\n",
      "\n",
      "-> i_step = 4915\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 452.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 452.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.36  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.46  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.36\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 452.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.55\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.09 0.06 0.11 0.1  0.13 0.09 0.14 0.   0.   0.01 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.50\n",
      "\n",
      "-> i_step = 4916\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 20.67\n",
      "new_state = [1 1]\n",
      "[ 38. 453.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 453.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.32  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.48  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 453.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.54\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.06 0.12 0.09 0.14 0.07 0.14 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.45\n",
      "\n",
      "-> i_step = 4917\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 16.61\n",
      "new_state = [2 5]\n",
      "[ 38. 453.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 453.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.32  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.48  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 453.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.54\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.06 0.1  0.11 0.15 0.09 0.14 0.   0.   0.01 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.39\n",
      "\n",
      "-> i_step = 4918\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -3.50\n",
      "new_state = [3 5]\n",
      "[ 38. 453.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 453.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.32  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.48  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 453.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.54\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.08 0.06 0.09 0.11 0.16 0.11 0.12 0.   0.   0.02 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.56\n",
      "\n",
      "-> i_step = 4919\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 453.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 453.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.32  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.48  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 453.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.54\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.08 0.06 0.09 0.1  0.16 0.08 0.12 0.   0.   0.03 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.66\n",
      "\n",
      "-> i_step = 4920\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 23.53\n",
      "new_state = [1 1]\n",
      "[ 38. 454.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 454.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.28  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.51  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.28\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 454.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.52\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.14 0.09 0.05 0.08 0.1  0.16 0.07 0.14 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.49\n",
      "\n",
      "-> i_step = 4921\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -1.10\n",
      "new_state = [2 5]\n",
      "[ 38. 454.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 454.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.28  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.51  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.28\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 454.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.52\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.11 0.05 0.09 0.1  0.15 0.08 0.15 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.41\n",
      "\n",
      "-> i_step = 4922\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -2.31\n",
      "new_state = [3 5]\n",
      "[ 38. 454.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 454.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.28  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.51  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.28\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 454.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.52\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.13 0.09 0.06 0.09 0.11 0.17 0.07 0.12 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.48\n",
      "\n",
      "-> i_step = 4923\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 454.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 454.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.28  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.51  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.28\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 454.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.52\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.05 0.09 0.12 0.16 0.07 0.12 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.45\n",
      "\n",
      "-> i_step = 4924\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -12.65\n",
      "new_state = [1 1]\n",
      "[ 38. 455.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 455.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.31  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.52  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.31\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 455.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.53\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.13 0.1  0.05 0.09 0.1  0.16 0.09 0.12 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.46\n",
      "\n",
      "-> i_step = 4925\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 5.85\n",
      "new_state = [2 5]\n",
      "[ 38. 455.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 455.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.31  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.52  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.31\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 455.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.53\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.08 0.05 0.09 0.09 0.16 0.09 0.14 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.51\n",
      "\n",
      "-> i_step = 4926\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -2.34\n",
      "new_state = [3 5]\n",
      "[ 38. 455.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 455.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.31  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.52  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.31\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 455.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.53\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.08 0.11 0.17 0.08 0.12 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.50\n",
      "\n",
      "-> i_step = 4927\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 455.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 455.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.31  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.52  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.31\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 455.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.53\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.13 0.08 0.06 0.1  0.11 0.15 0.09 0.11 0.   0.   0.01 0.07 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.56\n",
      "\n",
      "-> i_step = 4928\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -9.43\n",
      "new_state = [1 1]\n",
      "[ 38. 456.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 456.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.34  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.53  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.34\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 456.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.54\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.11 0.06 0.1  0.1  0.14 0.09 0.13 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.48\n",
      "\n",
      "-> i_step = 4929\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 5.01\n",
      "new_state = [2 5]\n",
      "[ 38. 456.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 456.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.34  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.53  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.34\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 456.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.54\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.1  0.11 0.16 0.08 0.13 0.   0.   0.01 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.41\n",
      "\n",
      "-> i_step = 4930\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -3.12\n",
      "new_state = [3 5]\n",
      "[ 38. 456.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 456.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.34  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.53  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.34\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 456.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.54\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.12 0.05 0.09 0.1  0.15 0.09 0.11 0.   0.   0.02 0.04 0.   0.11\n",
      " 0.   0.  ]\n",
      "Q_est = -5.45\n",
      "\n",
      "-> i_step = 4931\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 456.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 456.   6. 191. 312.  56.  31. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.34  -5.19  -4.38  -4.38  -4.76  -4.65  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.53  8.95 10.44 11.14 14.53 10.34 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.34\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 456.   6. 191. 312.  56.  31. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.54\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.11 0.06 0.11 0.09 0.15 0.09 0.13 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.35\n",
      "\n",
      "-> i_step = 4932\n",
      "cur_state = [0 0]\n",
      "action = 6\n",
      "reward = -3.33\n",
      "new_state = [1 6]\n",
      "[ 38. 456.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 456.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.34  -5.19  -4.38  -4.38  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.53  8.95 10.44 11.14 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.34\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 456.   6. 191. 312.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.55\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.13 0.09 0.07 0.08 0.1  0.15 0.08 0.12 0.   0.   0.01 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.55\n",
      "\n",
      "-> i_step = 4933\n",
      "cur_state = [1 6]\n",
      "action = 1\n",
      "reward = -2.75\n",
      "new_state = [2 1]\n",
      "[ 38. 456.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 456.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.34  -5.19  -4.38  -4.38  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.53  8.95 10.44 11.14 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.34\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 456.   6. 191. 312.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.55\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.09 0.07 0.08 0.11 0.17 0.08 0.11 0.   0.   0.01 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.61\n",
      "\n",
      "-> i_step = 4934\n",
      "cur_state = [2 1]\n",
      "action = 6\n",
      "reward = 10.90\n",
      "new_state = [3 6]\n",
      "[ 38. 456.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 456.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.34  -5.19  -4.38  -4.38  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.53  8.95 10.44 11.14 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.34\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 456.   6. 191. 312.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.55\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.06 0.09 0.09 0.15 0.09 0.12 0.   0.   0.03 0.06 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.61\n",
      "\n",
      "-> i_step = 4935\n",
      "cur_state = [3 6]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 456.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 456.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.34  -5.19  -4.38  -4.38  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.53  8.95 10.44 11.14 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.34\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.26 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 456.   6. 191. 312.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.55\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.13 0.1  0.07 0.09 0.09 0.14 0.08 0.13 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.51\n",
      "\n",
      "-> i_step = 4936\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -10.96\n",
      "new_state = [1 1]\n",
      "[ 38. 457.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 457.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.37  -5.19  -4.38  -4.38  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.54  8.95 10.44 11.14 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.37\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 457.   6. 191. 312.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.56\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.14 0.1  0.06 0.09 0.09 0.15 0.08 0.15 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.45\n",
      "\n",
      "-> i_step = 4937\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 2.72\n",
      "new_state = [2 5]\n",
      "[ 38. 457.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 457.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.37  -5.19  -4.38  -4.38  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.54  8.95 10.44 11.14 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.37\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 457.   6. 191. 312.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.56\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.11 0.1  0.05 0.1  0.12 0.15 0.08 0.11 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.54\n",
      "\n",
      "-> i_step = 4938\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -15.07\n",
      "new_state = [3 5]\n",
      "[ 38. 457.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 457.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.37  -5.19  -4.38  -4.38  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.54  8.95 10.44 11.14 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.37\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 457.   6. 191. 312.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.56\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.11 0.06 0.07 0.1  0.17 0.07 0.13 0.   0.   0.02 0.05 0.   0.11\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.58\n",
      "\n",
      "-> i_step = 4939\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 457.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 457.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.37  -5.19  -4.38  -4.38  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.54  8.95 10.44 11.14 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.37\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 457.   6. 191. 312.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.56\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.04 0.1  0.11 0.14 0.1  0.12 0.   0.   0.03 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.61\n",
      "\n",
      "-> i_step = 4940\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 12.61\n",
      "new_state = [1 1]\n",
      "[ 38. 458.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 458.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.35  -5.19  -4.38  -4.38  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.54  8.95 10.44 11.14 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.35\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 458.   6. 191. 312.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.55\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.11 0.09 0.04 0.1  0.11 0.16 0.08 0.14 0.   0.   0.02 0.06 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.52\n",
      "\n",
      "-> i_step = 4941\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 13.02\n",
      "new_state = [2 5]\n",
      "[ 38. 458.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 458.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.35  -5.19  -4.38  -4.38  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.54  8.95 10.44 11.14 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.35\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 458.   6. 191. 312.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.55\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.12 0.05 0.08 0.09 0.17 0.09 0.13 0.   0.   0.03 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.56\n",
      "\n",
      "-> i_step = 4942\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 0.52\n",
      "new_state = [3 5]\n",
      "[ 38. 458.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 458.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.35  -5.19  -4.38  -4.38  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.54  8.95 10.44 11.14 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.35\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 458.   6. 191. 312.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.55\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.1  0.11 0.16 0.09 0.12 0.   0.   0.02 0.05 0.   0.07\n",
      " 0.   0.  ]\n",
      "Q_est = -5.45\n",
      "\n",
      "-> i_step = 4943\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 458.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 458.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.35  -5.19  -4.38  -4.38  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.54  8.95 10.44 11.14 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.35\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 458.   6. 191. 312.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.55\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.09 0.1  0.16 0.07 0.13 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.53\n",
      "\n",
      "-> i_step = 4944\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -9.90\n",
      "new_state = [1 1]\n",
      "[ 38. 459.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 459.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.38  -5.19  -4.38  -4.38  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.54  8.95 10.44 11.14 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.38\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 459.   6. 191. 312.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.56\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.11 0.05 0.1  0.11 0.14 0.08 0.12 0.   0.   0.01 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.55\n",
      "\n",
      "-> i_step = 4945\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -17.96\n",
      "new_state = [2 5]\n",
      "[ 38. 459.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 459.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.38  -5.19  -4.38  -4.38  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.54  8.95 10.44 11.14 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.38\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 459.   6. 191. 312.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.56\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.07 0.09 0.1  0.18 0.09 0.12 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.47\n",
      "\n",
      "-> i_step = 4946\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -13.95\n",
      "new_state = [3 5]\n",
      "[ 38. 459.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 459.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.38  -5.19  -4.38  -4.38  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.54  8.95 10.44 11.14 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.38\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 459.   6. 191. 312.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.56\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.06 0.1  0.1  0.15 0.08 0.14 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.50\n",
      "\n",
      "-> i_step = 4947\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 459.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 459.   6. 191. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.38  -5.19  -4.38  -4.38  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.54  8.95 10.44 11.14 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.38\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 459.   6. 191. 312.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.56\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.1  0.11 0.15 0.08 0.12 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.48\n",
      "\n",
      "-> i_step = 4948\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = 2.32\n",
      "new_state = [1 3]\n",
      "[ 38. 459.   6. 192. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 459.   6. 192. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.38  -5.19  -4.38  -4.38  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.54  8.95 10.41 11.14 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.38\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 459.   6. 192. 312.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.57\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.07 0.1  0.08 0.15 0.08 0.12 0.   0.   0.02 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.59\n",
      "\n",
      "-> i_step = 4949\n",
      "cur_state = [1 3]\n",
      "action = 3\n",
      "reward = 8.63\n",
      "new_state = [2 3]\n",
      "[ 38. 459.   6. 192. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 459.   6. 192. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.38  -5.19  -4.38  -4.38  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.54  8.95 10.41 11.14 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.38\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 459.   6. 192. 312.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.57\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.11 0.05 0.08 0.11 0.16 0.07 0.15 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.46\n",
      "\n",
      "-> i_step = 4950\n",
      "cur_state = [2 3]\n",
      "action = 2\n",
      "reward = -13.76\n",
      "new_state = [3 2]\n",
      "[ 38. 459.   6. 192. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 459.   6. 192. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.38  -5.19  -4.38  -4.38  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.54  8.95 10.41 11.14 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.38\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 459.   6. 192. 312.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.57\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.09 0.1  0.16 0.08 0.14 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.47\n",
      "\n",
      "-> i_step = 4951\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 459.   6. 192. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 459.   6. 192. 312.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.38  -5.19  -4.38  -4.38  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.54  8.95 10.41 11.14 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.38\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 459.   6. 192. 312.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.57\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.13 0.1  0.06 0.09 0.09 0.15 0.08 0.13 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.48\n",
      "\n",
      "-> i_step = 4952\n",
      "cur_state = [0 0]\n",
      "action = 4\n",
      "reward = -13.44\n",
      "new_state = [1 4]\n",
      "[ 38. 459.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 459.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.38  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.54  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.38\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 459.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.58\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.06 0.08 0.1  0.17 0.08 0.14 0.   0.   0.02 0.04 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.41\n",
      "\n",
      "-> i_step = 4953\n",
      "cur_state = [1 4]\n",
      "action = 0\n",
      "reward = -2.66\n",
      "new_state = [2 0]\n",
      "[ 38. 459.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 459.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.38  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.54  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.38\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 459.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.58\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.13 0.11 0.06 0.11 0.09 0.14 0.1  0.12 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.45\n",
      "\n",
      "-> i_step = 4954\n",
      "cur_state = [2 0]\n",
      "action = 7\n",
      "reward = -7.99\n",
      "new_state = [3 7]\n",
      "[ 38. 459.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 459.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.38  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.54  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.38\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 459.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.58\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.06 0.09 0.1  0.12 0.08 0.13 0.   0.   0.02 0.06 0.   0.12\n",
      " 0.   0.  ]\n",
      "Q_est = -5.66\n",
      "\n",
      "-> i_step = 4955\n",
      "cur_state = [3 7]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 459.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 459.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.38  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.54  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.38\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 459.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.58\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.05 0.09 0.11 0.15 0.09 0.14 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.44\n",
      "\n",
      "-> i_step = 4956\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 6.76\n",
      "new_state = [1 1]\n",
      "[ 38. 460.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 460.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.37  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.53  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.37\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 460.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.58\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.04 0.09 0.09 0.15 0.1  0.15 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.48\n",
      "\n",
      "-> i_step = 4957\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = 0.49\n",
      "new_state = [2 5]\n",
      "[ 38. 460.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 460.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.37  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.53  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.37\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 460.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.58\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.09 0.11 0.17 0.09 0.1  0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.47\n",
      "\n",
      "-> i_step = 4958\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -6.28\n",
      "new_state = [3 5]\n",
      "[ 38. 460.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 460.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.37  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.53  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.37\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 460.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.58\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.11 0.07 0.05 0.1  0.1  0.17 0.09 0.14 0.   0.   0.02 0.04 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.43\n",
      "\n",
      "-> i_step = 4959\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 460.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 460.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.37  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.53  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.37\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 460.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.58\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.13 0.09 0.06 0.1  0.12 0.15 0.09 0.12 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.38\n",
      "\n",
      "-> i_step = 4960\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 7.73\n",
      "new_state = [1 1]\n",
      "[ 38. 461.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 461.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.36  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.52  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.36\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 461.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.57\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.11 0.07 0.1  0.12 0.13 0.09 0.12 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.46\n",
      "\n",
      "-> i_step = 4961\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -5.88\n",
      "new_state = [2 5]\n",
      "[ 38. 461.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 461.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.36  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.52  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.36\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 461.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.57\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.06 0.08 0.1  0.15 0.09 0.14 0.   0.   0.03 0.06 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.66\n",
      "\n",
      "-> i_step = 4962\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 13.54\n",
      "new_state = [3 5]\n",
      "[ 38. 461.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 461.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.36  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.52  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.36\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 461.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.57\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13]\n",
      "probs = [0.11 0.1  0.07 0.1  0.11 0.15 0.08 0.12 0.   0.   0.01 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.49\n",
      "\n",
      "-> i_step = 4963\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 461.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 461.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.36  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.52  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.36\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.37 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 461.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.57\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.14 0.1  0.06 0.08 0.1  0.15 0.08 0.13 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.44\n",
      "\n",
      "-> i_step = 4964\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 21.80\n",
      "new_state = [1 1]\n",
      "[ 38. 462.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 462.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.32  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.55  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.38 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 462.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.56\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.06 0.09 0.09 0.14 0.1  0.14 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.51\n",
      "\n",
      "-> i_step = 4965\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -5.18\n",
      "new_state = [2 5]\n",
      "[ 38. 462.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 462.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.32  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.55  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.38 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 462.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.56\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.09 0.1  0.17 0.07 0.13 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.54\n",
      "\n",
      "-> i_step = 4966\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -2.23\n",
      "new_state = [3 5]\n",
      "[ 38. 462.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 462.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.32  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.55  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.38 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 462.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.56\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.13 0.09 0.05 0.08 0.08 0.14 0.11 0.14 0.   0.   0.01 0.06 0.   0.1\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.55\n",
      "\n",
      "-> i_step = 4967\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 462.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 462.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.32  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.55  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.32\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.38 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 462.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.56\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.11 0.05 0.08 0.11 0.16 0.08 0.12 0.   0.   0.02 0.06 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.52\n",
      "\n",
      "-> i_step = 4968\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -8.52\n",
      "new_state = [1 1]\n",
      "[ 38. 463.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 463.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.35  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.55  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.35\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.38 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 463.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.57\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.06 0.08 0.1  0.14 0.08 0.14 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.56\n",
      "\n",
      "-> i_step = 4969\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -4.79\n",
      "new_state = [2 5]\n",
      "[ 38. 463.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 463.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.35  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.55  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.35\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.38 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 463.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.57\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.11 0.09 0.06 0.11 0.1  0.15 0.07 0.14 0.   0.   0.01 0.06 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.52\n",
      "\n",
      "-> i_step = 4970\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = -2.10\n",
      "new_state = [3 5]\n",
      "[ 38. 463.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 463.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.35  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.55  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.35\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.38 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 463.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.57\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.08 0.06 0.11 0.12 0.15 0.08 0.12 0.   0.   0.01 0.04 0.   0.11\n",
      " 0.   0.  ]\n",
      "Q_est = -5.43\n",
      "\n",
      "-> i_step = 4971\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 463.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 463.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.35  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.55  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.35\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.38 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 463.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.57\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13]\n",
      "probs = [0.12 0.1  0.06 0.09 0.13 0.14 0.07 0.12 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.42\n",
      "\n",
      "-> i_step = 4972\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = -15.48\n",
      "new_state = [1 1]\n",
      "[ 38. 464.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 464.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.39  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.57  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.39\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.38 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 464.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.58\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8 10 11 13 14]\n",
      "probs = [0.11 0.08 0.06 0.1  0.09 0.16 0.09 0.16 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.44\n",
      "\n",
      "-> i_step = 4973\n",
      "cur_state = [1 1]\n",
      "action = 5\n",
      "reward = -6.05\n",
      "new_state = [2 5]\n",
      "[ 38. 464.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 464.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.39  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.57  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.39\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.38 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 464.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.58\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.09 0.06 0.1  0.1  0.17 0.07 0.12 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.51\n",
      "\n",
      "-> i_step = 4974\n",
      "cur_state = [2 5]\n",
      "action = 5\n",
      "reward = 5.31\n",
      "new_state = [3 5]\n",
      "[ 38. 464.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 464.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.39  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.57  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.39\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.38 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 464.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.58\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.06 0.09 0.1  0.16 0.1  0.13 0.   0.   0.03 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.50\n",
      "\n",
      "-> i_step = 4975\n",
      "cur_state = [3 5]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 464.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 464.   6. 192. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.39  -5.19  -4.38  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.57  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.39\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.38 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 464.   6. 192. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.58\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.09 0.1  0.05 0.1  0.12 0.16 0.08 0.14 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.52\n",
      "\n",
      "-> i_step = 4976\n",
      "cur_state = [0 0]\n",
      "action = 3\n",
      "reward = -7.31\n",
      "new_state = [1 3]\n",
      "[ 38. 464.   6. 193. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 464.   6. 193. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.39  -5.19  -4.44  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.57  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.39\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.38 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 464.   6. 193. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.59\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.09 0.11 0.06 0.11 0.1  0.14 0.1  0.13 0.   0.   0.02 0.05 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.49\n",
      "\n",
      "-> i_step = 4977\n",
      "cur_state = [1 3]\n",
      "action = 3\n",
      "reward = -7.27\n",
      "new_state = [2 3]\n",
      "[ 38. 464.   6. 193. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 464.   6. 193. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.39  -5.19  -4.44  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.57  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.39\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.38 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 464.   6. 193. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.59\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.05 0.09 0.09 0.17 0.08 0.15 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.   0.  ]\n",
      "Q_est = -5.45\n",
      "\n",
      "-> i_step = 4978\n",
      "cur_state = [2 3]\n",
      "action = 2\n",
      "reward = 4.60\n",
      "new_state = [3 2]\n",
      "[ 38. 464.   6. 193. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 464.   6. 193. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.39  -5.19  -4.44  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.57  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.39\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.38 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 464.   6. 193. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.59\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.11 0.07 0.09 0.11 0.14 0.1  0.11 0.   0.   0.01 0.05 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.45\n",
      "\n",
      "-> i_step = 4979\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 464.   6. 193. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 464.   6. 193. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.39  -5.19  -4.44  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.57  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.39\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.38 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 464.   6. 193. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.59\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.1  0.1  0.07 0.08 0.09 0.15 0.08 0.14 0.   0.   0.02 0.06 0.   0.11\n",
      " 0.   0.  ]\n",
      "Q_est = -5.68\n",
      "\n",
      "-> i_step = 4980\n",
      "cur_state = [0 0]\n",
      "action = 1\n",
      "reward = 3.36\n",
      "new_state = [1 1]\n",
      "[ 38. 465.   6. 193. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 465.   6. 193. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.39  -5.19  -4.44  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.56  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.39\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.38 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 465.   6. 193. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.59\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7 10 11 13 14]\n",
      "probs = [0.11 0.1  0.06 0.1  0.11 0.16 0.1  0.11 0.   0.   0.01 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.43\n",
      "\n",
      "-> i_step = 4981\n",
      "cur_state = [1 1]\n",
      "action = 3\n",
      "reward = -1.34\n",
      "new_state = [2 3]\n",
      "[ 38. 465.   6. 193. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 465.   6. 193. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.39  -5.19  -4.44  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.56  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.39\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.38 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 465.   6. 193. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.59\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.11 0.12 0.06 0.08 0.1  0.15 0.09 0.13 0.   0.   0.02 0.05 0.   0.08\n",
      " 0.   0.  ]\n",
      "Q_est = -5.48\n",
      "\n",
      "-> i_step = 4982\n",
      "cur_state = [2 3]\n",
      "action = 2\n",
      "reward = -4.18\n",
      "new_state = [3 2]\n",
      "[ 38. 465.   6. 193. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 465.   6. 193. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.39  -5.19  -4.44  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.56  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.39\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.38 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 465.   6. 193. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.59\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.1  0.05 0.09 0.11 0.16 0.08 0.11 0.   0.   0.02 0.05 0.   0.1\n",
      " 0.   0.  ]\n",
      "Q_est = -5.56\n",
      "\n",
      "-> i_step = 4983\n",
      "cur_state = [3 2]\n",
      "action = 0\n",
      "reward = -10.00\n",
      "new_state = [0 0]\n",
      "terminated\n",
      "[ 38. 465.   6. 193. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ 38. 465.   6. 193. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "[ -4.4   -4.39  -5.19  -4.44  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42]\n",
      "[11.82 10.56  8.95 10.41 11.16 14.53 10.25 12.76  6.43  4.62  9.86 13.49\n",
      "  0.65 13.99  7.58  2.75]\n",
      "haver3_estimator\n",
      "action_maxlcb_idx = 1\n",
      "action_maxlcb_muhat = -4.39\n",
      "Bset_idxes = [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]\n",
      "Bset_probs = [0.03 0.38 0.   0.16 0.25 0.05 0.03 0.09 0.   0.   0.   0.   0.   0.01\n",
      " 0.   0.  ]\n",
      "Bset_nvisits = [ 38. 465.   6. 193. 313.  56.  32. 105.   0.   5.   4.   4.   0.  10.\n",
      "   4.   0.]\n",
      "Q_est = -4.59\n",
      "weightedms_estimator\n",
      "idxes = [ 0  1  2  3  4  5  6  7  9 10 11 13 14]\n",
      "probs = [0.12 0.11 0.06 0.1  0.08 0.16 0.08 0.13 0.   0.   0.02 0.04 0.   0.09\n",
      " 0.01 0.  ]\n",
      "Q_est = -5.52\n",
      "\n",
      "-> i_step = 4984\n",
      "cur_state = [0 0]\n",
      "action = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "tdqm_disable = True\n",
    "\n",
    "# params\n",
    "num_trials = 1\n",
    "num_steps_train = 5000\n",
    "num_episodes_eval = 100\n",
    "\n",
    "lr_sched_type = \"linear\"\n",
    "lr_sched_fn = create_lr_sched_fn(lr_sched_type, lr=0.7)\n",
    "\n",
    "max_eps = 1.0\n",
    "min_eps = 1.0\n",
    "decay_rate = 0.0001\n",
    "eps_sched_type = \"poly\"\n",
    "eps_sched_fn = create_eps_sched_fn(eps_sched_type, min_eps, max_eps, decay_rate)\n",
    "\n",
    "# create gym env\n",
    "env_id = \"gym_examples/NNWorldEnv01-v1\"\n",
    "env_scheme = \"two_island\"\n",
    "gamma = 0.95\n",
    "\n",
    "num_depths = 4\n",
    "num_widths = 16\n",
    "num_actions = num_widths\n",
    "terminal_reward = -10.0\n",
    "\n",
    "reward_dist = \"normal\"\n",
    "problem_instance = \"multi_gap_nonlinear\"\n",
    "action_max_mu = 0.0\n",
    "action_sigma = 10.0\n",
    "action_sigmas = action_sigma*np.ones(num_actions)\n",
    "gap_splits = [0.5]\n",
    "gap_deltas = [5.0]\n",
    "bandit_problem = BanditProblem(\n",
    "    problem_instance, reward_dist, num_actions, action_max_mu, \n",
    "    action_sigmas=action_sigmas, gap_splits=gap_splits, gap_deltas=gap_deltas)\n",
    "print(f\"action_mus = {bandit_problem.action_mus}\")\n",
    "print(f\"action_sigmas = {bandit_problem.action_sigmas}\")\n",
    "\n",
    "action_max_mu = bandit_problem.action_mus[0]\n",
    "optimal_num_steps = num_depths\n",
    "optimal_vstar = terminal_reward*gamma**(optimal_num_steps-1) \\\n",
    "    + action_max_mu*np.sum([gamma**k for k in range(optimal_num_steps-1)])\n",
    "optimal_reward_per_step = (terminal_reward + action_max_mu*(optimal_num_steps-1))/optimal_num_steps  \n",
    "print(f\"optimal_num_steps = {optimal_num_steps}\")\n",
    "print(f\"optimal_reward_per_step = {optimal_reward_per_step}\")\n",
    "print(f\"optimal_vstar = {optimal_vstar}\")\n",
    "\n",
    "env = gym.make(env_id, num_depths=num_depths, num_widths=num_widths, \n",
    "               bandit_problem=bandit_problem, terminal_reward=terminal_reward)\n",
    "env_wrapped = FlattenObservation(env)\n",
    "cur_state, info = env_wrapped.reset()\n",
    "\n",
    "manager = multiprocessing.Manager()\n",
    "episode_start_sigmahats_list = manager.list()\n",
    "episode_rewards_list = manager.list()\n",
    "episode_vstar_est_list = manager.list()\n",
    "Q_table_list = manager.list()\n",
    "Q_nvisits_list = manager.list()    \n",
    "\n",
    "def run_trial(i_trial, args):\n",
    "\n",
    "    random.seed(10000+i_trial)\n",
    "    np.random.seed(10000+i_trial)\n",
    "\n",
    "    # env = gym.make(env_id, size=gridworld_size)\n",
    "    # env_wrapped = FlattenObservation(env)\n",
    "    # env_wrapped.reset(seed=10000+i_trial)\n",
    "\n",
    "    # lr_sched_fn = create_lr_sched_fn(lr_sched_type)\n",
    "    # eps_sched_fn = create_eps_sched_fn(eps_sched_type, min_eps, max_eps, decay_rate)\n",
    "    q_algo = create_q_algo(args[\"est_name\"])\n",
    "\n",
    "    Q_table, Q_nvisits, stats = q_algo(\n",
    "        env_wrapped, num_actions, num_steps_train,\n",
    "        gamma, lr_sched_fn, eps_sched_fn, tdqm_disable, args)\n",
    "\n",
    "    episode_start_sigmahats, episode_rewards, episode_vstar_est= zip(*stats)\n",
    "    episode_start_sigmahats_list.append(episode_start_sigmahats)\n",
    "    episode_rewards_list.append(episode_rewards)\n",
    "    episode_vstar_est_list.append(episode_vstar_est)\n",
    "    Q_table_list.append(Q_table)\n",
    "    Q_nvisits_list.append(Q_nvisits)\n",
    "\n",
    "args = dict()\n",
    "args[\"action_sigma\"] = action_sigma\n",
    "args[\"haver_alpha\"] = 2.0\n",
    "args[\"haver_delta\"] = 0.05\n",
    "args[\"haver_const\"] = 1.0\n",
    "args[\"weightedms_num_data\"] = 1000\n",
    "args[\"num_depths\"] = num_depths\n",
    "args[\"env_scheme\"] = env_scheme\n",
    "\n",
    "pool = multiprocessing.Pool()\n",
    "\n",
    "episode_start_sigmahats_dict = defaultdict()\n",
    "episode_rewards_dict = defaultdict()\n",
    "episode_vstar_est_dict = defaultdict()\n",
    "episode_vstar_est_bias_dict = defaultdict()\n",
    "episode_vstar_est_var_dict = defaultdict()\n",
    "episode_vstar_est_mse_dict = defaultdict()\n",
    "Q_table_dict = defaultdict()\n",
    "Q_nvisits_dict = defaultdict()\n",
    "\n",
    "haver_const_ary = [1.0]\n",
    "haver_name_ary = [f\"haver_{x}\" for x in haver_const_ary]\n",
    "haver3_name_ary = [f\"haver3_{x}\" for x in haver_const_ary]\n",
    "\n",
    "est_name_ary = [\"max\", \"weightedms\"]\n",
    "# est_name_ary = haver_name_ary + est_name_ary \n",
    "# est_name_ary = est_name_ary + haver_name_ary\n",
    "# est_name_ary = est_name_ary + haver2_name_ary\n",
    "est_name_ary = est_name_ary + haver3_name_ary\n",
    "# est_name_ary = est_name_ary + haver4_name_ary\n",
    "est_name_ary = [\"haver3_1.0\"]\n",
    "for est_name in est_name_ary:\n",
    "    start_time = time.time()\n",
    "    print(f\"\\n-> est_name = {est_name}\")\n",
    "    if \"haver\" in est_name:\n",
    "        elems = est_name.split(\"_\")\n",
    "        args[\"est_name\"] = elems[0]\n",
    "        args[\"haver_const\"] = float(elems[-1])\n",
    "        print(f\"haver_const = {args['haver_const']}\")\n",
    "    else:\n",
    "        args[\"est_name\"] = est_name\n",
    "    \n",
    "    pool.starmap(run_trial, [(i, args) for i in range(num_trials)])\n",
    "\n",
    "    episode_start_sigmahats_ary = np.hstack([episode_start_sigmahats_list])\n",
    "    episode_rewards_ary = np.hstack([episode_rewards_list])\n",
    "    episode_vstar_est_ary = np.hstack([episode_vstar_est_list])\n",
    "\n",
    "    episode_start_sigmahats_dict[est_name] = np.mean(episode_start_sigmahats_ary, 0)\n",
    "    episode_rewards_dict[est_name] = np.mean(episode_rewards_ary, 0)\n",
    "    episode_vstar_est_dict[est_name] = np.mean(episode_vstar_est_ary, 0)\n",
    "    print(f\"last_episode_start_sigmahat = {episode_start_sigmahats_dict[est_name][-1]:.4f}\")\n",
    "    print(f\"last_episode_reward_per_step = {episode_rewards_dict[est_name][-1]:.4f}\")\n",
    "    print(f\"last_episode_estim_start_muhat = {episode_vstar_est_dict[est_name][-1]:.4f}\")\n",
    "    \n",
    "    episode_vstar_est_bias_dict[est_name] = np.mean(episode_vstar_est_ary - optimal_vstar, 0)\n",
    "    episode_vstar_est_var_dict[est_name] = np.var(episode_vstar_est_ary - optimal_vstar, 0, ddof=1)\n",
    "    episode_vstar_est_mse_dict[est_name] = \\\n",
    "        episode_vstar_est_bias_dict[est_name]**2 \\\n",
    "        + episode_vstar_est_var_dict[est_name]\n",
    "    \n",
    "    # Q_table_dict[est_name] = np.mean(np.stack(Q_table_list), 0)\n",
    "    # Q_nvisits_dict[est_name] = np.mean(np.stack(Q_nvisits_list), 0)\n",
    "    # print(np.stack(Q_table_list).shape)\n",
    "    Q_table_dict[est_name] = np.stack(Q_table_list)[0,:,:,:]\n",
    "    Q_nvisits_dict[est_name] = np.stack(Q_nvisits_list)[0,:,:,:]\n",
    "    # print(Q_table_list[0][0,0,:])\n",
    "    # print(Q_table_list[1][0,0,:])\n",
    "    # print(Q_table_ary)\n",
    "    # stop\n",
    "                           \n",
    "    episode_start_sigmahats_list[:] = []\n",
    "    episode_rewards_list[:] = []\n",
    "    episode_vstar_est_list[:] = []\n",
    "    Q_table_list[:] = []\n",
    "    Q_nvisits_list[:] = []\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"it takes {end_time-start_time:0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdfeb72d-1e21-4c0f-bfd6-66ab5dac4bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2IAAAPeCAYAAABup6mcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAD9IUlEQVR4nOzdd3hT9f4H8Hdmk3RvKG0pUNpCoWVWmUVEBBEuICLKuCLIVAH1Kl794Rbl4kBAQUBwIAIKCMoQFFGhgJQlexZoKd0raXbO74+0kdBd2qQN79fz9Ck9OTn5nKQJ593vEgmCIICIiIiIiIgcRuzsAoiIiIiIiO40DGJEREREREQOxiBGRERERETkYAxiREREREREDsYgRkRERERE5GAMYkRERERERA7GIEZERERERORgDGJEREREREQOxiBGRERERETkYAxi1CBt2LAB0dHRSE1NdXYpRA3e2LFjMXbsWKc9fnR0NN544w2nPb4z9e3bF7Nnz3Z2GVRNqampiI6OxoYNG2p83wMHDiA6OhoHDhyoh8qI6E7EIEbkRFu2bMGqVaucXUYZY8eOxYMPPlhme1JSEuLj4zFs2DDk5+ff1mNs3boVzz//PPr374/o6Ogqg8TJkycxZcoUJCQkID4+Hg8++CC+/PLL26qBqu/w4cNYuHAhCgsLnV1KlYxGIx544AFER0djxYoVzi6n0crMzMT8+fMxduxYdOzYscoQcvjwYTz66KOIj49Hjx498NZbb0Gj0VT78davX4+BAweiffv26N+/P7766qu6OI165czP8Ojo6HK/Pvvss2rd32Aw4H//+x969uyJuLg4PPzww9i7d289V01EN5M6uwCiO9mPP/6I8+fP4/HHH3d2KVVKSkrClClT0KJFC6xcuRI+Pj63dbw1a9bgxIkTaN++fZWh7s8//8SUKVPQtm1bTJs2DSqVClevXsWNGzduqwaqviNHjmDRokUYNmwYvLy8nF1Opb7++mukp6c75LG2b98OkUjkkMdytMuXL2PZsmWIiIhAdHQ0jhw5UuG+p0+fxuOPP45WrVph9uzZuHHjBj7//HOkpKRg+fLlVT7Wt99+i1dffRX3338/xo8fj0OHDuGtt96CVqvFpEmT6vK06pSzP8N79OiBf/3rX3bb2rZtW637zp49Gzt27MC4ceMQERGBjRs3YtKkSfjiiy/QpUuX+iiXiG7BIOaiiouLoVKpnF1GhSwWC4xGI9zc3JxdSo1ptVoolUpnl+FQBw8exNSpUxEREVEnIQwA5s2bh+DgYIjF4nJb30qp1Wq8+OKL6NOnDz7++GOIxWzIp4rl5ORg8eLFmDhxIj7++ON6fzy5XF7vj+EssbGxOHDgAHx8fLB9+/ZKg9gHH3wALy8vfPXVV/Dw8AAAhIaG4pVXXsGff/6Jnj17VnhfnU6HDz/80PYeB4CRI0fCYrHg008/xSOPPAJvb++6PTkXERERUSaIVcfx48fx008/4YUXXsCECRMAAEOHDsWDDz6I+fPn49tvv63rUomoHLyicQELFy5EdHQ0Lly4gOeeew5du3bFY489Zrv9hx9+wPDhwxEXF4eEhATMmjXL7q/FX375Jdq0aWPX5ejzzz9HdHQ05s6da9tmNpvRsWNH/O9//7NtW7FiBUaNGoW77roLcXFxGD58OLZv316mxtIxJJs3b8agQYPQvn17/PHHHwCA8+fPY9y4cYiLi0Pv3r3xySefwGKx1Pp5uHjxImbMmIFOnTrhrrvuwltvvQW9Xl9m/6qeF+CfLnonTpzA6NGjER8fjw8++KBa9ajVarz99tvo27cv2rVrh27dumH8+PE4efKk7di//fYb0tLSbF1K+vbta7u/wWDAxx9/jPvuuw/t2rVDYmIi5s2bB4PBYPc4Nz+3999/P9q3b4/hw4fjr7/+qulTWK5Dhw5h8uTJCA8Px8qVK+Hr61snx23atGm1QtWWLVuQnZ2NWbNmQSwWo7i4uFa/HzcrHYOYnJyMuXPn4u6770aHDh0wffp05Obm2u0bHR2NhQsXljnGrWODSo9Z+pf8u+++G126dMGcOXNgMBhQWFiIF154AV27dkXXrl0xb948CIJQ49rXrl2Lfv36IS4uDiNGjMChQ4fK3a8uf38WLlyIefPmAQDuvfde2+/rrWM4d+3ahQcffBDt2rXDoEGD8Pvvv9vdXtV7oi7Mnz8fLVq0wJAhQ277WCkpKXj66afRo0cPtG/fHr1798asWbNQVFRk26e8MWJnzpzBmDFj7D7Tvv/++zLPWd++fTF58mQcOHDA9lk0ePBgW/e/n3/+GYMHD7a9JqdOnSrzOLNnz8a9996L9u3bo0ePHnjppZeQl5d32+cOAB4eHtX6o4tarca+ffswZMgQWwgDgH/9619QqVTYtm1bpfc/cOAA8vPz7f7fAoDRo0ejuLgYv/32W23KR2FhIWbPno3OnTujS5cuePHFF+1eu5tdvHgRzzzzDBISEmzP9y+//FLp8Sv7DDcYDFiwYAGGDx+Ozp07o0OHDnjsscewf//+Wp1LZXQ6Xbn/x1Vm+/btkEgkeOSRR2zb3NzcMGLECBw5csRhLcpEdzq2iLmQGTNmoHnz5pg1a5btAu/TTz/FggULMHDgQIwYMQK5ubn4+uuvMXr0aGzatAleXl7o0qULLBYLkpOTcc899wCwXnyLxWK7i7xTp06huLgYXbt2tW378ssv0bdvXwwePBhGoxE//fQTZsyYgaVLl6JPnz529e3fvx/btm3D6NGj4evri2bNmiErKwvjxo2D2WzGpEmToFQqsW7duttqKZs5cyaaNWuG5557DkePHsVXX32FwsJC24VkdZ+XUvn5+XjyyScxaNAgDBkyBP7+/tWq49VXX8WOHTswZswYtGrVCvn5+UhOTsbFixcRGxuLKVOmoKioCDdu3MBLL70EAHB3dwdgbTGcOnUqkpOTMXLkSLRq1Qrnzp3DF198gZSUFHzyySd2j/XXX39h69atGDt2LORyOdasWYOJEydi/fr1iIqKqvVzmZycjCeffBKhoaFYtWoV/Pz8yuxTVFQEo9FY5bHc3Nxs51cTSUlJ8PDwQEZGBqZNm4aUlBSoVCoMGTIE//3vf2/rd+Wtt96Cl5cXnnrqKaSlpeGLL77AG2+8gY8++ui2jhkQEICnn34ax44dw9q1a+Hp6YkjR46gadOmmDVrFn7//XesWLECUVFRGDp0aLWPvX79esyZMwcdO3bEv//9b1y7dg1Tp06Ft7c3mjZtatuvrn9/7rvvPqSkpODHH3/ESy+9ZAvjN/8+JCcn4+eff8Zjjz0Gd3d3fPXVV3jmmWewe/du2/5VvScAa4uzVqut8rmQSCRlWkmOHz+OTZs24Ztvvrnt7oIGgwETJkyAwWDAmDFjEBAQgIyMDPz2228oLCyEp6dnuffLyMjAv//9bwDApEmToFKpsH79+gpbzq5cuYLnnnsOo0aNwpAhQ/D5559jypQpeP311/Hhhx/i0UcfBQB89tlnmDlzJrZv3277A8a+fftw7do1DB8+HIGBgTh//jzWrVuHCxcuYN26dbbnwGg0VhhAbuXj41PjVuezZ8/CZDKhXbt2dtvlcjnatGmD06dPV3r/0oB56/1jY2MhFotx+vTpGrf6CIKAadOmITk5GaNGjUKrVq2wc+dOvPjii2X2PX/+PB599FEEBwfjySeftIXH6dOnY+HChbjvvvvKfYzKPsPVajXWr1+PBx98EA8//DA0Gg2+++472/uqTZs2tuMUFBTAbDZXeU5KpbJMb4yNGzfim2++gSAIaNWqFaZOnYrBgwdXeazTp08jIiLCLjgDQFxcnO32mz9TiKieCNToffzxx0JUVJTw7LPP2m1PTU0V2rRpI3z66ad228+ePSu0bdvWtt1sNgudOnUS5s2bJwiCIFgsFiEhIUF45plnhDZt2ghqtVoQBEFYuXKlEBMTIxQUFNiOpdVq7Y5tMBiEBx98UBg3bpzd9qioKCEmJkY4f/683fa3335biIqKEo4dO2bblpOTI3Tu3FmIiooSrl27VuPnYcqUKXbbX3vtNSEqKko4ffp0jZ4XQRCEMWPGCFFRUcKaNWuqXUepzp07C6+//nql+0yaNEm45557ymzftGmTEBMTI/z1119229esWSNERUUJycnJtm1RUVFCVFSU8Pfff9u2paWlCe3btxemT59e47oFwXreCQkJQseOHYVBgwYJOTk5le5bWkNlXy+++GKFxxg0aJAwZsyYcm8bPHiwEB8fL8THxwtvvvmmsGPHDuHNN98UoqKihFmzZtXq/L7//nshKipKePzxxwWLxWLb/s477wht2rQRCgsLbduioqKEjz/+uMwx7rnnHrtzKj3mE088YXfMRx55RIiOjhbmzJlj22YymYTevXtXeM7lMRgMQrdu3YR//etfgl6vt21fu3atEBUVZXes+vj9Wb58eYXvyaioKCE2Nla4cuWKbdvp06eFqKgo4auvvrJtq857ovR9XNXXre8bi8UijBgxwvY5eO3aNSEqKkpYvnx5pY9XkVOnTglRUVHCtm3bKt3v1t+DN998U4iOjhZOnTpl25aXlyckJCSUef7uueceISoqSjh8+LBt2x9//CFERUUJcXFxQlpamm37t99+K0RFRQn79++3bbv181cQBOHHH38UoqKi7F77/fv3V+s5rewzd9u2bWUe/9bbbv19EwRBeOaZZ4QePXqUe8xSr7/+utCmTZtyb7v77rtr9T7fuXOnEBUVJSxbtsy2zWQyCY899pgQFRUlfP/997bt//73v4UHH3zQ7n1lsViERx55ROjfv79tW+nzePNzUNFnuMlksjueIAhCQUGB0L17d+Gll16y2176e1DV162fQ4888oiwatUqYdeuXcI333wjPPjgg0JUVJSwevXqKp+fQYMGlfl/WhAE4fz587X+P4+Iao4tYi5k1KhRdj/v3LkTFosFAwcOtOtuFRAQgObNm+PAgQOYMmUKxGIxOnbsaGv9unjxIvLz8zFp0iT8/PPPOHr0KHr06IFDhw6hdevWdq1FCoXC9u/Sv+p17twZP/30U5n6unbtisjISLtte/bsQYcOHWx/hQOsf2UfPHgwvvnmm1o9D6NHj7b7ecyYMfjmm2/w+++/IyYmptrPSym5XI7hw4fXuA4vLy8cO3YMGRkZCA4OrtF9t2/fjlatWqFly5Z2Nd59990ArF15OnXqZNvesWNHu78mh4SE4N5778Xu3bthNpshkUhqXH9xcTEMBgP8/f3L/NX0Zi+++GK1ZtILCgqqcQ2ldWi1WowaNQqvvPIKAKB///4wGAxYu3YtnnnmGURERNTq2CNHjrRrOenSpQtWrVqFtLQ0xMTE1OqYI0aMsDtmXFwcjhw5ghEjRti2SSQStGvXrkZd8k6cOIGcnBw888wzdq0rw4YNs2vtBZzz+9O9e3eEh4fbfo6JiYGHhweuXbtm21ad98TQoUPRuXPnKh/v1pbQDRs24Ny5c3U2Lqz0d/7PP/9EYmJitceF/vHHH+jQoYNdi4ePjw8GDx5c7iyAkZGR6Nixo+3n+Ph4ANbXKiQkpMz2a9eu4a677gJg//mr1+uh0Whs+508edI24UJMTAxWrlxZrfoDAwOrtd/NdDodgPLHy7m5udlur+z+Mpms3Nuqc//y/P7775BKpbYWRcD6vhszZoxdT4/8/Hzs378fzzzzDNRqtd0xevbsiYULF9bqM1wikdjeNxaLBYWFhbBYLGjXrl2ZLqb/+9//qtW1MCwszO7nW8dxPfTQQ3jooYfw4YcfYvjw4Xa/H7fS6XQVvl6ltxNR/WMQcyGhoaF2P6ekpEAQBPTv37/c/aXSf17+Ll26YNGiRdDpdDh06BACAwMRGxuLmJgYHDp0CD169EBycjIGDhxod4zdu3fj008/xenTp+3GnpTXLejW+gDg+vXrtguHm7Vo0aLyk61E8+bN7X4ODw+HWCy2jc2oyfMCAMHBwbUakP/8889j9uzZ6NOnD2JjY5GYmIihQ4eW+c+0PFeuXMHFixfRrVu3cm/Pycmx+/nWcwasg7i1Wi1yc3NrdXHVvHlz/Otf/8L8+fPx7LPPYsGCBeVekN/anaiulV5M3Dqhx+DBg7F27VocPXq01kHs5gtdALY/MtzOFO23HrO0C9ut3Xw8PT1RUFBQ7eNev34dQNnXWiaTlfmdcsbvT3ndmLy9ve2ey+q8J8LCwqr1HrmZWq3GBx98gAkTJtRZd6qwsDCMHz8eK1euxJYtW9ClSxf07dsXQ4YMqbBbIgCkpaWhQ4cOZbbfHFJvVt7vBQA0adLEbntpMLz5+czPz8eiRYuwdevWMq/pzV0Rvb290b179wprvl2l79Fbxx8C1oBYWSAovX9F3Zurc//ypKWlITAwsEx36Fv/b7l69SoEQcCCBQuwYMGCco+Vk5NT4yAGWLsNfv7557h8+bLd+d36f2F1/vBQHXK5HKNHj8arr76KEydOVDrzoUKhqPD1Kr2diOofg5gLufUvxBaLBSKRCMuWLSv3AvrmWRU7d+4Mo9GII0eO4NChQ7YP8M6dO+PQoUO4ePEicnNz7T7YDx06hKlTp6Jr16549dVXERgYCJlMhu+//x4//vhjmcdz1gf7raGwJs8LUPu6H3jgAXTp0gU7d+7E3r17sWLFCixbtgwLFy5EYmJipfe1WCyIioqyjTu41a0XafXlySefRH5+PpYvX45XXnkF77zzTpnnMz8/v1pjxBQKRaUXsBUJCgrC+fPny4zNKx2fVJMwc6uKxsII1ZhEo6IxHRUd05GzPTrj96eiVrObn8vqvCc0Gg2Ki4ur9XilvwMrVqywrR1W+geX0qUNCgsLkZqaiqCgoBr/QWX27NkYNmwYfvnlF+zduxdvvfUWli5dinXr1tXZc1jR81ad53PmzJk4cuQIJkyYgDZt2kClUsFisWDixIl2+xkMhmq/T/z8/Grcgl4a1DMzM8vclpWVVWVreGBgIMxmM3Jycuze5waDAfn5+bVuTa+O0ol/nnjiCfTq1avcfSoK0ZX54YcfMHv2bPTr1w8TJkyAv78/JBIJli5datdKDAC5ubnVGiOmUqmqHGdbGuyrer0DAwORkZFRZntWVhaA2vdgIKKaYRBzYeHh4RAEAaGhoVW2MMXFxUEmkyE5ORnJycm26Wy7du2K9evX22Z6ujmI7dixA25ublixYoXdBc73339f7RpDQkJw5cqVMtsvX75c7WPc6sqVK3Z/Ub9y5QosFovtr5A1eV5uV1BQEEaPHo3Ro0cjJycHw4YNw5IlS2wXnRVNKBAeHo4zZ86gW7du1Zp0oLznMCUlBUqlstwJNmriP//5DwoKCrB+/Xp4e3uXmSHu6aefxsGDB6s8zrBhw/Duu+/W+PFjY2Oxd+9eZGRkoGXLlrbtpRd9t3t+Vbm1VQewXiCWXrA4SmlL25UrV+xauoxGI1JTU+26UtbH709drZVV1Xvi888/x6JFi6o8TrNmzfDrr78CANLT01FQUIBBgwaV2W/JkiVYsmQJNm3aZNddsLpKZ8ObNm2abcHiNWvWYNasWRXWVd7zefXq1Ro/dmUKCgqQlJSEp59+Gk899ZRte0pKSpl9jxw5gnHjxlXruL/88ku5vRcqExUVBalUihMnTuCBBx6wbTcYDDh9+nSZnhS3Kn1dTpw4YfdHqhMnTsBisdSqm3CzZs2wf/9+aDQau/By6/8tpf9XyGSyWrUaVvS+2LFjB8LCwrBo0SK7fcrrOjtixAikpaVV+VhPPfUUnn766Ur3KQ15VX0uxsTE4MCBA1Cr1XZdz48dOwYAtXqvEFHNMYi5sP79++ODDz7AokWLMH/+fLv/DARBQH5+vm02Mzc3N7Rv3x4//vgjrl+/bgtcXbp0gU6nw5dffonw8HC7v5JJJBKIRCK7v+SlpqZWOeXvzRITE/HFF1/g+PHjtnFiubm52LJlS63Pe/Xq1XZr1nz99dcAgN69ewOo2fNSW2azGcXFxXYtQP7+/ggKCrLrDqJUKsudzWzgwIHYs2cP1q1bZze9MGDtu2+xWOxa7o4cOYKTJ0/aZp5LT0/HL7/8gl69etVqfNit3njjDRQWFmLlypXw8vLCtGnTbLfV9xixgQMH4rPPPsN3331nF0C+++47SKVSJCQk1Oq41RUWFlZmivh169ZV6y/Ydaldu3bw8/PDt99+i+HDh9v++LFx48Yyz399/P6UjpGq7ux7t6rue6I2Y8TGjh2Lfv362d2ek5ODOXPmYPjw4bj33ntrHC7UajUUCoVdV+WoqCiIxeJyu3SV6tmzJ1avXo3Tp0/bLmbz8/Nv6zOtPBW9r7/44osy2+p7jJinpye6deuGzZs3Y9q0abYL+x9++AHFxcUYMGCAbV+tVovr16/D19fXFhbuvvtu+Pj4YM2aNXZBbM2aNVAqlWVm4K2O3r17Y+3atbYZQAHr72Dp/wel/P39kZCQgLVr12LMmDFlPqdyc3MrDTUVfYaXvj6CINj+jzl27BiOHj1apvtybcaIlVeXWq3GF198AV9fX9t7uXTfvLw8hISE2N7HAwYMwOeff461a9fa/vBqMBiwYcMGxMfHc8ZEIgdhEHNh4eHhmDlzJt5//32kpaWhX79+cHd3R2pqKnbt2oWRI0faPoABa+j67LPP4OnpaZvy3N/fHy1atMDly5fLTFiRmJiIlStXYuLEiXjwwQeRk5ODb775BuHh4Th79my1apw4cSJ++OEHTJw4EePGjbNNXx8SElLtY9wqNTUVU6ZMQa9evXD06FFs3rwZDz74oO2vqjV9XmpDo9EgMTER999/P2JiYqBSqbBv3z78/fffdi1KsbGx2Lp1K+bOnYv27dtDpVKhb9+++Ne//oVt27bh1VdftU2sYDabcenSJWzfvh3Lly9H+/btbceJiorChAkT7KYfB1Dmr6fR0dFISEgod9KAyojFYsyfPx9qtRoLFiyAt7e3bVKU2o4R++uvv2xrVeXm5qK4uNg2rXrpWlsA0LZtWzz00EP4/vvvYTab0bVrVxw8eBDbt2/H5MmT7cZuLFy4EIsWLcKXX35pm9Dgdj388MN49dVX8fTTT6N79+44c+YM/vzzzzpbT626ZDIZZs6ciTlz5uDf//63rRvehg0byoypqo/fn9ILuw8//BAPPPAAZDIZ7rnnnmovHF/d90RtxojFxsbaXXgCsHVRjIyMLBPSStd6Km1RK8/+/fvxxhtvYMCAAYiIiIDZbMYPP/wAiUSC+++/v8L7TZw4EZs3b8b48eMxZswY2/T1TZs2RX5+fp21LHp4eKBr165Yvnw5jEYjgoODsXfv3jJruwG3N0as9D154cIFANZwlZycDAB2f5CZNWsWRo0ahbFjx2LkyJG4ceMGVq5ciZ49e9r+CAZYlxgYN26cXeuOQqHAM888gzfeeAPPPPMMevXqhUOHDmHz5s2YNWuW3VpmBw4cKHP/8vTt2xedOnWyfc5HRkbi559/Ljc0vfrqq3jssccwePBgjBw5EmFhYcjOzsbRo0dx48YNbN68ucLHqegzvE+fPvj5558xffp09OnTB6mpqfj2228RGRlZputtbcaIrV69Grt27cI999yDkJAQZGZmYsOGDbh+/TrmzZtn10tl9erVZT4X4+PjMWDAAHzwwQfIyclB8+bNsXHjRqSlpeHtt9+ucT1EVDsMYi5u0qRJiIiIwKpVq7B48WIA1vEhPXr0sFs8GPgniHXs2NFuPEuXLl1w+fLlMv9ZdOvWDW+//TaWLVuGd955B6GhoXj++eeRlpZW7RAVFBSEL7/8Em+99RY+++wz+Pj4YNSoUQgKCsLLL79cq3P+6KOPsGDBArz//vuQSqUYM2YMXnjhBbt9avK81IZCocCjjz6KvXv34ueff4YgCAgPD7f9h1/qsccew+nTp7FhwwasWrUKzZo1Q9++fSEWi7F48WKsWrUKP/zwA3bu3AmlUonQ0FCMHTu2TJfKrl27okOHDli8eDGuX7+OyMhIzJ07165Lj0ajAVC7v3gD1oHgixYtwvjx423rb1VnvZqK7N+/v0wXtNLB8k899ZTdenWvv/46QkJCsGHDBuzatQshISF46aWX8Pjjj9vdv7i4GCKRCAEBAbWu61YjR45EamoqvvvuO/zxxx/o3LkzVq5cWeaxHeGRRx6B2WzGihUrMG/ePERFRdnWxLtZffz+xMXFYcaMGfj222/xxx9/wGKx4Jdffql2EKvue8IRiouLy52g5GbR0dHo2bMndu/ejYyMDCiVSkRHR2PZsmXlTsZRqmnTprbPtKVLl8LPzw+jR4+GUqnEW2+9dVvr3t3q/fffx5tvvmlbR6pHjx5YtmxZhWOdauPW362bu57fHMRiY2OxcuVKzJ8/H3PnzoW7uztGjBiBZ599tlqPM3r0aMhkMnz++ef49ddf0bRpU7z00ku2NdlKlYaYqj7HxGIxPv30U7zzzjvYvHkzRCKRbfHtW9fui4yMxPfff49FixZh48aNyM/Ph5+fH9q2bYvp06dX+jgVfYYPHz4c2dnZWLt2Lf78809ERkbif//7H7Zv316trtxV6dSpE44cOYLvvvsO+fn5UCqViIuLw9tvv13hJD23mjdvHj766CNs3rwZBQUFiI6OxpIlS+w+e4mofomE6oxKJ2oESltDkpKS6n3cUEMSHR2N0aNHY86cOZXut2fPHkyePBk//PADoqOjHVSdY40YMQIhISF1NoX5naC6vz+u4sKFCxg0aFC5i87Xp7fffhtr167FkSNH6qS78J1q3rx5+Omnn7Bz585azWZLRNSQOG4aLyJyqv3792PQoEEuG8LUajXOnDmDGTNmOLsUasAOHDiAjh071msIu3UNpry8PGzevBmdO3dmCLtNBw4cwLRp0xjCiMglsGsiNXjVmc7akS1g1a2noV1wvfjii84uoV55eHjgxIkTzi6jVqpaAuDmqdrp9pTO2FifHnnkESQkJKBVq1bIzs7G999/D7VabdeVj2qnJrPyEhE1dAxi1OBVZzrrmszUeLuqW09NZ2mjO1dVSwDcPFU7NXyJiYnYsWMH1q1bB5FIhLZt2+Ltt9/m2BsiIrLDMWLU4F27dq3MApi36ty5c50Ogm9M9VDjd+LEiUqXAHBzc6vVzGpERETUcDGIERERERERORgn6yAiIiIiInIwjhGrgMViQWZmJtzd3etsAU4iIiIiqjuCIECj0SAoKMhuDVSixoBBrAKZmZlITEx0dhlEREREVIU9e/agSZMmzi6DqEYYxCrg7u4OwPrG9vDwcHI1RERERHQrtVqNxMRE23UbUWPCIFaB0u6IHh4eDGJEREREDRiHkVBjxM60REREREREDsYgRkRERERE5GAMYkRERERERA7GINZA/Hj8Ov5KyXV2GURERERE5AAMYg1AnsaAp745gqlfJzu7FCIiIiIicgAGsQZAKrHO9JOtNkBrMDu5GiIiIiIiqm+NMoj99ddfmDJlCnr27Ino6Gjs2rXL7nZBELBgwQL07NkTcXFxePzxx5GSkuKcYqvBw00KN6n1pchW651cDRERERER1bdGGcSKi4sRHR2NV199tdzbly1bhq+++gqvvfYa1q1bB6VSiQkTJkCvb5ghRyQSIdDTDQCQWdQwayQiIiIiorrTKBd0TkxMRGJiYrm3CYKAL7/8ElOnTkW/fv0AAPPmzUP37t2xa9cuDBo0yJGlVluAhxtS87RsESMiIiIiugM0yhaxyqSmpiIrKwvdu3e3bfP09ER8fDyOHDnixMoqF+BhbRFjECMiIiIicn2NskWsMllZWQAAf39/u+3+/v7Izs6u8H4GgwEGg8H2s1qtrp8CK1DaNTGLXROJiIiIiFyeywWx2lq6dCkWLVrktMcP9JADYIsYEREREdGdwOWCWGBgIAAgJycHQUFBtu05OTmIiYmp8H6TJ0/G+PHjbT+r1eoKx6HVhwC2iBERERER3TFcboxYaGgoAgMDkZSUZNumVqtx7NgxdOzYscL7yeVyeHh42H05UqBtjJihij2JiIiIiKixa5QtYhqNBlevXrX9nJqaitOnT8Pb2xshISEYN24cPv30UzRv3hyhoaFYsGABgoKCbLMoNkSlLWLsmkhERERE5PoaZRA7ceIExo0bZ/t57ty5AIBhw4bh3XffxZNPPgmtVos5c+agsLAQnTt3xvLly+Hm5uaskqtU2iLGrolERERERK6vUQaxu+66C2fPnq3wdpFIhBkzZmDGjBkOrOr2lLaIFRvMKDaYoJI3ypeGiIiIiIiqweXGiDVW7nIJFDLry5FdxHFiRERERESujEGsgRCJRP+sJabWObkaIiIiIiKqTwxiDUiAbZwYW8SIiIiIiFwZg1gDYgtinDmRiIiIiMilMYg1IKVdE7M5cyIRERERkUtjEGtAAjy4lhgRERER0Z2AQawBsU3WwRYxIiIiIiKXxiDWgAR6yAGwRYyIiIiIyNUxiDUgnKyDiIiIiOjOwCDWgPwzWQenryciIiIicmUMYg1IaYuY1miGRm9ycjVERERERFRfGMQaEHc3KZQyCQBO2EFERERE5MoYxBoYW/dEjhMjIiIiInJZDGINTABnTiQiIiIicnkMYg0M1xIjIiIiInJ9DGINzD9T2HPmRCIiIiIiV8Ug1sDYghhbxIiIiIiIXBaDWAPDyTqIiIiIiFwfg1gDU9oixiBGREREROS6GMQamEBP66yJ7JpIREREROS6GMQamEAPBQBri5ggCE6uhoiIiIiI6gODWAMTUNIipjNaoDGYnVwNERERERHVBwaxBkYll0IllwBg90QiIiIiIlfFINYAceZEIiIiIiLXxiDWAHEtMSIiIiIi18Yg1gAFcgp7IiIiIiKXxiDWAJVO2JHNFjEiIiIiIpfEINYA2bomskWMiIiIiMglMYg1QKWTdWQVGZxcCRERERER1QcGsQYogGPEiIiIiIhcGoNYA8RZE4mIiIiIXBuDWAMUdNM6YoIgOLkaIiIiIiKqawxiDVBpi5jeZEGR3uTkaoiIiIiIqK4xiDVASrkEHm5SAJzCnoiIiIjIFTGINVABHiVriak5cyIRERERkathEGugOGEHEREREZHrYhBroAI9OYU9EREREZGrYhBroLiWGBERERGR65I6u4D6sHDhQixatMhuW4sWLbB9+3YnVVRz7JpIREREROS6XDKIAUDr1q2xcuVK288SicSJ1dQcuyYSEREREbkulw1iEokEgYGBzi6j1kpnTWSLGBERERGR63HZIHblyhX07NkTbm5u6NChA5577jmEhIQ4u6xq+6dFjNPXExERERG5GpcMYnFxcZg7dy5atGiBrKwsLF68GKNHj8aWLVvg4eFR7n0MBgMMhn9Cj1qtdlS55bKNEVPrIQgCRCKRU+shIiIiIqK645JBLDEx0fbvmJgYxMfH45577sG2bdvw8MMPl3ufpUuXlpngw5lKW8QMJgsKdSZ4K2VOroiIiIiIiOqKSwaxW3l5eSEiIgJXr16tcJ/Jkydj/Pjxtp/VarVdoHM0hUwCTzcpivQmZKv1DGJERERERC7kjghiGo0G165dq3TyDrlcDrlc7sCqqhbg6YYivQlZRXq0Ciy/SyURERERETU+Lrmg83vvvYeDBw8iNTUVhw8fxlNPPQWxWIwHH3zQ2aXVSOnMiZzCnoiIiIjItbhki9iNGzfw7LPPIj8/H35+fujcuTPWrVsHPz8/Z5dWI7aZEzmFPRERERGRS3HJIPbhhx86u4Q6cfPMiURERERE5DpcsmuiqwjzVQEADl/Jd24hRERERERUpxjEGrAH4ppCJAKSLuUgJVvj7HKIiIiIiKiOMIg1YM18lOjd2jrT47pD15xcDRERERER1RUGsQZuVNcwAMD65FSYzBYnV0NERERERHWBQayBu7dNMAI85Mgq0uPXM5nOLoeIiIiIiOoAg1gDJ5eK8VCnUADA2r/YPZGIiIiIyBUwiDUCI0u6J+4+m4kbBTonV0NERERERLeLQawRaBXogYQIP1gEYD0n7SAiIiIiavQYxBqJUQnWVrG1h67BYhGcXA0REREREd0OBrFGYmC7pvBUSJGap8W+iznOLoeIiIiIiG4Dg1gjoZRLMLRDMwDAt39ddXI1RERERER0OxjEGpHS7ok/n8xArsbg5GqIiIiIiKi2GMQakdgQb7Rv5g2D2YINh1Nv61iFOiOu5RbXUWVERERERFQTDGKNzCMlU9mv/esaBKF2k3YIgoBRS/ej17zdGPDR7/jktwtIy9fWZZlERERERFQJBrFGZkiHEChlEpzPVOPw1fxaHSM1T4tT6YUAgDM3ijBv+1n0ePdXjFyShNUHrqBQZ6zDiomIiIiI6FYMYo2Ml0KGge2aAAC+r2X3xIOXcwEA7Zp5Ye7w9rirhZ91e0ouXt54Avf87zes4zT5RERERET1hkGsEXqocygA4Mdj16Ezmmt8/9Ig1iMyAI8mhGPt5G7YN7svXhoYgxYB7sjRGPDCd8cx/NN9OJ6aX5elExERERERGMQapW4t/RHirUChzoRdpzNqfP+/UqxBrLQlDABCfJSYnNgKO2b2xssPtIG7XIKj1/Lxr8V78dKGvzlLIxERERFRHWIQa4TEYhGGd7K2in2fXLPuiZlFOlzK1kAkAjo39ytzu1wqxpO9W+LX5/tgWMdmEARgzcGr6PO/3Xjxu+PYeSoDWkPNW+GIiIiIiOgfUmcXQLUzvFMzLNp9AXvOZSGzUIcgL0W17ncoJQ8AEB3sCW+lrML9gr0U+PCRDng0IRxzfjiBMzeKsPbQNaw9dA1uUjF6tQ5AvzbBCPdT4UpuMa7kFONqrgYp2cW4XqBFU28lOob7oEOYDzqG+aBVoAfEYlGdnDsRERERUWPHINZItQz0QKdwHxy+mo9NR9MwqXerat2vdHzYzd0SK5PQwg8/PdML+y5m45fTmdh5KgNp+VrsOp2JXaczK7xffrERp9ML8c2BqwAATzcpukf6462h7RHo6VatxyYiIiIiclUMYo3YQ51DcfhqPr5PTsOTvVpCJKq6xak0iHWtZhADAIlYhF6tA9GrdSBeHdwWZ24UYdepDOw6k4lCrRHhfipE+KvQ3N8dzf1VCPFR4kqOBkeu5ePI1Xz8nVqAIr0JO05mQCwS4dMxnWt9zkREREREroBBrBF7MC4Er285hbMZRTh5vRDtmnlXun+hzojTN6zrhyVEVD+I3UwkEqFNUy+0aeqFp+9tXeF+bZp6YUC7pgAAk9mCA5dzMe7zg9h24gZ+PZOBvjHBtXp8IiIiIiJXwMk6GjFvpQz3tbUGmu+qMWlHckoeBAGI8FdVe0xZXZBKxOgRGYCJPVsAAP5v00lO+EFEREREdzQGsUZuRMnsiZuPXYfBZKl034Ml09Z3rWVr2O2a0a81mvkokZavxce/nndKDUREREREDQGDWCPXq3UAAj3dkKsx4LezFU+eAQB/lYwPS6jB+LC6pJJL8dqQWADAst8v4eyNIqfUQURERETkbAxijZxUIsawjs0AAN8frrh7os5oxrHUfADOC2IAcF/bYPRvGwyTRcArm/6GxSI4rRYiIiIiImdhEHMBD5V0T/z1TCZyNYZy9zl6LR9Gs4AgTzeE+6kcWV4Zrw6JhUouwV8pedUa20ZERERE5GoYxFxAdBNPtGvmBaNZwOajaeXuc3O3xOpMc1+fmvkoMatfFADgnW2nkaPWO7UeIiIiIiJHYxBzEaWtYl/tvwKdseyMhKUTdTizW+LNxveIQJumXsgvNmLutjPOLoeIiIiIyKEYxFzEsI7N4Ocux8UsDV7fcsruNpPZguQreQAaThCTSsR4e1g7iETWqff3X8pxdklERERERA7DIOYifFRyfPRIB4hEwJqDV7HxyD9jr05eL0SxwQxvpQxRQZ5OrNJep3BfPJoQDgB4ZdOJKqffJyIiIiJyFQxiLqR3VCCe7tsaAPDfDSdwPsM6PfxfJd0SuzT3hVjs3PFht3rx/hgEeMhxIVONz36/6OxyiIiIiIgcgkHMxcy4tzV6RgZAazRj6urDKDaYcNDJ64dVxlslwyuD2gIAFv56AVdyNE6uiIiIiIio/jGIuRiJWISPRnVAkKcbLmSq8d8Nf9taxLo2wCAGAP/qEIKekQHQmyz4vx9OQhC4thgRERERuTYGMRcU4OGGRY91gkQswqaj15FXbIRSJkG7EG9nl1YukUiEN4e2g1wqxu/nsvDj8XRnl0REREREVK8YxFxUQgs//Of+aNvPHcN9IJc23Je7RYA7pvVpBQB448dTKNQZnVwREREREVH9abhX5nTbJvVqiX5tggAAiVGBTq6malP7tELLAHdkFekxf8dZZ5dDRERERFRvGMRcmFgswiejO+OrCQkY36OFs8upkptUgreGtgNgXZj66LV85xZERERERFRPXDqIrV69Gn379kX79u3x8MMP4/jx484uyeHkUjF6tQ5s0N0Sb9Y9MgDDOjaDIAD/3fA3TOaq1xb79UwGRi5Jwr4L2Q6okIiIiIjo9jWOq/Na2Lp1K+bOnYvp06dj48aNiImJwYQJE5CTk+Ps0qgKLw9qA2+lDKfSCzGvii6KF7PUePqbIziYkouJXx7CibQCB1VJRERERFR7LhvEVq5ciZEjR+Khhx5CZGQkXn/9dSgUCnz//ffOLo2qEODhhvceag8A+Oz3S9j6d/mzKGoNZkxffRgagxlyiRjFBjMeX/kXruUWO7JcIiIiIqIac8kgZjAYcPLkSXTv3t22TSwWo3v37jhy5EiF91Gr1XZf5DwD2jXF5MSWAID/rD+GC5lFZfZ5fctJnLlRhAAPN2yf2QttmnohW63Hvz8/iFyNwdElExERERFVm0sGsby8PJjNZvj7+9tt9/f3R3Z2+eOIli5dis6dO9u+EhMTHVEqVeI//aPRraU/NAYzJn+VDLXeZLtt45FUfPvXNYhEwIJRHdAy0AOrxndFMx8lLmVrMOGLv6A1mJ1YPRERERFRxVwyiNXG5MmTkZycbPvas2ePs0u640klYnz8aEc08VLgYpYGL3x3DIIg4EJmEf674QQAYMa9rdEjMgAAEOylwBdPdIW3UoYjV/Px9Joj1Zrsg4iIiIjI0VwyiPn6+kIikZSZmCMnJwcBAQHl3kcul8PDw8Pui5wv0NMNi0d3gkwiwta/b2DhrxcwbfVhaI1m9Ij0x9N9W9vtHxnkiRX/7gI3qRi7Tmfg1c0nIQiCk6onIiIiIiqfSwYxuVyO2NhYJCUl2bZZLBYkJSWhY8eOTqyMaqNzc1/834NtAQAf7DyHcxlqBHq64aNHOkIiFpXZv0uEHxaM6giRCFh94Cp2nspwdMlERERERJVyySAGAOPHj8e6deuwceNGXLx4Ea+99hq0Wi2GDx/u7NKoFsbe3RzDOjYDAIhLxoUFerpVuP+Adk0wNbEVAOD1Lac4XoyIiIiIGhSpswuoLw888AByc3Px8ccfIysrC23atMHy5csr7JpIDZtIJMI7w9oj2EuB+FBvdG9V9ev4VN9I/HD0OtLytVi0+zz+c3+MAyolIiIiIqqaSOAAmnKp1Wp07twZycnJHC/WiO04eQOTv0qGTCLC9pm90SqQryUREZGr4PUaNWYu2zWRCAD6tw3GPdGBMJoFvPoDJ+5oKHRGM18LIiIiuqO5bNdEIsDapfG1IbHY++Hv+PNCNn48no7B8SHOLqtBUetNkIpFUMgkdX5si0XA1dxinE4vxOn0QpxKL8Lp9EKk5WsR4a/ChF4tMaJTKJTyun9sIiIiooaMQYxcXnN/d0zr0wof7TqPt346hXtiguDhduf96guCgLR8LU5dL8Tp9CKcSi/A6fQiXM0thkImRv+2TTC8UzP0jAyAVHJ7jeWXstRYtS8FG4+koUhnKneflJxi/N+mE/jg57MY2y0C47o1R4BHxROwEBEREbkSjhGrAPscuxad0Yz7P/odV3KKMbFnC7xSMh1+ZfQmM17a8DeK9Wa8/q9YBHspKt3/RFoB9l/KwciuYfBSyOqq9EplFupwLU+LFgHu8FXJIBLZT+evM5qRdDEHu89m4tczmUjN01Z5zEBPN/wrPgTDOjVDywAPyCSiagUzQRDwx/lsrNx7GbvPZtm2y6ViRAd7ok1TT8Q08UKbpl5oEeCO7SfSsfzPy7aa3KRiDO8UitF3hSM2xKvMuRAREd2K12vUmDGIVYBvbNez+2wmxq/8CxKxCD890xMxTbwq3NdiETBj7VFsOXYdABDg4YZFj3XE3S39y+xrtgj49LcL+HDXeZgtApr5KPHhIx2Q0MKvwuPrjGZsOpKGrCI9hnVqhlBfVY3P53R6IUZ9th8FWiMAwFspQ8tAd7QIcEeojxInrhdi38Vs6IwW231kEhEigzzRtqkX2jS1fo9p6oVrucXYcDgVm49dR16xscxjiUXWQCWTiKGUSeCjksFHJYevSgZflRyeCil+O5uF85lqAIBIBNwbE4TxPVrgrhZ+FQY5k9mCHScz8NnvF3EstcC2PaaJJ0Z0DsXQjs3YSkZERBXi9Ro1ZgxiFeAb2zVN/uoQdpzMQMtAd6x8vCua+7uXu9/cbaexdM8lSMUihPurcClLA4lYhBcHROPJXi1trTXX87WYufYoDl7OBQB4KqQo0pkgFgFT+7TCjHujIJf+E0K0BjPWHLyKpb9fREahHgAgFYswJD4EkxNbIbqJZ7XO42KWGo8sTUK22gB3uQSaStZJC/FW4J6YINwTHYTukf5QySvulmkwWbDnXBY2HE7FL2cyYTBZKty3PO5yCR7uEobHu0cgIqD857Y8giDgr5Q8fJGUgp2nMmyPKxWL0Cc6CA93CcW9MUG33WWSiIhcC6/XqDFjEKsA39iuKb1Ai+Gf7EN6gQ6+KhmWju1SpuXqy6QUzPnhJADg/Yfj8UD7pvjvxr+x8UgaAGBguyaYNyIOv5/LxksbjqNQZ4K7XII3/tUO/WOD8caWU1ifnAoAaNfMCx890hFNvRVYfeAKPvv9ErLVBgBAU28Fwv1UOFAS4gCgX5sgTElshS4RFbemXcstxsilSUgv0KFtUy+smXQ35BIxUnI0uJytwaUsNa7mFiMiwB19Y4IQHexZq25+ZosAndEMg8kCo9kCvckCg9kCrcGM/GIj8ooNyC82IK/k3xH+7hjWqdltd8ssKDZiy/Hr+C45FUev5du2B3u5YVTXcIxKCENTb+VtPQYREbkGXq9RY8YgVgG+sV1XRqEOT355CMdTCyCTiPDu8Dg81DkUALDzVAYmf3UIFgF47r4oPH1vawDWFpuvD1zFG1tOwmgW4OcuR67GGqg6hPlgwagOdq1r2/5Ox0sb/0Z+sREKmRgqudS2f6ivEtP6ROKhzs3gJpXg2LV8LP39IraduIHSd2PXCF9MSWyFe6KDIBaL7Gp/eEkSruYWIzLIA2sn3Q1/F+66dyGzCOuTU/F9cqotwIpFwL1tgjH6rnD0bh1o9/wQEdGdhddr1JgxiFWAb2zXpjWY8ey6o9h24gYA4Kl7ItG3TRAeW7YfOqMFo7qGYe7w9mVako5czcO01YeRXqCDSARM7xOJGf1aQ1ZOl7mMQh2eX38Mf5zPBgA091dh+j2RGNaxWbn7X8pSY9kfl/B9choMZmvXvKhgD0xJbIXB8SEo1Box6rP9OJ+pRrifCusmd0MT78onEHEVBpMFO07ewOoDV7D/0j8tiPfHBuOT0Z0hYRgjIroj8XqNGjMGsQrwje36LBYB7+88i8W7LwIAJGIRzBYBfaIDsXxclwrHI+Wo9fhq/xX0jAyotAth6WNsOX4dErEIA2KbVGuMU2ahDiv2Xsbq/Veh1lunfm/mo4RSLsGFTDWaeiuwbnI3hPnVfIIPV3AhU41vDlzF1weuwGCy4MleLfDyoKpnwSQiItfD6zVqzBjEKsA39p3j++RUzN5wHEazgHbNvLB2Uje4N4B1xgq0Rqw+cAWf/5mCbLV1Yo8ADznWTu6GVoH8nfzx+HU89c0RAMC7w9tjVEK4kysiIiJH4/UaNWbOv9okcrKHOoeiZaA7dp7KwBM9WzSIEAZYp6Of1icST/Roge8PpyLpYg6e7tuaIazEg3EhuJipwYe7zuGVTScQ7q9C91YBzi6LiIiIqFrYIlYB/oWFqOETBAEzvj2Kzceuw1spw8Zp3dGSQZWI6I7B6zVqzLgoDxE1WiKRCPNGxKFTuA8KtEZM+OIQ8osNzi6LiIiIqEoMYkTUqClkEiwd2wXNfJS4nK3B1K8PI6tI7+yyiIiIiCrFIEZEjV6gpxtWPN4F7nIJki7l4K53dmHM8gNY+9dVFBQbnV3eHaWg2AhNyWyfREREVLGGMStBA6bRaMqsJUVEDU+YpwSLR7bF/J/P4XhqAX4/lYrfT6XivxIRerYOQK/IADTzVaKZjwrNfJVQyCTOLrnBM5kt2HEqA3+czUJ0E0/0jw1GM9+yyyZYLAL+uJCFtX9dw56zWQCAyCAPxIV6Iy7UB3Fh3ogM9OR6b0RU5zQajbNLIKo1BrEqhISEwGKxOLsMIroNlwB86ewi7jBXAPzi7CKIyOWJxWJERkY6uwyiWmHXRCIiIiIiIgdji1gVrl+/zulQiVyIIAjILzYiNb8Yl7I0+O1MFn4/n4Vig9m2j7+HDM/eF41hHZu5fNfkS1lq/HI6E7tOZ+B4aoFte4sAFR7v0QJD4kNs3Tgzi3T45VQGtp+8gb9S8iAIQLtmXhiVEI4H2jWFUl5+d0+zRcCFrCKk5miRrTEgV61HbrEB2WoDMgt1OJ1eBK3RXO59yyMWWbs+tm/mjbgwH4T6KPHj8XT8dDwdBrO1B0Owlxt6tQ7AhUw1TqUXwWD6p2eDRCzCU/e0wpO9W7G7JFEjp1ar0bt3b2eXQVQrXEesAlyXgujOoTOa8ef5bOw4eQO7Tmcgr2SCj24t/fH2sHYusTaZzmhGZqEemUU6ZBbpcSKtADtO3sDFLPvxFd1a+mNirxa4JzoI4kpCSlaRHmq9CS0C3G+7NpPZgjM3inDkah4OX83H4at5uJJTDIVMDHe5FO5uUqjkEqjkEqQX6JBeoKvwWB3DfTC+RwsMbNcEMom104fRbMHZG0U4lpqP3WeysOt0BgCgeyt/fPhIBwR7KW77HIjIOXi9Ro0Zg1gF+MYmujMZzRZ8/udlfLjrHHRGC+QSMabfE4kpfVrCTdo4Jvgo0hmRdDEHf5zPxsHLubheoEWRrvyZDGUSEbq1CkD/tsHo3zYYQQ0klFgsQoVBMKNQh6PX8nHsWj6OpebjYqYGXSJ88UTPFugU7lvpcQVBwPeH0/B/m05AazTD312O+SPjcU90UH2cBhHVM16vUWPGIFYBvrGJ7mzXcovxyqYT2HPun1kAX7g/Gr1aB1bYBc9Z9CYz/k4twN4LOfjjfBaOXMuH2VL2o91NKkaQlxuCPBUI81Xinpgg3BMTBC+FzAlVO9fFLDWe+uYITqcXAgCe7NUCT/RsgSZeCpfvjkrkSni9Ro0Zg1gF+MYmIkEQsOV4Ot7YchLZagMAQC4V464WfkiMCkRiVCAigzwgEomgM5qRVaRHRqEOGYV6aPQmqNwkdl3r3N2k8FXJ4KOS31Zdar0JyVfy8NflXBxMycWxa/nQm+xnd20R4I6ekQHoERmAyCB3BHoq4KWQMmTcRGc0491tZ7BqX4ptm69KhrYhXmjb1AttQ7zQMcwXEXXQ/ZKI6gev16gxYxCrAN/YRFSqoNiIj389j+0nbiAtX2t3W4CHG4xmCwq01V84um1TL/RrE4R+bYPRLsS70rFYpfI0Bmw/eQNbjl3H/ks5uLXBy99djrtb+qNn6wD0jAxAmF/Z9b6ofD+fvIGPdp3H2YyiclsSu7fyx7huEejXJghSCScbJmpIeL1GjRmDWAX4xiaiWwmCgItZauw5l40957Jw4FKOXUuUm1SMYC8Fgr3c4O4mhdZghsZgQrHe+l2jN0Ottx+rFezlhr4xwega4QsflQxeChm8lTJ4KWWQScTYcy4TW46l4/dzWTDdFBLC/JToGuGHhAg/dG3hh5YB7mztuk06oxnnM9Q4lV6AU9cLcfJ6IQ5fzbOF3mY+Soy+OxyjuobDz73qVk2j2YJj1/KRfCUPKrkETb2VaOqjQIi3Ej4qGV8vojrA6zVqzBjEKsA3NhFVRWc04+T1QngqpAj2VMBLWXXXv1yNAbvPWKeL//1cFjSG6k/b3rapFwbHh+DBuKZs8XKQtHwtVu+/gm//uoZcjX331JgmnogK9kRMEy9EBnlAIRPjQqYaf17Ixt4L2dh/KbdM8C6llElsYbp7qwDc3dIP/h5ujjw1IpfA6zVqzBjEKsA3NhHVN73JjP2XcrHrVAYuZatRqDWhQGtEoc6IQq0RFgFoGeCOwfEhGBwfgsggfhY5i85oxo/H0/HFvhT8nVZQ5naRCPBSyMp0UfVRyXBXCz9YBCC9QIv0fB1ySgLdraKDPdGtlT+6RPiiTVMvRPi73/Y6ZwaTBUev5WPvhWz8nVYApUwCb5UMPkoZfFQy+Cjl8HWXI9jLDcFeCvi7yxt898vMIh3WH0qFzmhGmJ8Kzf1UCPdXIdhTUa1uvuRaeL1GjRmDWAX4xiYiZxIEAVqjGUqZhF3YGhBBEHDyeiH+TivA2RtF1q+MIltrmZtUjIQWfugRaR2r17apV5lwoDOacaNAh7MZRdh/KQdJF3Nw5kZRmcdSyiSIauKJtk090TrIEzqTdUKYbLUBWUU6ZBXpoTdZ0NRbgabeSoT4KNHMR4Em3kqkZGvw54Vs/JWSa7dYeVXEIuu4x2AvBcL9VGgV5IFWge6IDPJAywCPKmcM1RnNSL6Sh6SLOdh/KQfX8orRzEeJCH93NPd3R0SACs393RHirYCPSg65tPqh70qOBkt/v4TvklPtFugu5SYVI9xPhU7hvri7lR/ubumPpt7Kah8fsL6+xQYzVHK+7xoLXq9RY8YgVgG+sYmIqLqy1Xqk5+vQOtgDClnNlzfIUetx4HIuki7m4HhaAc7eKITOWDZs1Ia/uxzdWvkjoYUfLBYB+Voj8ouNKNAakV9sQLbagMySYFfOXCU2IhEQ4q1EoKcbAjzcEOgpL/nuhhy1AUmXcnD0aj4M5urX7amQws9dDj93Ofzd5Wjmo0S4vzvC/VS2r8vZGizZcxE/Hr9uq69TuA9imnrhWm4xruYWIy1PazeGslSEvwp3t/RHp3BfhPmpEOanRFNvpa2lURAEXM7W4MDlXBy4lFOy7p4OKrkEob5KhPqqEFbyPSLAHbEhXmjqXf4SB5qS2UyTLuXgwKUc28LwAFC6t0QsQmyIF+5u6Y+7W/qjub+qUQa+gmIjLmSp4ecuR5CndUyss/B6jRozBrEK8I1NRETOYrYISMnR4HR6IU5dL8SlLA08FFJb8LGGITncpGKkF+iQnq9DWr4W1/O1uFGoQ4CHG7q38kePyABEB3tWq8ue2SIgR61HZpEe6QU6XMnR4EKmGhez1LiQqbYLFpVp4qVAt1b+6NbSH5HBHkjP1yElR4MrORpcySlGSo6mytBXkcSoQEzr0woJLfzsAozJbEF6gQ7nM4tw4FIu9l/Kwd9pBeU+hlQsQlMfaytiSrYGmUX6GtXgq5IhNsQbsSFeiAr2xKVstTVApxaUGwYr09Rbgbtb+qNtUy+IRIAgABZBgKXku5dShmBPNzTxVqCJlwL+Hm633V21NqwTFWnw65kM7DqdieQreXYzjLrLJQjyUiDQ0w1hvirMuLc1wv0dM46V12vUmDGIVYBvbCIion/kagy4nK1BtlqPbLW+pJukHtlFBihkYtxV0soTUY1WHotFQKHOiByNAXkaA3I0BmSr9UjN0+JqjrWV60qOBoU6E8Qi4IH2TTG1TyvEhnhXu95CnRGHUnJtXT9T87RIy9OWabGTS8XoEOaDu1v4IaGFP9o180KuxoDUPC1S87S4lleMa7nFuJCpxvlMdblLHJRq5qNEt1bW5yHcT4VbnwaN3oTDV/Kw/1IujlzLg9Fcs0swiViEYE83tGnqhbhQH8SFeiMu1NtuoheDyYKMQmswv1GgAwAoZBKo5BIo5RIoZf+saeilkJUJ6YIgIFttwKUsNS5maXD2RiH2nMtCSk6x3X7BXm4o0pnK7fr6n/ujMf2eyBqdW23xeo0aMwaxCvCNTURE5FwFxUZYBAG+1VguoDosFgEZRTqk5llbD4O9FOgQ5lPt7qQ6oxnnMopw8nohTl4vwLkMNUJ9lLi7pAWwJrOZag1mHL5qHU93JbcYYhEgFokgKv0OIF9rRGahDjcKK+862szH2mU0vUCLzCI9qntlJxGL4KuSw89dBj93OXRGCy5mqVGkKzvbp1wixl0t/XBvTBDubRNsO1e13oTMQh0yi6ytqTqjGQPaNYGXQlbt5+J28HqNGjMGsQrwjU1EREQNhdkiIFutx7XcYvydVoDjqQU4lpqPS1maMvvKJWKElHS/lIhF0BrNKDaYoTOaUVzBmoY3E4mAUF8lWgVaJ2lJaOGLnq0D4eHEsWAV4fUaNWYN7x1FRERERHYkYlHJgvEKdInws20v1BlxIq0AhVqjbfZMf3d5leMC9SYz8jRG5Gj0tu8yiRgtA90R4e9eq0lniKhmGMSIiIiIGikvhQzdWwXU+H5uUgmaeEvQxFtRD1URUXU07FUbiYiIiIiIXBCDGBERERERkYMxiBERERERETkYgxgREREREZGDcbKOCpTO6q9Wq51cCRERERGVp/Q6jasxUWPEIFYBjca6LkdiYqKTKyEiIiKiymg0Gnh6ejq7DKIa4YLOFbBYLMjMzIS7uztEosrX4qgLarUaiYmJ2LNnDxckbKT4GjZ+fA0bN75+jR9fw8bP0a+hIAjQaDQICgqCWMwRN9S4sEWsAmKxGE2aNHH443p4ePA/n0aOr2Hjx9ewcePr1/jxNWz8HPkasiWMGiv+6YCIiIiIiMjBGMSIiIiIiIgcjEGsgZDL5Xjqqacgl8udXQrVEl/Dxo+vYePG16/x42vY+PE1JKo+TtZBRERERETkYGwRIyIiIiIicjAGMSIiIiIiIgdjECMiIiIiInIwBjEiogZu9erV2LBhg7PLqBNLlizBrl27nF0GERGR0zGIERE1cGvWrMHGjRudXUadWLp0KYMYERERGMSIiO5Ier0eFovF2WUQERHdsRjEiIjqwfbt2xEdHY2DBw+Wue3bb79FdHQ0zp07h6ysLLz00kvo3bs32rVrh549e2Lq1KlITU0FAPTt2xfnz5/HwYMHER0djejoaIwdOxYAkJ+fj/feew+DBw9Gx44d0alTJ0ycOBFnzpyxe7wDBw4gOjoaP/30Ez788EP06tUL8fHxUKvV1T6fH374AcOHD0dcXBwSEhIwa9YspKen2+2TkpKCp59+Gj169ED79u3Ru3dvzJo1C0VFRQCA6OhoFBcXY+PGjbZzmT17do2eVyIiIlchdXYBRESuqE+fPlCpVNi2bRsSEhLsbtu6dStat26NqKgojBo1ChcuXMCYMWPQrFkz5ObmYu/evUhPT0doaCj++9//4s0334RKpcKUKVMAAAEBAQCAa9euYdeuXRgwYABCQ0ORnZ2NtWvXYsyYMfjpp58QHBxs97iffPIJZDIZJkyYAIPBAJlMVq1z+fTTT7FgwQIMHDgQI0aMQG5uLr7++muMHj0amzZtgpeXFwwGg+24Y8aMQUBAADIyMvDbb7+hsLAQnp6emDdvHl555RXExcVh5MiRAIDw8PDbfaqJiIgaJS7oTERUT5577jkkJSXhjz/+gEQiAQBkZWWhd+/eeOqppzB27Fh07doVL7zwAiZMmFDhcR588EH4+vriq6++sttuMBgglUohFv/TuSE1NRUDBw7ElClTMH36dADWFrFx48YhLCwMP/74IxQKRbXPIS0tDffddx+eeeYZWxAEgHPnzmHYsGF4+umnMWXKFJw+fRpDhw7FggULMGDAgAqP17FjR9x///149913q10DERGRK2LXRCKiejJw4EDk5OTYdU/csWMHLBYLHnjgASgUCshkMhw8eBAFBQU1Pr5cLreFMLPZjLy8PKhUKrRo0QKnTp0qs//QoUNrFMIAYOfOnbBYLBg4cCByc3NtXwEBAWjevDkOHDgAAPDw8AAA/Pnnn9BqtTU+FyIiojsNuyYSEdWT3r17w9PTE1u3bkW3bt0AWLsltmnTBi1atAAAPP/883jvvffQo0cPxMfHo0+fPhg6dCgCAwOrPL7FYsGXX36Jb775BqmpqTCbzbbbfHx8yuwfGhpa43NISUmBIAjo379/ubdLpdb/RsLCwjB+/HisXLkSW7ZsQZcuXdC3b18MGTIEnp6eNX5cIiIiV8cgRkRUT+RyOfr164edO3fi1VdfRU5ODg4fPoxnn33Wts/jjz+Ovn37YteuXfjzzz+xYMECfPbZZ/jiiy/Qtm3bSo+/ZMkSLFiwAA899BBmzJgBb29viMVivPPOOyiv13lNW8MAa9gTiURYtmyZrXvlzVQqle3fs2fPxrBhw/DLL79g7969eOutt7B06VKsW7cOTZo0qfFjExERuTIGMSKiejRw4EBs3LgRSUlJuHjxIgRBwMCBA+32CQ8PxxNPPIEnnngCKSkpGDp0KD7//HPMnz8fACASico99o4dO3DXXXfhnXfesdteWFgIX1/fOqk/PDwcgiAgNDTU1opXmdLZEKdNm4bDhw/j0UcfxZo1azBr1qw6qYeIiMhVcIwYEVE96t69O3x8fLB161Zs27YNcXFxCAsLAwBotVro9Xq7/cPDw+Hu7g6DwWDbplQqUVhYWObYEomkTMvXtm3bkJGRUWf19+/fHxKJBIsWLSrzWIIgIC8vDwCgVqthMpnsbo+KioJYLLY7F5VKVe65EBER3WnYIkZEVI9kMhnuu+8+/PTTT9BqtXjxxRdtt6WkpODxxx/HgAEDEBkZCYlEgl27diE7OxuDBg2y7RcbG4s1a9bgk08+QfPmzeHn54du3bqhT58+WLx4MV566SV07NgR586dw5YtW2xBry6Eh4dj5syZeP/995GWloZ+/frB3d0dqamp2LVrF0aOHIkJEyZg//79eOONNzBgwABERETAbDbjhx9+gEQiwf333293LklJSVi5ciWCgoIQGhqK+Pj4OquXiIiosWAQIyKqZw888ADWr18PkUhk1y2xSZMmGDRoEJKSkrB582ZIJBK0bNkSH330kV14mT59Oq5fv47ly5dDo9EgISEB3bp1w5QpU6DVarFlyxZs3boVbdu2xdKlS/H+++/Xaf2TJk1CREQEVq1ahcWLF9tq79GjB/r27QvA2iWxZ8+e2L17NzIyMqBUKhEdHY1ly5ahQ4cOtmPNnj0bc+bMwUcffQSdTodhw4YxiBER0R2J64gRERERERE5GMeIERERERERORi7JhIR3aGysrIqvV2hUHANMCIionrCrolERHeo6OjoSm8fNmwY3n33XQdVQ0REdGdhECMiukPt27ev0tuDgoIQGRnpoGqIiIjuLAxiREREREREDsbJOoiIiIiIiByMk3VUwGKxIDMzE+7u7hCJRM4uh4iIiIhuIQgCNBoNgoKCIBazfYEaFwaxCmRmZiIxMdHZZRARERFRFfbs2YMmTZo4uwyiGmEQq4C7uzsA6xvbw8PDydUQERER0a3UajUSExNt121EjQmDWAVKuyN6eHgwiBERERE1YBxGQo0RO9MSERERERE5GIMYERERERGRgzGIERERERERORjHiDUQRToj0vK1AAARRLi5q7PBZIHOaIb+pu+CAHgopPBwk8JLIYWnQgYPhRTucgn7SRMRERE1ABaLBQaDwdllkAPJ5fJqL6XAINYAaA1m9HxvNwq0xts+llwqRqCHGwI9//nyUcqQrzUiu0iPbLUeORoDsov0MJoF+Khk8FXJ4ete+l0O39JtN233Vsogk4ghFosgFYsgFokgEYsgk4ggl4ohl4jLBECDyYICrREFWiMKdUbojRb4e8gR6OEGH5WMgZGIiIhclsFgwOXLl2GxWJxdCjmQWCxGixYtIJfLq9yXQawBkEvF6BjugxNphQAECIJ1u1B6u0QMhUwMN6nE9h0A1HoTivRGFOlMKNKZYLYIMJgsSMvX2lrXqpJZpEdmkb7OzsOtJJRpDCbojBV/8MgkIgSUBMYgTwWim3igXYg32jXzRqivkiGNiIiIGi1BEJCeng6JRIKwsDAuNn2HsFgsuH79OtLT0xEeHl7l9SyDWAMgEYuwanzCbR1DEARojWbkqA3IUuuRVfTPV4HWCC+lDIEecgR4uCHA0w0BHm6QSUTILzYir9iAvGIj8jQG5GoMyC/9udhg/dIYUag1wmQRYBYEWCwCTBahTA0GkwUGk334EokATzcpvFXWFjXr8Y0wmgWkF+iQXqADUIBdpzNs9/FSSNGumTWUtW/mjfhQH4T5MZwRERFR42AymVBcXIyQkBCoVCpnl0MOFBgYiOvXr8NkMkEmk1W6r0sHMYPBgIcffhhnzpzBpk2b0KZNG2eXVG9EIhFUcilUflKE+VX/DR/qW/vHtFgEGMwW65fJAn1JEDOYLFDJJfBSyOCpkEIstg9QelNJYCwJitcLtDidXogTaYU4e6MIhToT9l3Mwb6LObb7+KpkaB/qg/hQb/iq5LAIAsw3BUNBABQyCRRyCZQy65dKLoGXUoZmPkoEebqVqaOU0WxBZpEe2UV6mCwWmC2A2SLYHqNAa0RGoTU03ijU4UaBDtlqPfzc5Wjh744WAe6ICLB+D/NVQSmXQCYRMTgSERHdocxmMwBUq3sauZbS19xsNt/ZQWzevHkICgrCmTNnnF2KSxKLRVCIJVDIJDW6n5tUghAfJUJ8lGVuM5gsOJ9ZhBNpBfg7rQDHUwtwOr0QecVG/H4uC7+fy6pVrTKJCE29lWjmo0RTHwWK9WakF+pwo0CLzCK9rTtoTVzJKcaRq/nl3iYRi6CQiq3hUCZBqK8S3VsFoEekP+LDfCCTsIsCERGRq+MfZe88NXnNXTaI7dmzB3v37sXChQvx+++/O7scqia5VIzYEG/Ehnjjka7WbXqTGWfSi3A8NR8n0gpRbDRDIrIGQYnIOnGISAToTRZoDWZojdYvXUlXzRuFOhjNAq7mFuNqbnG5j1s6Zk0uFVuPWXpssQieblI08VagibcCwV4KNPVWIMDDDVlFeqTkaHApS4OUHA1SsjXI0VhnRjJbBGgMZmgM1r+IpeVrceByLj7cBbjLJUho4YcekQGID/OBl0IGdzcJPN2s36UMaUREREQuzyWDWHZ2Nv7v//4PixcvhkKhcHY5dJvcpBLEh/kgPsynVvc3mS3IKNIjLU+L6/laXC/QwsNNiiZeCjT1VqKJtwL+7vIKuy7WhM5oht5ogc5khtZghs5kRrHBjFPXC7HvYjaSLuYgr9iI3WezsPts+a17CpkYSpnEbnIWN1npzJQoM5kLAIhFgLgklIrF1n8rZRJ4lnQP9SxZ6sDdTQqFTPLPxCol3z3dZPD3kMPfQ26bDIaIiIjuLGPHjkVMTAxefvllZ5dyR3C5ICYIAmbPno1Ro0ahffv2SE1Nrdb9DAaD3ToParW6vkokB5NKxGjmY+2WWN9KuyJ6w75PcKdwX4y5uzksFgGnbxRi34Uc7L2YjUtZGmj0JhTpTbaJTnRGS8mMk7e/nEFteLpJEeDpBl+VDGaLgOLSVkaDNVQKEBDqq0JzPxXC/FQI91Ohub91bFzpPqUtkzqjGVKJfegrDZYKqQRKucQWPJUy688eblKnd+UQBOt55xVbJ5cpndRGazBDbxsTaYbBZIHJLEAiti7jIJOIIJOIIZOI4eEmRTNfJUJ9lQjyVEBSB0GfiIjoTrVw4UL89NNPuHHjBmQyGWJjYzFr1izEx8dX6/6ffvop9uzZg9OnT0Mmk+HQoUNV3kcQBHz88cdYv349CgsL0alTJ7z22muIiIi4zbOxajRBbP78+Vi2bFml+2zduhV79+6FRqPB5MmTa3T8pUuXYtGiRbdTIlGVxGKRrevlk71b2t1mNFusoUxngt5khs5ovdgvbWG7dUZKoPTC3jpZiUUALIJg+9LozdYlDnRGqEuWOFDrTbZJVfQm6+LgepMFRTojctQGmCwCikqC4eVKzuNCphoXMuvnjxVuUjGCvKzLGgR5uiHI0w3eKjlkYhGkEmvYkYpFkEnF8Hd3s4ZsXyV8q1ibzmwRcCVHg3MZRTiXocbZjCJcytJAazDBaBZgslhgNAswmi3QG62T0NSV0jGKob7WsZG+Khm8FDJ4KWXwVsrgpbQuyq6SS+Aul0LlZg2kCqmkTlpqiYiIGiuDwQC5XI6IiAjMmTMHYWFh0Ol0WLVqFZ544gns3LkTfn5+VR7HaDRiwIAB6NChA7777rtqPfayZcvw1Vdf4d1330VoaCgWLFiACRMmYOvWrXBzc7vdU4NIEGozTYHj5ebmIi8vr9J9wsLCMHPmTOzevdvugsxsNkMikWDw4MF47733yr1veS1iiYmJSE5OhoeHR92cBFEDJggCCrUmZGv0yFEbkKvRQyoWQyW3zkapkkugkklhEQRcyyu2jbm7lluMKznFMJottlYtlVwKpVwCN6kYZosAvdE++OmMZtuYPl1Jy1mx0VyrSVNKKWUSNPNVIsBDDosFtpYrY8n3jEId9GXCbOXkErFt0XMflQweblLrAuYl6+VZW8Gs52gsmUHUaBZgLFnMPC3f2h22vOUeqkshs076oixpbXUrmQTGGkjFkNpa4aw/W8c3/jOGUioRwV1uDXqlgc9TIYW3UgZ/dzn83OXwUcnZYkdEjZJarUbnzp0b3PWaTqfD5cuX0aJFi0Y1TGbs2LGIjo6GXC7Hd999B5lMhlGjRuHpp58GAKxcuRIbNmzAtWvX4O3tjXvuuQf/+c9/4O7uDrVaje7du2PhwoVITEy0HXPnzp144YUXsG/fPiiVSqSnp+Pdd9/F3r17IRaL0blzZ7z88ssIDQ0FAMyePRuFhYVo3749Vq9eDblcjl9//bVMraWv/apVq9CtW7dqn+OGDRvwzjvvVNkiJggCevXqhfHjx2PChAkAgKKiInTv3h3vvvsuBg0aVO79avLaN5oWMT8/v2ql3VdeeQUzZ860/ZyZmYkJEybgww8/rLTpUi6Xc4pRuqOJRCJ4q2TwVsnQKrDyfSMC3Ov88UvXwitd1iCzSI/MQh0yi/Qo0plsLVYmswXGksXLM4v0uJ6vRVaRHlqjuaSlruLHUMjEiAr2ROsgT0Q38UBkkAe8FDJIJWJIS7oXSsUiuMkk8FFaW6hut5uk2SIgo1CH1DwtUvOKcT1fi0KdCYVaIwp1RhRqTSjQGqHWm6DRm1BsMENjMNlCaWlX1fx67KoqEgG+KmsoKz1nEW4aeygWQV7SxbR0vKJbSddSb6UMvioZfFRyeJeEVj+VHH4ecrhX8PwV6YxIyS7GpWw1ruUWQywWwcNNavcll4pRpDOVPEdG23PmJhUj1FeFUF8lQn1VaOqj4CykRNQolP4/50hKWc3/H9u4cSPGjx+PdevW4ejRo5g9ezY6deqEHj16QCQS2ULTtWvX8Prrr+N///sfXnvtNXh4eKBPnz748ccf7YLYli1b0K9fPyiVShiNRkyYMAEdOnTA6tWrIZVK8cknn2DixInYvHmz7Vo8KSkJHh4eWLlyZbk1GgwGrF27Fp6enoiOjq79E1SJ1NRUZGVloXv37rZtnp6eiI+Px5EjRyoMYjXRaIJYdYWEhNj9XLqIXnh4OJo0aeKMkoioGkrXwmvuL0Vz/5oFPZ3RjBsFOqTla5Gt1kNeMk7L1nolFSPA3Q2hvkqHd/WTiEW25RoSWlT9xyTgn/+sNfp/Wgx1N00CozdZbIHUZLaOUzOYLda19W5aA88sCDCZBWj0JmuQ0RlRpLN2Vy0oNiJHY0CB1ghBAHJLFnSvS3Kp2Nbq5u/hBp3RjMvZGmQV6evsMcQiIMhTAaVcAklJK6BELLK1FKpKxh26u5VOWCOBv7sbQnysk/U09VEgwL38dQYtJS2Z7B5KRLdLEASMWJKE5CuV9+6qa12a+2L9lG41CmPR0dF46qmnAAARERH4+uuvkZSUhB49euDxxx+37RcaGoqZM2fi1VdfxWuvvQYAGDJkCP7zn/9Aq9VCqVRCrVbjt99+sw3/2bp1KywWC95++21bTXPnzkXXrl1x8OBB9OzZE4D1+v2tt94q00iye/duPPvss9BqtQgMDMTnn39erYaa2sjKsk6q5u/vb7fd398f2dnZdfIYLhfEiOjOo5BJEFGysLYrsC3QLq//j2ij2YK8YmsIy1UboDOZYbGUjje0XjyYBfuxc6XfNXpra15+sRH52n8mNsnVGKA1Wsc1phdYF0O/VYCHG1oGuCPcXwURALXeZPvSlIxl9FRIrWPpFNaxdJ4KKYqNZlvrYlqeFnqTBTcKyx6/JuQSMQI93SAIgq37rN5khrFkIpYmXgqE+lrHIoaWjElUyCQwmW8KvBbr4vKSktZDqaRkTKPYGgiDvRQI81PCW1n5WEYicl2N5Z1/awtTYGAgcnJyAAD79u3D0qVLcenSJajVapjNZuj1elvw6t27N2QyGX799VcMGjQIO3bsgIeHh61V6cyZM7h69So6depk9xh6vR5Xr161/RwVFVVuT7W77roLmzZtQl5eHtatW4eZM2di/fr1ZcJSY+HyQSw0NBRnz551dhlERA2STCIumRilbscwaA1m5NjGGxqQrdZDJhGjRYA7WgS6w0shq/ogVRAEAdlqA67na2EoaRm03BSK9CZrWNQY/gl4ap0J2WoD0vK1SC9Z0N1gtiAtX1vuY5gtAtLytdbbK5vBppo83aQI81MhzM/aSupVMmbPw806fs9DIUWAhxzhfip41sFzREQNg0gkwvop3RpF10Sp1D4eiEQiCIKA1NRUTJ48GY8++ihmzZoFb29vJCcn4+WXX4bRaIRSqYRcLsf999+PLVu2YNCgQfjxxx/xwAMP2I5ZXFyM2NhYzJ8/v8zj3tyypVSWP9O1SqVC8+bN0bx5c3To0AH9+/fHd999V+NJ+qojMNA6TiMnJwdBQUG27Tk5OYiJiamTx3D5IEZERI6nlEsQKlch1FdVb48hEokQ6OmGQM/az1xlNFsncsks0kMmto6Bsy2zIBVDb7IgLb8YqXnWMJZash6h0WyBRCyGRARIxNaxhWIxYDJbg6CxJBiaLNYWtvQCHbKK9CjSm3AqvRCn0gurrM1XJUN4yTIRob4qyCQiWwucxSLAbLGOe4wM8kBUsCcigzygkHEdQKKGqrS3Q2N18uRJ2zJRYrF1bO62bdvK7Dd48GA88cQTOH/+PPbv3283d0NsbCy2bdsGf3//OplcxWKx2E22V5dCQ0MRGBiIpKQktGnTBoB1gpBjx47h0UcfrZPHaLy/DURERLdJJimd/KPiwNjEW4HOzW//sbQGM1LzinEtrxjXcrVIL9BBrbcuL6EuWbqiSGdCRqEOORoD8oqNyCsuwLHUgmodXywCIvzdERXsieYBKjT1UqCJtxJNvRVo4q1AgIcbZ8ckolpr3rw5jEYjvvrqK/Tt2xfJycn49ttvy+zXtWtXBAQE4Pnnn0doaKjdZHmDBw/GihUrMHXqVMyYMQPBwcG4fv06du7ciYkTJ1Y4n0NxcTGWLFmCvn37IjAwEHl5eVi9ejUyMjIwYMCAatV//fp1FBQU4Pr16zCbzTh9+jQA6zwS7u7WoQ0DBgzAc889h/vuuw8ikQjjxo3Dp59+iubNm9umrw8KCkK/fv1q+vSVi0GMiIjIAZRyCVoHe6J1sGeV+6r1JlzN+WeJiLR8LQRBsC1LIBFbZ7NU60w4l1GEsxlFyC824lK2BpeyNeUeUyIWwd9djgAPNwR4uiHAQ45ADzf4qOS2SW3cbprkRlGy8LpCbr98QulkMKVdQE23TBJj/Q6YLBaIIIK7mwTublK4y62TpajkUgZCokYoJiYGL730EpYtW4YPPvgAXbp0wbPPPosXX3zRbj+RSIRBgwZh+fLlmD59ut1tSqUSX3/9NebPn4+nnnoKGo0GwcHB6NatW6UtZBKJBJcuXcLGjRuRl5cHHx8f2/T2rVu3rlb9H3/8MTZu3Gj7eejQoQCAL7/8EnfddRcA4PLlyygqKrLt8+STT0Kr1WLOnDkoLCxE586dsXz58jpZQwxoROuIOVpDXZeCiIjoVoIgIEutx7kb1sXKU/OKcaNkopQbBTpkFulwG8vZ1TmV3BrOPN2k8FBI7Wa2LJ3pUlUS3LwUMlsX1CBPN/izZY9u0lCv1xrrOmJ0+1xyHTEiIiIqn0gksk260rN1QJnbTWYLstXWSVOy1HpkF+ltPxdojTCYrAufG0oWQDeYrMsl6IxmaEuXTyhZOkEshnXxcBEglYghFokgEQOSkjXnSpcREItFsAgCtAazbbKU0jBYbDCj2GCu1VIGYhHg5+4GN6kYJovF1jpnNgsQAAR4yNHE27o8gfW7tVumqmSxeZXcugaeu1yKQE+GOiJyHgYxIiIiFyeViNGkZKyYs5QuD6DWm1CsN6PopvFxpWPkig0maPRm63eD2bZEQmahNUDmqPWwCEC2uuIAp9abkJJTXK2aPN2k6BDugy7N/dAlwhcdwnzg7sZLI6LGZsmSJVi6dGm5t5V2J2yI+GlDRERE9U4kEkFRMtYMtexBZjJbkKsxILNID5NFgLRk8W5pycyVAoCsIj3SC7S2bpnpBVrkagwoNlgXRNcYTLYWuSK9CX+cz8Yf562Ls4pFQHQTL4T5WlvTgr0UaOJlDbBBnm7wc5fDRyVnKxpRAzNq1CgMHDiw3NsactdQBjEiIiJqFKQSMYK8FAjyqvjCqkU1F3Y3WwScuVGI5Ct5SL6Sh0MpeUjL1+J0eiFOV7K8gEgE+Chl8HWXw99dfsv4Nik83CRQ2bZJSrZZu0R6KqxLEsil4hqfOxFVzMfHBz4+Ps4uo8YYxIiIiOiOIxGLEBvijdgQb4zrFgEASC/Q4kRaIW4UaHGjUIcbBXpkFOpwo9C6DlyB1ghBQMnSAkZcyip/hsrKSMUiRAZ5oG2IF9o2tX6F+6sgCIAgwLpOXMlacVKJdV07a0uidX07tsYRuQ4GMSIiIiIATb2VaOqtrPB2k9mCvGIjcjUG25emZIzbzePaSsfBaQzWSUo0euuEJQVaI9R6E87cKMKZG0XYgLQa1yiXiOHvIbfOJOnhhgAP64yS3kqZtZumxNpNUyIWQSYRQSmTwkshhadCBg+FFJ4KKZQyCYpvmkSl9LtUIkaorxLNfJRcHLyOcHLyO09NXnMGMSIiIqJqkErEtqn0a0MQhJLuj0U4dd3aBfJUeiFuFOggEllb6cQiEcQiQCwWwWQWoDeZYTT/c2FnMFuQXrI0QX0K9HSzhTKZRAyTRYDJbIHRLMBkscAiWFv3pGIRZBIxpBLrd0+FFBN7tUQzn4oD7Z1AIrEGWYPBAKXyzn4u7jQGgwHAP78DlWEQIyIiInIAkUiEUF8VQn1VuK9tcLXvZ7ZYA5nOaEGxwYQctQFZRXrrcgQl3wt1JruwZLZYYLII0JTMSKm+6bu1FtgW2S4d46YzmpGap7UtLZBVpMeRq/k1Ps8ADzdMvyeyxvdzJVKpFCqVCllZWZDJZBCLOS7wTmCxWJCVlQWVSgWptOqYxSBGRERE1IBJxKKSNdAAP3c5Qn1VtT6WxWJdRsBNKoa4nPFmgiAgv9iI1DwtUvOKkZavhSCgZHbKf7o+ikUimC0CjBYLTGYBxpIAKJeKMbxjs9s5XZcgEonQtGlTXL58GVeuXHF2OeRAYrEY4eHhEImqHs/JIEZERER0hxCLRVDKK+4yJRKJ4Osuh6+7HO1DvR1YmeuRy+Vo3bq1rasa3Rnkcnm1W0AZxIiIiIiI6oFYLG7Q61iRc7HDKhERERERkYMxiBERERERETkYgxgREREREZGDMYgRERERERE5GIMYERERERGRgzGIERERERERORiDGBERERERkYMxiBERERERETkYgxgREREREZGDMYgRERERERE5GIMYERERERGRgzGIERERERERORiDGBERERERkYMxiBERERERETkYgxgREREREZGDMYgRERERERE5GIMYERERERGRgzGIERERERERORiDGBERERERkYMxiBERERERETkYgxgREREREZGDMYgRERERERE5GIMYERERERGRgzGIERERERERORiDGBERERERkYMxiBERERERETkYgxgREREREZGDMYgRERERERE5GIMYERERERGRgzGIERERERERORiDGBERERERkYMxiBERERERETkYgxgREREREZGDMYgRERERERE5mMsGsd9++w0PP/ww4uLi0LVrV0ybNs3ZJREREREREQEApM4uoD7s2LED//d//4dZs2bh7rvvhtlsxrlz55xdFhEREREREQAXDGImkwlvv/02/vOf/+Dhhx+2bY+MjHRiVURERERERP9wua6Jp06dQkZGBsRiMYYOHYqePXti4sSJbBEjIiIiIqIGw+WC2LVr1wAAixYtwtSpU7FkyRJ4e3tj7NixyM/Pr/B+BoMBarXa7ouIiIiIiKg+NJquifPnz8eyZcsq3Wfr1q2wWCwAgClTpuD+++8HAMydOxe9e/fG9u3bMWrUqHLvu3TpUixatKhuiyYiIiIiIipHowliTzzxBIYNG1bpPmFhYcjKygIAtGrVyrZdLpcjLCwM6enpFd538uTJGD9+vO1ntVqNxMTE26yaiIiIiIiorEYTxPz8/ODn51flfu3atYNcLsfly5fRpUsXAIDRaERaWhpCQkIqvJ9cLodcLq+zeomIiIiIiCrSaIJYdXl4eGDUqFFYuHAhmjZtipCQEKxYsQIAMGDAACdXR0RERERE5IJBDABeeOEFSKVSvPDCC9DpdIiPj8cXX3wBb29vZ5dGRERERETkmkFMJpPhxRdfxIsvvujsUoiIiIiIiMpwuenriYiIiIiIGjoGMSIiIiIiIgdjECMiIiIiInIwBjEiIiIiIiIHYxAjIiIiIiJyMAYxIiIiIiIiB2MQIyIiIiIicjAGMSIiIiIiIgdjECMiIiIiInIwBjEiIiIiIiIHYxAjIiIiIiJyMAYxIiIiIiIiB2MQIyIiIiIicjAGMSIiIiIiIgdjECMiIiIiInIwBjEiIiIiIiIHYxAjIiIiIiJyMAYxIiIiIiIiB2MQIyIiIiIicjAGMSIiIiIiIgdjECMiIiIiInIwBjEiIiIiIiIHYxAjIiIiIiJyMAYxIiIiIiIiB2MQIyIiIiIicjAGMSIiIiIiIgdjECMiIiIiInIwBjEiIiIiIiIHYxAjIiIiIiJyMAYxIiIiIiIiB2MQIyIiIiIicjAGMSIiIiIiIgdjECMiIiIiInIwBjEiIiIiIiIHYxAjIiIiIiJyMAYxIiIiIiIiB2MQIyIiIiIicjAGMSIiIiIiIgdjECMiIiIiInIwBjEiIiIiIiIHYxAjIiIiIiJyMAYxIiIiIiIiB2MQIyIiIiIicjAGMSIiIiIiIgdjECMiIiIiInIwBjEiIiIiIiIHYxAjIiIiIiJyMAYxIiIiIiIiB2MQIyIiIiIicjAGMSIiIiIiIgdzySB2+fJlTJ06FXfddRc6deqERx99FPv373d2WURERERERABcNIhNmTIFZrMZX3zxBTZs2ICYmBhMmTIFWVlZzi6NiIiIiIjI9YJYbm4uUlJSMGnSJMTExCAiIgLPPfcctFotzp8/7+zyiIiIiIiIXC+I+fr6okWLFti0aROKi4thMpmwdu1a+Pv7IzY2tsL7GQwGqNVquy8iIiIiIqL6IHV2AXVNJBJh1apVmDZtGjp16gSxWAw/Pz8sX74c3t7eFd5v6dKlWLRokQMrJSIiIiKiO5VIEATB2UVUx/z587Fs2bJK99m6dStatmyJadOmwWQyYcqUKVAoFFi/fj1+/fVXfPfddwgKCir3vgaDAQaDwfazWq1GYmIikpOT4eHhUafnQkRERES3T61Wo3Pnzrxeo0ap0bSIPfHEExg2bFil+4SFhWH//v347bff8Ndff9nekLGxsdi3bx82bdqESZMmlXtfuVwOuVxe53UTERERERHdqtEEMT8/P/j5+VW5n1arBWDtongzkUgEi8VSL7URERERERHVhMtN1tGhQwd4eXlh9uzZOHPmDC5fvoz33nsPaWlp6NOnj7PLIyIiIiIicr0gVjoxR3FxMf7973/joYcewuHDh7F48WLExMQ4uzwiIiIiIqLG0zWxJtq3b48VK1Y4uwwiIiIiIqJyuVyLGBERERERUUPHIEZERERERORgDGJEREREREQOxiBGRERERETkYAxiREREREREDsYgRkRERERE5GAMYkRERERERA7GIEZERERERORgDGJEREREREQOJnV2AQ2dRqOBSCRydhlEREREdAuNRuPsEohqjUGsCiEhIbBYLM4ug4iIiIhuIRaLERkZ6ewyiGqFXROJiIiIiIgcjC1iVbh+/To8PDycXQYRERER3UKtVqN3797OLoOoVhjEquDu7g53d3dnl0FEREREtxAEwdklENUauyYSERERERE5GIMYERERERGRgzGIERERERERORjHiFWgtM+xWq12ciVEREREVJ7S6zSOFaPGiEGsAqULBCYmJjq5EiIiIiKqjEajgaenp7PLIKoRkcA/IZTLYrEgMzMT7u7uEIlE9f54arUaiYmJ2LNnD6fLb6T4GjZ+fA0bN75+jR9fw8bP0a+hIAjQaDQICgqCWMwRN9S4sEWsAmKxGE2aNHH443p4ePA/n0aOr2Hjx9ewcePr1/jxNWz8HPkasiWMGiv+6YCIiIiIiMjBGMSIiIiIiIgcjEGsgZDL5Xjqqacgl8udXQrVEl/Dxo+vYePG16/x42vY+PE1JKo+TtZBRERERETkYGwRIyIiIiIicjAGMSIiIiIiIgdjECMiIiIiInIwBjEiIiIiIiIHYxAjIqojq1evxoYNG5xdRp1YsmQJdu3a5ewyiIiIXBaDGBFRHVmzZg02btzo7DLqxNKlSxnEiIiI6hGDGBFRA6bX62GxWJxdBhEREdUxBjEiuqNt374d0dHROHjwYJnbvv32W0RHR+PcuXPIysrCSy+9hN69e6Ndu3bo2bMnpk6ditTUVABA3759cf78eRw8eBDR0dGIjo7G2LFjAQD5+fl47733MHjwYHTs2BGdOnXCxIkTcebMGbvHO3DgAKKjo/HTTz/hww8/RK9evRAfHw+1Wl3t8/nhhx8wfPhwxMXFISEhAbNmzUJ6errdPikpKXj66afRo0cPtG/fHr1798asWbNQVFQEAIiOjkZxcTE2btxoO5fZs2dX6/FTU1MRHR2NFStWYPXq1bj33nsRHx+PJ554Aunp6RAEAYsXL0bv3r0RFxeHqVOnIj8/3+4Yf//9NyZMmIC77roLcXFx6Nu3L1566SW7fSwWC1atWoVBgwahffv26N69O+bMmYOCgoJqP1dERETOJHV2AUREztSnTx+oVCps27YNCQkJdrdt3boVrVu3RlRUFEaNGoULFy5gzJgxaNasGXJzc7F3716kp6cjNDQU//3vf/Hmm29CpVJhypQpAICAgAAAwLVr17Br1y4MGDAAoaGhyM7Oxtq1azFmzBj89NNPCA4OtnvcTz75BDKZDBMmTIDBYIBMJqvWuXz66adYsGABBg4ciBEjRiA3Nxdff/01Ro8ejU2bNsHLywsGg8F23DFjxiAgIAAZGRn47bffUFhYCE9PT8ybNw+vvPIK4uLiMHLkSABAeHh4jZ7XLVu2wGg0YuzYscjPz8fy5csxc+ZM3H333Thw4ACefPJJXLlyBV9//TXee+89zJ07FwCQk5ODCRMmwNfXF5MmTYKXlxdSU1Oxc+dOu+PPmTMHGzduxPDhwzF27FikpqZi9erVOHXqFNasWVPt54yIiMhpBCKiO9yzzz4rdOvWTTCZTLZtmZmZQkxMjLBo0SKhoKBAiIqKEpYvX17pcQYNGiSMGTOmzHa9Xi+YzWa7bdeuXRPatWsnLFq0yLZt//79QlRUlHDvvfcKWq22RueQmpoqtGnTRvj000/ttp89e1Zo27atbfupU6eEqKgoYdu2bZUer0OHDsKLL75YoxoEwXpeUVFRwt133y0UFhbatr///vtCVFSUMGTIEMFoNNq2P/vss0JsbKyg1+sFQRCEnTt3ClFRUcLx48crfIy//vpLiIqKEjZv3my3/ffffy93OxERUUPErolEdMcbOHAgcnJy7Lon7tixAxaLBQ888AAUCgVkMhkOHjxYq65vcrkcYrH149ZsNiMvLw8qlQotWrTAqVOnyuw/dOhQKBSKGj3Gzp07YbFYMHDgQOTm5tq+AgIC0Lx5cxw4cAAA4OHhAQD4888/odVqa3wu1TVgwAB4enrafo6LiwMADBkyBFKp1G670WhERkYGANju89tvv8FoNJZ77O3bt8PT0xM9evSwO9fY2FioVCrbuRIRETVk7JpIRHe83r17w9PTE1u3bkW3bt0AWLsltmnTBi1atAAAPP/883jvvffQo0cPxMfHo0+fPhg6dCgCAwOrPL7FYsGXX36Jb775BqmpqTCbzbbbfHx8yuwfGhpa43NISUmBIAjo379/ubeXhp+wsDCMHz8eK1euxJYtW9ClSxf07dsXQ4YMsQtOt6tp06Z2P5ceu6LtBQUFCAsLQ0JCAu6//34sWrQIq1atQkJCAvr164fBgwdDLpcDAK5cuYKioiLba3WrnJycOjsPIiKi+sIgRkR3PLlcjn79+mHnzp149dVXkZOTg8OHD+PZZ5+17fP444+jb9++2LVrF/78808sWLAAn332Gb744gu0bdu20uMvWbIECxYswEMPPYQZM2bA29sbYrEY77zzDgRBKLN/TVvDAGvYE4lEWLZsGSQSSZnbVSqV7d+zZ8/GsGHD8Msvv2Dv3r146623sHTpUqxbtw5NmjSp8WOXp7waANhaBm9V+jyIRCJ8/PHHOHr0KHbv3o0//vgD//3vf7Fy5UqsXbsW7u7usFgs8Pf3x/z588s9lp+fX52cAxERUX1iECMigrV74saNG5GUlISLFy9CEAQMHDjQbp/w8HA88cQTeOKJJ5CSkoKhQ4fi888/twUCkUhU7rF37NiBu+66C++8847d9sLCQvj6+tZJ/eHh4RAEAaGhobZWvMqUzoY4bdo0HD58GI8++ijWrFmDWbNm1Uk9t6tDhw7o0KEDZs2ahS1btuD555/H1q1b8fDDDyM8PBxJSUno1KlTrUIrERFRQ8AxYkREALp37w4fHx9s3boV27ZtQ1xcHMLCwgAAWq0Wer3ebv/w8HC4u7vDYDDYtimVShQWFpY5tkQiKdPytW3bNtu4qLrQv39/SCQSLFq0qMxjCYKAvLw8AIBarYbJZLK7PSoqCmKx2O5cVCpVuedS3woKCsrU36ZNGwCw1Tdw4ECYzWZ88sknZe5vMpmcUjcREVFNsUWMiAiATCbDfffdh59++glarRYvvvii7baUlBQ8/vjjGDBgACIjIyGRSLBr1y5kZ2dj0KBBtv1iY2OxZs0afPLJJ2jevDn8/PzQrVs39OnTB4sXL8ZLL72Ejh074ty5c9iyZYst6NWF8PBwzJw5E++//z7S0tLQr18/uLu7IzU1Fbt27cLIkSMxYcIE7N+/H2+88QYGDBiAiIgImM1m/PDDD5BIJLj//vvtziUpKQkrV65EUFAQQkNDER8fX2f1VmTjxo1Ys2YN+vXrh/DwcGg0Gqxbtw4eHh7o3bs3ACAhIQGPPPIIli5ditOnT6NHjx6QyWRISUnB9u3b8fLLL2PAgAH1XisREdHtYBAjIirxwAMPYP369RCJRHbdEps0aYJBgwYhKSkJmzdvhkQiQcuWLfHRRx/ZhZfp06fj+vXrWL58OTQaDRISEtCtWzdMmTIFWq0WW7ZswdatW9G2bVssXboU77//fp3WP2nSJERERGDVqlVYvHixrfYePXqgb9++AKxdEnv27Indu3cjIyMDSqUS0dHRWLZsGTp06GA71uzZszFnzhx89NFH0Ol0GDZsmEOCWEJCAv7++29s3boV2dnZ8PT0RFxcHObPn28XXN944w20a9cO3377LT788ENIJBI0a9YMQ4YMQadOneq9TiIiotslEsobKU5ERERERET1hmPEiIiIiIiIHIxdE4mIGrisrKxKb1coFHW6Blh5zGYzcnNzK91HpVLB3d29XusgIiJyFeyaSETUwEVHR1d6+7Bhw/Duu+/Waw2pqam49957K93nqaeewtNPP12vdRAREbkKBjEiogZu3759ld4eFBSEyMjIeq1Br9cjOTm50n3CwsLqdCZIIiIiV8YgRkRERERE5GCcrIOIiIiIiMjBOFlHBSwWCzIzM+Hu7g6RSOTscoiIiIjoFoIgQKPRICgoCGIx2xeocWEQq0BmZiYSExOdXQYRERERVWHPnj1o0qSJs8sgqhEGsQqUTsG8Z88eeHh4OLkaIiIiIrqVWq1GYmIil86gRskhQWz16tVYsWIFsrKyEBMTg//7v/9DXFxchftv27YNCxYsQFpaGiIiIvD888/btU7Nnj0bGzdutLtPz549sWLFCtvP+fn5ePPNN7F7926IxWL0798fL7/8crXfqKXdET08PBjEiIiIiBowDiOhxqjeO9Nu3boVc+fOxfTp07Fx40bExMRgwoQJyMnJKXf/w4cP47nnnsOIESOwadMm3HvvvZg+fTrOnTtnt1+vXr3w559/2r4++OADu9uff/55XLhwAStXrsSSJUtw6NAhzJkzp97Ok4iIiIiIqLrqPYitXLkSI0eOxEMPPYTIyEi8/vrrUCgU+P7778vd/8svv0SvXr0wceJEtGrVCjNnzkTbtm3x9ddf2+0nl8sRGBho+/L29rbddvHiRfzxxx946623EB8fjy5duuCVV17BTz/9hIyMjHo9XyIiIiIioqrUaxAzGAw4efIkunfv/s8DisXo3r07jhw5Uu59jh49im7dutlt69mzJ44ePWq37eDBg+jWrRvuv/9+vPrqq8jLy7PdduTIEXh5eaF9+/a2bd27d4dYLMbx48fr4MyIiIiIiIhqr17HiOXl5cFsNsPf399uu7+/Py5dulTufbKzsxEQEFBm/+zsbNvPvXr1wn333YfQ0FBcu3YNH3zwAZ588kmsXbsWEokE2dnZ8PPzszuGVCqFt7c3srKyyn1cg8EAg8Fg+1mtVtfoXImIiIiIiKqrUc6aOGjQINu/o6OjER0djX79+tlayWpj6dKlWLRoUV2VSEREREREVKF67Zro6+sLiURSZmKOnJycMq1epQICAuxav6raHwDCwsLg6+uLK1eu2I6Rm5trt4/JZEJBQQECAwPLPcbkyZORnJxs+9qzZ0+V50dERERERFQb9RrE5HI5YmNjkZSUZNtmsViQlJSEjh07lnufDh06YP/+/Xbb9u3bhw4dOlT4ODdu3EB+fr4tZHXs2BGFhYU4ceKEbZ/9+/fDYrFUOG2+XC63TVXPKeuJiIiIiKg+1fusiePHj8e6deuwceNGXLx4Ea+99hq0Wi2GDx8OAHjhhRfw/vvv2/YfN24c/vjjD3z++ee4ePEiFi5ciBMnTmDMmDEAAI1Gg/feew9Hjx5FamoqkpKSMG3aNDRv3hy9evUCALRq1Qq9evXC//3f/+H48eNITk7Gm2++iUGDBiE4OLi+T5mIiIiIiKhS9T5G7IEHHkBubi4+/vhjZGVloU2bNli+fLmtq2F6ejrE4n/yYKdOnTB//nx89NFH+OCDDxAREYHFixcjKioKACCRSHDu3Dls2rQJRUVFCAoKQo8ePTBjxgzI5XLbcebPn48333wT//73v20LOr/yyiv1fbpERERERERVEgmCIDi7iIZIrVajc+fOSE5OZjdFIiIiogaI12vUmNV710QiIiIiIiKyxyBGRERERETkYAxiREREREREDsYgRkRERERE5GAMYkRERERERA7GIEZERERERORgDGJEREREREQOxiBGRERERETkYAxiREREREREDsYgRkRERERE5GAMYkRERERERA7GIEZERERERORgDGJEREREREQOxiBGRERERETkYAxiREREREREDsYgRkRERERE5GAMYkRERERERA7GIEZERERERORgDGJEREREREQOxiBGRERERETkYAxiREREREREDsYgRkRERERE5GAMYkRERERERA7GIEZERERERORgDGJEREREREQOxiBGRERERETkYA4JYqtXr0bfvn3Rvn17PPzwwzh+/Hil+2/btg0DBgxA+/btMXjwYOzZs8d2m9FoxP/+9z8MHjwYHTp0QM+ePfHCCy8gIyPD7hh9+/ZFdHS03ddnn31WL+dHRERERERUE/UexLZu3Yq5c+di+vTp2LhxI2JiYjBhwgTk5OSUu//hw4fx3HPPYcSIEdi0aRPuvfdeTJ8+HefOncP/s3ff4VFViRvH35kkQ0iFNFooUhJaKkgJwSggdXEBFRtSREVFXRR/CIi4iGJDFxXUKAIWFBVEZQkWLAhSlEAIRUQ6gUAaKRNCJuX+/mCZ3TEJRZNJAt/P88yjOffce8/hOHjfnHvPlaTTp09r165duvfee/Xpp59q7ty5OnDggO69994yx3rwwQe1bt06+2fEiBFV2lcAAAAAuBBVHsQWLlyo4cOH6/rrr1fr1q01Y8YMubu7a9myZeXWf/fdd9WzZ0/deeedatWqlSZMmKD27dvr/ffflyR5e3tr4cKFGjhwoFq2bKnIyEg9/vjj2rlzp44dO+ZwLE9PTwUGBto/Hh4eVd1dAAAAADivKg1iNptNO3fuVExMzH9PaDYrJiZGW7duLXefpKQkde/e3aEsNjZWSUlJFZ7HarXKZDLJx8fHofytt95S165dNWTIEM2fP1/FxcXnbKvVanX4AAAAAEBVcK3Kg588eVIlJSXy9/d3KPf399f+/fvL3ScjI0MBAQFl6mdkZJRbv7CwULNnz9agQYPk5eVlL7/99tvVvn17+fr6auvWrXrppZeUnp6uKVOmlHuc+Ph4zZ0792K6BwAAAAB/SpUGsapWVFSkf/zjHzIMQzNmzHDYNmbMGPu/t23bVm5ubnriiSc0ceJEWSyWMscaN26cwz5Wq1VxcXFV13gAAAAAl60qDWL169eXi4tLmYU5MjMzy8x6nRUQEFBm9qu8+kVFRZowYYKOHTumd955x2E2rDwREREqLi5WSkqKWrZsWWa7xWIpN6ABAAAAQGWr0mfELBaLOnTooA0bNtjLSktLtWHDBkVFRZW7T2RkpDZu3OhQtn79ekVGRtp/PhvCDh06pEWLFql+/frnbcuvv/4qs9lc5jZJAAAAAHC2Kr81ccyYMXr00UfVsWNHhYeH65133lFBQYGGDRsmSZo0aZIaNGigiRMnSpJGjhyp22+/XQsWLFBcXJwSEhK0Y8cOPfnkk5LOhLAHH3xQu3btUnx8vEpKSpSeni5J8vX1lcVi0datW7Vt2zZ169ZNnp6e2rp1q5555hldd9118vX1reouAwAAAMA5VXkQGzhwoLKysvTKK68oPT1d7dq10/z58+23Gqampsps/u/EXHR0tGbPnq05c+bopZdeUosWLTRv3jyFhIRIkk6cOKHvvvtOkvT3v//d4VzvvvuuunbtKovFooSEBM2dO1c2m03BwcEaPXq0wzNgAAAAAFBdTIZhGNXdiJrIarWqU6dOSkxMPO/zZwAAAHA+rtdQm1X5C50BAAAAAI4IYgAAAADgZAQxAAAAAHAyghgAAAAAOBlBDAAAAACcjCAGAAAAAE5GEAMAAAAAJyOIAQAAAICTEcQAAAAAwMkIYgAAAADgZAQxAAAAAHAyghgAAAAAOBlBDAAAAACcjCAGAAAAAE5GEAMAAAAAJyOIAQAAAICTEcQAAAAAwMkIYgAAAADgZAQxAAAAAHAyghgAAAAAOBlBDAAAAACcjCAGAAAAAE5GEAMAAAAAJyOIAQAAAICTEcQAAAAAwMmcEsQWL16sXr16KSwsTDfeeKOSk5PPWX/VqlXq37+/wsLCNHjwYK1Zs8Zhu2EYevnllxUbG6vw8HCNHj1aBw8edKiTnZ2tiRMnKjo6Wp07d9bUqVOVn59f2V0DAAAAgItW5UEsISFBzzzzjMaPH6/ly5erbdu2Gjt2rDIzM8utv2XLFk2cOFE33HCDPvvsM/Xu3Vvjx4/Xnj177HXeeustvffee/rnP/+pjz/+WHXr1tXYsWNVWFhor/PII49o7969Wrhwod544w1t3rxZ06dPr+ruAgAAAMB5VXkQW7hwoYYPH67rr79erVu31owZM+Tu7q5ly5aVW//dd99Vz549deedd6pVq1aaMGGC2rdvr/fff1/Smdmwd999V/fee6/69Omjtm3b6vnnn1daWppWr14tSdq3b5/Wrl2rp556ShEREercubOmTZumlStX6sSJE1XdZQAAAAA4pyoNYjabTTt37lRMTMx/T2g2KyYmRlu3bi13n6SkJHXv3t2hLDY2VklJSZKklJQUpaenOxzT29tbERER9mNu3bpVPj4+CgsLs9eJiYmR2Wyu8LZIm80mq9Xq8AEAAACAquBalQc/efKkSkpK5O/v71Du7++v/fv3l7tPRkaGAgICytTPyMiQJKWnp9vLKqqTkZEhPz8/h+2urq7y9fW17/9H8fHxmjt37gX2DAAAAAD+vCoNYrXJuHHjNGbMGPvPVqtVcXFx1dgiAAAAAJeqKr01sX79+nJxcSmzMEdmZmaZWa+zAgIC7DNb5dUPDAy0l1VUJyAgQFlZWQ7bi4uLlZOTY9//jywWi7y8vBw+AAAAAFAVqjSIWSwWdejQQRs2bLCXlZaWasOGDYqKiip3n8jISG3cuNGhbP369YqMjJQkBQcHKzAw0OGYVqtV27Ztsx8zKipKubm52rFjh73Oxo0bVVpaqvDw8MrqHgAAAAD8KVW+auKYMWP08ccfa/ny5dq3b5/++c9/qqCgQMOGDZMkTZo0SS+++KK9/siRI7V27VotWLBA+/bt06uvvqodO3ZoxIgRkiSTyaSRI0fq9ddf17fffqvffvtNkyZNUlBQkPr06SNJatWqlXr27KnHH39cycnJSkxM1MyZMzVo0CA1aNCgqrsMAAAAAOdU5c+IDRw4UFlZWXrllVeUnp6udu3aaf78+fbbCFNTU2U2/zcPRkdHa/bs2ZozZ45eeukltWjRQvPmzVNISIi9zl133aWCggJNnz5dubm56tSpk+bPn686derY68yePVszZ87UqFGjZDab1bdvX02bNq2quwsAAAAA52UyDMOo7kbURFarVZ06dVJiYiLPiwEAANRAXK+hNqvyWxMBAAAAAI4IYgAAAADgZAQxAAAAAHAyghgAAAAAOBlBDAAAAACcjCAGAAAAAE5GEAMAAAAAJyOIAQAAAICTEcQAAAAAwMkIYgAAAADgZAQxAAAAAHAyghgAAAAAOBlBDAAAAACcjCAGAAAAAE5GEAMAAAAAJyOIAQAAAICTEcQAAAAAwMkIYgAAAADgZAQxAAAAAHAyghgAAAAAOBlBDAAAAACcjCAGAAAAAE5GEAMAAAAAJyOIAQAAAICTEcQAAAAAwMmqLIhlZ2dr4sSJio6OVufOnTV16lTl5+efc5/CwkLNmDFDXbt2VVRUlB544AFlZGTYt+/evVsPP/yw4uLiFB4ergEDBuidd95xOMamTZsUGhpa5pOenl4l/QQAAACAi+VaVQd+5JFHlJ6eroULF6qoqEhTp07V9OnT9eKLL1a4z6xZs7RmzRrNmTNH3t7emjlzpu6//34tWbJEkrRjxw75+fnphRdeUKNGjbRlyxZNnz5dLi4uGjFihMOxvvzyS3l5edl/9vf3r5qOAgAAAMBFqpIgtm/fPq1du1ZLly5VWFiYJGnatGm6++67NWnSJDVo0KDMPnl5eVq2bJlmz56t7t27SzoTzAYOHKikpCRFRkbqhhtucNinadOmSkpK0tdff10miPn7+8vHx6cqugcAAAAAf0mV3Jq4detW+fj42EOYJMXExMhsNis5ObncfXbs2KGioiLFxMTYy1q1aqXGjRsrKSmpwnPl5eWpXr16ZcqHDBmi2NhYjRkzRomJiedts81mk9VqdfgAAAAAQFWokhmxjIwM+fn5OZ7I1VW+vr4VPquVkZEhNze3MrNY/v7+Fe6zZcsWrVq1SvHx8faywMBAzZgxQx07dpTNZtMnn3yikSNH6uOPP1aHDh0qbHN8fLzmzp17oV0EAAAAgD/tooLY7Nmz9dZbb52zTkJCwl9q0IXas2eP7rvvPo0fP16xsbH28pYtW6ply5b2n6Ojo3XkyBEtWrRIL7zwQoXHGzdunMaMGWP/2Wq1Ki4urmoaDwAAAOCydlFB7I477tDQoUPPWadp06YKCAhQVlaWQ3lxcbFycnIUGBhY7n4BAQEqKipSbm6uw6xYZmZmmX327t2r0aNH66abbtJ999133naHhYVpy5Yt56xjsVhksVjOeywAAAAA+KsuKoj5+fmVueWwPFFRUcrNzdWOHTvUsWNHSdLGjRtVWlqq8PDwcvfp2LGj3NzctGHDBvXr10+StH//fh07dkyRkZH2er///rtGjRqlIUOG6KGHHrqgdu/evbvCAAgAAAAAzlYlz4i1atVKPXv21OOPP64ZM2aoqKhIM2fO1KBBg+wrJp44cUKjRo3S888/r/DwcHl7e+v666/Xs88+K19fX3l5eempp55SVFSUPYjt2bNHo0aNsi/CcfbZMRcXF3tAXLRokYKDg9WmTRsVFhbqk08+0caNG7VgwYKq6CoAAAAAXLQqe4/Y7NmzNXPmTI0aNUpms1l9+/bVtGnT7NuLiop04MABFRQU2MumTp0qs9msBx98UDabTbGxsXriiSfs27/66itlZWXpiy++0BdffGEvb9Kkib777jv7cZ977jmdOHFCdevWVUhIiBYuXKhu3bpVVVcBAAAA4KKYDMMwqrsRNZHValWnTp2UmJjo8GJoAAAA1Axcr6E2q5L3iAEAAAAAKkYQAwAAAAAnI4gBAAAAgJMRxAAAAADAyQhiAAAAAOBkBDEAAAAAcDKCGAAAAAA4GUEMAAAAAJyMIAYAAAAATkYQAwAAAAAnI4gBAAAAgJMRxAAAAADAyQhiAAAAAOBkBDEAAAAAcDKCGAAAAAA4GUEMAAAAAJyMIAYAAAAATkYQAwAAAAAnI4gBAAAAgJMRxAAAAADAyQhiAAAAAOBkBDEAAAAAcDKCGAAAAAA4GUEMAAAAAJyMIAYAAAAATlZlQSw7O1sTJ05UdHS0OnfurKlTpyo/P/+c+xQWFmrGjBnq2rWroqKi9MADDygjI8OhTmhoaJnPypUrHeps2rRJQ4cOVceOHXXttdfq008/rfT+AQAAAMCfVWVB7JFHHtHevXu1cOFCvfHGG9q8ebOmT59+zn1mzZql77//XnPmzNF7772ntLQ03X///WXqPfPMM1q3bp3906dPH/u2I0eOaNy4ceratas+//xzjRo1StOmTdPatWsrvY8AAAAA8Ge4VsVB9+3bp7Vr12rp0qUKCwuTJE2bNk133323Jk2apAYNGpTZJy8vT8uWLdPs2bPVvXt3SWeC2cCBA5WUlKTIyEh7XR8fHwUGBpZ77iVLlig4OFiTJ0+WJLVq1UqJiYlatGiRevbsWck9BQAAAICLVyUzYlu3bpWPj489hElSTEyMzGazkpOTy91nx44dKioqUkxMjL2sVatWaty4sZKSkhzqnr198YYbbtDSpUtlGIZ9W1JSkj3InRUbG1vmGAAAAABQXapkRiwjI0N+fn6OJ3J1la+vr9LT0yvcx83NTT4+Pg7l/v7+Dvs8+OCD6tatm+rWrat169ZpxowZOnXqlEaOHGk/TkBAgMMxAgICZLVadfr0abm7u5d7fpvNJpvNZv/ZarVeeIcBAAAA4CJcVBCbPXu23nrrrXPWSUhI+EsNOp/x48fb/719+/YqKCjQ22+/bQ9if1Z8fLzmzp37V5sHAAAAAOd1UUHsjjvu0NChQ89Zp2nTpgoICFBWVpZDeXFxsXJycip8tisgIEBFRUXKzc11mBXLzMyscB9JioiI0GuvvSabzSaLxaKAgIAyKy1mZGTIy8urwtkwSRo3bpzGjBlj/9lqtSouLu6cfQUAAACAP+Oigpifn1+ZWw7LExUVpdzcXO3YsUMdO3aUJG3cuFGlpaUKDw8vd5+OHTvKzc1NGzZsUL9+/SRJ+/fv17FjxxwW6vijX3/9Vb6+vrJYLJKkyMhI/fjjjw511q9ff85jSJLFYrEfAwAAAACqUpUs1tGqVSv17NlTjz/+uJKTk5WYmKiZM2dq0KBB9hUTT5w4of79+9sX7/D29tb111+vZ599Vhs3btSOHTs0depURUVF2UPUd999p08++UR79uzRoUOH9MEHHyg+Pl4jRoywn/vmm2/WkSNH9Pzzz2vfvn1avHixVq1apdGjR1dFVwEAAADgolXJYh3SmefJZs6cqVGjRslsNqtv376aNm2afXtRUZEOHDiggoICe9nUqVNlNpv14IMPymazKTY2Vk888cR/G+vqqsWLF2vWrFmSpGbNmmny5MkaPny4vU7Tpk0VHx+vZ555Ru+++64aNmyop556iqXrAQAAANQYJuN/136HndVqVadOnZSYmCgvL6/qbg4AAAD+gOs11GZVNiNW253NpyxjDwAAUDOdvU5jXgG1EUGsAvn5+ZLEyokAAAA1XH5+vry9vau7GcBF4dbECpSWliotLU2enp4ymUxVfr6zy+WvWbOGqfVaijGs/RjD2o3xq/0Yw9rP2WNoGIby8/MVFBQks7lK1qADqgwzYhUwm81q2LCh08/r5eXF/3xqOcaw9mMMazfGr/ZjDGs/Z44hM2GorfjVAQAAAAA4GUEMAAAAAJyMIFZDWCwW3X///bJYLNXdFPxJjGHtxxjWboxf7ccY1n6MIXDhWKwDAAAAAJyMGTEAAAAAcDKCGAAAAAA4GUEMAAAAAJyMIAYAqFQpKSkKDQ3V22+/fd66r776qkJDQ53QKgAAahaCGABUosWLF+vTTz+t7mZUijfeeEOrV6+u7mYAAHBJIogBQCX68MMPtXz58upuRqWIj4+v8iB27733Kjk5uUrPAQBATUQQA4AarrCwUKWlpdXdjCrh6uqqOnXqVHczAABwOoIYgMvel19+qdDQUP38889lti1ZskShoaHas2eP0tPTNWXKFF111VXq2LGjYmNjde+99yolJUWS1KtXL/3+++/6+eefFRoaqtDQUN1+++2SpOzsbD333HMaPHiwoqKiFB0drTvvvFO7d+92ON+mTZsUGhqqlStX6l//+pd69uypiIgIWa3WC+7P559/rmHDhik8PFxdunTRQw89pNTUVIc6Bw8e1AMPPKAePXooLCxMV111lR566CHl5eVJkkJDQ3Xq1CktX77c3pfJkydf1J+rJC1atEjXXHONwsPDNWLECO3Zs8dhe3nPiC1btkwjR45U9+7d1bFjRw0cOFAffPBBmWNv375dY8eOVdeuXRUeHq5evXppypQpF91GAACqg2t1NwAAqtvVV18tDw8PrVq1Sl26dHHYlpCQoDZt2igkJEQ333yz9u7dqxEjRqhJkybKysrSTz/9pNTUVAUHB2vq1KmaOXOmPDw8dM8990iSAgICJElHjhzR6tWr1b9/fwUHBysjI0MfffSRRowYoZUrV6pBgwYO533ttdfk5uamsWPHymazyc3N7YL68vrrr+vll1/WgAEDdMMNNygrK0vvv/++brvtNn322Wfy8fGRzWazH3fEiBEKCAjQiRMn9MMPPyg3N1fe3t56/vnnNW3aNIWHh2v48OGSpGbNml3Un+tnn32m/Px83XrrrSosLNR7772nUaNGacWKFfY/l/J8+OGHatOmjXr16iVXV1d9//33mjFjhgzD0G233SZJyszM1NixY1W/fn3dfffd8vHxUUpKir755puLaiMAANXGAAAYDz/8sNG9e3ejuLjYXpaWlma0bdvWmDt3rpGTk2OEhIQY8+fPP+dxBg0aZIwYMaJMeWFhoVFSUuJQduTIEaNjx47G3Llz7WUbN240QkJCjN69exsFBQUX1YeUlBSjXbt2xuuvv+5Q/ttvvxnt27e3l+/atcsICQkxVq1adc7jRUZGGo8++uhFtcEwzvQrJCTECA8PN44fP24v37ZtmxESEmLMmjXLXvbKK68YISEhDvuX1+877rjD6N27t/3nb775xggJCTGSk5Mvun0AANQE3JoIAJIGDBigzMxMh9sTv/rqK5WWlmrgwIFyd3eXm5ubfv75Z+Xk5Fz08S0Wi8zmM3/llpSU6OTJk/Lw8NAVV1yhXbt2lak/ZMgQubu7X9Q5vvnmG5WWlmrAgAHKysqyfwICAtS8eXNt2rRJkuTl5SVJWrdunQoKCi66LxeqT58+DjN94eHhioiI0Jo1a8653//2Oy8vT1lZWerSpYuOHDliv3XS29tbkvTDDz+oqKioCloPAEDV4tZEAJB01VVXydvbWwkJCerevbukM7cltmvXTldccYUk6ZFHHtFzzz2nHj16KCIiQldffbWGDBmiwMDA8x6/tLRU7777rj744AOlpKSopKTEvq1evXpl6gcHB190Hw4ePCjDMNS3b99yt7u6nvkrv2nTphozZowWLlyoFStWqHPnzurVq5euu+46e8CpDM2bNy9T1qJFC61ateqc+yUmJurVV19VUlJSmaCYl5cnb29vdenSRf369dPcuXO1aNEidenSRX369NHgwYNlsVgqrQ8AAFQVghgA6MyMVZ8+ffTNN9/oiSeeUGZmprZs2aKHH37YXmf06NHq1auXVq9erXXr1unll1/Wm2++qXfeeUft27c/5/HfeOMNvfzyy7r++uv1j3/8Q76+vjKbzZo1a5YMwyhT/2Jnw6QzYc9kMumtt96Si4tLme0eHh72f588ebKGDh2qb7/9Vj/99JOeeuopxcfH6+OPP1bDhg0v+tyV5fDhwxo9erRatmypyZMnq1GjRnJzc9OaNWu0aNEi++qRJpNJr7zyipKSkvT9999r7dq1mjp1qhYuXKiPPvpInp6e1dYHAAAuBEEMAP5jwIABWr58uTZs2KB9+/bJMAwNGDDAoU6zZs10xx136I477tDBgwc1ZMgQLViwQLNnz5Z0JiCU56uvvlLXrl01a9Ysh/Lc3FzVr1+/UtrfrFkzGYah4OBg+yzeuZxdDfG+++7Tli1bdMstt+jDDz/UQw89VCntOXToUJmygwcPqkmTJhXu891338lms+n1119X48aN7eVnb6v8o8jISEVGRuqhhx7SihUr9MgjjyghIUE33njjX+8AAABViGfEAOA/YmJiVK9ePSUkJGjVqlUKDw9X06ZNJUkFBQUqLCx0qN+sWTN5enrKZrPZy+rWravc3Nwyx3ZxcSkz87Vq1SqdOHGi0trft29fubi4aO7cuWXOZRiGTp48KUmyWq0qLi522B4SEiKz2ezQFw8Pj3L7cqFWr17t0L/k5GRt27ZNV111VYX7nJ3J+9/25+XladmyZQ71cnJyyvSxXbt2kuTQBwAAaipmxADgP9zc3HTttddq5cqVKigo0KOPPmrfdvDgQY0ePVr9+/dX69at5eLiotWrVysjI0ODBg2y1+vQoYM+/PBDvfbaa2revLn8/PzUvXt3XX311Zo3b56mTJmiqKgo7dmzRytWrLAHvcrQrFkzTZgwQS+++KKOHj2qPn36yNPTUykpKVq9erWGDx+usWPHauPGjXryySfVv39/tWjRQiUlJfr888/l4uKifv36OfRlw4YNWrhwoYKCghQcHKyIiIiLas8tt9yiW265RTabTe+++67q1aunO++8s8J9evToITc3N91zzz26+eablZ+fr08++UT+/v5KT0+311u+fLk+/PBD9enTR82aNVN+fr4+/vhjeXl5nTPoAQBQUxDEAOB/DBw4UJ988olMJpPDbYkNGzbUoEGDtGHDBn3xxRdycXFRy5YtNWfOHIfwMn78eB07dkzz589Xfn6+unTpou7du+uee+5RQUGBVqxYoYSEBLVv317x8fF68cUXK7X9d999t1q0aKFFixZp3rx59rb36NFDvXr1knTmlsTY2Fh9//33OnHihOrWravQ0FC99dZbioyMtB9r8uTJmj59uubMmaPTp09r6NChFxXEhgwZIrPZrHfeeUeZmZkKDw/X448/rqCgoAr3admypV555RXNmTNHzz33nAICAnTLLbfIz89PU6dOtdfr0qWLtm/froSEBGVkZMjb21vh4eGaPXt2pYZbAACqisko7ylxAAAAAECV4RkxAAAAAHAybk0EgFrgf5+PKo+7u3ulvgOsPCUlJcrKyjpnHQ8PD5aOBwDgAnBrIgDUAqGhoefcPnToUD377LNV2oaUlBT17t37nHXuv/9+PfDAA1XaDgAALgUEMQCoBdavX3/O7UFBQWrdunWVtqGwsFCJiYnnrNO0aVMWywAA4AIQxAAAAADAyVisAwAAAACcjMU6KlBaWqq0tDR5enrKZDJVd3MAAADwB4ZhKD8/X0FBQTKbmV9A7UIQq0BaWpri4uKquxkAAAA4jzVr1qhhw4bV3QzgohDEKnB2+eU1a9bIy8urmlsDAACAP7JarYqLi+O1GaiVCGIVOHs7opeXF0EMAACgBuMxEtRGte5m2jfffFOhoaF6+umnz1lv0aJF6tevn8LDwxUXF6dZs2apsLDQSa0EAAAAgIrVqhmx5ORkLVmy5LwvNl2xYoVefPFFzZo1S1FRUTp48KAmT54sk8mkKVOmOKm1AAAAAFC+WjMjlp+fr//7v//TU089JV9f33PW3bp1q6KjozV48GAFBwcrNjZWf/vb35ScnOyk1gIAAABAxWrNjNiTTz6puLg4xcTE6PXXXz9n3aioKH3xxRdKTk5WeHi4jhw5ojVr1ujvf/+7k1pbeQzDUFpeoban5GjHsRztOJqjHUdzVVhcot7tGmhQeCPFtg6Qm0utydQAAADAZa9WBLGVK1dq165dWrp06QXVHzx4sE6ePKlbb71VhmGouLhYN998s+65554K97HZbLLZbPafrVbrX273hSoqKdWw19ZrV2quXMwmuZlNZ/7pYlZxqaGcgqJy91uamKKliSnyreum/h0aalB4I8W08pcroQwAAACo0Wp8EEtNTdXTTz+tBQsWqE6dOhe0z6ZNmxQfH68nnnhC4eHhOnz4sJ5++mnNmzdP48ePL3ef+Ph4zZ07tzKbfsFKSg1l5dtUUmqopNSQ7Q/bXcwmtQnyUofGvurYxEcdm/iqpNRQwvZUJWw/rgxroT7afEQfbT6iZn4emtQ/VIPCGlW4gtCm/Zma+/1eZeXbdEOnYN3Yuam86tT4/xQAAACAS4bJMAyjuhtxLqtXr9b48ePl4uJiLyspKZHJZJLZbNb27dsdtknSrbfeqoiICD366KP2ss8//1zTp0/X1q1by33zenkzYnFxcUpMTHTK8vW24lJln7KpqNRQSYmhotJSlZQaMgypub+H3N1cyt2vpNTQzweytHL7MSVsP66s/DN9iGxaT48NaqcrW/jZ625PydELX/+mH/ekOxzD291Vt3RpplExLdSkXt2q6yQAAEAlslqt6tSpk9Ou14DKVOOnQbp166YVK1Y4lE2ZMkUtW7bUXXfdVSaESdLp06fLhK2z9SrKnRaLRRaLpZJaffEsrmYF+bhf9H4uZpO6t/JX91b+mjKgnd5au19v/rhfSUeydeMbG9S3fQPd1q25lvx8WKt2HJckuZpNGn5lU4U28NY76w9qf0a+3vxxv95ed0D9OzbUnbFXKKpZ/cruIgAAAID/qPFBzMvLSyEhIQ5lHh4eqlevnr180qRJatCggSZOnChJuuaaa7Rw4UK1b9/efmviyy+/rGuuuabc4Hap8Kzjqgl9QnRr12aas/p3Lfn5sL7edUJf7zohSTKZpKGRTfSPPm3U3P/MG+hv79Zc3/+WprfXHdD6fZlamZyqlcmp6ty8vu7seYWubd9QLmZekggAAABUphofxC5EamqqwwzYvffeK5PJpDlz5ujEiRPy8/PTNddco4ceeqgaW+k8Qd7umjU0THf0aKFnV+3W6l/T1K9DA03sG6qQBt4Odc1mk3q3a6De7Rpo17FczV+3Xyu2HdPmQye1+dBJNfWrqzt6XKHhnZvK808+R5ZhLdRnW4/qSNYp3di5qTo2OffrBwAAAIBLXY1/Rqy6XEr3HBcWl6iO64XPBKblnta7Gw7p/U2HlH3qzIqNdd1c1MjXXfU9LarvYVF9Dzf5eVrU0NddIQ28FdLAWwFeFvsCIcUlpfrht3R9knhE3/6apuLS//5nNiSysR7pF6rg+h6V21EAAHBZuZSu13D5IYhVgC+2dMpWrGVbjmrBugM6kJF/3vp+nha1CfJSk/p1tfb3DKXnFdq3RQT7qnG9uvbn1CwuZo3u0ULjr24tXw+3KusDAAC4dHG9htqMIFYBvtj/VVpqaH+GVZlWm06esikrv+g//7TpSNYp7TmRp0NZp/TH/5L8PS0aGtVEN3ZuqtCGZ26J3J6So1kJv2rD/kxJko+7q+7v1VqjY66QxZX3nwEAgAvH9Rpqs0viGTFULbPZpNZB3modVHGdAluJ9qVb9dvxM6GsfSMf9WobVCZchQX76oO7uuqHPel6NmG3fjuRp1kJu5V46KReu60TC4MAAADgskAQQ6Woa3FRxya+F7QQh8lk0jWhQbqqTaCWJh7R45/t1Fc7T+iplbv0xOAOTmgtAAAAUL24FwzVxsVs0k1XNtOLwyMkSQt/Oqi31x2o5lYBAAAAVY8ghmo3OKKxpgxoK0l6auUurdqeWs0tAgAAAKoWQQw1wt1XtdTI7s1lGNI/PkpS4qGs6m4SAAAAUGUIYqgRTCaTnhjcQX3aBclWXKo739ms/enW6m4WAAAAUCUIYqgxXMwmvXJLlCKCfXXyVJFGL/xFWfm26m4WAAAAUOkIYqhRPCyumj/qSjX1q6vDWad07/uJshWXVnezAAAAgEpFEEONE+hdRwtGXSmvOq7adCBLT3yxQ7x3HAAAAJcSghhqpDYNvPXqLVEymaQPfz6id9YfrO4mAQAAAJWGIIYa65q2QfZl7Z/89y79uCe9mlt0RnJKth78cKsSWGYfAAAAfxJBDDXaXT1b6vroYJUa0v0fbKnWlRSthcWasWKnhsz7SV9sO6b7Fm/RnNV7uG0SAAAAF821uhsAnIvJZNKsYR11IMOqLYezdec7m/Xu2C4qLjGUXVCknP98CotK1K6Rj9o29JarS+X/fuGbXSc0/fMdSs05LUmKbFpPSUeyNWf17zqUeUrPXh+mOq4ulX5eAAAAXJoIYqjx6ri6KP72zvr73HXan5Gv2Oe+r7Cup8VFUc3qq1Pz+urcor6im9WXZ52L/8+8pNRQbkGRTuSd1pxvfteXO49Lkpr5eeipIR11VUigPvz5sKZ9tkPLtx7V0ZMFir+9k+p7Wv50PwEAAHD5MBncV1Uuq9WqTp06KTExUV5eXtXdHEjaeSxHt761STkFRfK0uMi3rpt8PSzyresqs8mk7Sk5yissdtjHx91VM4d01N8jm1R43NJSQx9vPqKliSnKsBbq5Kki5Z4u0v9+M1zNJt11VUs92KuN6lr+O/O19vd03ff+FuUVFquFv4cWjL5SLQP57wUAAGfgeg21GUGsAnyxa6aikjPvFHMr5/bDklJDe07kafOhk0o8mKVNB7LstxIOiWysJ4d0lI+7m8M+BzPyNfnTZG3cn1Xu+bzruCos2FfTB7dX24Y+5dbZcyJPYxb+oqPZBfKu46qY1v6KaFpPkU3rKayJr7z/cE4AAFA5uF5DbUYQqwBf7NqvqKRUr363V3O/+12lhtSkXl3966ZIdbnCT8UlpVrw0wG9+PUeFRaXyt3NrH/0DlGn5vVV38NN9TwsqufhVm7gK096XqHufm+zth7Odig3maTWgV666cqmurNnyyroJQAAly+u11CbEcQqwBf70pF4KEsTPkrSkawCmU3SmB5X6JeDWUpOyZEk9Wjtr2eGhquZv8dfOk9JqaHEQye17Ui2kv7zOZpdYN/+5u2d1LdDw790DgAA8F9cr6E2I4hVgC/2pSXvdJFmrNilpYkp9jJvd1c9Pqi9buwcLJPJVCXnTc8r1Kvf/a53NxxSkHcdffNQnHw9uFURAIDKwPUaajPeI4bLgre7m2bfGKHXbotWk3p1NSiskb59OE7Dr2xaZSFMkgK962jqwHZqGeiptLxCPbVyV5WdCwAAALUHQQyXlYFhjfTT5F6ad1u0gnzcnXJOdzcXPX99uEwm6ZPEFP24J90p5wUAAEDNRRADnKBzCz+NjmkhSZry6XZZ/7DMPgAAAC4vBDHASf6vX6ia+tXV0ewCPbdqd3U3BwAAANWo1gWxN998U6GhoXr66afPWS83N1czZsxQbGysOnbsqH79+mnNmjVOaiVQlofFVc8OC5ckvbfxkDbuz6zmFgEAAKC6uFZ3Ay5GcnKylixZotDQ0HPWs9lsGjNmjPz9/fXyyy+rQYMGOnbsmHx8yn8hL+AsPVoH6JYuzfThz4c1eVmyVv3jKtW1uFR3swAAAOBktWZGLD8/X//3f/+np556Sr6+vuesu2zZMuXk5GjevHnq1KmTgoOD1aVLF7Vt29ZJrQUqNmVgWzXyddfBzFN64avfxBskAAAALj+1Jog9+eSTiouLU0xMzHnrfvfdd4qMjNSTTz6pmJgY/e1vf9Mbb7yhkpKSCvex2WyyWq0OH6Aq+Li7adbQMEnSgp8OKPa57/XE5zu09vd02YpLq7l1AAAAcIZacWviypUrtWvXLi1duvSC6h85ckQbN27U4MGD9eabb+rw4cOaMWOGiouLdf/995e7T3x8vObOnVuZzQYqdE3bIP2jdxvF/7hPR7ML9M6GQ3pnwyF51XFVXGigurX0V4fGPmrX0IdbFwEAAC5BJqOG3xeVmpqq66+/XgsWLLDfWnj77berbdu2euyxx8rdp1+/fiosLNS3334rF5czF7ELFy7U22+/rXXr1pW7j81mk81ms/9stVoVFxfHm9pRpU4XleinvRla/esJrf41Tel5hQ7bzSapZaCXOjT2UUgDb7m5mFRSKpUahkpLDZUakov5zEIgXnVc5VHHRZ4WV3nWcVW7Rt7ydnerpp4BAFD1rFarOnXqxPUaaqUaPyO2c+dOZWZmatiwYfaykpIS/fLLL1q8eLG2b99uD1tnBQYGytXV1aG8ZcuWSk9Pl81mk8ViKXMei8VSbjlQldzdXNS7XQP1btdAT5caSj6ao+9+PaFtKTnaeSxXGdZC7U2zam/axd8qa3Ex66qQAA0Ma6Q+7RvIh1AGAABQY9T4INatWzetWLHCoWzKlClq2bKl7rrrrjIhTJKio6P173//W6WlpTKbzzwGd/DgQQUGBhK2UGOZzSZFNq2nyKb17GVpuae181iudh7L0f70fHs9s0lyMZtkNplUXGLoVFGJThUWy1pYrFO2EmXl23Q0u0Crf03T6l/T5OZiUs82gerfoaHCgn3VKtBLFtda84goAADAJafGBzEvLy+FhIQ4lHl4eKhevXr28kmTJqlBgwaaOHGiJOmWW27R+++/r6efflojRozQoUOHFB8fr9tvv93p7Qf+iiAfdwX5uOuatkEXve+eE3lamZyqhO2p+j3Nqu92p+m73WmSJFezSS0DPRXa0EehDbzUvZW/OjX3q+zmAwAAoAI1PohdiNTUVPvMlyQ1atRIb7/9tp555hldd911atCggUaOHKm77rqrGlsJOFdIA2+FXOuth64N0e8n8pSw/bjW/p6u347nKa+wWHtOWLXnhFVn55u7t/TXQ9eGqMsVBDIAAICqVuMX66guPPyJS5VhGDqWc1p7judp9/E87TiWo693HldRyZm/Cnq09tdDfULUucWZQHa6qERbDp3UxgNZ2rQ/U4XFpZrUL1QxrQOqsxsAAHC9hlrtkpgRA3DhTCaTmtSrqyb16tpveTyaXaB53+/VJ5uP6Ke9mfpp7wZ1b+mvopJSbUvJtoe0s0a8vUmT+rfVuKtaymQyVUc3AAAAajWe1gegJvXqatbQMH3/yNW6pUtTuZpN2rA/U5sPnVRRiaGGPu76e2RjzRoaphs7BavUkJ5dtVv3vr9FeaeLqrv51eaUrVh70/J0Mt8mbi4AAAAXgxkxAHbB9T30zLBw3Xd1a32edFRB3u7q2tJPzfw87DNft3Rpqqhm9fXPL3bqy53HtSctT/EjOqlNA28ZhqH9Gfn6+T+3Me5KzVVD37pq19BbbRt5q21Dn1q7YuOvqbnaejj7zOsE0q3al2bV0ewC+3Zvd1c19/dQcz9PNfP3UFgTX/Xv0FBmMzOGAACgLJ4RqwD3HAPnlnQkW/e+n6jUnNPysLjoqjaBSjx8ssxLqf/IzcWkVoFeCmviq+jm9RXdrL7aBHnVyMBSVFKqVTuOa9FPB7TlcHa5dbzruCqvsLjcbXEhgXpxeIQCvOpUYSsB4PLF9RpqM4JYBfhiA+eXaS3UAx9u1fp9mfYyi6tZkU3rqdsVfgoPrqe0vELtPp6r3al5+vV4rvJOlw0t3nVcFdmsnjo1r69buzZTkLe7M7tRRqa1UB9sOqz3Nx3SidwzwdLNxaRuLf0V0sBbrYO8znwCvVTf06LTRSU6nHVKhzNP6VDWKe1Pt2ppYooKi0sV6F1H/xoeqdg2LG4CAJWN6zXUZgSxCvDFBi5McUmpliamKDPfpitb+Ck82FfubmVftC6dWbHxaHaBdh3L1baUbG05lK1tKdk6ZSux1/Gq46rx17TWmB4tKjxOZTmSdUq/p+Xp6MkCpWQX6OjJAh3NLtDOY7myFZdKkgK86mhEt2YXHRB/O56nBz7coj0nrDKZpHvjWumha0Pk5lL7bssEgJqK6zXUZgSxCvDFBpyjuKRUv53I05bD2Vq6+Yi2peRIkpr61dXUAe3Uv2PDKlmZcd73e/XCV79VuD0i2FdjelyhgWGN/vQzbQW2Es1cuUsfbDosSYpqVk+v3Bylpn4ef+p4AABHXK+hNiOIVYAvNuB8paWGPt92VM+t+k3Hc09Lkrpc4acHe7XRFYGeCvKuUykzSq9++7te/GaPJKltQ2819fNQk3p1FVz/zKdloJdCGnj/5fOclbA9VY8uS1be6WJ5u7vqli7NdH10sEIbVt45AOByxPUaajOCWAX4YgPV55StWG+s2a/4NftU+J9bBCXJbJICveuooW9dNannrmFRwerTvsFFHfvl1b/rX6vPhLBJ/UN139WtK7XtFTmSdUr/WLLVYdGPsCa+uqFTsK6LaKz6nhantAMALiVcr6E2I4hVgC82UP2OZhfoX9/s0aYDmTqec7rMi6Ul6cZOwXriug7yqnP+t3HMWb1Hc1b/Lkl6tH9b3Xt1q0pv87kUl5Tq291pWpaYou92p6m49Ex/3FxMigsJVFxIoK4KCVRzf0+ntgsAaiuu11CbEcQqwBcbqFlKSw1l5tuUmlOgY9mntelAphatPyjDOPM82UvDI3VlC79y9zUMQ/9a/bte+fZMCJsyoK3GxTk3hP1RprVQX2w7pmVbUrTjaK7Dtub+HurZJkBXtQlUlyv8VM+D2TIAKA/Xa6jNCGIV4IsN1Hyb9mfq4Y+36Wh2gcwm6Z64VprQJ0QWV7PyC4u1Pz1f+zOs+mlvhj7enCJJmjqwre6+qnpD2B/tPp6rb39N04970pV46KR9puysFv4eimhaT5FN6ymiaT21b+RT5StKAkBtwPUaajOCWAX4YgO1Q+7pIs34YpeWbTkTtILr11VxiWFf7ON/TRvUTnf2bOnsJl4Ua2GxNu7L1I+/p2vd7xnan5Ffpo7ZJAV5u6txPXc1rlf3zMfXXUE+7qrn4SY/T4vqe1hUz8NNdVwJbAAuXVyvoTYjiFWALzZQu6zanqopy7cr+1SRvczf06JWgV5qGeipXm2D1LdDw2ps4Z+Tfcqm5JQcbTuSraT/fDLzbRe8v1cdV3Vr6afrIpuoT7sgeVjO/ywdANQWXK+hNiOIVYAvNlD7ZFgL9fOBLDXwcVerQM9L8tkqwzCUYbXpWHaBjmWfeQF1as5pHT1ZoAxroU6esin7VJGyC4pU8odbHD0sLurbvoGui2ysnm0Cebk0gFqP6zXUZvxqFMAlI8CrjgaGNaruZlQpk8mkQO86CvSuo4im9SqsV1pqKO90sY6cPKUvdxzXF9uO6XDWKX2WdEyfJR2Tv6dFo2NaaGRMC/nWdXNeBwAAgCRmxCrEb1gAXEoMw1DSkWx9nnRM/05OVYa1UJLkXcdVt3dvrrGxV8jfq041txIALg7Xa6jNCGIV4IsN4FJVXFKqldtTNe/7vdpzwipJcncz65YuzTQorJE867jKw+IiD4urPOu4yN3VRWazqZpbDQBlcb2G2oxbEwHgMuPqYtbfI5tocHhjffPrCc37fq+SU3K08KeDWvjTwTL1zSaphb+nQhp4K6Sht9o29FZIA2+18PeQK8+ZAQDwpxDEAOAyZTab1K9DQ/Vt30A//p6h+Wv361DmKZ2yFeuUrUSnbCWSpFJD2p+Rr/0Z+fpy53H7/j7urrqhU1ON6NZMLQMv/jfROQVFWvTTQQXXr6tebYNU37P8xVUyrIX6IumYvth25tm2p4eGqaGv+5/rNAAANQS3JlaAqW4Al7vSUkOni0uUU1CkvWlW/XY8T78dz9OeE3nac8KqgqISe92ebQI0oltz9W4bdEGzZCknT+mORb/Yb410MZt0ZYv6urb9mWAY6F1H3+1O06dbUvTDb+kOL7mu7+Gm2TdGqHe7BpXfaQC1CtdrqM0IYhXgiw0AFSspNbT293S9v/GQvt2dprP/J2nk666R3Vvo9u7N5VWn/JsudhzN0ZhFvyg9r1BB3nXk71VHv6bmOtRxdzPrdFGp/eeIYF8Njmis5VuPauexM3XH9GihyQPa8tJq4DLG9RpqM4JYBfhiA8CFOZJ1Sh/8fFgf/XJEWf952bRvXTfd0eMKje7huDz+97vTNP6DLTplK1FoA28tHHOlGterqyNZp/TNrhP6etdx/XLwpEpKDTXyddfQqCYaFt1ErYO8JUmFxSV6btVvWvDTAUlSh8Y+evWWqD91aySA2o/rNdRmBLEK8MUGgItTWFyiFdtS9doPe7U/PV/SmeXxR8Y019jYllq1I1XTP9+pklJDsa0D9NqIaPm4l32H2cl8m1JzTqttQ+8KV2v89tcTeuSTbTp5qkgeFhd1vcJPfp515OfpJj/POvL3tKhxvbrq3KK+3N2YMQMuVVyvoTardUHszTff1IsvvqiRI0fqscceO2/9lStX6uGHH1bv3r312muvXfB5+GIDwJ9TUmooYXuq5n63V7+dyJMk1XE1q7D4zK2GN3QK1jPDwuT2F1dcPJ5zWhM+2qqN+7MqrFPXzUU9Wgeod7sg9WobpAY+LPIBXEq4XkNtVqtWTUxOTtaSJUsUGhp6QfVTUlL03HPPqXPnzlXcMgDAWS5mkwZHNNagsEb6etcJvfrd7/bnuh7qE6IHe7eWyfTX30vW0Nddi+/spg37MnUsu0CZ+TZl5RcqM9+mk/k27T6ep9Sc01r96wmt/vWEJCmsia+Gdw7WbV2b8240AEC1qjVBLD8/X//3f/+np556Sq+//vp565eUlOiRRx7RAw88oMTEROXm5p53HwBA5TGbTerfsaH6dWig9fsyZTJJMa0CKvUcLmaTYtuUf0zDMLQrNVff/Zqmb3enaVtKtrYfzdH2ozn6YtsxvXBDhFoEeFZqewAAuFC15k2cTz75pOLi4hQTE3NB9efNmyd/f3/deOONF1TfZrPJarU6fAAAf53JZFKP1gGVHsIu5LwdGvvqgd5t9Nn4Hvp5ah9NG9ROnhYX/XLwpPq//KMWrDug0tJadYc+AOASUStmxFauXKldu3Zp6dKlF1R/8+bNWrp0qT777LMLPkd8fLzmzp37J1sIAKjpAr3r6M6eLdWvQ0NN/jRZP+3N1JP/3qVVO1L1wg0Rqufhpt3H87Q7NVe7j+fp1+N5cnc167FB7RQeXK+6mw8AuMTU+CCWmpqqp59+WgsWLFCdOnXOW99qtWrSpEmaOXOm/Pz8Lvg848aN05gxYxyOExcX96faDACouZr6eej9sV31wc+HNWvlr/rl4En1evEHVTQxNuy19Xq4b4jGXdVKLjxXBgCoJDV+1cTVq1dr/PjxcnH57/LDJSUlMplMMpvN2r59u8O2X3/9VUOGDHEoKy09s1KX2WzWl19+qWbNmp33vKzCAwCXvpSTpzR52Xat25shSQquX1dtG/qoXSNvhTb0VsL2VCVsPy5J6nqFn/51U6Qa16tbnU0G8D+4XkNtVuODmNVq1bFjxxzKpkyZopYtW+quu+5SSEiIw7bCwkIdOnTIoWzOnDnKz8/XY489phYtWshisVzQefliA8ClzzAMHc46pfqeljLvNTMMQ58kpuifX+zUKVuJfNxd9cywcA0KbyRbcamy8m3KzC9UptWmvNPFCvSuo8b13NXAx/0vL88P4Py4XkNtVuNvTfTy8ioTtjw8PFSvXj17+aRJk9SgQQNNnDhRderUKVPfx8dHksqUAwBgMpnU3L/81RNNJpOGd26qK1v4acKSrdqWkqPxH2zR5E9dlXe6uMJjmk1SkLe7GtdzV3B9D93cpanTFysBANRsl8Sv61JTU5Wenl7dzQAAXKKuCPDU0ntjNP6aVjKZZA9hLmaTAr3rqG1Db3VuXl/N/T1kcTGr1JCO557WlsPZ+mLbMd02f5P+9c0elbBCIwDgP2r8rYnVhaluAEB5jueclrWwWP6eFvnWdSvzYujSUkMZ+YVKzT6tY9kF+nZ3mpYmpkiSYlsHaM7NkQrwOv/iUwDOj+s11GaXxIwYAADO0tDXXa2DvFTf01ImhElnXmQd5O2uiKb1NCCskWbfGKGXhkeorpuL1u3N0KBX1uqXg1nV0HIAQE1CEAMAoIoNiw7W5/f3UKtAT53ILdTNb27UG2v26ZSt4ufMAACXNoIYAABOENLAW1/cH6vrIhqrpNTQs6t2K3rmN7rnvUR9nnRUeaeLqruJAAAnqvGrJgIAcKnwrOOql2+OVLeW/np9zV4dySrQlzuP68udx2VxMSu2TYBu6dJM17ZvUN1NBQBUMYIYAABOZDKZdGvXZrqlS1PtPJarL3cc16odqdqXnq/vdqfpu91pGtW9uR4b1F4WV25cAYBLFUEMAIBqYDKZ1LGJrzo28dUj/UK1Ny1PH/58RG+vO6B3NhzS9qM5eu22Tmro617dTQUAVAF+1QYAQA3QOshbj/+tvd4e1Vne7q7acjhbf3t1rTbsy6zupgEAqgAzYgAA1CC92zXQivtjdc/7idp9PE8j3t6kR/uH6urQIGWfKlJOQZGyT9mUU1CkQO86+lt4Y7mUs4w+AKBmI4gBAFDDtAjw1PL7emjq8u1avvWoZiXs1qyE3eXW/eG3dM2+MYIwBgC1DEEMAIAaqK7FRS8Nj1B0s3p6+dvfVVJqyLeum3w9LPKt6yavOi76aucJLd96VCZJLxDGAKBWIYgBAFBDmUwm3d69hW7v3qLc7au2p+r+D7fq061HJZP0wg2EMQCoLVisAwCAWmpAWCO9ekuUXMwmfbrlqCYtTVZJqVHdzQIAXABmxAAAqMUGhjWSYUgPLtmqZVtSZDZJz10fLjMzYwBQozEjBgBALTcovJFevjlSLmaTPklM0YNLtir7lK26mwUAOAeCGAAAl4C/hTfWnJvOhLF/J6eqz0trtGLbMRkGtyoCQE1EEAMA4BIxOKKxPrq7m1oHeSnDatMDH27V2Hc262h2QXU3DQDwBwQxAAAuIZ1b+Gnlg7Ga0KeN3FxM+m53mvq+tEYLfzrAQh4AUIMQxAAAuMTUcXXRhD4hWvWPnurcvL7ybSWasWKXBrz8o77aeZzbFQGgBiCIAQBwiWod5K2Px3XXU0M6yreum/acsGrce4ka+tp6rd+bUd3NA4DLGkEMAIBLmNls0ohuzfXjpGs0/ppWquvmoqQj2bp1/iaNmL9JG/ZlKr+wuLqbCQCXHd4jBgDAZcC3rpv+r19bjYppoXnf7dUHPx/Wur0ZWvefmbHGvu5qFeSlNkHeah3kpQ6NfdSukY8srvzOFgCqAkEMAIDLSJC3u2b8vaPu7NlSL3/7u374LU0ZVpuO5ZzWsZzTWvv7f29ZtLiaFdbEV5FN6ymqWT21beijAluJMvMLlZVvU1a+TZn5NmWfsin7VJFyCv7nc6pIMkndWvrrmtAgXR0aqMb16lZjzwGgZjEZPLFbLqvVqk6dOikxMVFeXl7V3RwAAKpM9imb9qZZtTfNqt//80lOyVb2qaJKPU9oA29d3TZQvUKD1LmFn1zMpko9Pi4/XK+hNmNGDACAy1w9D4s6t/BT5xZ+9jLDMHQw85S2Hj6ppCPZ2no4W3vTrPKp6yo/zzry97TI738+vnXdVM/DTT513eT7n09+YbHW/JauH/aka+vhk/rtRJ5+O5Gn+DX75edpUZ92QerXoaF6tA6Qu5tLNf4JAIDz1boZsTfffFMvvviiRo4cqccee6zcOh9//LE+++wz/f7775KkDh066OGHH1Z4ePgFn4ffsAAAUHmyT9n04+8Z+mF3mr7dnaacgv/OtnlYXBQXEqhebYMUFxKoIB/3amwpahOu11Cb1aoZseTkZC1ZskShoaHnrLdp0yYNGjRI0dHRslgsmj9/vu644w6tXLlSDRo0cFJrAQDAWfU8LLouorGui2isopJS/XIgS1/tPK6vd51Qas5prdpxXKt2HJcktWvko7iQQMWFBKpT8/osGALgklRrZsTy8/M1bNgwPfHEE3r99dfVtm3bCmfE/qikpERXXnmlpk+friFDhlzQPvyGBQCAqmcYhrYfzdHqXSe0Zk+6ko/m6H+vTOp5uOmBXm10e7fmBDKUwfUaarNa8zfak08+qbi4OMXExFz0vgUFBSouLpavr28VtAwAAPxZJpNJ4cH19HDfUH1+f6w2P9ZHL98cqWFRTRTgZVH2qSLN/Pcu9Zvzo77eeVy15PfHAHBeteLWxJUrV2rXrl1aunTpn9p/9uzZCgoKOmeIs9lsstls9p+tVuufOhcAAPjz/L3q6O+RTfT3yCYqKTX0yeYjmv31Hh3IyNfd7yWqe0t/PTaonTo28VVJqaHM/EKl5RYqLe+0TheV6qqQQHnVqRWXNwAuczX+b6rU1FQ9/fTTWrBggerUqXPR+7/55ptKSEjQu+++e8794+PjNXfu3L/SVAAAUIlczCbd3KWZ/hbRWK//sFdvrT2gDfszNXjuOgV61VFmvk0lpY4zZI183fXUkI7q3Y5nwgHUbDX+GbHVq1dr/PjxcnH577K2JSUlMplMMpvN2r59u8O2//X222/r9ddf18KFCxUWFnbO85Q3IxYXF8c9xwAA1BApJ0/p+S9/0xfbjtnLzKYzs2hB3nV0Mv/Mi6klaVB4I/1zcAcFel/8L3FRe/CMGGqzGh/ErFarjh075lA2ZcoUtWzZUnfddZdCQkLK3e+tt97SG2+8obfffluRkZF/6rx8sQEAqHkOZOTLerpYQT5n3mfm6nLmkfcCW4nmfLtH89ceUEmpId+6bnpsUDvd2ClYJhMvj74Ucb2G2qzG35ro5eVVJmx5eHioXr169vJJkyapQYMGmjhxoqQztyO+8sorevHFF9WkSROlp6fb9/P09HRuBwAAQKW6IqD8/5fXtbhoyoB2GhzeWI8uS9bOY7matDRZS34+rH4dGiqmVYDaN/aRi5lQBqD61fggdiFSU1NlNv93AcglS5aoqKhIDz74oEO9+++/Xw888ICzmwcAAJyoYxNffT6+hxb8dEAvfbNHWw5na8vhbEmSb103dWvppx6tA3RdRGPV87BUb2MBXLZq/K2J1YWpbgAAar+j2QX6asdxrd+XoY37s2QtLLZvuyLAUyseiGWVxVqM6zXUZvzNAwAALllN6tXVHbFX6I7YK1RcUqrkozlavzdD7244pAMZ+Zr66Xa9fHMkz5ABcLpa80JnAACAv8LVxazoZvV1f682eu22aLmYTfpi2zF9vPlIdTcNwGWIIAYAAC47nVv4aWLfM4t+PfHFTu05kVfNLQJwuSGIAQCAy9I9V7VSzzYBOl1UqvGLt6jAVlLdTQJwGSGIAQCAy5LZbNK/bopUoHcd/Z5m1T+/2FndTQJwGSGIAQCAy1aAV53/LNYhfbT5iD7berS6mwTgMkEQAwAAl7WYVgF6oFcbSdJjy7dr88Gsam4RgMsBQQwAAFz2/tG7jbpe4ad8W4lueGODpny6XTmniqq7WQAuYQQxAABw2XMxm/TmyM4a3jlYkvThz4fV+6UftHxrigzDqObWAbgUEcQAAAAk+dZ10/M3ROiju7updZCXMqw2PfTRNt02f5P2pVuru3kALjEEMQAAgP/RtaW/Eh7sqf/rF6o6rmat35epvv/6UROWbNXu47nV3TwAlwiCGAAAwB9YXM0af01rff3QVerVNkglpYY+Szqm/nPWauyiX1jQA8Bf5lrdDQAAAKipmvt7asHoK7XjaI5eX7NPCdtT9e3uNH27O01Xtqivm65spriQQAV616nupgKoZQhiAAAA59Gxia/m3RqtAxn5evPHfVqWeFS/HDypXw6elCSFNfHV1aGBujo0UJFN68vFbKrmFgOo6UwGSwGVy2q1qlOnTkpMTJSXl1d1NwcAANQgJ3JP64NNh/Xd7jRtP5rjsM23rpt6tgnQNaFBigsNVIAXs2VVhes11GYEsQrwxQYAABciPa9Qa/ak64ff0rT29wzlFDi+fywi2FdxoUHq1TZIEcG+MpmYLassXK+hNiOIVYAvNgAAuFjFJaVKOpKtH35L1/e/pWnnMcdVFm/p0lSzhoYRxioJ12uozXhGDAAAoJK4upjVuYWfOrfw0yP9QpWWe1o//Ge27Msdx/Xhz0fkW9eiyQPaVndTAVQzlq8HAACoIkE+7hreualeu62TnhkWJkl6Y80+vfnjvmpuGYDqRhADAABwgpuubKZH+5+ZCZuVsFufbD5SzS0CUJ0IYgAAAE5yT1xL3dXzCknS5E+365tdJ6q5RQCqC8+IAQAAOInJZNLUge2UlV+kZVtSNP6DLVo4+kqFNPCWtbBYeaeLlHe6WHmnixXobVG7Rj7ysHC5BlyK+GYDAAA4kclk0nPXhymnwKbVv6bptvmbKqxrNkmtAr3UsYmvOjbxVXiwrzo1qy8zL4wGaj2CGAAAgJO5upg199Zo3ft+or7/LV2S5FXHVd7uZz6edVx19GSB0vIK9XuaVb+nWbV861FJUrtGPpo8oK2uahPAMvhALUYQAwAAqAbubi5aOKaL8guLVdfNpdxZrrTc09p5LFfbj+Zox9EcbdiXqV9TczVqwc/q0dpfk/u3U1iwbzW0HsBfVesW63jzzTcVGhqqp59++pz1Vq1apf79+yssLEyDBw/WmjVrnNRCAACAC+dZx7XCWw2DfNx1TdsgPdi7jd4c2Vk/TrpGY2OvkMXFrJ/2Zmrw3HV64MOt2nUsVwW2Eie3HMBfUatmxJKTk7VkyRKFhoaes96WLVs0ceJEPfzww7rmmmu0YsUKjR8/Xp9++qlCQkKc1FoAAIDKVd/Tosf/1l6jY1ropW/26LOko1qx7ZhWbDsmSfJxd1UDH3f7J6pZPfXv2FABXnUqPGaBrUQbD2SqXl03RTWr76yuAJc9k2EYRnU34kLk5+dr2LBheuKJJ/T666+rbdu2euyxx8qtO2HCBBUUFCg+Pt5eNnz4cLVt21ZPPvnkBZ3ParWqU6dOSkxMlJeXV6X0AQAAoDLtPJajF7/eow37MlVQVP6MmNkkdWvpr0HhjdS/Q0P5e9VRWt5pffdrmlb/ekLr9mbodFGpJOnmK5vqicEdVNfi4sxu/Glcr6E2qzUzYk8++aTi4uIUExOj119//Zx1k5KSNHr0aIey2NhYrV69usJ9bDabbDab/Wer1fqX2gsAAFDVOjT21YLRV8owDOUVFist97SO5xTqRO5pHTl5St/tTlNySo7W78vU+n2ZevyzHboiwFP70vMdjtPQx10n8k5ryS9HlHjopF69NUptG/pUU6+Ay0OtCGIrV67Url27tHTp0guqn5GRoYCAAIcyf39/ZWRkVLhPfHy85s6d+5faCQAAUB1MJpN83N3k4+6m1kHe9vIJfUJ0OPOUEnakamVyqrYfzbGHsIhgX/Vp10C92zVQu0be2rAvUxM+StLvaVb9fe5Pmva39hrRtRkrMwJVpMYHsdTUVD399NNasGCB6tSp+P7mv2rcuHEaM2aM/Wer1aq4uLgqOx8AAIAzNPP30D1xrXRPXCsdzjylXam5im5WT0E+7g71YloHaNU/euqRT7bp+9/S9fhnO/TT7xnq1TZIqTmndTy34Mw/c04r73SxgnzqqHG9umpSr64a+7qrcb26ahHgqZAG3hW0BMD/qvFBbOfOncrMzNSwYcPsZSUlJfrll1+0ePFibd++XS4ujvcxBwQElJn9yszMLDNL9r8sFossFkvlNh4AAKAGaebvoWb+HhVu9/eqowWjr9Tb6w7ouS9368udx/XlzuPl1j2aXaCth7PLlD81pKNGdGteWU0GLlk1Poh169ZNK1ascCibMmWKWrZsqbvuuqtMCJOkyMhIbdy40eE5sfXr1ysyMrKKWwsAAFC7mUwm3dmzpbpe4a85q/eoxDDUyNddDX3qnvmnr7u83F2VlntaR7NP61h2gf1jLSzWFQGe1d0FoFao8UHMy8urzJLzHh4eqlevnr180qRJatCggSZOnChJGjlypG6//XYtWLBAcXFxSkhI0I4dOy54xUQAAIDLXViwr94efWV1NwO4ZNW6FzqXJzU1Venp6fafo6OjNXv2bH300Uf6+9//rq+++krz5s3jHWIAAAAAaoRa8x4xZ+O9FAAAADUb12uozS6JGTEAAAAAqE0IYgAAAADgZDV+sY7qcvaOTavVWs0tAQAAQHnOXqfxpA1qI4JYBfLzz7x1npc6AwAA1Gz5+fny9uZF0qhdWKyjAqWlpUpLS5Onp6dMJlOVn89qtSouLk5r1qzhYdNaijGs/RjD2o3xq/0Yw9rP2WNoGIby8/MVFBQks5knblC7MCNWAbPZrIYNGzr9vF5eXvzPp5ZjDGs/xrB2Y/xqP8aw9nPmGDIThtqKXx0AAAAAgJMRxAAAAADAyQhiNYTFYtH9998vi8VS3U3Bn8QY1n6MYe3G+NV+jGHtxxgCF47FOgAAAADAyZgRAwAAAAAnI4gBAAAAgJMRxAAAAADAyQhiAAAAAOBkBDEAqEKLFy/Wp59+Wt3NqBRvvPGGVq9eXd3NAADgkkAQA4Aq9OGHH2r58uXV3YxKER8fTxADAKCSEMQAoJYpLCxUaWlpdTejRikuLpbNZqvuZgAAcMEIYgDwB19++aVCQ0P1888/l9m2ZMkShYaGas+ePUpPT9eUKVN01VVXqWPHjoqNjdW9996rlJQUSVKvXr30+++/6+eff1ZoaKhCQ0N1++23S5Kys7P13HPPafDgwYqKilJ0dLTuvPNO7d692+F8mzZtUmhoqFauXKl//etf6tmzpyIiImS1Wi+4P59//rmGDRum8PBwdenSRQ899JBSU1Md6hw8eFAPPPCAevToobCwMF111VV66KGHlJeXJ0kKDQ3VqVOntHz5cntfJk+efN5zFxUVqUuXLpoyZUqZbVarVWFhYXruueckSTabTS+//LKGDRumTp06KTIyUrfeeqs2btzosF9KSopCQ0P19ttva9GiRerTp4/CwsK0b9++C/4zAQCgurlWdwMAoKa5+uqr5eHhoVWrVqlLly4O2xISEtSmTRuFhITo5ptv1t69ezVixAg1adJEWVlZ+umnn5Samqrg4GBNnTpVM2fOlIeHh+655x5JUkBAgCTpyJEjWr16tfr376/g4GBlZGToo48+0ogRI7Ry5Uo1aNDA4byvvfaa3NzcNHbsWNlsNrm5uV1QX15//XW9/PLLGjBggG644QZlZWXp/fff12233abPPvtMPj4+stls9uOOGDFCAQEBOnHihH744Qfl5ubK29tbzz//vKZNm6bw8HANHz5cktSsWbPznt/NzU19+vTRN998oxkzZshisdi3rV69WjabTQMHDpR0Jph98skn+tvf/qYbb7xR+fn5Wrp0qe6880598sknateuncOxP/30UxUWFmr48OGyWCzy9fW9oD8TAABqBAMAUMbDDz9sdO/e3SguLraXpaWlGW3btjXmzp1r5OTkGCEhIcb8+fPPeZxBgwYZI0aMKFNeWFholJSUOJQdOXLE6NixozF37lx72caNG42QkBCjd+/eRkFBwUX1ISUlxWjXrp3x+uuvO5T/9ttvRvv27e3lu3btMkJCQoxVq1ad83iRkZHGo48+elFtMAzDWLt2rRESEmJ89913DuV33XWX0bt3b/vPxcXFRmFhoUOdnJwcIyYmxpgyZYq97MiRI0ZISIgRHR1tZGZmXnR7AACoCbg1EQDKMWDAAGVmZjrcnvjVV1+ptLRUAwcOlLu7u9zc3PTzzz8rJyfnoo9vsVhkNp/5K7ikpEQnT56Uh4eHrrjiCu3atatM/SFDhsjd3f2izvHNN9+otLRUAwYMUFZWlv0TEBCg5s2ba9OmTZIkLy8vSdK6detUUFBw0X05n27duql+/fpKSEiwl+Xk5Gj9+vX22TBJcnFxsc+YlZaWKjs7W8XFxerYsWO5fyZ9+/aVn59fpbcXAABn4NZEACjHVVddJW9vbyUkJKh79+6SztyW2K5dO11xxRWSpEceeUTPPfecevTooYiICF199dUaMmSIAgMDz3v80tJSvfvuu/rggw+UkpKikpIS+7Z69eqVqR8cHHzRfTh48KAMw1Dfvn3L3e7qeuZ/AU2bNtWYMWO0cOFCrVixQp07d1avXr103XXXydvb+6LPW955+vbtq3//+9+y2WyyWCz6+uuvVVRU5BDEJGn58uVasGCBDhw4oKKiInt5ef3/M38mAADUFAQxACiHxWKxP9v0xBNPKDMzU1u2bNHDDz9srzN69Gj16tVLq1ev1rp16/Tyyy/rzTff1DvvvKP27duf8/hvvPGGXn75ZV1//fX6xz/+IV9fX5nNZs2aNUuGYZSpf7GzYdKZsGcymfTWW2/JxcWlzHYPDw/7v0+ePFlDhw7Vt99+q59++klPPfWU4uPj9fHHH6thw4YXfe4/GjRokD766CP9+OOP6tOnj7788ku1bNlSbdu2tdf5/PPPNXnyZPXp00djx46Vv7+/XFxcFB8fryNHjpQ55p/5MwEAoKYgiAFABQYMGKDly5drw4YN2rdvnwzD0IABAxzqNGvWTHfccYfuuOMOHTx4UEOGDNGCBQs0e/ZsSZLJZCr32F999ZW6du2qWbNmOZTn5uaqfv36ldL+Zs2ayTAMBQcH22fxzuXsaoj33XeftmzZoltuuUUffvihHnroob/cliuvvFKBgYFKSEhQdHS0Nm7caF/A5KyvvvpKTZs21dy5cx3+3F555ZW/fH4AAGoanhEDgArExMSoXr16SkhI0KpVqxQeHq6mTZtKkgoKClRYWOhQv1mzZvL09HR4n1XdunWVm5tb5tguLi5lZr5WrVqlEydOVFr7+/btKxcXF82dO7fMuQzD0MmTJyWdWa2wuLjYYXtISIjMZrNDXzw8PMrty4Uwm83q37+/vv/+e33xxRcqLi4uc1vi2Vm7/23rtm3blJSU9KfOCQBATcaMGABUwM3NTddee61WrlypgoICPfroo/ZtBw8e1OjRo9W/f3+1bt1aLi4uWr16tTIyMjRo0CB7vQ4dOujDDz/Ua6+9pubNm8vPz0/du3fX1VdfrXnz5mnKlCmKiorSnj17tGLFCnvQqwzNmjXThAkT9OKLL+ro0aPq06ePPD09lZKSotWrV2v48OEaO3asNm7cqCeffFL9+/dXixYtVFJSos8//1wuLi7q16+fQ182bNighQsXKigoSMHBwYqIiLjg9gwYMEDvvfeeXnnlFYWEhKhVq1YO26+++mp9/fXXGj9+vK6++mqlpKRoyZIlat26tU6dOlVpfy4AANQEBDEAOIeBAwfqk08+kclkcrgtsWHDhho0aJA2bNigL774Qi4uLmrZsqXmzJnjEF7Gjx+vY8eOaf78+crPz1eXLl3UvXt33XPPPSooKNCKFSuUkJCg9u3bKz4+Xi+++GKltv/uu+9WixYttGjRIs2bN8/e9h49eqhXr16SztySGBsbq++//14nTpxQ3bp1FRoaqrfeekuRkZH2Y02ePFnTp0/XnDlzdPr0aQ0dOvSiglh0dLQaNWqk1NTUMrNhkjRs2DD7+9TWrVun1q1b64UXXtCXX35Z7su1AQCozUxGeU+FAwAAAACqDM+IAQAAAICTcWsiANRC6enp59zu7u5eKe8AO5eSkhJlZWWds46Hh4c8PT2rtB0AANRG3JoIALVQaGjoObcPHTpUzz77bJW2ISUlRb179z5nnfvvv18PPPBAlbYDAIDaiCAGALXQ+vXrz7k9KChIrVu3rtI2FBYWKjEx8Zx1mjZtWqkrQQIAcKkgiAEAAACAk7FYBwAAAAA4GYt1VKC0tFRpaWny9PSUyWSq7uYAAADgDwzDUH5+voKCgmQ2M7+A2oUgVoG0tDTFxcVVdzMAAABwHmvWrFHDhg2ruxnARSGIVeDscstr1qyRl5dXNbcGAAAAf2S1WhUXF8drMlArEcQqcPZ2RC8vL4IYAABADcZjJKiNnHIz7eLFi9WrVy+FhYXpxhtvVHJy8jnrr1q1Sv3791dYWJgGDx6sNWvWOGyfPHmyQkNDHT5jx451qJOdna2JEycqOjpanTt31tSpU5Wfn1/pfQMAAACAi1XlQSwhIUHPPPOMxo8fr+XLl6tt27YaO3asMjMzy62/ZcsWTZw4UTfccIM+++wz9e7dW+PHj9eePXsc6vXs2VPr1q2zf1566SWH7Y888oj27t2rhQsX6o033tDmzZs1ffr0KusnAAAAAFyoKg9iCxcu1PDhw3X99derdevWmjFjhtzd3bVs2bJy67/77rvq2bOn7rzzTrVq1UoTJkxQ+/bt9f777zvUs1gsCgwMtH98fX3t2/bt26e1a9fqqaeeUkREhDp37qxp06Zp5cqVOnHiRJX2FwAAAADOp0qDmM1m086dOxUTE/PfE5rNiomJ0datW8vdJykpSd27d3coi42NVVJSkkPZzz//rO7du6tfv3564okndPLkSfu2rVu3ysfHR2FhYfaymJgYmc3mCm+LtNlsslqtDh8AAAAAqApVuljHyZMnVVJSIn9/f4dyf39/7d+/v9x9MjIyFBAQUKZ+RkaG/eeePXvq2muvVXBwsI4cOaKXXnpJd911lz766CO5uLgoIyNDfn5+DsdwdXWVr6+v0tPTyz1vfHy85s6d+2e6CQAAAAAXpVaumjho0CD7v59drKNPnz72WbI/Y9y4cRozZoz957PLoQIAAABAZavSWxPr168vFxeXMgtzZGZmlpn1OisgIMBh9ut89SWpadOmql+/vg4dOmQ/RlZWlkOd4uJi5eTkKDAwsNxjWCwW+1L1LFkPAAAAoCpVaRCzWCzq0KGDNmzYYC8rLS3Vhg0bFBUVVe4+kZGR2rhxo0PZ+vXrFRkZWeF5jh8/ruzsbHvIioqKUm5urnbs2GGvs3HjRpWWlio8PPwv9AgAAAAA/roqXzVxzJgx+vjjj7V8+XLt27dP//znP1VQUKBhw4ZJkiZNmqQXX3zRXn/kyJFau3atFixYoH379unVV1/Vjh07NGLECElSfn6+nnvuOSUlJSklJUUbNmzQfffdp+bNm6tnz56SpFatWqlnz556/PHHlZycrMTERM2cOVODBg1SgwYNqrrLAAAAAHBOVf6M2MCBA5WVlaVXXnlF6enpateunebPn2+/1TA1NVVm83/zYHR0tGbPnq05c+bopZdeUosWLTRv3jyFhIRIklxcXLRnzx599tlnysvLU1BQkHr06KF//OMfslgs9uPMnj1bM2fO1KhRo2Q2m9W3b19NmzatqrsLAAAAAOdlMgzDqO5G1ERWq1WdOnVSYmIiz4sBAADUQFyvoTar8lsTAQAAAACOCGIAAAAA4GQEMQAAAABwMoIYAAAAADgZQQwAAAAAnIwgBgAAAABORhADAAAAACcjiAEAAACAkxHEAAAAAMDJCGIAAAAA4GQEMQAAAABwMoIYAAAAADgZQQwAAAAAnIwgBgAAAABORhADAAAAACcjiAEAAACAkxHEAAAAAMDJCGIAAAAA4GQEMQAAAABwMoIYAAAAADgZQQwAAAAAnIwgBgAAAABORhADAAAAACcjiAEAAACAkxHEAAAAAMDJnBLEFi9erF69eiksLEw33nijkpOTz1l/1apV6t+/v8LCwjR48GCtWbPGvq2oqEgvvPCCBg8erMjISMXGxmrSpEk6ceKEwzF69eql0NBQh8+bb75ZJf0DAAAAgItR5UEsISFBzzzzjMaPH6/ly5erbdu2Gjt2rDIzM8utv2XLFk2cOFE33HCDPvvsM/Xu3Vvjx4/Xnj17JEmnT5/Wrl27dO+99+rTTz/V3LlzdeDAAd17771ljvXggw9q3bp19s+IESOqtK8AAAAAcCGqPIgtXLhQw4cP1/XXX6/WrVtrxowZcnd317Jly8qt/+6776pnz56688471apVK02YMEHt27fX+++/L0ny9vbWwoULNXDgQLVs2VKRkZF6/PHHtXPnTh07dszhWJ6engoMDLR/PDw8qrq7AAAAAHBeVRrEbDabdu7cqZiYmP+e0GxWTEyMtm7dWu4+SUlJ6t69u0NZbGyskpKSKjyP1WqVyWSSj4+PQ/lbb72lrl27asiQIZo/f76Ki4vP2Var1erwAQAAAICq4FqVBz958qRKSkrk7+/vUO7v76/9+/eXu09GRoYCAgLK1M/IyCi3fmFhoWbPnq1BgwbJy8vLXn777berffv28vX11datW/XSSy8pPT1dU6ZMKfc48fHxmjt37sV0DwAAAAD+lCoNYlWtqKhI//jHP2QYhmbMmOGwbcyYMfZ/b9u2rdzc3PTEE09o4sSJslgsZY41btw4h32sVqvi4uKqrvEAAAAALltVGsTq168vFxeXMgtzZGZmlpn1OisgIKDM7Fd59YuKijRhwgQdO3ZM77zzjsNsWHkiIiJUXFyslJQUtWzZssx2i8VSbkADAAAAgMpWpc+IWSwWdejQQRs2bLCXlZaWasOGDYqKiip3n8jISG3cuNGhbP369YqMjLT/fDaEHTp0SIsWLVL9+vXP25Zff/1VZrO5zG2SAAAAAOBsVX5r4pgxY/Too4+qY8eOCg8P1zvvvKOCggINGzZMkjRp0iQ1aNBAEydOlCSNHDlSt99+uxYsWKC4uDglJCRox44devLJJyWdCWEPPvigdu3apfj4eJWUlCg9PV2S5OvrK4vFoq1bt2rbtm3q1q2bPD09tXXrVj3zzDO67rrr5OvrW9VdBgAAAIBzqvIgNnDgQGVlZemVV15Renq62rVrp/nz59tvNUxNTZXZ/N+JuejoaM2ePVtz5szRSy+9pBYtWmjevHkKCQmRJJ04cULfffedJOnvf/+7w7neffddde3aVRaLRQkJCZo7d65sNpuCg4M1evRoh2fAAAAAAKC6mAzDMKq7ETWR1WpVp06dlJiYeN7nzwAAAOB8XK+hNqvyFzoDAAAAABwRxAAAAADAyQhiAAAAAOBkBDEAAAAAcDKCGAAAAAA4GUEMAAAAAJyMIAYAAAAATkYQAwAAAAAnI4gBAAAAgJMRxAAAAADAyQhiAAAAAOBkBDEAAAAAcDKCGAAAAAA4GUEMAAAAAJyMIAYAAAAATkYQAwAAAAAnI4gBAAAAgJMRxAAAAADAyQhiAAAAAOBkBDEAAAAAcDKCGAAAAAA4GUEMAAAAAJyMIAYAAAAATkYQAwAAAAAnI4gBAAAAgJM5JYgtXrxYvXr1UlhYmG688UYlJyefs/6qVavUv39/hYWFafDgwVqzZo3DdsMw9PLLLys2Nlbh4eEaPXq0Dh486FAnOztbEydOVHR0tDp37qypU6cqPz+/srsGAAAAABetyoNYQkKCnnnmGY0fP17Lly9X27ZtNXbsWGVmZpZbf8uWLZo4caJuuOEGffbZZ+rdu7fGjx+vPXv22Ou89dZbeu+99/TPf/5TH3/8serWrauxY8eqsLDQXueRRx7R3r17tXDhQr3xxhvavHmzpk+fXtXdBQAAAIDzqvIgtnDhQg0fPlzXX3+9WrdurRkzZsjd3V3Lli0rt/67776rnj176s4771SrVq00YcIEtW/fXu+//76kM7Nh7777ru6991716dNHbdu21fPPP6+0tDStXr1akrRv3z6tXbtWTz31lCIiItS5c2dNmzZNK1eu1IkTJ6q6ywAAAABwTlUaxGw2m3bu3KmYmJj/ntBsVkxMjLZu3VruPklJSerevbtDWWxsrJKSkiRJKSkpSk9Pdzimt7e3IiIi7MfcunWrfHx8FBYWZq8TExMjs9l83tsiAQAAAKCquVblwU+ePKmSkhL5+/s7lPv7+2v//v3l7pORkaGAgIAy9TMyMiRJ6enp9rKK6mRkZMjPz89hu6urq3x9fe37/5HNZpPNZrP/bLVaz9c9AAAAAPhTqjSI1Sbx8fGaO3dudTcDAAAAwGWgSoNY/fr15eLiUmZhjszMzDKzXmcFBATYZ7bKqx8YGGgvCwoKcqjTtm1b+zGysrIcjlFcXKycnBz7/n80btw4jRkzxv6z1WpVXFzchXQTAAAAAC5KlT4jZrFY1KFDB23YsMFeVlpaqg0bNigqKqrcfSIjI7Vx40aHsvXr1ysyMlKSFBwcrMDAQIdjWq1Wbdu2zX7MqKgo5ebmaseOHfY6GzduVGlpqcLDwytsq5eXl8MHAAAAAKpCla+aOGbMGH388cdavny59u3bp3/+858qKCjQsGHDJEmTJk3Siy++aK8/cuRIrV27VgsWLNC+ffv06quvaseOHRoxYoQkyWQyaeTIkXr99df17bff6rffftOkSZMUFBSkPn36SJJatWqlnj176vHHH1dycrISExM1c+ZMDRo0SA0aNKjqLgMAAADAOVX5M2IDBw5UVlaWXnnlFaWnp6tdu3aaP3++/VbD1NRUmc3/zYPR0dGaPXu25syZo5deekktWrTQvHnzFBISYq9z1113qaCgQNOnT1dubq46deqk+fPnq06dOvY6s2fP1syZMzVq1CiZzWb17dtX06ZNq+ruAgAAAMB5mQzDMKq7ETWR1WpVp06dlJiYyG2KAAAANRDXa6jNqvzWRAAAAACAI4IYAAAAADgZQQwAAAAAnIwgBgAAAABORhADAAAAACcjiAEAAACAkxHEAAAAAMDJCGIAAAAA4GQEMQAAAABwMoIYAAAAADgZQQwAAAAAnIwgBgAAAABORhADAAAAACcjiAEAAACAkxHEAAAAAMDJCGIAAAAA4GQEMQAAAABwMoIYAAAAADgZQQwAAAAAnIwgBgAAAABORhADAAAAACcjiAEAAACAkxHEAAAAAMDJCGIAAAAA4GQEMQAAAABwsioLYtnZ2Zo4caKio6PVuXNnTZ06Vfn5+efcp7CwUDNmzFDXrl0VFRWlBx54QBkZGfbtu3fv1sMPP6y4uDiFh4drwIABeueddxyOsWnTJoWGhpb5pKenV0k/AQAAAOBiuVbVgR955BGlp6dr4cKFKioq0tSpUzV9+nS9+OKLFe4za9YsrVmzRnPmzJG3t7dmzpyp+++/X0uWLJEk7dixQ35+fnrhhRfUqFEjbdmyRdOnT5eLi4tGjBjhcKwvv/xSXl5e9p/9/f2rpqMAAAAAcJGqJIjt27dPa9eu1dKlSxUWFiZJmjZtmu6++25NmjRJDRo0KLNPXl6eli1bptmzZ6t79+6SzgSzgQMHKikpSZGRkbrhhhsc9mnatKmSkpL09ddflwli/v7+8vHxqYruAQAAAMBfUiW3Jm7dulU+Pj72ECZJMTExMpvNSk5OLnefHTt2qKioSDExMfayVq1aqXHjxkpKSqrwXHl5eapXr16Z8iFDhig2NlZjxoxRYmLin+4LAAAAAFS2KpkRy8jIkJ+fn+OJXF3l6+tb4bNaGRkZcnNzKzOL5e/vX+E+W7Zs0apVqxQfH28vCwwM1IwZM9SxY0fZbDZ98sknGjlypD7++GN16NChwjbbbDbZbDb7z1ar9bz9BAAAAIA/46KC2OzZs/XWW2+ds05CQsJfatCF2rNnj+677z6NHz9esbGx9vKWLVuqZcuW9p+jo6N15MgRLVq0SC+88EKFx4uPj9fcuXOrtM0AAAAAIF1kELvjjjs0dOjQc9Zp2rSpAgIClJWV5VBeXFysnJwcBQYGlrtfQECAioqKlJub6zArlpmZWWafvXv3avTo0brpppt03333nbfdYWFh2rJlyznrjBs3TmPGjLH/bLVaFRcXd95jAwAAAMDFuqgg5ufnV+aWw/JERUUpNzdXO3bsUMeOHSVJGzduVGlpqcLDw8vdp2PHjnJzc9OGDRvUr18/SdL+/ft17NgxRUZG2uv9/vvvGjVqlIYMGaKHHnrogtq9e/fuCgPgWRaLRRaL5YKOBwAAAAB/RZU8I9aqVSv17NlTjz/+uGbMmKGioiLNnDlTgwYNsq+YeOLECY0aNUrPP/+8wsPD5e3treuvv17PPvusfH195eXlpaeeekpRUVH2ILZnzx6NGjXKvgjH2WfHXFxc7AFx0aJFCg4OVps2bVRYWKhPPvlEGzdu1IIFC6qiqwAAAABw0arsPWKzZ8/WzJkzNWrUKJnNZvXt21fTpk2zby8qKtKBAwdUUFBgL5s6darMZrMefPBB2Ww2xcbG6oknnrBv/+qrr5SVlaUvvvhCX3zxhb28SZMm+u677+zHfe6553TixAnVrVtXISEhWrhwobp161ZVXQUAAACAi2IyDMOo7kbURFarVZ06dVJiYqLDi6EBAABQM3C9htqsSt4jBgAAAACoGEEMAAAAAJyMIAYAAAAATkYQAwAAAAAnI4gBAAAAgJMRxAAAAADAyQhiAAAAAOBkBDEAAAAAcDKCGAAAAAA4GUEMAAAAAJyMIAYAAAAATkYQAwAAAAAnI4gBAAAAgJMRxAAAAADAyQhiAAAAAOBkBDEAAAAAcDKCGAAAAAA4GUEMAAAAAJyMIAYAAAAATkYQAwAAAAAnI4gBAAAAgJMRxAAAAADAyQhiAAAAAOBkBDEAAAAAcDKCGAAAAAA4GUEMAAAAAJysyoJYdna2Jk6cqOjoaHXu3FlTp05Vfn7+OfcpLCzUjBkz1LVrV0VFRemBBx5QRkaGQ53Q0NAyn5UrVzrU2bRpk4YOHaqOHTvq2muv1aefflrp/QMAAACAP6vKgtgjjzyivXv3auHChXrjjTe0efNmTZ8+/Zz7zJo1S99//73mzJmj9957T2lpabr//vvL1HvmmWe0bt06+6dPnz72bUeOHNG4cePUtWtXff755xo1apSmTZumtWvXVnofAQAAAODPcK2Kg+7bt09r167V0qVLFRYWJkmaNm2a7r77bk2aNEkNGjQos09eXp6WLVum2bNnq3v37pLOBLOBAwcqKSlJkZGR9ro+Pj4KDAws99xLlixRcHCwJk+eLElq1aqVEhMTtWjRIvXs2bOSewoAAAAAF69KZsS2bt0qHx8fewiTpJiYGJnNZiUnJ5e7z44dO1RUVKSYmBh7WatWrdS4cWMlJSU51D17++INN9ygpUuXyjAM+7akpCR7kDsrNja2zDH+yGazyWq1OnwAAAAAoCpUyYxYRkaG/Pz8HE/k6ipfX1+lp6dXuI+bm5t8fHwcyv39/R32efDBB9WtWzfVrVtX69at04wZM3Tq1CmNHDnSfpyAgACHYwQEBMhqter06dNyd3cv9/zx8fGaO3fuRfcVAAAAAC7WRQWx2bNn66233jpnnYSEhL/UoPMZP368/d/bt2+vgoICvf322/Yg9meNGzdOY8aMsf9stVoVFxf3l44JAAAAAOW5qCB2xx13aOjQoees07RpUwUEBCgrK8uhvLi4WDk5ORU+2xUQEKCioiLl5uY6zIplZmZWuI8kRURE6LXXXpPNZpPFYlFAQECZlRYzMjLk5eVV4WyYJFksFlkslnP2DQAAAAAqw0UFMT8/vzK3HJYnKipKubm52rFjhzp27ChJ2rhxo0pLSxUeHl7uPh07dpSbm5s2bNigfv36SZL279+vY8eOOSzU8Ue//vqrfH197SEqMjJSP/74o0Od9evXn/MYAAAAAOBMVbJYR6tWrdSzZ089/vjjSk5OVmJiombOnKlBgwbZV0w8ceKE+vfvb1+8w9vbW9dff72effZZbdy4UTt27NDUqVMVFRVlD1HfffedPvnkE+3Zs0eHDh3SBx98oPj4eI0YMcJ+7ptvvllHjhzR888/r3379mnx4sVatWqVRo8eXRVdBQAAAICLViWLdUhnniebOXOmRo0aJbPZrL59+2ratGn27UVFRTpw4IAKCgrsZVOnTpXZbNaDDz4om82m2NhYPfHEE/9trKurFi9erFmzZkmSmjVrpsmTJ2v48OH2Ok2bNlV8fLyeeeYZvfvuu2rYsKGeeuoplq4HAAAAUGOYjP9d+x12eXl56ty5s9asWSMvL6/qbg4AAAD+4Oziaps3b5a3t3d1Nwe4KFU2I1bb5efnSxIrJwIAANRw+fn5BDHUOsyIVaC0tFRpaWny9PSUyWSq8vOd/Y0OM3C1F2NY+zGGtRvjV/sxhrWfs8fQMAzl5+crKChIZnOVLH0AVBlmxCpgNpvVsGFDp5/Xy8uL//nUcoxh7ccY1m6MX+3HGNZ+zhxDZsJQW/GrAwAAAABwMoIYAAAAADgZQayGsFgsuv/+++0vpkbtwxjWfoxh7cb41X6MYe3HGAIXjsU6AAAAAMDJmBEDAAAAACcjiAEAAACAkxHEAAAAAMDJCGIAAAAA4GQEsSry5ptvKjQ0VE8//bS9rLCwUDNmzFDXrl0VFRWlBx54QBkZGQ77HTt2THfffbciIiLUvXt3PffccyouLnaos2nTJg0dOlQdO3bUtddeq08//dQpfbrc/HEMs7OzNXPmTPXr10/h4eG6+uqr9dRTTykvL89hP8aw5ijve3iWYRi68847FRoaqtWrVztsYwxrjorGcOvWrRo5cqQiIyMVHR2t2267TadPn7Zvz87O1sSJExUdHa3OnTtr6tSpys/PdzjG7t27deuttyosLExxcXF66623nNKny0l545eenq7/+7//U48ePRQZGamhQ4fqq6++ctiP8ater776qkJDQx0+/fv3t2/negaoHASxKpCcnKwlS5YoNDTUoXzWrFn6/vvvNWfOHL333ntKS0vT/fffb99eUlKicePGqaioSEuWLNGzzz6r5cuX65VXXrHXOXLkiMaNG6euXbvq888/16hRozRt2jStXbvWaf27HJQ3hmlpaUpLS9Ojjz6qf//733rmmWe0du1aPfbYY/Y6jGHNUdH38Kx33nlHJpOpTDljWHNUNIZbt27VnXfeqdjYWH3yySdaunSpbrvtNpnN//1f2iOPPKK9e/dq4cKFeuONN7R582ZNnz7dvt1qtWrs2LFq3LixPv30U02aNElz587VRx995LT+XeoqGr9HH31UBw4c0Ouvv64VK1bo2muv1YQJE7Rr1y57Hcav+rVp00br1q2zfz744AP7Nq5ngEpioFJZrVajb9++xk8//WSMGDHCeOqppwzDMIzc3FyjQ4cOxqpVq+x19+7da4SEhBhbt241DMMwfvjhB6Nt27ZGenq6vc4HH3xgREdHG4WFhYZhGMbzzz9vDBo0yOGcEyZMMO64444q7tnlo6IxLE9CQoLRoUMHo6ioyDAMxrCmON8Y7tq1y+jZs6eRlpZmhISEGN988419G2NYM5xrDG+88UbjX//6V4X7nv27NTk52V62Zs0aIzQ01Dh+/LhhGIaxePFi48orr7SPqWEYxgsvvGD069ev8jtzGTrX+EVGRhrLly93qN+lSxfj448/NgyD8asJXnnlFeO6664rdxvXM0DlYUaskj355JOKi4tTTEyMQ/mOHTtUVFTkUN6qVSs1btxYSUlJkqSkpCSFhIQoICDAXic2NlZWq1V79+611+nevbvDsWNjY+3HwF9X0RiWx2q1ysvLS66urpIYw5riXGNYUFCgiRMnavr06QoMDCyznTGsGSoaw8zMTG3btk3+/v66+eabFRMToxEjRmjz5s32Olu3bpWPj4/CwsLsZTExMTKbzUpOTpZ0Zgw7d+7s8NLZ2NhYHThwQDk5OVXcu0vfub6DUVFRWrVqlbKzs1VaWqqVK1eqsLBQXbp0kcT41RSHDh1SbGysevfurYkTJ+rYsWOSuJ4BKpNrdTfgUrJy5Urt2rVLS5cuLbMtIyNDbm5u8vHxcSj39/dXenq6vc7//qUlyf7z+epYrVadPn1a7u7uldafy9G5xvCPsrKy9Nprr+mmm26ylzGG1e98Y/jMM88oKipKffr0KXc7Y1j9zjWGR44ckSTNnTtXkyZNUrt27fTZZ59p9OjR+ve//60WLVooIyNDfn5+Dvu5urrK19fXYQyDg4Md6pwd04yMDPn6+lZF1y4L5/sOzpkzRw899JC6du0qV1dXubu7a+7cuWrevLkkMX41QHh4uJ555hldccUVSk9P17x583TbbbdpxYoVXM8AlYggVklSU1P19NNPa8GCBapTp051Nwd/wsWModVq1bhx49SqVSuH++JRvc43ht9++602btyo5cuXV0PrcCHON4alpaWSpJtuuknXX3+9JKl9+/basGGDli1bpokTJzq1vXB0IX+Pvvzyy8rNzdWiRYtUv359rV69WhMmTNDixYsrfKYTzhUXF2f/97Zt2yoiIkLXXHONVq1aRUACKhFBrJLs3LlTmZmZGjZsmL2spKREv/zyixYvXqy3335bRUVFys3NdfgtUmZmpv32qICAAPttF2edXYXof+v8cWWijIwMeXl58ZfjX3S+Mdy+fbtcXFxktVp15513ytPTU/PmzZObm5u9PmNYvc43hrfccosOHz6sK6+80mG/Bx54QJ07d9Z7773HGFaz843hl19+KenMrVD/q1WrVvZbpwICApSVleWwvbi4WDk5Oecdw7Pb8OdcyPi9//77+ve//602bdpIOnOhv3nzZi1evFhPPvkk41cD+fj4qEWLFjp8+LBiYmK4ngEqCUGsknTr1k0rVqxwKJsyZYpatmypu+66S40aNZKbm5s2bNigfv36SZL279+vY8eOKTIyUpIUGRmpN954Q5mZmfL395ckrV+/Xl5eXmrdurW9zo8//uhwnvXr19uPgT/vfGN4NoSNHTtWFotFr7/+epnf+DKG1et8Y1i/fn2HW0klafDgwZoyZYquueYaSYxhdTvfGDZt2lRBQUE6cOCAQ52DBw/qqquuknTmGaTc3Fzt2LFDHTt2lCRt3LhRpaWlCg8Pl3RmDOfMmaOioiL7L1PWr1+vK664gtva/oLzjV9BQYEkOaxwKUkuLi4yDEMS41cT5efn68iRIwoMDFTHjh25ngEqS3WvFnIp++NKUdOnTzeuvvpqY8OGDcb27duNm266ybjpppvs24uLi42//e1vxh133GH8+uuvxo8//mh069bNePHFF+11Dh8+bERERBjPPfecsXfvXuP999832rVrZ/z4449O7dvl4n/HMC8vz7jxxhuNv/3tb8ahQ4eMtLQ0+6e4uNgwDMawJjrfypd/XDWRMax5/jiGCxcuNKKjo41Vq1YZBw8eNP71r38ZYWFhxqFDh+x1xo4dawwZMsTYtm2bsXnzZqNv377Gww8/bN+em5trxMTEGP/3f/9n7Nmzx1i5cqURERFhLFmyxKl9uxz87/jZbDbj2muvNW699VZj27ZtxqFDh4y3337bCA0NNX744Qf7Poxf9Xr22WeNTZs2GUeOHDESExON0aNHG127djUyMzMNw+B6BqgsBLEq9MeLh9OnTxv//Oc/jSuvvNKIiIgwxo8fb6SlpTnsk5KSYtx5551GeHi40bVrV+PZZ5+1L41+1saNG42///3vRocOHYzevXsby5Ytc0p/Lkf/O4YbN240QkJCyv0cOXLEvg9jWLNcbBAzDMawpilvDOPj442rrrrKiIiIMG666Sbjl19+cdh+8uRJ4+GHHzYiIyON6OhoY/LkyYbVanWo8+uvvxq33HKL0bFjR6Nnz55GfHx8lfflcvTH8Ttw4IBx//33G927dzciIiKMwYMHl1nOnvGrXhMmTDB69OhhdOjQwejZs6cxYcIEh190cD0DVA6TYfznXgAAAAAAgFPwHjEAAAAAcDKCGAAAAAA4GUEMAAAAAJyMIAYAAAAATkYQAwAAAAAnI4gBAAAAgJMRxAD8f/t1LAAAAAAwyN96FrvKIgAAZiIGAAAwEzEAAICZiAEAAMxEDAAAYCZiAAAAswCIkJ27L7nFzQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 800x1200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, axes = fig, axes = plt.subplots(\n",
    "        nrows=5, ncols=1, sharex=True, sharey=False, figsize=(8,12))\n",
    "# axes = [axes]\n",
    "\n",
    "x_ary = np.linspace(4000, num_steps_train-1, num=100, dtype=np.int32)\n",
    "# est_name_ary = [\"weightedms\"]\n",
    "est_name_ary_unwanted = []\n",
    "est_name_ary_wanted = [est_name for est_name in est_name_ary[:8] \\\n",
    "                 if est_name not in est_name_ary_unwanted]\n",
    "for est_name in est_name_ary_wanted:\n",
    "    # axes[0].plot(x_ary, episode_rewards_dict[est_name][x_ary], label=est_name)\n",
    "    y_ary = running_avg(episode_rewards_dict[est_name][x_ary], 100)\n",
    "    axes[0].plot(\n",
    "        x_ary, y_ary, label=est_name)\n",
    "    axes[1].plot(x_ary, episode_vstar_est_dict[est_name][x_ary], label=est_name)\n",
    "    axes[2].plot(x_ary, episode_vstar_est_mse_dict[est_name][x_ary], label=est_name)\n",
    "    axes[3].plot(x_ary, episode_vstar_est_bias_dict[est_name][x_ary], label=est_name)\n",
    "    axes[4].plot(x_ary, episode_vstar_est_var_dict[est_name][x_ary], label=est_name)\n",
    "\n",
    "axes[0].axhline(y=optimal_reward_per_step, color=\"black\")\n",
    "axes[1].axhline(y=optimal_vstar, color=\"black\")\n",
    "axes[0].set_title(f\"reward_per_step, K={num_actions}, num_depths={num_depths}, sigma={action_sigma},\"\n",
    "                    f\" delta={gap_deltas[0]}\")\n",
    "axes[1].set_title(\"vstar_est\")\n",
    "axes[2].set_title(\"vstar_est_mse\")\n",
    "axes[3].set_title(\"vstar_est_bias\")\n",
    "axes[4].set_title(\"vstar_est_var\")\n",
    "# axes[0].legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "axes[1].legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "# axes[2].legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "262b601f-0e05-4e14-bf6e-b8b8d348a72a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x1200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, axes = fig, axes = plt.subplots(\n",
    "        nrows=5, ncols=1, sharex=True, sharey=False, figsize=(8,12))\n",
    "# axes = [axes]\n",
    "\n",
    "x_ary = np.linspace(4000, num_steps_train-1, num=100, dtype=np.int32)\n",
    "# est_name_ary = [\"weightedms\"]\n",
    "est_name_ary_unwanted = [\"weightedms\", \"weightedms2\"]\n",
    "est_name_ary_wanted = [est_name for est_name in est_name_ary[:8] \\\n",
    "                 if est_name not in est_name_ary_unwanted]\n",
    "for est_name in est_name_ary_wanted:\n",
    "    # axes[0].plot(x_ary, episode_rewards_dict[est_name][x_ary], label=est_name)\n",
    "    y_ary = running_avg(episode_rewards_dict[est_name][x_ary], 100)\n",
    "    axes[0].plot(\n",
    "        x_ary, y_ary, label=est_name)\n",
    "    axes[1].plot(x_ary, episode_vstar_est_dict[est_name][x_ary], label=est_name)\n",
    "    axes[2].plot(x_ary, episode_vstar_est_mse_dict[est_name][x_ary], label=est_name)\n",
    "    axes[3].plot(x_ary, episode_vstar_est_bias_dict[est_name][x_ary], label=est_name)\n",
    "    axes[4].plot(x_ary, episode_vstar_est_var_dict[est_name][x_ary], label=est_name)\n",
    "\n",
    "axes[0].axhline(y=optimal_reward_per_step, color=\"black\")\n",
    "axes[1].axhline(y=optimal_vstar, color=\"black\")\n",
    "axes[0].set_title(f\"reward_per_step, K={num_actions}, num_depths={num_depths}, sigma={action_sigma},\"\n",
    "                    f\" delta={gap_deltas[0]}\")\n",
    "axes[1].set_title(\"vstar_est\")\n",
    "axes[2].set_title(\"vstar_est_mse\")\n",
    "axes[3].set_title(\"vstar_est_bias\")\n",
    "axes[4].set_title(\"vstar_est_var\")\n",
    "# axes[0].legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "axes[1].legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "# axes[2].legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27c3344b-55df-4701-b41a-01ef27b88cd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> est_name = haver3_1.0\n",
      "0 0: [ -4.4   -4.39  -5.19  -4.44  -4.43  -4.76  -4.87  -4.56 -15.94  -9.12\n",
      " -11.98 -12.12 -13.01  -8.42 -14.54 -18.42], \n",
      "     [ 38. 469.   6. 193. 313.  56.  32. 105.   5.   5.   4.   4.   2.  10.\n",
      "   4.   4.]\n",
      "0 1: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 2: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 3: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 4: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 5: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 6: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 7: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 8: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 9: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 10: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 11: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 12: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 13: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 14: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0 15: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1 0: [-11.36 -13.05  -4.47  -9.62 -10.15 -16.29 -11.29 -10.56   0.     0.\n",
      "   0.     0.     0.     0.     0.     0.  ], \n",
      "     [ 3.  3. 10.  4.  8.  2.  5.  3.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "1 1: [-10.68  -8.06 -10.33  -8.32 -13.32  -7.95  -8.41  -7.94   0.     0.\n",
      "   0.     0.     0.     0.     0.     0.  ], \n",
      "     [ 10.  89.   9.  11.   4. 288.  23.  35.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "1 2: [-16.17   8.31   0.   -10.05   0.    -4.15 -21.01  -5.51   0.     0.\n",
      "   0.     0.     0.     0.     0.     0.  ], \n",
      "     [1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1 3: [ -9.54  -9.22 -10.94  -7.66  -8.94  -9.65  -7.92  -8.05   0.     0.\n",
      "   0.     0.     0.     0.     0.     0.  ], \n",
      "     [ 4.  2.  2. 43. 12.  4. 99. 27.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "1 4: [ -8.15  -8.15 -10.39  -9.9  -15.49 -12.4   -8.15  -8.39   0.     0.\n",
      "   0.     0.     0.     0.     0.     0.  ], \n",
      "     [198.   5.   8.   5.   4.   6.  42.  45.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "1 5: [-12.18  -7.17 -12.04 -18.3  -46.58  -8.58 -10.97 -12.89   0.     0.\n",
      "   0.     0.     0.     0.     0.     0.  ], \n",
      "     [ 1. 32.  1.  2.  1. 10.  6.  3.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "1 6: [ -7.35  -7.07 -10.9   -9.74 -13.12 -13.52 -10.89 -21.94   0.     0.\n",
      "   0.     0.     0.     0.     0.     0.  ], \n",
      "     [ 2. 16.  3.  2.  3.  2.  2.  2.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "1 7: [ -7.42  -8.65 -15.45  -7.73  -8.39  -9.21  -8.7   -9.4    0.     0.\n",
      "   0.     0.     0.     0.     0.     0.  ], \n",
      "     [62.  2.  3. 11.  5.  5. 14.  3.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "1 8: [  0.     0.     0.     0.     0.     0.     0.     0.     0.   -15.32\n",
      "   0.     0.   -19.67   0.    -8.11  -5.55], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 1.]\n",
      "1 9: [  0.     0.     0.     0.     0.     0.     0.     0.     0.   -25.4\n",
      " -15.79   0.     7.76  -5.16  -6.34   0.  ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0.]\n",
      "1 10: [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  -3.82   0.     1.49   0.     0.   -19.13], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 2. 0. 0. 1.]\n",
      "1 11: [  0.     0.     0.     0.     0.     0.     0.     0.    -8.7  -17.97\n",
      "   0.     0.   -14.26 -12.52   0.     0.  ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0.]\n",
      "1 12: [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.    -8.86   0.     0.   -24.07   0.  ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "1 13: [  0.     0.     0.     0.     0.     0.     0.     0.     0.   -33.22\n",
      " -17.37 -27.38  12.96 -17.36 -30.46  -3.86], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 1. 1. 1. 3. 1. 1.]\n",
      "1 14: [  0.     0.     0.     0.     0.     0.     0.     0.   -11.56 -17.88\n",
      "   0.     0.     0.     0.   -19.95   7.7 ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1.]\n",
      "1 15: [  0.     0.     0.     0.     0.     0.     0.     0.   -18.44   0.\n",
      "   8.71   0.    -8.67   0.     0.     0.  ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 2. 0. 0. 0.]\n",
      "2 0: [ -8.9   -8.87 -17.08  -9.4  -10.17 -17.07 -15.22  -8.33   0.     0.\n",
      "   0.     0.     0.     0.     0.     0.  ], \n",
      "     [ 24. 150.   3.  24.   6.   6.   4.  64.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "2 1: [-12.47  -8.88  -8.6  -15.   -10.4  -14.02  -8.14 -13.46   0.     0.\n",
      "   0.     0.     0.     0.     0.     0.  ], \n",
      "     [  4.   3.  10.   5.  17.   4. 103.   4.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "2 2: [-13.48 -11.04 -10.37 -21.09 -23.11  -9.48  -6.14 -13.82   0.     0.\n",
      "   0.     0.     0.     0.     0.     0.  ], \n",
      "     [4. 5. 8. 2. 1. 5. 9. 2. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "2 3: [ -9.38 -13.52  -9.32 -21.67  -9.6  -16.9  -11.58 -15.87   0.     0.\n",
      "   0.     0.     0.     0.     0.     0.  ], \n",
      "     [ 5.  2. 52.  3. 11.  3.  1.  2.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "2 4: [-15.42 -13.57 -10.76  -9.92 -14.98 -17.59 -13.02  -9.35   0.     0.\n",
      "   0.     0.     0.     0.     0.     0.  ], \n",
      "     [ 2.  1. 10. 13.  4.  2.  3.  2.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "2 5: [ -9.87 -12.3   -9.81 -14.17  -9.91  -8.91  -9.29  -9.53   0.     0.\n",
      "   0.     0.     0.     0.     0.     0.  ], \n",
      "     [  9.   9.  40.   4.  21. 201.  13.  21.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "2 6: [-12.9  -10.31 -10.12  -9.94 -10.47 -10.26 -10.33  -6.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.  ], \n",
      "     [ 3. 13. 24. 96. 21. 12. 17.  6.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "2 7: [-13.65 -11.66 -20.12  -8.78 -21.06  -8.65  -9.12  -9.42   0.     0.\n",
      "   0.     0.     0.     0.     0.     0.  ], \n",
      "     [ 4.  9.  2.  9.  3. 74. 14.  4.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "2 8: [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " -34.19  -0.57  -1.81   0.     0.     0.  ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]\n",
      "2 9: [  0.     0.     0.     0.     0.     0.     0.     0.    -5.26 -11.96\n",
      "   0.     0.   -29.75 -16.02  -9.7    0.  ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 2. 1. 0. 0. 1. 2. 1. 0.]\n",
      "2 10: [  0.     0.     0.     0.     0.     0.     0.     0.   -10.58   0.\n",
      "   0.     0.     1.3  -25.13   0.     0.  ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 1. 1. 0. 0.]\n",
      "2 11: [  0.     0.     0.     0.     0.     0.     0.     0.     0.   -22.99\n",
      "   0.     0.     0.     0.   -11.81   0.  ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      "2 12: [  0.     0.     0.     0.     0.     0.     0.     0.   -24.78  -8.68\n",
      "  -4.04   0.   -17.13 -13.95   0.    -4.1 ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 3.]\n",
      "2 13: [  0.     0.     0.     0.     0.     0.     0.     0.   -21.81   0.\n",
      "   0.   -31.51 -20.32   0.     0.   -16.54], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 2. 0. 0. 1.]\n",
      "2 14: [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      " -17.65  -9.48   0.     0.   -13.48 -31.3 ], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 1. 0. 0. 1. 1.]\n",
      "2 15: [  0.     0.     0.     0.     0.     0.     0.     0.   -14.59   0.\n",
      "   0.    -4.85   0.     0.     4.36 -18.87], \n",
      "     [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1.]\n",
      "3 0: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [55.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "3 1: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [192.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "3 2: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [149.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "3 3: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [156.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "3 4: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [84.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "3 5: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [307.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "3 6: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [164.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "3 7: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [105.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "3 8: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [7. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 9: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 10: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 11: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 12: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 13: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 14: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "3 15: [-10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.], \n",
      "     [6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for est_name in est_name_ary:\n",
    "    print(f\"\\n-> est_name = {est_name}\")\n",
    "    Q_table = Q_table_dict[est_name]\n",
    "    Q_nvisits = Q_nvisits_dict[est_name]\n",
    "    for i_row in range(num_depths):\n",
    "        for j_col in range(num_actions):\n",
    "            print(f\"{i_row} {j_col}: {Q_table[i_row,j_col]}, \\n     {Q_nvisits[i_row,j_col]}\")\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
